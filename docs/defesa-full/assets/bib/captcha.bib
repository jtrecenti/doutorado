@article{baldiUnderstandingDropout2013,
  title = {Understanding Dropout},
  author = {Baldi, Pierre and Sadowski, Peter J.},
  year = {2013},
  journal = {Advances in neural information processing systems},
  volume = {26},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MALVSGRZ\\Baldi e Sadowski - 2013 - Understanding dropout.pdf;C\:\\Users\\julio\\Zotero\\storage\\GMWNKBT6\\71f6278d140af599e06ad9bf1ba03cb0-Abstract.html}
}

@article{blumNoteLearningMultipleinstance1998,
  title = {A Note on Learning from Multiple-Instance Examples},
  author = {Blum, Avrim and Kalai, Adam},
  year = {1998},
  journal = {Machine learning},
  volume = {30},
  number = {1},
  pages = {23--29},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\ZEJLU35H\\Blum e Kalai - 1998 - A note on learning from multiple-instance examples.pdf;C\:\\Users\\julio\\Zotero\\storage\\FEW9R9UD\\A1007402410823.html}
}

@misc{CaptchaGoogleAcademico,
  title = {Captcha - {{Google Acad\^emico}}},
  howpublished = {https://scholar.google.com.br/scholar?hl=pt-BR\&as\_sdt=0\%2C5\&q=captcha\&btnG=},
  file = {C\:\\Users\\julio\\Zotero\\storage\\S76JUQGJ\\scholar.html}
}

@inproceedings{chellapillaBuildingSegmentationBased2005,
  title = {Building {{Segmentation Based Human-Friendly Human Interaction Proofs}} ({{HIPs}})},
  booktitle = {Human {{Interactive Proofs}}},
  author = {Chellapilla, Kumar and Larson, Kevin and Simard, Patrice Y. and Czerwinski, Mary},
  editor = {Baird, Henry S. and Lopresti, Daniel P.},
  year = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--26},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11427896_1},
  abstract = {Human interaction proofs (HIPs) have become common place on the internet due to their effectiveness in deterring automated abuse of online services intended for humans. However, there is a co-evolutionary arms race in progress and these proofs are becoming more difficult for genuine users while attackers are getting better at breaking existing HIPs. We studied various popular HIPs on the internet to understand their strength and human friendliness. To determine HIP strength, we adopted a direct approach of building computer attacks using image processing and machine learning techniques. To understand human-friendliness, a sequence of users studies were conducted to investigate HIP character recognition by humans under a variety of visual distortions and clutter commonly employed in reading-based HIPs. We found that many of the online HIPs are pure recognition tasks that can be easily broken using machine learning. The stronger HIPs tend to pose a combination of segmentation and recognition challenges. Further, the HIP user studies show that given correct segmentation, computers are much better at HIP character recognition than humans. In light of these results, we propose that segmentation-based reading challenges are the future for building stronger human-friendly HIPs. An example of such a segmentation-based HIP is presented with a preliminary assessment of its strength and human-friendliness.},
  isbn = {978-3-540-32117-0},
  langid = {english},
  keywords = {Baseline Setting,Convolutional Neural Network,High Accuracy Rate,Optical Character Recognition,User Study}
}

@inproceedings{chellapillaDesigningHumanFriendly2005,
  title = {Designing Human Friendly Human Interaction Proofs ({{HIPs}})},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chellapilla, Kumar and Larson, Kevin and Simard, Patrice and Czerwinski, Mary},
  year = {2005},
  month = apr,
  series = {{{CHI}} '05},
  pages = {711--720},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1054972.1055070},
  abstract = {HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.},
  isbn = {978-1-58113-998-3},
  keywords = {completely automated public turing tests to tell computers and humans apart (CAPTCHAs),computer vision,evaluation,human interaction proofs (HIPs),human perception,visual letter recognition}
}

@article{chellapillaUsingMachineLearning2004,
  title = {Using Machine Learning to Break Visual Human Interaction Proofs ({{HIPs}})},
  author = {Chellapilla, Kumar and Simard, Patrice},
  year = {2004},
  journal = {Advances in neural information processing systems},
  volume = {17},
  file = {C\:\\Users\\julio\\Zotero\\storage\\IBYHP2ZN\\Chellapilla e Simard - 2004 - Using machine learning to break visual human inter.pdf;C\:\\Users\\julio\\Zotero\\storage\\QVBFGY7B\\283085d30e10513624c8cece7993f4de-Abstract.html}
}

@inproceedings{cid-sueiroConsistencyLossesLearning2014,
  title = {Consistency of Losses for Learning from Weak Labels},
  booktitle = {Joint {{European Conference}} on {{Machine Learning}} and {{Knowledge Discovery}} in {{Databases}}},
  author = {{Cid-Sueiro}, Jes{\'u}s and {Garc{\'i}a-Garc{\'i}a}, Dar{\'i}o and {Santos-Rodr{\'i}guez}, Ra{\'u}l},
  year = {2014},
  pages = {197--210},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\IQHUNGZ4\\Cid-Sueiro et al. - 2014 - Consistency of losses for learning from weak label.pdf;C\:\\Users\\julio\\Zotero\\storage\\CDFGRK2S\\978-3-662-44848-9_13.html}
}

@book{colosimoAnaliseSobrevivenciaAplicada2006a,
  title = {An\'alise de Sobreviv\^encia Aplicada},
  author = {Colosimo, Enrico Antonio and Giolo, Suely Ruiz},
  year = {2006},
  publisher = {{Editora Blucher}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\G8XW3UW4\\books.html}
}

@article{courLearningPartialLabels2011,
  title = {Learning from Partial Labels},
  author = {Cour, Timothee and Sapp, Ben and Taskar, Ben},
  year = {2011},
  journal = {The Journal of Machine Learning Research},
  volume = {12},
  pages = {1501--1536},
  publisher = {{JMLR. org}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\9NKQTJUN\\Cour et al. - 2011 - Learning from partial labels.pdf}
}

@inproceedings{dasguptaAnalysisPerceptronbasedActive2005,
  title = {Analysis of Perceptron-Based Active Learning},
  booktitle = {International Conference on Computational Learning Theory},
  author = {Dasgupta, Sanjoy and Kalai, Adam Tauman and Monteleoni, Claire},
  year = {2005},
  pages = {249--263},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\RG3A66PQ\\Dasgupta et al. - 2005 - Analysis of perceptron-based active learning.pdf;C\:\\Users\\julio\\Zotero\\storage\\WQ46CS9E\\11503415_17.html}
}

@misc{diagnosticoABJ,
  title = {Diagn\'ostico Do {{Contencioso Tribut\'ario Administrativo}}},
  abstract = {Estudo sobre estrutura do contencioso, processos administrativos tribut\'arios e percep\c{c}\~oes dos agentes},
  howpublished = {https://abj.org.br/pesquisas/bid-tributario/},
  file = {C\:\\Users\\julio\\Zotero\\storage\\4IA5SLM6\\bid-tributario.html}
}

@article{fanPartialLabelLearning2022,
  title = {Partial {{Label Learning}} with Competitive Learning Graph Neural Network},
  author = {Fan, Jinfu and Yu, Yang and Wang, Zhongjie},
  year = {2022},
  month = may,
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {111},
  pages = {104779},
  issn = {0952-1976},
  doi = {10.1016/j.engappai.2022.104779},
  abstract = {Partial Label Learning (PLL) is a weakly supervised learning framework where each instance may be associated with more than one candidate label, among which only one is true. Traditionally, the PLL problem is solved by removing the false candidate labels based on the instance relationship, while the potentially useful information between instances and labels as well as the potential candidate label relationship is ignored. In this paper, a new PLL framework PL-CGNN is proposed, which treats the instances with false labels as noise, and the PLL is reformulated to remove the noise instances. First of all, the feature of each label class is approximately represented by the center point of all the related instances. The significant operation enables the similarity between instances and labels measurable. Next, all the candidate labels for each instance compete for the biggest similarity. To further improve the robustness of the model, the competition procedure for the most similar label is extended to the neighbors of this instance. The label with the most wins is the final ground-truth one. The relationship between candidate labels guides the situation that the competition process develops into. Through iterative competitive learning, each label class approaches the true value. Experiments carried out on diverse datasets show that the performance of the PL-CGNN model is outstanding.},
  langid = {english},
  keywords = {Competitive learning,Graph neural network,Noise instances},
  file = {C\:\\Users\\julio\\Zotero\\storage\\FIFD6L5B\\Fan et al. - 2022 - Partial Label Learning with competitive learning g.pdf;C\:\\Users\\julio\\Zotero\\storage\\EWN9HMUZ\\S0952197622000641.html}
}

@inproceedings{fengLearningMultipleComplementary2020,
  title = {Learning with Multiple Complementary Labels},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Feng, Lei and Kaneko, Takuo and Han, Bo and Niu, Gang and An, Bo and Sugiyama, Masashi},
  year = {2020},
  pages = {3072--3081},
  publisher = {{PMLR}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\FKZFVXBD\\Feng et al. - 2020 - Learning with multiple complementary labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\KLI2F4Z9\\feng20a.html}
}

@inproceedings{fengLearningMultipleComplementary2020a,
  title = {Learning with Multiple Complementary Labels},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Feng, Lei and Kaneko, Takuo and Han, Bo and Niu, Gang and An, Bo and Sugiyama, Masashi},
  year = {2020},
  pages = {3072--3081},
  publisher = {{PMLR}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\8FM96TJH\\Feng et al. - 2020 - Learning with multiple complementary labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\JCSESU33\\feng20a.html}
}

@article{fengProvablyConsistentPartiallabel2020,
  title = {Provably Consistent Partial-Label Learning},
  author = {Feng, Lei and Lv, Jiaqi and Han, Bo and Xu, Miao and Niu, Gang and Geng, Xin and An, Bo and Sugiyama, Masashi},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {10948--10960},
  file = {C\:\\Users\\julio\\Zotero\\storage\\6MM6CV7A\\Feng et al. - 2020 - Provably consistent partial-label learning.pdf;C\:\\Users\\julio\\Zotero\\storage\\GMV8VU74\\7bd28f15a49d5e5848d6ec70e584e625-Abstract.html}
}

@article{fengProvablyConsistentPartiallabel2020a,
  title = {Provably Consistent Partial-Label Learning},
  author = {Feng, Lei and Lv, Jiaqi and Han, Bo and Xu, Miao and Niu, Gang and Geng, Xin and An, Bo and Sugiyama, Masashi},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {10948--10960},
  file = {C\:\\Users\\julio\\Zotero\\storage\\FYBSBPIQ\\Feng et al. - 2020 - Provably consistent partial-label learning.pdf;C\:\\Users\\julio\\Zotero\\storage\\8E9A5P5G\\7bd28f15a49d5e5848d6ec70e584e625-Abstract.html}
}

@article{galarReviewEnsemblesClass2011,
  title = {A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches},
  shorttitle = {A Review on Ensembles for the Class Imbalance Problem},
  author = {Galar, Mikel and Fernandez, Alberto and Barrenechea, Edurne and Bustince, Humberto and Herrera, Francisco},
  year = {2011},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {42},
  number = {4},
  pages = {463--484},
  publisher = {{IEEE}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MG299HXS\\Galar et al. - 2011 - A review on ensembles for the class imbalance prob.pdf;C\:\\Users\\julio\\Zotero\\storage\\PCHVWFWL\\5978225.html}
}

@article{georgeGenerativeVisionModel2017,
  title = {A Generative Vision Model That Trains with High Data Efficiency and Breaks Text-Based {{CAPTCHAs}}},
  author = {George, Dileep and Lehrach, Wolfgang and Kansky, Ken and {L{\'a}zaro-Gredilla}, Miguel and Laan, Christopher and Marthi, Bhaskara and Lou, Xinghua and Meng, Zhaoshi and Liu, Yi and Wang, Huayan},
  year = {2017},
  journal = {Science},
  volume = {358},
  number = {6368},
  pages = {eaag2612},
  publisher = {{American Association for the Advancement of Science}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\KC3B5SXB\\George et al. - 2017 - A generative vision model that trains with high da.pdf;C\:\\Users\\julio\\Zotero\\storage\\6R7A57BD\\science.html}
}

@inproceedings{gongPartialLabelLearning2022,
  title = {Partial {{Label Learning}} via {{Label Influence Function}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Gong, Xiuwen and Yuan, Dong and Bao, Wei},
  year = {2022},
  pages = {7665--7678},
  publisher = {{PMLR}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MNKV6ZGC\\Gong et al. - 2022 - Partial Label Learning via Label Influence Functio.pdf;C\:\\Users\\julio\\Zotero\\storage\\7KI5ECIN\\gong22c.html}
}

@misc{goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year = {2014},
  month = jun,
  number = {arXiv:1406.2661},
  eprint = {1406.2661},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1406.2661},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\julio\\Zotero\\storage\\IHI84MWI\\Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf;C\:\\Users\\julio\\Zotero\\storage\\MMXSV359\\1406.html}
}

@article{goodfellowGenerativeAdversarialNetworks2020,
  title = {Generative Adversarial Networks},
  author = {Goodfellow, Ian and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year = {2020},
  journal = {Communications of the ACM},
  volume = {63},
  number = {11},
  pages = {139--144},
  publisher = {{ACM New York, NY, USA}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\S48E3C2P\\Goodfellow et al. - 2020 - Generative adversarial networks.pdf;C\:\\Users\\julio\\Zotero\\storage\\CKQ9JKS5\\3422622.html}
}

@article{goodfellowMultidigitNumberRecognition2013,
  title = {Multi-Digit Number Recognition from Street View Imagery Using Deep Convolutional Neural Networks},
  author = {Goodfellow, Ian J. and Bulatov, Yaroslav and Ibarz, Julian and Arnoud, Sacha and Shet, Vinay},
  year = {2013},
  journal = {arXiv preprint arXiv:1312.6082},
  eprint = {1312.6082},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\julio\\Zotero\\storage\\KCGB4ZNU\\Goodfellow et al. - 2013 - Multi-digit number recognition from street view im.pdf;C\:\\Users\\julio\\Zotero\\storage\\7C9FYAPR\\1312.html}
}

@misc{goodfellowMultidigitNumberRecognition2014,
  title = {Multi-Digit {{Number Recognition}} from {{Street View Imagery}} Using {{Deep Convolutional Neural Networks}}},
  author = {Goodfellow, Ian J. and Bulatov, Yaroslav and Ibarz, Julian and Arnoud, Sacha and Shet, Vinay},
  year = {2014},
  month = apr,
  number = {arXiv:1312.6082},
  eprint = {1312.6082},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1312.6082},
  abstract = {Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over \$96\textbackslash\%\$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving \$97.84\textbackslash\%\$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over \$90\textbackslash\%\$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a \$99.8\textbackslash\%\$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\julio\\Zotero\\storage\\JS95HUKQ\\Goodfellow et al. - 2014 - Multi-digit Number Recognition from Street View Im.pdf;C\:\\Users\\julio\\Zotero\\storage\\CK5MUERD\\1312.html}
}

@inproceedings{grandvaletLogisticRegressionPartial2002,
  title = {Logistic Regression for Partial Labels},
  booktitle = {Proc. {{IPMU}}},
  author = {Grandvalet, Yves},
  year = {2002}
}

@article{hernandez-gonzalezWeakSupervisionOther2016,
  title = {Weak Supervision and Other Non-Standard Classification Problems: A Taxonomy},
  shorttitle = {Weak Supervision and Other Non-Standard Classification Problems},
  author = {{Hern{\'a}ndez-Gonz{\'a}lez}, Jer{\'o}nimo and Inza, Inaki and Lozano, Jose A.},
  year = {2016},
  journal = {Pattern Recognition Letters},
  volume = {69},
  pages = {49--55},
  publisher = {{Elsevier}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\DV8JSLNY\\S0167865515003505.html}
}

@article{hullermeierLearningAmbiguouslyLabeled2006,
  title = {Learning from Ambiguously Labeled Examples},
  author = {H{\"u}llermeier, Eyke and Beringer, J{\"u}rgen},
  year = {2006},
  journal = {Intelligent Data Analysis},
  volume = {10},
  number = {5},
  pages = {419--439},
  publisher = {{IOS Press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\ENTEXRP5\\ida00259.html}
}

@misc{InaccessibilityCAPTCHA,
  title = {Inaccessibility of {{CAPTCHA}}},
  howpublished = {https://www.w3.org/TR/turingtest/},
  file = {C\:\\Users\\julio\\Zotero\\storage\\ZUPP2IYZ\\turingtest.html}
}

@inproceedings{ioffeBatchNormalizationAccelerating2015,
  title = {Batch Normalization: {{Accelerating}} Deep Network Training by Reducing Internal Covariate Shift},
  shorttitle = {Batch Normalization},
  booktitle = {International Conference on Machine Learning},
  author = {Ioffe, Sergey and Szegedy, Christian},
  year = {2015},
  pages = {448--456},
  publisher = {{PMLR}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\S997AFBM\\Ioffe e Szegedy - 2015 - Batch normalization Accelerating deep network tra.pdf;C\:\\Users\\julio\\Zotero\\storage\\PI52PX8F\\ioffe15.html}
}

@article{ishidaLearningComplementaryLabels2017,
  title = {Learning from Complementary Labels},
  author = {Ishida, Takashi and Niu, Gang and Hu, Weihua and Sugiyama, Masashi},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30},
  file = {C\:\\Users\\julio\\Zotero\\storage\\K85Y5ZS9\\Ishida et al. - 2017 - Learning from complementary labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\7TDQVWAW\\1dba5eed8838571e1c80af145184e515-Abstract.html}
}

@article{ishidaLearningComplementaryLabels2017a,
  title = {Learning from Complementary Labels},
  author = {Ishida, Takashi and Niu, Gang and Hu, Weihua and Sugiyama, Masashi},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30},
  file = {C\:\\Users\\julio\\Zotero\\storage\\5WF53RWE\\Ishida et al. - 2017 - Learning from complementary labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\INNSZUIP\\1dba5eed8838571e1c80af145184e515-Abstract.html}
}

@article{jinLearningMultipleLabels2002,
  title = {Learning with Multiple Labels},
  author = {Jin, Rong and Ghahramani, Zoubin},
  year = {2002},
  journal = {Advances in neural information processing systems},
  volume = {15},
  file = {C\:\\Users\\julio\\Zotero\\storage\\URYQSBNC\\Jin e Ghahramani - 2002 - Learning with multiple labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\9J72FHIJ\\653ac11ca60b3e021a8c609c7198acfc-Abstract.html}
}

@article{kanekoOnlineMulticlassClassification2019,
  title = {Online Multiclass Classification Based on Prediction Margin for Partial Feedback},
  author = {Kaneko, Takuo and Sato, Issei and Sugiyama, Masashi},
  year = {2019},
  journal = {arXiv preprint arXiv:1902.01056},
  eprint = {1902.01056},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\julio\\Zotero\\storage\\4T3GASIC\\Kaneko et al. - 2019 - Online multiclass classification based on predicti.pdf;C\:\\Users\\julio\\Zotero\\storage\\LCVQRSJE\\1902.html}
}

@article{kaurCaptchaItsTechniques2014,
  title = {Captcha and {{Its Techniques}}: {{A Review}}},
  shorttitle = {Captcha and {{Its Techniques}}},
  author = {Kaur, Kiranjot and Behal, Sunny},
  year = {2014},
  month = jan,
  journal = {International Journal of Computer Science and Information Technologies,},
  volume = {5},
  abstract = {Captcha (Completely Automated public Turing test to tell Computers and Humans Apart) system is used to verify whether a user is human or computer program. It's also known as human Interactive Proof (HIP) and based upon Artificial Intelligence. Captcha is a program that protects websites from web-bots by generating tests that computer cannot pass but human can pass .This paper comprise introduction of captcha, various techniques, application of captcha and drawbacks of captcha.},
  file = {C\:\\Users\\julio\\Zotero\\storage\\67CED3MB\\Kaur e Behal - 2014 - Captcha and Its Techniques A Review.pdf}
}

@misc{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6980},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\julio\\Zotero\\storage\\462HFWSP\\Kingma e Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;C\:\\Users\\julio\\Zotero\\storage\\TH5QBVQ3\\1412.html}
}

@book{kuhnFeatureEngineeringSelection2019,
  title = {Feature Engineering and Selection: {{A}} Practical Approach for Predictive Models},
  shorttitle = {Feature Engineering and Selection},
  author = {Kuhn, Max and Johnson, Kjell},
  year = {2019},
  publisher = {{CRC Press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\JT5KCESH\\books.html}
}

@book{kuhnFeatureEngineeringSelection2019a,
  title = {Feature Engineering and Selection: {{A}} Practical Approach for Predictive Models},
  shorttitle = {Feature Engineering and Selection},
  author = {Kuhn, Max and Johnson, Kjell},
  year = {2019},
  publisher = {{CRC Press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\JWQXB632\\books.html}
}

@article{kunchevaRestrictedSetClassification2017,
  title = {Restricted Set Classification: {{Who}} Is There?},
  shorttitle = {Restricted Set Classification},
  author = {Kuncheva, Ludmila I. and Rodriguez, Juan J. and Jackson, Aaron S.},
  year = {2017},
  journal = {Pattern Recognition},
  volume = {63},
  pages = {158--170},
  publisher = {{Elsevier}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\K7WIZ98B\\S0031320316302412.html}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  journal = {nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {{Nature Publishing Group}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\AGAIXG5H\\nature14539.html}
}

@incollection{lecunEfficientBackprop2012,
  title = {Efficient Backprop},
  booktitle = {Neural Networks: {{Tricks}} of the Trade},
  author = {LeCun, Yann A. and Bottou, L{\'e}on and Orr, Genevieve B. and M{\"u}ller, Klaus-Robert},
  year = {2012},
  pages = {9--48},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\C5ENCTPY\\LeCun et al. - 2012 - Efficient backprop.gz;C\:\\Users\\julio\\Zotero\\storage\\WJISFNP3\\978-3-642-35289-8_3.html}
}

@article{lecunGradientbasedLearningApplied1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  year = {1998},
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  publisher = {{Ieee}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\3VWVJAGI\\LeCun et al. - 1998 - Gradient-based learning applied to document recogn.pdf;C\:\\Users\\julio\\Zotero\\storage\\FL8WBYP2\\726791.html}
}

@patent{lillibridgeMethodSelectivelyRestricting2001,
  title = {Method for Selectively Restricting Access to Computer Systems},
  author = {Lillibridge, Mark D. and Abadi, Martin and Bharat, Krishna and Broder, Andrei Z.},
  year = {2001},
  month = feb,
  number = {US6195698B1},
  assignee = {Compaq Computer Corp},
  nationality = {US},
  keywords = {access request,answer,computer,riddle,string},
  file = {C\:\\Users\\julio\\Zotero\\storage\\KE38TUHP\\Lillibridge et al. - 2001 - Method for selectively restricting access to compu.pdf}
}

@article{liMultivariateBinomialMultinomial2014,
  title = {Multivariate Binomial/Multinomial Control Chart},
  author = {Li, Jian and Tsung, Fugee and Zou, Changliang},
  year = {2014},
  journal = {IIE Transactions},
  volume = {46},
  number = {5},
  pages = {526--542},
  publisher = {{Taylor \& Francis}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\UBBBW96S\\Li et al. - 2014 - Multivariate binomialmultinomial control chart.pdf;C\:\\Users\\julio\\Zotero\\storage\\KHACMS2U\\0740817X.2013.html}
}

@article{liuConditionalMultinomialMixture2012,
  title = {A Conditional Multinomial Mixture Model for Superset Label Learning},
  author = {Liu, Liping and Dietterich, Thomas},
  year = {2012},
  journal = {Advances in neural information processing systems},
  volume = {25},
  file = {C\:\\Users\\julio\\Zotero\\storage\\8XWC2GNY\\Liu e Dietterich - 2012 - A conditional multinomial mixture model for supers.pdf;C\:\\Users\\julio\\Zotero\\storage\\2IC3QA4H\\aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html}
}

@inproceedings{macparthalainFuzzyroughSetBased2011,
  title = {Fuzzy-Rough Set Based Semi-Supervised Learning},
  booktitle = {2011 {{IEEE International Conference}} on {{Fuzzy Systems}} ({{FUZZ-IEEE}} 2011)},
  author = {Mac Parthal{\'a}in, Neil and Jensen, Richard},
  year = {2011},
  pages = {2465--2472},
  publisher = {{IEEE}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\IGHTR98T\\Mac Parthaláin e Jensen - 2011 - Fuzzy-rough set based semi-supervised learning.pdf;C\:\\Users\\julio\\Zotero\\storage\\HE8XMRLG\\6007483.html}
}

@techreport{michenerEstadoBrasileiroTransparencia2015,
  title = {Estado Brasileiro e Transpar\^encia Avaliando a Aplica\c{c}\~ao Da {{Lei}} de {{Acesso}} \`a {{Informa\c{c}\~ao}}},
  author = {Michener, Gregory and Moncau, Luiz Fernando and Velasco, Rafael Braem},
  year = {2015},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MJJWZ678\\Michener et al. - 2015 - Estado brasileiro e transparência avaliando a apli.pdf}
}

@article{migonDynamicModels2005,
  title = {Dynamic Models},
  author = {Migon, Helio S. and Gamerman, Dani and Lopes, Hedibert F. and Ferreira, Marco AR},
  year = {2005},
  journal = {Handbook of statistics},
  volume = {25},
  pages = {553--588},
  publisher = {{Elsevier}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\SYGVV4FT\\Migon et al. - 2005 - Dynamic models.pdf;C\:\\Users\\julio\\Zotero\\storage\\UZAFDZY3\\S0169716105250198.html}
}

@inproceedings{moriRecognizingObjectsAdversarial2003,
  title = {Recognizing Objects in Adversarial Clutter: {{Breaking}} a Visual {{CAPTCHA}}},
  shorttitle = {Recognizing Objects in Adversarial Clutter},
  booktitle = {2003 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}, 2003. {{Proceedings}}.},
  author = {Mori, Greg and Malik, Jitendra},
  year = {2003},
  volume = {1},
  pages = {I--I},
  publisher = {{IEEE}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MZZE3LLQ\\Mori e Malik - 2003 - Recognizing objects in adversarial clutter Breaki.pdf;C\:\\Users\\julio\\Zotero\\storage\\LSC5WGXU\\1211347.html}
}

@article{murray-rustOpenDataScience2008,
  title = {Open Data in Science},
  author = {{Murray-Rust}, Peter},
  year = {2008},
  journal = {Nature Precedings},
  pages = {1--1},
  publisher = {{Nature Publishing Group}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\PYHZVG6P\\Murray-Rust - 2008 - Open data in science.pdf;C\:\\Users\\julio\\Zotero\\storage\\MYNAVGF2\\npre.2008.1526.html}
}

@inproceedings{murrayAVALargescaleDatabase2012,
  title = {{{AVA}}: {{A}} Large-Scale Database for Aesthetic Visual Analysis},
  shorttitle = {{{AVA}}},
  booktitle = {2012 {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {Murray, Naila and Marchesotti, Luca and Perronnin, Florent},
  year = {2012},
  pages = {2408--2415},
  publisher = {{IEEE}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\5R27QDWY\\Murray et al. - 2012 - AVA A large-scale database for aesthetic visual a.pdf;C\:\\Users\\julio\\Zotero\\storage\\VDNPB5DJ\\6247954.html}
}

@inproceedings{naDeepGenerativePositiveUnlabeled2020,
  title = {Deep {{Generative Positive-Unlabeled Learning}} under {{Selection Bias}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Na, Byeonghu and Kim, Hyemi and Song, Kyungwoo and Joo, Weonyoung and Kim, Yoon-Yeong and Moon, Il-Chul},
  year = {2020},
  month = oct,
  series = {{{CIKM}} '20},
  pages = {1155--1164},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3340531.3411971},
  abstract = {Learning in the positive-unlabeled (PU) setting is prevalent in real world applications. Many previous works depend upon theSelected Completely At Random (SCAR) assumption to utilize unlabeled data, but the SCAR assumption is not often applicable to the real world due to selection bias in label observations. This paper is the first generative PU learning model without the SCAR assumption. Specifically, we derive the PU risk function without the SCAR assumption, and we generate a set of virtual PU examples to train the classifier. Although our PU risk function is more generalizable, the function requires PU instances that do not exist in the observations. Therefore, we introduce the VAE-PU, which is a variant of variational autoencoders to separate two latent variables that generate either features or observation indicators. The separated latent information enables the model to generate virtual PU instances. We test the VAE-PU on benchmark datasets with and without the SCAR assumption. The results indicate that the VAE-PU is superior when selection bias exists, and the VAE-PU is also competent under the SCAR assumption. The results also emphasize that the VAE-PU is effective when there are few positive-labeled instances due to modeling on selection bias.},
  isbn = {978-1-4503-6859-9},
  keywords = {positive-unlabeled learning,selection bias,variational autoencoders}
}

@article{nelderGeneralizedLinearModels1972,
  title = {Generalized Linear Models},
  author = {Nelder, John Ashworth and Wedderburn, Robert WM},
  year = {1972},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {135},
  number = {3},
  pages = {370--384},
  publisher = {{Wiley Online Library}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\NVLDRX89\\Nelder e Wedderburn - 1972 - Generalized linear models.pdf;C\:\\Users\\julio\\Zotero\\storage\\YZRVCI2G\\2344614.html}
}

@inproceedings{nguyenClassificationPartialLabels2008,
  title = {Classification with Partial Labels},
  booktitle = {Proceedings of the 14th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Nguyen, Nam and Caruana, Rich},
  year = {2008},
  pages = {551--559},
  file = {C\:\\Users\\julio\\Zotero\\storage\\GCTSTI2D\\Nguyen e Caruana - 2008 - Classification with partial labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\NTBLS83W\\1401890.html}
}

@article{nohRegularizingDeepNeural2017,
  title = {Regularizing Deep Neural Networks by Noise: {{Its}} Interpretation and Optimization},
  shorttitle = {Regularizing Deep Neural Networks by Noise},
  author = {Noh, Hyeonwoo and You, Tackgeun and Mun, Jonghwan and Han, Bohyung},
  year = {2017},
  journal = {Advances in Neural Information Processing Systems},
  volume = {30},
  file = {C\:\\Users\\julio\\Zotero\\storage\\5P94JU58\\Noh et al. - 2017 - Regularizing deep neural networks by noise Its in.pdf;C\:\\Users\\julio\\Zotero\\storage\\P3YY4NZS\\217e342fc01668b10cb1188d40d3370e-Abstract.html}
}

@misc{ObservatorioInsolvenciaRio,
  title = {Observat\'orio Da Insolv\^encia: {{Rio}} de {{Janeiro}}},
  shorttitle = {Observat\'orio Da Insolv\^encia},
  abstract = {Estudo sobre as recupera\c{c}\~oes judiciais do estado do Rio de Janeiro.},
  howpublished = {https://abj.org.br/pesquisas/obsrjrj/},
  file = {C\:\\Users\\julio\\Zotero\\storage\\C97CUUAZ\\obsrjrj.html}
}

@misc{rameshHierarchicalTextConditionalImage2022,
  title = {Hierarchical {{Text-Conditional Image Generation}} with {{CLIP Latents}}},
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  year = {2022},
  month = apr,
  number = {arXiv:2204.06125},
  eprint = {2204.06125},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.06125},
  abstract = {Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\julio\\Zotero\\storage\\V7KCX6CY\\Ramesh et al. - 2022 - Hierarchical Text-Conditional Image Generation wit.pdf;C\:\\Users\\julio\\Zotero\\storage\\889MFBYT\\2204.html}
}

@article{rameshHierarchicalTextconditionalImage2022,
  title = {Hierarchical Text-Conditional Image Generation with Clip Latents},
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  year = {2022},
  journal = {arXiv preprint arXiv:2204.06125},
  eprint = {2204.06125},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\julio\\Zotero\\storage\\UJ3M98E4\\2204.html}
}

@patent{reshefMethodSystemDiscriminating2005,
  title = {Method and System for Discriminating a Human Action from a Computerized Action},
  author = {Reshef, Eran and Raanan, Gil and Solan, Eilon},
  year = {2005},
  month = may,
  number = {US20050114705A1},
  assignee = {Watchfire Corp},
  nationality = {US},
  keywords = {ability challenge,challenge,human,human ability,response},
  file = {C\:\\Users\\julio\\Zotero\\storage\\LGBB9HQD\\Reshef et al. - 2005 - Method and system for discriminating a human actio.pdf}
}

@article{rolnickDeepLearningRobust2017,
  title = {Deep Learning Is Robust to Massive Label Noise},
  author = {Rolnick, David and Veit, Andreas and Belongie, Serge and Shavit, Nir},
  year = {2017},
  journal = {arXiv preprint arXiv:1705.10694},
  eprint = {1705.10694},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  file = {C\:\\Users\\julio\\Zotero\\storage\\56HXNTKC\\Rolnick et al. - 2017 - Deep learning is robust to massive label noise.pdf;C\:\\Users\\julio\\Zotero\\storage\\Y2EUWLYV\\1705.html}
}

@article{schwenkerPartiallySupervisedLearning2014,
  title = {Partially Supervised Learning for Pattern Recognition},
  author = {Schwenker, Friedhelm and Trentin, Edmondo},
  year = {2014},
  journal = {Pattern Recognition Letters},
  volume = {37},
  pages = {1--3},
  file = {C\:\\Users\\julio\\Zotero\\storage\\JGLAFBIH\\abstract.html}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: {{An}} Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  publisher = {{MIT press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\39EYM6XI\\Sutton e Barto - 2018 - Reinforcement learning An introduction.pdf;C\:\\Users\\julio\\Zotero\\storage\\DMBBYYGU\\books.html}
}

@misc{TempoDosProcessos,
  title = {Tempo Dos Processos Relacionados \`a Ado\c{c}\~ao},
  abstract = {An\'alise do tempo dos processos relacionados \`a ado\c{c}\~ao no Brasil, especialmente de processos relativos a desconstitui\c{c}\~ao do poder familiar.},
  howpublished = {https://abj.org.br/pesquisas/adocao/},
  file = {C\:\\Users\\julio\\Zotero\\storage\\76DWFWY4\\adocao.html}
}

@incollection{turingComputingMachineryIntelligence2009,
  title = {Computing Machinery and Intelligence},
  booktitle = {Parsing the Turing Test},
  author = {Turing, Alan M.},
  year = {2009},
  pages = {23--65},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\2K8D7N7Y\\Turing - 2009 - Computing machinery and intelligence.pdf;C\:\\Users\\julio\\Zotero\\storage\\3Q5YU9PL\\978-1-4020-6710-5_3.html}
}

@inproceedings{vannoorenberghePartiallySupervisedLearning2005,
  title = {Partially Supervised Learning by a Credal {{EM}} Approach},
  booktitle = {European {{Conference}} on {{Symbolic}} and {{Quantitative Approaches}} to {{Reasoning}} and {{Uncertainty}}},
  author = {Vannoorenberghe, Patrick and Smets, Philippe},
  year = {2005},
  pages = {956--967},
  publisher = {{Springer}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\8DLZ29MP\\11518655_80.html}
}

@inproceedings{vonahnCaptchaTellingHumans2003,
  title = {Captcha: {{Telling}} Humans and Computers Apart Automatically},
  shorttitle = {Captcha},
  booktitle = {Proceedings of Eurocrypt},
  author = {Von Ahn, Luis and Blum, Manuel and Hopper, Nicholas and Langford, John},
  year = {2003},
  file = {C\:\\Users\\julio\\Zotero\\storage\\JYTDG6AN\\Von Ahn et al. - 2003 - Captcha Telling humans and computers apart automa.pdf}
}

@article{vonahnReCAPTCHAHumanBasedCharacter2008,
  title = {{{reCAPTCHA}}: {{Human-Based Character Recognition}} via {{Web Security Measures}}},
  shorttitle = {{{reCAPTCHA}}},
  author = {{von Ahn}, Luis and Maurer, Benjamin and McMillen, Colin and Abraham, David and Blum, Manuel},
  year = {2008},
  month = sep,
  journal = {Science},
  volume = {321},
  number = {5895},
  pages = {1465--1468},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1160379},
  abstract = {CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) are widespread security measures on the World Wide Web that prevent automated programs from abusing online services. They do so by asking humans to perform a task that computers cannot yet perform, such as deciphering distorted characters. Our research explored whether such human effort can be channeled into a useful purpose: helping to digitize old printed material by asking users to decipher scanned words from books that computerized optical character recognition failed to recognize. We showed that this method can transcribe text with a word accuracy exceeding 99\%, matching the guarantee of professional human transcribers. Our apparatus is deployed in more than 40,000 Web sites and has transcribed over 440 million words.},
  langid = {english},
  file = {C\:\\Users\\julio\\Zotero\\storage\\YJ9ZW5PF\\von Ahn et al. - 2008 - reCAPTCHA Human-Based Character Recognition via W.pdf}
}

@techreport{vonahnTellingHumansComputers2002,
  title = {Telling Humans and Computers Apart Automatically or How Lazy Cryptographers Do {{AI}} ({{Tech}}. {{Rep}}. {{No}}. {{CMU-CS-02-117}})},
  author = {{von Ahn}, L. and Blum, M. and Langford, J.},
  year = {2002},
  institution = {{Carnegie Mellon University}}
}

@article{vonahnTellingHumansComputers2004,
  title = {Telling Humans and Computers Apart Automatically},
  author = {Von Ahn, Luis and Blum, Manuel and Langford, John},
  year = {2004},
  journal = {Communications of the ACM},
  volume = {47},
  number = {2},
  pages = {56--60},
  publisher = {{ACM New York, NY, USA}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\KPLT2HTX\\Von Ahn et al. - 2004 - Telling humans and computers apart automatically.pdf;C\:\\Users\\julio\\Zotero\\storage\\66K88CTC\\966389.html}
}

@article{wangMakeComplexCaptchas2021,
  title = {Make Complex Captchas Simple: A Fast Text Captcha Solver Based on a Small Number of Samples},
  shorttitle = {Make Complex Captchas Simple},
  author = {Wang, Yao and Wei, Yuliang and Zhang, Mingjin and Liu, Yang and Wang, Bailing},
  year = {2021},
  journal = {Information Sciences},
  volume = {578},
  pages = {181--194},
  publisher = {{Elsevier}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\E86LGP55\\S0020025521007301.html}
}

@article{xuSurveyCAPTCHATechnologies2020,
  title = {A Survey of {{CAPTCHA}} Technologies to Distinguish between Human and Computer},
  author = {Xu, Xin and Liu, Lei and Li, Bo},
  year = {2020},
  journal = {Neurocomputing},
  volume = {408},
  pages = {292--307},
  publisher = {{Elsevier}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\E8VNTNAB\\S0925231220304896.html}
}

@misc{xuUnderstandingSigmoidLogistic2022,
  title = {Understanding {{Sigmoid}}, {{Logistic}}, {{Softmax Functions}}, and {{Cross-Entropy Loss}} ({{Log Loss}})},
  author = {Xu, Zhou (Joe)},
  year = {2022},
  month = jul,
  journal = {Medium},
  abstract = {Practical Maths for Key Concepts in Logistic Regression and Deep Learning},
  howpublished = {https://towardsdatascience.com/understanding-sigmoid-logistic-softmax-functions-and-cross-entropy-loss-log-loss-dbbbe0a17efb},
  langid = {english},
  file = {C\:\\Users\\julio\\Zotero\\storage\\I5RVD4XX\\understanding-sigmoid-logistic-softmax-functions-and-cross-entropy-loss-log-loss-dbbbe0a17efb.html}
}

@inproceedings{yaoDeepDiscriminativeCnn2020,
  title = {Deep Discriminative Cnn with Temporal Ensembling for Ambiguously-Labeled Image Classification},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Yao, Yao and Deng, Jiehui and Chen, Xiuhua and Gong, Chen and Wu, Jianxin and Yang, Jian},
  year = {2020},
  volume = {34},
  pages = {12669--12676},
  file = {C\:\\Users\\julio\\Zotero\\storage\\P8T9URLM\\Yao et al. - 2020 - Deep discriminative cnn with temporal ensembling f.pdf;C\:\\Users\\julio\\Zotero\\storage\\VYWKW32X\\6959.html}
}

@inproceedings{yeAnotherTextCaptcha2018,
  title = {Yet Another Text Captcha Solver: {{A}} Generative Adversarial Network Based Approach},
  shorttitle = {Yet Another Text Captcha Solver},
  booktitle = {Proceedings of the 2018 {{ACM SIGSAC}} Conference on Computer and Communications Security},
  author = {Ye, Guixin and Tang, Zhanyong and Fang, Dingyi and Zhu, Zhanxing and Feng, Yansong and Xu, Pengfei and Chen, Xiaojiang and Wang, Zheng},
  year = {2018},
  pages = {332--348},
  file = {C\:\\Users\\julio\\Zotero\\storage\\CG2H4BN6\\Ye et al. - 2018 - Yet another text captcha solver A generative adve.pdf;C\:\\Users\\julio\\Zotero\\storage\\97VN79T2\\3243734.html}
}

@article{yuanAdversarialExamplesAttacks2019,
  title = {Adversarial Examples: {{Attacks}} and Defenses for Deep Learning},
  shorttitle = {Adversarial Examples},
  author = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  year = {2019},
  journal = {IEEE transactions on neural networks and learning systems},
  volume = {30},
  number = {9},
  pages = {2805--2824},
  publisher = {{IEEE}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\MSSKGEKJ\\Yuan et al. - 2019 - Adversarial examples Attacks and defenses for dee.pdf;C\:\\Users\\julio\\Zotero\\storage\\6CSAD978\\8611298.html}
}

@inproceedings{yuLearningBiasedComplementary2018,
  title = {Learning with Biased Complementary Labels},
  booktitle = {Proceedings of the {{European}} Conference on Computer Vision ({{ECCV}})},
  author = {Yu, Xiyu and Liu, Tongliang and Gong, Mingming and Tao, Dacheng},
  year = {2018},
  pages = {68--83},
  file = {C\:\\Users\\julio\\Zotero\\storage\\9RSQZ9T6\\Yu et al. - 2018 - Learning with biased complementary labels.pdf;C\:\\Users\\julio\\Zotero\\storage\\PGMWU4RH\\Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.html}
}

@inproceedings{zhaoNeuralNetworksIncorporating2018,
  title = {Neural Networks Incorporating Unlabeled and Partially-Labeled Data for Cross-Domain Chinese Word Segmentation.},
  booktitle = {{{IJCAI}}},
  author = {Zhao, Lujun and Zhang, Qi and Wang, Peng and Liu, Xiaoyu},
  year = {2018},
  pages = {4602--4608},
  file = {C\:\\Users\\julio\\Zotero\\storage\\RM8EIJKJ\\Zhao et al. - 2018 - Neural networks incorporating unlabeled and partia.pdf}
}

@article{zhaoWebScraping2017a,
  title = {Web Scraping},
  author = {Zhao, Bo},
  year = {2017},
  journal = {Encyclopedia of big data},
  pages = {1--3},
  publisher = {{Springer Living ed. Cham}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\YG4HK43G\\Zhao - 2017 - Web scraping.pdf}
}

@article{zhouBriefIntroductionWeakly2018,
  title = {A Brief Introduction to Weakly Supervised Learning},
  author = {Zhou, Zhi-Hua},
  year = {2018},
  journal = {National science review},
  volume = {5},
  number = {1},
  pages = {44--53},
  publisher = {{Oxford University Press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\G7RLUC4Y\\4093912.html;C\:\\Users\\julio\\Zotero\\storage\\LNKD7FDG\\4093912.html}
}

@article{zhouBriefIntroductionWeakly2018a,
  title = {A Brief Introduction to Weakly Supervised Learning},
  author = {Zhou, Zhi-Hua},
  year = {2018},
  journal = {National science review},
  volume = {5},
  number = {1},
  pages = {44--53},
  publisher = {{Oxford University Press}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\2XGDG4TE\\4093912.html;C\:\\Users\\julio\\Zotero\\storage\\D2L6QK4Q\\4093912.html}
}

@inproceedings{zhouPriorawareNeuralNetwork2019,
  title = {Prior-Aware Neural Network for Partially-Supervised Multi-Organ Segmentation},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Zhou, Yuyin and Li, Zhe and Bai, Song and Wang, Chong and Chen, Xinlei and Han, Mei and Fishman, Elliot and Yuille, Alan L.},
  year = {2019},
  pages = {10672--10681},
  file = {C\:\\Users\\julio\\Zotero\\storage\\94ZJIGK2\\Zhou et al. - 2019 - Prior-aware neural network for partially-supervise.pdf;C\:\\Users\\julio\\Zotero\\storage\\MIFP5C3B\\Zhou_Prior-Aware_Neural_Network_for_Partially-Supervised_Multi-Organ_Segmentation_ICCV_2019_pap.html}
}

@article{zhuSemisupervisedLearningLiterature2005,
  title = {Semi-Supervised Learning Literature Survey},
  author = {Zhu, Xiaojin Jerry},
  year = {2005},
  publisher = {{University of Wisconsin-Madison Department of Computer Sciences}},
  file = {C\:\\Users\\julio\\Zotero\\storage\\NTYFTH2W\\Zhu - 2005 - Semi-supervised learning literature survey.pdf;C\:\\Users\\julio\\Zotero\\storage\\K7AT4Z4H\\60444.html}
}
