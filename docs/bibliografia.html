<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt" xml:lang="pt"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Resolvendo Captchas - Bibliografia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./pacote.html" rel="next">
<link href="./conclusoes.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>


<meta name="citation_title" content="Bibliografia">
<meta name="citation_language" content="pt">
<meta name="citation_reference" content="citation_title=Understanding dropout;,citation_author=Pierre Baldi;,citation_author=Peter J. Sadowski;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=26;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=A note on learning from multiple-instance examples;,citation_author=Avrim Blum;,citation_author=Adam Kalai;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_volume=30;,citation_journal_title=Machine learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Captcha - Google Acadêmico;,citation_publisher=https://scholar.google.com.br/scholar?hl=pt-BR&amp;amp;amp;as_sdt=0%2C5&amp;q=captcha&amp;btnG=;">
<meta name="citation_reference" content="citation_title=Building Segmentation Based Human-Friendly Human Interaction Proofs (HIPs);,citation_abstract=Human interaction proofs (HIPs) have become common place on the internet due to their effectiveness in deterring automated abuse of online services intended for humans. However, there is a co-evolutionary arms race in progress and these proofs are becoming more difficult for genuine users while attackers are getting better at breaking existing HIPs. We studied various popular HIPs on the internet to understand their strength and human friendliness. To determine HIP strength, we adopted a direct approach of building computer attacks using image processing and machine learning techniques. To understand human-friendliness, a sequence of users studies were conducted to investigate HIP character recognition by humans under a variety of visual distortions and clutter commonly employed in reading-based HIPs. We found that many of the online HIPs are pure recognition tasks that can be easily broken using machine learning. The stronger HIPs tend to pose a combination of segmentation and recognition challenges. Further, the HIP user studies show that given correct segmentation, computers are much better at HIP character recognition than humans. In light of these results, we propose that segmentation-based reading challenges are the future for building stronger human-friendly HIPs. An example of such a segmentation-based HIP is presented with a preliminary assessment of its strength and human-friendliness.;,citation_author=Kumar Chellapilla;,citation_author=Kevin Larson;,citation_author=Patrice Y. Simard;,citation_author=Mary Czerwinski;,citation_editor=Henry S. Baird;,citation_editor=Daniel P. Lopresti;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_doi=10.1007/11427896_1;,citation_isbn=978-3-540-32117-0;,citation_language=en-US;,citation_conference_title=Human Interactive Proofs;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=Designing human friendly human interaction proofs (HIPs);,citation_abstract=HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.;,citation_author=Kumar Chellapilla;,citation_author=Kevin Larson;,citation_author=Patrice Simard;,citation_author=Mary Czerwinski;,citation_publication_date=2005-04;,citation_cover_date=2005-04;,citation_year=2005;,citation_doi=10.1145/1054972.1055070;,citation_isbn=978-1-58113-998-3;,citation_conference_title=Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’05;">
<meta name="citation_reference" content="citation_title=Using machine learning to break visual human interaction proofs (HIPs);,citation_author=Kumar Chellapilla;,citation_author=Patrice Simard;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=17;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Consistency of losses for learning from weak labels;,citation_author=Jesús Cid-Sueiro;,citation_author=Darío García-García;,citation_author=Raúl Santos-Rodríguez;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=Joint European Conference on Machine Learning and Knowledge Discovery in Databases;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Análise de sobrevivência aplicada;,citation_author=Enrico Antonio Colosimo;,citation_author=Suely Ruiz Giolo;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Learning from partial labels;,citation_author=Timothee Cour;,citation_author=Ben Sapp;,citation_author=Ben Taskar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=The Journal of Machine Learning Research;,citation_publisher=JMLR. org;">
<meta name="citation_reference" content="citation_title=Analysis of perceptron-based active learning;,citation_author=Sanjoy Dasgupta;,citation_author=Adam Tauman Kalai;,citation_author=Claire Monteleoni;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=International conference on computational learning theory;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Diagnóstico do Contencioso Tributário Administrativo;,citation_abstract=Estudo sobre estrutura do contencioso, processos administrativos tributários e percepções dos agentes;,citation_publisher=https://abj.org.br/pesquisas/bid-tributario/;">
<meta name="citation_reference" content="citation_title=Partial Label Learning with competitive learning graph neural network;,citation_abstract=Partial Label Learning (PLL) is a weakly supervised learning framework where each instance may be associated with more than one candidate label, among which only one is true. Traditionally, the PLL problem is solved by removing the false candidate labels based on the instance relationship, while the potentially useful information between instances and labels as well as the potential candidate label relationship is ignored. In this paper, a new PLL framework PL-CGNN is proposed, which treats the instances with false labels as noise, and the PLL is reformulated to remove the noise instances. First of all, the feature of each label class is approximately represented by the center point of all the related instances. The significant operation enables the similarity between instances and labels measurable. Next, all the candidate labels for each instance compete for the biggest similarity. To further improve the robustness of the model, the competition procedure for the most similar label is extended to the neighbors of this instance. The label with the most wins is the final ground-truth one. The relationship between candidate labels guides the situation that the competition process develops into. Through iterative competitive learning, each label class approaches the true value. Experiments carried out on diverse datasets show that the performance of the PL-CGNN model is outstanding.;,citation_author=Jinfu Fan;,citation_author=Yang Yu;,citation_author=Zhongjie Wang;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_doi=10.1016/j.engappai.2022.104779;,citation_issn=0952-1976;,citation_volume=111;,citation_language=en-US;,citation_journal_title=Engineering Applications of Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Learning with multiple complementary labels;,citation_author=Lei Feng;,citation_author=Takuo Kaneko;,citation_author=Bo Han;,citation_author=Gang Niu;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International Conference on Machine Learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Learning with multiple complementary labels;,citation_author=Lei Feng;,citation_author=Takuo Kaneko;,citation_author=Bo Han;,citation_author=Gang Niu;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International Conference on Machine Learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Provably consistent partial-label learning;,citation_author=Lei Feng;,citation_author=Jiaqi Lv;,citation_author=Bo Han;,citation_author=Miao Xu;,citation_author=Gang Niu;,citation_author=Xin Geng;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=33;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=Provably consistent partial-label learning;,citation_author=Lei Feng;,citation_author=Jiaqi Lv;,citation_author=Bo Han;,citation_author=Miao Xu;,citation_author=Gang Niu;,citation_author=Xin Geng;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=33;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based approaches;,citation_author=Mikel Galar;,citation_author=Alberto Fernandez;,citation_author=Edurne Barrenechea;,citation_author=Humberto Bustince;,citation_author=Francisco Herrera;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=42;,citation_journal_title=IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews);,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs;,citation_author=Dileep George;,citation_author=Wolfgang Lehrach;,citation_author=Ken Kansky;,citation_author=Miguel Lázaro-Gredilla;,citation_author=Christopher Laan;,citation_author=Bhaskara Marthi;,citation_author=Xinghua Lou;,citation_author=Zhaoshi Meng;,citation_author=Yi Liu;,citation_author=Huayan Wang;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=6368;,citation_volume=358;,citation_journal_title=Science;,citation_publisher=American Association for the Advancement of Science;">
<meta name="citation_reference" content="citation_title=Partial Label Learning via Label Influence Function;,citation_author=Xiuwen Gong;,citation_author=Dong Yuan;,citation_author=Wei Bao;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=International Conference on Machine Learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Generative Adversarial Networks;,citation_abstract=We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.;,citation_author=Ian J. Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_fulltext_html_url=https://arxiv.org/abs/1406.2661;,citation_doi=10.48550/arXiv.1406.2661;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Generative adversarial networks;,citation_author=Ian Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=11;,citation_volume=63;,citation_journal_title=Communications of the ACM;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Multi-digit number recognition from street view imagery using deep convolutional neural networks;,citation_author=Ian J. Goodfellow;,citation_author=Yaroslav Bulatov;,citation_author=Julian Ibarz;,citation_author=Sacha Arnoud;,citation_author=Vinay Shet;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://arxiv.org/abs/1312.6082;,citation_journal_title=arXiv preprint arXiv:1312.6082;">
<meta name="citation_reference" content="citation_title=Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks;,citation_abstract=Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\%$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving $97.84\%$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over $90\%$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a $99.8\%$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.;,citation_author=Ian J. Goodfellow;,citation_author=Yaroslav Bulatov;,citation_author=Julian Ibarz;,citation_author=Sacha Arnoud;,citation_author=Vinay Shet;,citation_publication_date=2014-04;,citation_cover_date=2014-04;,citation_year=2014;,citation_fulltext_html_url=https://arxiv.org/abs/1312.6082;,citation_doi=10.48550/arXiv.1312.6082;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Logistic regression for partial labels;,citation_author=Yves Grandvalet;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proc. IPMU;">
<meta name="citation_reference" content="citation_title=Weak supervision and other non-standard classification problems: A taxonomy;,citation_author=Jerónimo Hernández-González;,citation_author=Inaki Inza;,citation_author=Jose A. Lozano;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=69;,citation_journal_title=Pattern Recognition Letters;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Learning from ambiguously labeled examples;,citation_author=Eyke Hüllermeier;,citation_author=Jürgen Beringer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=5;,citation_volume=10;,citation_journal_title=Intelligent Data Analysis;,citation_publisher=IOS Press;">
<meta name="citation_reference" content="citation_title=Inaccessibility of CAPTCHA;,citation_publisher=https://www.w3.org/TR/turingtest/;">
<meta name="citation_reference" content="citation_title=Batch normalization: Accelerating deep network training by reducing internal covariate shift;,citation_author=Sergey Ioffe;,citation_author=Christian Szegedy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Learning from complementary labels;,citation_author=Takashi Ishida;,citation_author=Gang Niu;,citation_author=Weihua Hu;,citation_author=Masashi Sugiyama;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning from complementary labels;,citation_author=Takashi Ishida;,citation_author=Gang Niu;,citation_author=Weihua Hu;,citation_author=Masashi Sugiyama;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning with multiple labels;,citation_author=Rong Jin;,citation_author=Zoubin Ghahramani;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=15;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Online multiclass classification based on prediction margin for partial feedback;,citation_author=Takuo Kaneko;,citation_author=Issei Sato;,citation_author=Masashi Sugiyama;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1902.01056;,citation_journal_title=arXiv preprint arXiv:1902.01056;">
<meta name="citation_reference" content="citation_title=Captcha and Its Techniques: A Review;,citation_abstract=Captcha (Completely Automated public Turing test to tell Computers and Humans Apart) system is used to verify whether a user is human or computer program. It’s also known as human Interactive Proof (HIP) and based upon Artificial Intelligence. Captcha is a program that protects websites from web-bots by generating tests that computer cannot pass but human can pass .This paper comprise introduction of captcha, various techniques, application of captcha and drawbacks of captcha.;,citation_author=Kiranjot Kaur;,citation_author=Sunny Behal;,citation_publication_date=2014-01;,citation_cover_date=2014-01;,citation_year=2014;,citation_volume=5;,citation_journal_title=International Journal of Computer Science and Information Technologies,;">
<meta name="citation_reference" content="citation_title=Adam: A Method for Stochastic Optimization;,citation_abstract=We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.;,citation_author=Diederik P. Kingma;,citation_author=Jimmy Ba;,citation_publication_date=2017-01;,citation_cover_date=2017-01;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1412.6980;,citation_doi=10.48550/arXiv.1412.6980;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Restricted set classification: Who is there?;,citation_author=Ludmila I. Kuncheva;,citation_author=Juan J. Rodriguez;,citation_author=Aaron S. Jackson;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=63;,citation_journal_title=Pattern Recognition;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=Yann LeCun;,citation_author=Yoshua Bengio;,citation_author=Geoffrey Hinton;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=7553;,citation_volume=521;,citation_journal_title=nature;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=Efficient backprop;,citation_author=Yann A. LeCun;,citation_author=Léon Bottou;,citation_author=Genevieve B. Orr;,citation_author=Klaus-Robert Müller;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_inbook_title=Neural networks: Tricks of the trade;">
<meta name="citation_reference" content="citation_title=Gradient-based learning applied to document recognition;,citation_author=Yann LeCun;,citation_author=Léon Bottou;,citation_author=Yoshua Bengio;,citation_author=Patrick Haffner;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=11;,citation_volume=86;,citation_journal_title=Proceedings of the IEEE;,citation_publisher=Ieee;">
<meta name="citation_reference" content="citation_title=Method for selectively restricting access to computer systems;,citation_author=Mark D. Lillibridge;,citation_author=Martin Abadi;,citation_author=Krishna Bharat;,citation_author=Andrei Z. Broder;,citation_publication_date=2001-02;,citation_cover_date=2001-02;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Multivariate binomial/multinomial control chart;,citation_author=Jian Li;,citation_author=Fugee Tsung;,citation_author=Changliang Zou;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=5;,citation_volume=46;,citation_journal_title=IIE Transactions;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=A conditional multinomial mixture model for superset label learning;,citation_author=Liping Liu;,citation_author=Thomas Dietterich;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=25;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Fuzzy-rough set based semi-supervised learning;,citation_author=Neil Mac Parthaláin;,citation_author=Richard Jensen;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Estado brasileiro e transparência avaliando a aplicação da Lei de Acesso à Informação;,citation_author=Gregory Michener;,citation_author=Luiz Fernando Moncau;,citation_author=Rafael Braem Velasco;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA;,citation_author=Greg Mori;,citation_author=Jitendra Malik;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=1;,citation_conference_title=2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Open data in science;,citation_author=Peter Murray-Rust;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_journal_title=Nature Precedings;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=AVA: A large-scale database for aesthetic visual analysis;,citation_author=Naila Murray;,citation_author=Luca Marchesotti;,citation_author=Florent Perronnin;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 IEEE conference on computer vision and pattern recognition;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Deep Generative Positive-Unlabeled Learning under Selection Bias;,citation_abstract=Learning in the positive-unlabeled (PU) setting is prevalent in real world applications. Many previous works depend upon theSelected Completely At Random (SCAR) assumption to utilize unlabeled data, but the SCAR assumption is not often applicable to the real world due to selection bias in label observations. This paper is the first generative PU learning model without the SCAR assumption. Specifically, we derive the PU risk function without the SCAR assumption, and we generate a set of virtual PU examples to train the classifier. Although our PU risk function is more generalizable, the function requires PU instances that do not exist in the observations. Therefore, we introduce the VAE-PU, which is a variant of variational autoencoders to separate two latent variables that generate either features or observation indicators. The separated latent information enables the model to generate virtual PU instances. We test the VAE-PU on benchmark datasets with and without the SCAR assumption. The results indicate that the VAE-PU is superior when selection bias exists, and the VAE-PU is also competent under the SCAR assumption. The results also emphasize that the VAE-PU is effective when there are few positive-labeled instances due to modeling on selection bias.;,citation_author=Byeonghu Na;,citation_author=Hyemi Kim;,citation_author=Kyungwoo Song;,citation_author=Weonyoung Joo;,citation_author=Yoon-Yeong Kim;,citation_author=Il-Chul Moon;,citation_publication_date=2020-10;,citation_cover_date=2020-10;,citation_year=2020;,citation_doi=10.1145/3340531.3411971;,citation_isbn=978-1-4503-6859-9;,citation_conference_title=Proceedings of the 29th ACM International Conference on Information &amp;amp;amp; Knowledge Management;,citation_conference=Association for Computing Machinery;,citation_series_title=CIKM ’20;">
<meta name="citation_reference" content="citation_title=Generalized linear models;,citation_author=John Ashworth Nelder;,citation_author=Robert WM Wedderburn;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_issue=3;,citation_volume=135;,citation_journal_title=Journal of the Royal Statistical Society: Series A (General);,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Classification with partial labels;,citation_author=Nam Nguyen;,citation_author=Rich Caruana;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining;">
<meta name="citation_reference" content="citation_title=Regularizing deep neural networks by noise: Its interpretation and optimization;,citation_author=Hyeonwoo Noh;,citation_author=Tackgeun You;,citation_author=Jonghwan Mun;,citation_author=Bohyung Han;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=Observatório da insolvência: Rio de Janeiro;,citation_abstract=Estudo sobre as recuperações judiciais do estado do Rio de Janeiro.;,citation_publisher=https://abj.org.br/pesquisas/obsrjrj/;">
<meta name="citation_reference" content="citation_title=Hierarchical Text-Conditional Image Generation with CLIP Latents;,citation_abstract=Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2204.06125;,citation_doi=10.48550/arXiv.2204.06125;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Hierarchical text-conditional image generation with clip latents;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2204.06125;,citation_journal_title=arXiv preprint arXiv:2204.06125;">
<meta name="citation_reference" content="citation_title=Method and system for discriminating a human action from a computerized action;,citation_author=Eran Reshef;,citation_author=Gil Raanan;,citation_author=Eilon Solan;,citation_publication_date=2005-05;,citation_cover_date=2005-05;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Deep learning is robust to massive label noise;,citation_author=David Rolnick;,citation_author=Andreas Veit;,citation_author=Serge Belongie;,citation_author=Nir Shavit;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1705.10694;,citation_journal_title=arXiv preprint arXiv:1705.10694;">
<meta name="citation_reference" content="citation_title=Partially supervised learning for pattern recognition;,citation_author=Friedhelm Schwenker;,citation_author=Edmondo Trentin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=37;,citation_journal_title=Pattern Recognition Letters;">
<meta name="citation_reference" content="citation_title=Reinforcement learning: An introduction;,citation_author=Richard S. Sutton;,citation_author=Andrew G. Barto;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Tempo dos processos relacionados à adoção;,citation_abstract=Análise do tempo dos processos relacionados à adoção no Brasil, especialmente de processos relativos a desconstituição do poder familiar.;,citation_publisher=https://abj.org.br/pesquisas/adocao/;">
<meta name="citation_reference" content="citation_title=Computing machinery and intelligence;,citation_author=Alan M. Turing;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_inbook_title=Parsing the turing test;">
<meta name="citation_reference" content="citation_title=Partially supervised learning by a credal EM approach;,citation_author=Patrick Vannoorenberghe;,citation_author=Philippe Smets;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=European Conference on Symbolic and Quantitative Approaches to Reasoning and Uncertainty;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Captcha: Telling humans and computers apart automatically;,citation_author=Luis Von Ahn;,citation_author=Manuel Blum;,citation_author=Nicholas Hopper;,citation_author=John Langford;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=Proceedings of eurocrypt;">
<meta name="citation_reference" content="citation_title=reCAPTCHA: Human-Based Character Recognition via Web Security Measures;,citation_abstract=CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) are widespread security measures on the World Wide Web that prevent automated programs from abusing online services. They do so by asking humans to perform a task that computers cannot yet perform, such as deciphering distorted characters. Our research explored whether such human effort can be channeled into a useful purpose: helping to digitize old printed material by asking users to decipher scanned words from books that computerized optical character recognition failed to recognize. We showed that this method can transcribe text with a word accuracy exceeding 99%, matching the guarantee of professional human transcribers. Our apparatus is deployed in more than 40,000 Web sites and has transcribed over 440 million words.;,citation_author=Luis Ahn;,citation_author=Benjamin Maurer;,citation_author=Colin McMillen;,citation_author=David Abraham;,citation_author=Manuel Blum;,citation_publication_date=2008-09;,citation_cover_date=2008-09;,citation_year=2008;,citation_issue=5895;,citation_doi=10.1126/science.1160379;,citation_issn=0036-8075, 1095-9203;,citation_volume=321;,citation_language=en-US;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Telling humans and computers apart automatically or how lazy cryptographers do AI (Tech. Rep. No. CMU-CS-02-117);,citation_author=L. Ahn;,citation_author=M. Blum;,citation_author=J. Langford;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_technical_report_institution=Carnegie Mellon University;">
<meta name="citation_reference" content="citation_title=Telling humans and computers apart automatically;,citation_author=Luis Von Ahn;,citation_author=Manuel Blum;,citation_author=John Langford;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=2;,citation_volume=47;,citation_journal_title=Communications of the ACM;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Make complex captchas simple: A fast text captcha solver based on a small number of samples;,citation_author=Yao Wang;,citation_author=Yuliang Wei;,citation_author=Mingjin Zhang;,citation_author=Yang Liu;,citation_author=Bailing Wang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=578;,citation_journal_title=Information Sciences;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A survey of CAPTCHA technologies to distinguish between human and computer;,citation_author=Xin Xu;,citation_author=Lei Liu;,citation_author=Bo Li;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=408;,citation_journal_title=Neurocomputing;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Understanding Sigmoid, Logistic, Softmax Functions, and Cross-Entropy Loss (Log Loss);,citation_abstract=Practical Maths for Key Concepts in Logistic Regression and Deep Learning;,citation_author=Zhou (Joe) Xu;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_language=en-US;,citation_journal_title=Medium;,citation_publisher=https://towardsdatascience.com/understanding-sigmoid-logistic-softmax-functions-and-cross-entropy-loss-log-loss-dbbbe0a17efb;">
<meta name="citation_reference" content="citation_title=Deep discriminative cnn with temporal ensembling for ambiguously-labeled image classification;,citation_author=Yao Yao;,citation_author=Jiehui Deng;,citation_author=Xiuhua Chen;,citation_author=Chen Gong;,citation_author=Jianxin Wu;,citation_author=Jian Yang;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=34;,citation_conference_title=Proceedings of the AAAI Conference on Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Yet another text captcha solver: A generative adversarial network based approach;,citation_author=Guixin Ye;,citation_author=Zhanyong Tang;,citation_author=Dingyi Fang;,citation_author=Zhanxing Zhu;,citation_author=Yansong Feng;,citation_author=Pengfei Xu;,citation_author=Xiaojiang Chen;,citation_author=Zheng Wang;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the 2018 ACM SIGSAC conference on computer and communications security;">
<meta name="citation_reference" content="citation_title=Adversarial examples: Attacks and defenses for deep learning;,citation_author=Xiaoyong Yuan;,citation_author=Pan He;,citation_author=Qile Zhu;,citation_author=Xiaolin Li;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=9;,citation_volume=30;,citation_journal_title=IEEE transactions on neural networks and learning systems;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Learning with biased complementary labels;,citation_author=Xiyu Yu;,citation_author=Tongliang Liu;,citation_author=Mingming Gong;,citation_author=Dacheng Tao;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the European conference on computer vision (ECCV);">
<meta name="citation_reference" content="citation_title=Neural networks incorporating unlabeled and partially-labeled data for cross-domain chinese word segmentation.;,citation_author=Lujun Zhao;,citation_author=Qi Zhang;,citation_author=Peng Wang;,citation_author=Xiaoyu Liu;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=IJCAI;">
<meta name="citation_reference" content="citation_title=Web scraping;,citation_author=Bo Zhao;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Encyclopedia of big data;,citation_publisher=Springer Living ed. Cham;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Prior-aware neural network for partially-supervised multi-organ segmentation;,citation_author=Yuyin Zhou;,citation_author=Zhe Li;,citation_author=Song Bai;,citation_author=Chong Wang;,citation_author=Xinlei Chen;,citation_author=Mei Han;,citation_author=Elliot Fishman;,citation_author=Alan L. Yuille;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=Proceedings of the IEEE/CVF International Conference on Computer Vision;">
<meta name="citation_reference" content="citation_title=Semi-supervised learning literature survey;,citation_author=Xiaojin Jerry Zhu;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_publisher=University of Wisconsin-Madison Department of Computer Sciences;">
<meta name="citation_reference" content="citation_title=Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA;,citation_author=Greg Mori;,citation_author=Jitendra Malik;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=1;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA;,citation_author=Greg Mori;,citation_author=Jitendra Malik;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=1;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Designing human friendly human interaction proofs (HIPs);,citation_author=Kumar Chellapilla;,citation_author=Kevin Larson;,citation_author=Patrice Simard;,citation_author=Mary Czerwinski;,citation_publication_date=2005-04-02;,citation_cover_date=2005-04-02;,citation_year=2005;,citation_fulltext_html_url=https://doi.org/10.1145/1054972.1055070;,citation_doi=10.1145/1054972.1055070;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’05;">
<meta name="citation_reference" content="citation_title=Using machine learning to break visual human interaction proofs (HIPs);,citation_author=Kumar Chellapilla;,citation_author=Patrice Simard;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=17;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Multi-digit number recognition from street view imagery using deep convolutional neural networks;,citation_author=Ian J. Goodfellow;,citation_author=Yaroslav Bulatov;,citation_author=Julian Ibarz;,citation_author=Sacha Arnoud;,citation_author=Vinay Shet;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1312.6082;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=Yann LeCun;,citation_author=Yoshua Bengio;,citation_author=Geoffrey Hinton;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=7553;,citation_volume=521;,citation_journal_title=nature;">
<meta name="citation_reference" content="citation_title=Generative adversarial networks;,citation_author=Ian Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=11;,citation_volume=63;,citation_journal_title=Communications of the ACM;">
<meta name="citation_reference" content="citation_title=Generative adversarial networks;,citation_author=Ian J. Goodfellow;,citation_author=Jean Pouget-Abadie;,citation_author=Mehdi Mirza;,citation_author=Bing Xu;,citation_author=David Warde-Farley;,citation_author=Sherjil Ozair;,citation_author=Aaron Courville;,citation_author=Yoshua Bengio;,citation_doi=10.48550/arXiv.1406.2661;">
<meta name="citation_reference" content="citation_title=A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs;,citation_author=Dileep George;,citation_author=Wolfgang Lehrach;,citation_author=Ken Kansky;,citation_author=Miguel Lázaro-Gredilla;,citation_author=Christopher Laan;,citation_author=Bhaskara Marthi;,citation_author=Xinghua Lou;,citation_author=Zhaoshi Meng;,citation_author=Yi Liu;,citation_author=Huayan Wang;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=6368;,citation_volume=358;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Yet another text captcha solver: A generative adversarial network based approach;,citation_author=Guixin Ye;,citation_author=Zhanyong Tang;,citation_author=Dingyi Fang;,citation_author=Zhanxing Zhu;,citation_author=Yansong Feng;,citation_author=Pengfei Xu;,citation_author=Xiaojiang Chen;,citation_author=Zheng Wang;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Make complex captchas simple: A fast text captcha solver based on a small number of samples;,citation_author=Yao Wang;,citation_author=Yuliang Wei;,citation_author=Mingjin Zhang;,citation_author=Yang Liu;,citation_author=Bailing Wang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=578;,citation_journal_title=Information Sciences;">
<meta name="citation_reference" content="citation_title=A survey of CAPTCHA technologies to distinguish between human and computer;,citation_author=Xin Xu;,citation_author=Lei Liu;,citation_author=Bo Li;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=408;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Adversarial examples: Attacks and defenses for deep learning;,citation_author=Xiaoyong Yuan;,citation_author=Pan He;,citation_author=Qile Zhu;,citation_author=Xiaolin Li;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=9;,citation_volume=30;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Regularizing deep neural networks by noise: Its interpretation and optimization;,citation_author=Hyeonwoo Noh;,citation_author=Tackgeun You;,citation_author=Jonghwan Mun;,citation_author=Bohyung Han;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=reCAPTCHA: Human-Based Character Recognition via Web Security Measures;,citation_author=Luis Ahn;,citation_author=Benjamin Maurer;,citation_author=Colin McMillen;,citation_author=David Abraham;,citation_author=Manuel Blum;,citation_publication_date=2008-09-12;,citation_cover_date=2008-09-12;,citation_year=2008;,citation_fulltext_html_url=https://www.science.org/doi/10.1126/science.1160379;,citation_issue=5895;,citation_doi=10.1126/science.1160379;,citation_volume=321;,citation_language=en;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Reinforcement learning: An introduction;,citation_author=Richard S. Sutton;,citation_author=Andrew G. Barto;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Deep generative positive-unlabeled learning under selection bias;,citation_author=Byeonghu Na;,citation_author=Hyemi Kim;,citation_author=Kyungwoo Song;,citation_author=Weonyoung Joo;,citation_author=Yoon-Yeong Kim;,citation_author=Il-Chul Moon;,citation_publication_date=2020-10-19;,citation_cover_date=2020-10-19;,citation_year=2020;,citation_fulltext_html_url=https://doi.org/10.1145/3340531.3411971;,citation_doi=10.1145/3340531.3411971;,citation_conference=Association for Computing Machinery;,citation_series_title=CIKM ’20;">
<meta name="citation_reference" content="citation_title=Análise de sobrevivência aplicada;,citation_author=Enrico Antonio Colosimo;,citation_author=Suely Ruiz Giolo;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;">
<meta name="citation_reference" content="citation_title=Computing machinery and intelligence;,citation_author=Alan M. Turing;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Telling humans and computers apart automatically or how lazy cryptographers do AI (tech. Rep. No. CMU-CS-02-117);,citation_author=L. Ahn;,citation_author=M. Blum;,citation_author=J. Langford;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf;">
<meta name="citation_reference" content="citation_title=Inaccessibility of CAPTCHA;,citation_author=undefined W3C;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.w3.org/TR/turingtest/;">
<meta name="citation_reference" content="citation_title=Estado brasileiro e transparência avaliando a aplicação da lei de acesso à informação;,citation_author=Gregory Michener;,citation_author=Luiz Fernando Moncau;,citation_author=Rafael Braem Velasco;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Open data in science;,citation_author=Peter Murray-Rust;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_journal_title=Nature Precedings;">
<meta name="citation_reference" content="citation_title=Observatório da insolvência: Rio de janeiro;,citation_author=undefined ABJ;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://abj.org.br/pesquisas/obsrjrj/;">
<meta name="citation_reference" content="citation_title=Tempo dos processos relacionados à adoção;,citation_author=undefined ABJ;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=https://abj.org.br/pesquisas/adocao/;">
<meta name="citation_reference" content="citation_title=Diagnóstico do contencioso tributário administrativo;,citation_author=undefined ABJ;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://abj.org.br/pesquisas/bid-tributario/;">
<meta name="citation_reference" content="citation_title=Diagnóstico do contencioso tributário administrativo;,citation_author=undefined ABJ;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://abj.org.br/pesquisas/bid-tributario/;">
<meta name="citation_reference" content="citation_title=Web scraping;,citation_author=Bo Zhao;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf;,citation_journal_title=Encyclopedia of big data;">
<meta name="citation_reference" content="citation_title=A brief introduction to weakly supervised learning;,citation_author=Zhi-Hua Zhou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=5;,citation_journal_title=National science review;">
<meta name="citation_reference" content="citation_title=Semi-supervised learning literature survey;,citation_author=Xiaojin Jerry Zhu;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=A note on learning from multiple-instance examples;,citation_author=Avrim Blum;,citation_author=Adam Kalai;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_volume=30;,citation_journal_title=Machine learning;">
<meta name="citation_reference" content="citation_title=Learning with multiple labels;,citation_author=Rong Jin;,citation_author=Zoubin Ghahramani;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=15;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Gradient-based learning applied to document recognition;,citation_author=Yann LeCun;,citation_author=Léon Bottou;,citation_author=Yoshua Bengio;,citation_author=Patrick Haffner;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=11;,citation_volume=86;,citation_journal_title=Proceedings of the IEEE;">
<meta name="citation_reference" content="citation_title=Generalized linear models;,citation_author=John Ashworth Nelder;,citation_author=Robert WM Wedderburn;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_issue=3;,citation_volume=135;,citation_journal_title=Journal of the Royal Statistical Society: Series A (General);">
<meta name="citation_reference" content="citation_title=Hierarchical Text-Conditional Image Generation with CLIP Latents;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2204.06125;,citation_issue=arXiv:2204.06125;,citation_doi=10.48550/arXiv.2204.06125;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Understanding dropout;,citation_author=Pierre Baldi;,citation_author=Peter J. Sadowski;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=26;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based approaches;,citation_author=Mikel Galar;,citation_author=Alberto Fernandez;,citation_author=Edurne Barrenechea;,citation_author=Humberto Bustince;,citation_author=Francisco Herrera;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=42;,citation_journal_title=IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews);">
<meta name="citation_reference" content="citation_title=Adam: A Method for Stochastic Optimization;,citation_author=Diederik P. Kingma;,citation_author=Jimmy Ba;,citation_publication_date=2017-01;,citation_cover_date=2017-01;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1412.6980;,citation_issue=arXiv:1412.6980;,citation_doi=10.48550/arXiv.1412.6980;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Efficient backprop;,citation_author=Yann A. LeCun;,citation_author=Léon Bottou;,citation_author=Genevieve B. Orr;,citation_author=Klaus-Robert Müller;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Learning from partial labels;,citation_author=Timothee Cour;,citation_author=Ben Sapp;,citation_author=Ben Taskar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=The Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Provably consistent partial-label learning;,citation_author=Lei Feng;,citation_author=Jiaqi Lv;,citation_author=Bo Han;,citation_author=Miao Xu;,citation_author=Gang Niu;,citation_author=Xin Geng;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=33;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=Logistic regression for partial labels;,citation_author=Yves Grandvalet;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Learning from ambiguously labeled examples;,citation_author=Eyke Hüllermeier;,citation_author=Jürgen Beringer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=5;,citation_volume=10;,citation_journal_title=Intelligent Data Analysis;">
<meta name="citation_reference" content="citation_title=A conditional multinomial mixture model for superset label learning;,citation_author=Liping Liu;,citation_author=Thomas Dietterich;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=25;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning from complementary labels;,citation_author=Takashi Ishida;,citation_author=Gang Niu;,citation_author=Weihua Hu;,citation_author=Masashi Sugiyama;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Magick: Advanced graphics and image-processing in r;,citation_author=Jeroen Ooms;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=magick;">
<meta name="citation_reference" content="citation_title=Learning with biased complementary labels;,citation_author=Xiyu Yu;,citation_author=Tongliang Liu;,citation_author=Mingming Gong;,citation_author=Dacheng Tao;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Learning with multiple complementary labels;,citation_author=Lei Feng;,citation_author=Takuo Kaneko;,citation_author=Bo Han;,citation_author=Gang Niu;,citation_author=Bo An;,citation_author=Masashi Sugiyama;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=xml2: Parse XML;,citation_author=Hadley Wickham;,citation_author=Jim Hester;,citation_author=Jeroen Ooms;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://CRAN.R-project.org/package=xml2;">
<meta name="citation_reference" content="citation_title=Stringr: Simple, consistent wrappers for common string operations;,citation_author=Hadley Wickham;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=stringr;">
<meta name="citation_reference" content="citation_title=Rvest: Easily harvest (scrape) web pages;,citation_author=Hadley Wickham;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rvest;">
<meta name="citation_reference" content="citation_title=Captcha and its techniques: A review;,citation_author=Kiranjot Kaur;,citation_author=Sunny Behal;,citation_publication_date=2014-01-01;,citation_cover_date=2014-01-01;,citation_year=2014;,citation_volume=5;,citation_journal_title=International Journal of Computer Science and Information Technologies,;">
<meta name="citation_reference" content="citation_title=Multivariate binomial/multinomial control chart;,citation_author=Jian Li;,citation_author=Fugee Tsung;,citation_author=Changliang Zou;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=5;,citation_volume=46;,citation_journal_title=IIE Transactions;">
<meta name="citation_reference" content="citation_title=Batch normalization: Accelerating deep network training by reducing internal covariate shift;,citation_author=Sergey Ioffe;,citation_author=Christian Szegedy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Torch: Tensors and neural networks with ’GPU’ acceleration;,citation_author=Daniel Falbel;,citation_author=Javier Luraschi;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=torch;">
<meta name="citation_reference" content="citation_title=Luz: Higher level ’API’ for ’torch’;,citation_author=Daniel Falbel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=luz;">
<meta name="citation_reference" content="citation_title=Torchvision: Models, datasets and transformations for images;,citation_author=Daniel Falbel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=torchvision;">
<meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;,citation_author=R Core Team;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.R-project.org/;">
<meta name="citation_reference" content="citation_title=Feature engineering and selection: A practical approach for predictive models;,citation_author=Max Kuhn;,citation_author=Kjell Johnson;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Tensorflow: R interface to ’TensorFlow’;,citation_author=JJ Allaire;,citation_author=Yuan Tang;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=tensorflow;">
<meta name="citation_reference" content="citation_title=Decryptr: An extensible API for breaking captchas;,citation_author=Julio Trecenti;,citation_author=Caio Lente;,citation_author=Daniel Falbel;,citation_author=Milene Farhat;,citation_author=Beatriz Vianna;,citation_author=Evelin Angelica;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Reticulate: Interface to ’python’;,citation_author=Kevin Ushey;,citation_author=JJ Allaire;,citation_author=Yuan Tang;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=reticulate;">
<meta name="citation_reference" content="citation_title=Piggyback: Managing larger data on a GitHub repository;,citation_author=Carl Boettiger;,citation_author=Tan Ho;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=piggyback;">
<meta name="citation_reference" content="citation_title=Usethis: Automate package and project setup;,citation_author=Hadley Wickham;,citation_author=Jennifer Bryan;,citation_author=Malcolm Barrett;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=usethis;">
<meta name="citation_reference" content="citation_title=Hierarchical Text-Conditional Image Generation with CLIP Latents;,citation_author=Aditya Ramesh;,citation_author=Prafulla Dhariwal;,citation_author=Alex Nichol;,citation_author=Casey Chu;,citation_author=Mark Chen;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2204.06125;,citation_issue=arXiv:2204.06125;,citation_doi=10.48550/arXiv.2204.06125;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=AVA: A large-scale database for aesthetic visual analysis;,citation_author=Naila Murray;,citation_author=Luca Marchesotti;,citation_author=Florent Perronnin;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference=IEEE;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Bibliografia</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Resolvendo Captchas</a> 
        <div class="sidebar-tools-main">
    <a href="./Resolvendo-Captchas.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Sobre este documento</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introducao.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introdução</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./metodologia.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Metodologia</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resultados.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Resultados</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusoes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conclusões</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bibliografia.html" class="sidebar-item-text sidebar-link active">Bibliografia</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Apêndices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pacote.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Pacotes</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Bibliografia</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div id="refs" class="references csl-bib-body" data-entry-spacing="1" role="doc-bibliography">
<div id="ref-tempodo" class="csl-entry" role="doc-biblioentry">
ABJ. <strong>Tempo dos processos relacionados à adoção</strong>., 2014.
Disponível em: &lt;<a href="https://abj.org.br/pesquisas/adocao/">https://abj.org.br/pesquisas/adocao/</a>&gt;.
</div>
<div id="ref-observat" class="csl-entry" role="doc-biblioentry">
ABJ. <strong>Observatório da insolvência: Rio de Janeiro</strong>.,
2021. Disponível em: &lt;<a href="https://abj.org.br/pesquisas/obsrjrj/">https://abj.org.br/pesquisas/obsrjrj/</a>&gt;.
</div>
<div id="ref-diagnosticoABJ" class="csl-entry" role="doc-biblioentry">
ABJ. <strong>Diagnóstico do Contencioso Tributário
Administrativo</strong>., 2022. Disponível em: &lt;<a href="https://abj.org.br/pesquisas/bid-tributario/">https://abj.org.br/pesquisas/bid-tributario/</a>&gt;.
</div>
<div id="ref-vonahnReCAPTCHAHumanBasedCharacter2008" class="csl-entry" role="doc-biblioentry">
AHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web
Security Measures. <strong>Science</strong>, v. 321, n. 5895, p.
1465–1468, 12 set. 2008. Disponível em: &lt;<a href="https://www.science.org/doi/10.1126/science.1160379">https://www.science.org/doi/10.1126/science.1160379</a>&gt;.
</div>
<div id="ref-vonahnTellingHumansComputers2002" class="csl-entry" role="doc-biblioentry">
AHN, L. VON; BLUM, M.; LANGFORD, J. <strong>Telling humans and computers
apart automatically or how lazy cryptographers do AI (Tech. Rep. No.
CMU-CS-02-117)</strong>. Disponível em: &lt;<a href="http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf">http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf</a>&gt;.
</div>
<div id="ref-tensorflow" class="csl-entry" role="doc-biblioentry">
ALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022.
Disponível em: &lt;<a href="https://CRAN.R-project.org/package=tensorflow">https://CRAN.R-project.org/package=tensorflow</a>&gt;.
</div>
<div id="ref-baldi2013" class="csl-entry" role="doc-biblioentry">
BALDI, P.; SADOWSKI, P. J. Understanding dropout. <strong>Advances in
neural information processing systems</strong>, v. 26, 2013.
</div>
<div id="ref-blum1998" class="csl-entry" role="doc-biblioentry">
BLUM, A.; KALAI, A. A note on learning from multiple-instance examples.
<strong>Machine learning</strong>, v. 30, n. 1, p. 2329, 1998.
</div>
<div id="ref-piggyback" class="csl-entry" role="doc-biblioentry">
BOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub
Repository. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=piggyback">https://CRAN.R-project.org/package=piggyback</a>&gt;.
</div>
<div id="ref-chellapilla2005" class="csl-entry" role="doc-biblioentry">
CHELLAPILLA, K. et al. <strong>Designing human friendly human
interaction proofs (HIPs)</strong>. : CHI ’05.New York, NY, USA:
Association for Computing Machinery, 2 abr. 2005. Disponível em: &lt;<a href="https://doi.org/10.1145/1054972.1055070">https://doi.org/10.1145/1054972.1055070</a>&gt;.
</div>
<div id="ref-chellapilla2004" class="csl-entry" role="doc-biblioentry">
CHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human
interaction proofs (HIPs). <strong>Advances in neural information
processing systems</strong>, v. 17, 2004.
</div>
<div id="ref-colosimo2006" class="csl-entry" role="doc-biblioentry">
COLOSIMO, E. A.; GIOLO, S. R. <strong>Análise de sobrevivência
aplicada</strong>. Editora Blucher, 2006.
</div>
<div id="ref-cour2011" class="csl-entry" role="doc-biblioentry">
COUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. <strong>The
Journal of Machine Learning Research</strong>, v. 12, p. 15011536, 2011.
</div>
<div id="ref-luz" class="csl-entry" role="doc-biblioentry">
FALBEL, D. luz: Higher Level ’API’ for ’torch’. a2022. Disponível em:
&lt;<a href="https://CRAN.R-project.org/package=luz">https://CRAN.R-project.org/package=luz</a>&gt;.
</div>
<div id="ref-torchvision" class="csl-entry" role="doc-biblioentry">
FALBEL, D. torchvision: Models, Datasets and Transformations for Images.
b2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=torchvision">https://CRAN.R-project.org/package=torchvision</a>&gt;.
</div>
<div id="ref-torch" class="csl-entry" role="doc-biblioentry">
FALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’
Acceleration. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=torch">https://CRAN.R-project.org/package=torch</a>&gt;.
</div>
<div id="ref-feng2020" class="csl-entry" role="doc-biblioentry">
FENG, L. et al. Provably consistent partial-label learning.
<strong>Advances in Neural Information Processing Systems</strong>, v.
33, p. 1094810960, 2020.
</div>
<div id="ref-galar2011" class="csl-entry" role="doc-biblioentry">
GALAR, M. et al. A review on ensembles for the class imbalance problem:
bagging-, boosting-, and hybrid-based approaches. <strong>IEEE
Transactions on Systems, Man, and Cybernetics, Part C (Applications and
Reviews)</strong>, v. 42, n. 4, p. 463484, 2011.
</div>
<div id="ref-george2017" class="csl-entry" role="doc-biblioentry">
GEORGE, D. et al. A generative vision model that trains with high data
efficiency and breaks text-based CAPTCHAs. <strong>Science</strong>, v.
358, n. 6368, p. eaag2612, 2017.
</div>
<div id="ref-goodfellow2013" class="csl-entry" role="doc-biblioentry">
GOODFELLOW, I. J. et al. Multi-digit number recognition from street view
imagery using deep convolutional neural networks. <strong>arXiv preprint
arXiv:1312.6082</strong>, 2013.
</div>
<div id="ref-goodfellowGenerativeAdversarialNetworks2014" class="csl-entry" role="doc-biblioentry">
GOODFELLOW, I. J. et al. <strong>Generative <span>Adversarial
Networks</span></strong>. <span>arXiv</span>, jun. 2014. Disponível em:
&lt;<a href="https://arxiv.org/abs/1406.2661">https://arxiv.org/abs/1406.2661</a>&gt;.
</div>
<div id="ref-grandvalet2002" class="csl-entry" role="doc-biblioentry">
GRANDVALET, Y. <strong>Logistic regression for partial labels</strong>.
2002.
</div>
<div id="ref-hullermeier2006" class="csl-entry" role="doc-biblioentry">
HÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled
examples. <strong>Intelligent Data Analysis</strong>, v. 10, n. 5, p.
419439, 2006.
</div>
<div id="ref-ioffe2015" class="csl-entry" role="doc-biblioentry">
IOFFE, S.; SZEGEDY, C. <strong>Batch normalization: Accelerating deep
network training by reducing internal covariate shift</strong>. PMLR,
2015.
</div>
<div id="ref-ishida2017" class="csl-entry" role="doc-biblioentry">
ISHIDA, T. et al. Learning from complementary labels. <strong>Advances
in neural information processing systems</strong>, v. 30, 2017.
</div>
<div id="ref-jin2002" class="csl-entry" role="doc-biblioentry">
JIN, R.; GHAHRAMANI, Z. Learning with multiple labels. <strong>Advances
in neural information processing systems</strong>, v. 15, 2002.
</div>
<div id="ref-kaur2014" class="csl-entry" role="doc-biblioentry">
KAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review.
<strong>International Journal of Computer Science and Information
Technologies,</strong> v. 5, 1 jan. 2014.
</div>
<div id="ref-kingmaAdamMethodStochastic2017" class="csl-entry" role="doc-biblioentry">
KINGMA, D. P.; BA, J. Adam: <span>A Method</span> for <span>Stochastic
Optimization</span>. n. arXiv:1412.6980, jan. 2017. Disponível em:
&lt;<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>&gt;.
</div>
<div id="ref-kuhn2019" class="csl-entry" role="doc-biblioentry">
KUHN, M.; JOHNSON, K. <strong>Feature engineering and selection: A
practical approach for predictive models</strong>. CRC Press, 2019.
</div>
<div id="ref-lecun1998" class="csl-entry" role="doc-biblioentry">
LECUN, Y. et al. Gradient-based learning applied to document
recognition. <strong>Proceedings of the IEEE</strong>, v. 86, n. 11, p.
22782324, 1998.
</div>
<div id="ref-lecun2012" class="csl-entry" role="doc-biblioentry">
LECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.
</div>
<div id="ref-lecun2015" class="csl-entry" role="doc-biblioentry">
LECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning.
<strong>nature</strong>, v. 521, n. 7553, p. 436444, 2015.
</div>
<div id="ref-li2014" class="csl-entry" role="doc-biblioentry">
LI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control
chart. <strong>IIE Transactions</strong>, v. 46, n. 5, p. 526542, 2014.
</div>
<div id="ref-lillibridgeMethodSelectivelyRestricting2001" class="csl-entry" role="doc-biblioentry">
LILLIBRIDGE, M. D. et al. <strong>Method for Selectively Restricting
Access to Computer Systems</strong>., fev. 2001.
</div>
<div id="ref-liu2012" class="csl-entry" role="doc-biblioentry">
LIU, L.; DIETTERICH, T. A conditional multinomial mixture model for
superset label learning. <strong>Advances in neural information
processing systems</strong>, v. 25, 2012.
</div>
<div id="ref-michener2015" class="csl-entry" role="doc-biblioentry">
MICHENER, G.; MONCAU, L. F.; VELASCO, R. B. <strong>Estado brasileiro e
transparência avaliando a aplicação da Lei de Acesso à
Informação</strong>.
</div>
<div id="ref-mori2003a" class="csl-entry" role="doc-biblioentry">
MORI, G.; MALIK, J. <strong>Recognizing objects in adversarial clutter:
Breaking a visual CAPTCHA</strong>. IEEE, 2003.
</div>
<div id="ref-murray2012" class="csl-entry" role="doc-biblioentry">
MURRAY, N.; MARCHESOTTI, L.; PERRONNIN, F. <strong>AVA: A large-scale
database for aesthetic visual analysis</strong>. IEEE, 2012.
</div>
<div id="ref-murray-rust2008" class="csl-entry" role="doc-biblioentry">
MURRAY-RUST, P. Open data in science. <strong>Nature
Precedings</strong>, p. 11, 2008.
</div>
<div id="ref-na2020" class="csl-entry" role="doc-biblioentry">
NA, B. et al. <strong>Deep Generative Positive-Unlabeled Learning under
Selection Bias</strong>. : CIKM ’20.New York, NY, USA: Association for
Computing Machinery, 19 out. 2020. Disponível em: &lt;<a href="https://doi.org/10.1145/3340531.3411971">https://doi.org/10.1145/3340531.3411971</a>&gt;.
</div>
<div id="ref-nelder1972" class="csl-entry" role="doc-biblioentry">
NELDER, J. A.; WEDDERBURN, R. W. Generalized linear models.
<strong>Journal of the Royal Statistical Society: Series A
(General)</strong>, v. 135, n. 3, p. 370384, 1972.
</div>
<div id="ref-noh2017" class="csl-entry" role="doc-biblioentry">
NOH, H. et al. Regularizing deep neural networks by noise: Its
interpretation and optimization. <strong>Advances in Neural Information
Processing Systems</strong>, v. 30, 2017.
</div>
<div id="ref-magick" class="csl-entry" role="doc-biblioentry">
OOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021.
Disponível em: &lt;<a href="https://CRAN.R-project.org/package=magick">https://CRAN.R-project.org/package=magick</a>&gt;.
</div>
<div id="ref-rcran" class="csl-entry" role="doc-biblioentry">
R CORE TEAM. <strong>R: A Language and Environment for Statistical
Computing</strong>. Vienna, Austria: R Foundation for Statistical
Computing, 2021. Disponível em: &lt;<a href="https://www.R-project.org/">https://www.R-project.org/</a>&gt;.
</div>
<div id="ref-rameshHierarchicalTextConditionalImage2022" class="csl-entry" role="doc-biblioentry">
RAMESH, A. et al. Hierarchical <span>Text-Conditional Image
Generation</span> with <span>CLIP Latents</span>. n. arXiv:2204.06125,
abr. 2022. Disponível em: &lt;<a href="https://arxiv.org/abs/2204.06125">https://arxiv.org/abs/2204.06125</a>&gt;.
</div>
<div id="ref-reshefMethodSystemDiscriminating2005" class="csl-entry" role="doc-biblioentry">
RESHEF, E.; RAANAN, G.; SOLAN, E. <strong>Method and System for
Discriminating a Human Action from a Computerized Action</strong>.,
2005.
</div>
<div id="ref-sutton2018" class="csl-entry" role="doc-biblioentry">
SUTTON, R. S.; BARTO, A. G. <strong>Reinforcement learning: An
introduction</strong>. MIT press, 2018.
</div>
<div id="ref-decryptr" class="csl-entry" role="doc-biblioentry">
TRECENTI, J. et al. decryptr: An extensible API for breaking captchas.
2022.
</div>
<div id="ref-turing2009" class="csl-entry" role="doc-biblioentry">
TURING, A. M. Computing machinery and intelligence. Em: Springer, 2009.
p. 2365.
</div>
<div id="ref-reticulate" class="csl-entry" role="doc-biblioentry">
USHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’.
2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=reticulate">https://CRAN.R-project.org/package=reticulate</a>&gt;.
</div>
<div id="ref-vonahnCaptchaTellingHumans2003" class="csl-entry" role="doc-biblioentry">
VON AHN, L. et al. <strong>Captcha: <span>Telling</span> Humans and
Computers Apart Automatically</strong>. Proceedings of Eurocrypt.
<strong>Anais</strong>...2003.
</div>
<div id="ref-vonahnTellingHumansComputers2004" class="csl-entry" role="doc-biblioentry">
VON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart
Automatically. <strong>Communications of the ACM</strong>, v. 47, n. 2,
p. 56–60, 2004.
</div>
<div id="ref-inaccess" class="csl-entry" role="doc-biblioentry">
W3C. <strong>Inaccessibility of CAPTCHA</strong>., 2021. Disponível em:
&lt;<a href="https://www.w3.org/TR/turingtest/">https://www.w3.org/TR/turingtest/</a>&gt;.
</div>
<div id="ref-wang2021" class="csl-entry" role="doc-biblioentry">
WANG, Y. et al. Make complex captchas simple: a fast text captcha solver
based on a small number of samples. <strong>Information
Sciences</strong>, v. 578, p. 181194, 2021.
</div>
<div id="ref-stringr" class="csl-entry" role="doc-biblioentry">
WICKHAM, H. stringr: Simple, Consistent Wrappers for Common String
Operations. b2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=stringr">https://CRAN.R-project.org/package=stringr</a>&gt;.
</div>
<div id="ref-rvest" class="csl-entry" role="doc-biblioentry">
WICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível
em: &lt;<a href="https://CRAN.R-project.org/package=rvest">https://CRAN.R-project.org/package=rvest</a>&gt;.
</div>
<div id="ref-usethis" class="csl-entry" role="doc-biblioentry">
WICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and
Project Setup. 2022. Disponível em: &lt;<a href="https://CRAN.R-project.org/package=usethis">https://CRAN.R-project.org/package=usethis</a>&gt;.
</div>
<div id="ref-xml2" class="csl-entry" role="doc-biblioentry">
WICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em:
&lt;<a href="https://CRAN.R-project.org/package=xml2">https://CRAN.R-project.org/package=xml2</a>&gt;.
</div>
<div id="ref-ye2018" class="csl-entry" role="doc-biblioentry">
YE, G. et al. <strong>Yet another text captcha solver: A generative
adversarial network based approach</strong>. 2018.
</div>
<div id="ref-yu2018" class="csl-entry" role="doc-biblioentry">
YU, X. et al. <strong>Learning with biased complementary
labels</strong>. 2018.
</div>
<div id="ref-yuan2019" class="csl-entry" role="doc-biblioentry">
YUAN, X. et al. Adversarial examples: Attacks and defenses for deep
learning. <strong>IEEE transactions on neural networks and learning
systems</strong>, v. 30, n. 9, p. 28052824, 2019.
</div>
<div id="ref-zhao2017" class="csl-entry" role="doc-biblioentry">
ZHAO, B. Web scraping. <strong>Encyclopedia of big data</strong>, p. 13,
2017. Disponível em: &lt;<a href="https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf">https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf</a>&gt;.
</div>
<div id="ref-zhou2018" class="csl-entry" role="doc-biblioentry">
ZHOU, Z.-H. A brief introduction to weakly supervised learning.
<strong>National science review</strong>, v. 5, n. 1, p. 4453, 2018.
</div>
<div id="ref-zhu2005" class="csl-entry" role="doc-biblioentry">
ZHU, X. J. Semi-supervised learning literature survey. 2005.
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiada");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiada");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./conclusoes.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conclusões</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./pacote.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Pacotes</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>