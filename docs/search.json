[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Captchas",
    "section": "",
    "text": "Sobre este documento\nBlabla, RMarkdown…"
  },
  {
    "objectID": "introducao.html#captchas-em-serviços-públicos",
    "href": "introducao.html#captchas-em-serviços-públicos",
    "title": "1  Introdução",
    "section": "Captchas em serviços públicos",
    "text": "Captchas em serviços públicos\nA Constituição Federal de 1988 (CF), em seu inciso XXXIII do art. 5º, prevê que “todos têm direito a receber dos órgãos públicos informações de seu interesse particular, ou de interesse coletivo ou geral, que serão prestadas no prazo da lei, sob pena de responsabilidade, ressalvadas aquelas cujo sigilo seja imprescindível à segurança da sociedade e do Estado;”. Essa previsão é implementada pela Lei de Acesso à Informação (Lei 12.527/2011; LAI), que se aplica “aos órgãos públicos integrantes da administração direta dos Poderes Executivo, Legislativo, incluindo as Cortes de Contas, e Judiciário e do Ministério Público”, bem como “as autarquias, as fundações públicas, as empresas públicas, as sociedades de economia mista e demais entidades controladas direta ou indiretamente pela União, Estados, Distrito Federal e Municípios” (Art. 1º).\nA LAI, apesar de trazer diversos benefícios à sociedade, tem dois problemas. A primeira é o esforço: tanto a pessoa/órgão que solicita os dados, quanto o órgão que retorna os dados precisam trabalhar para disponibilizar as informações, sendo necessário deslocar equipes para realizar os levantamentos pedidos. A segunda é o formato: os dados enviados como resultado de pedidos de LAI podem chegar em formatos inadequados para consumo da solicitante, muitas vezes em Portable Document Format (PDF), que dificulta a leitura e análise dos dados (MICHENER; MONCAU; VELASCO, 2015, pág. 55); além disso, como o levantamento é realizado de forma individualizada, o mesmo pedido feito em diferentes períodos (e.g. uma atualização mensal dos dados) pode vir em formatos diferentes, dificultando a leitura e arrumação dos dados.\nUma forma de evitar os problemas de esforço e formato em pedidos de LAI é disponibilizar os dados de forma aberta. Como definido pela Open Knowledge Foundation (OKFN), a base de dados “deve ser fornecida em uma forma conveniente e modificável isento de obstáculos tecnológicos desnecessários para a realização dos direitos licenciados. Especificamente, os dados devem ser legíveis-por-máquina, disponíveis todo o seu volume, e fornecidos em um formato aberto (ou seja, um formato com sua especificação livremente disponível, e publicada sem qualquer restrições, monetárias ou não, da sua utilização) ou, no mínimo, podem ser processados com pelo menos uma ferramenta de software livre e gratuita.”1\nAs vantagens ao disponibilizar dados públicos de forma aberta para a sociedade é um tema pacífico na comunidade científica (MURRAY-RUST, 2008). Infelizmente, existem diversos dados públicos que não estão disponíveis de forma aberta, em plataformas como o dados.gov.br.\nA dificuldade de acesso é particularmente evidente no Poder Judiciário, que além de não disponibilizar um portal de dados abertos, impõe barreiras aos pedidos de acesso à informação por utilizar diversos sistemas para armazenar os dados. Por exemplo, para pedir uma lista de todos os processos judiciais relacionados a recuperação judicial de empresas, as únicas alternativas são i) pedir os dados ao Conselho Nacional de Justiça (CNJ), que não possui informações suficientes para obter a lista2 ou ii) expedir ofícios aos 27 Tribunais Estaduais. Cada tribunal apresentaria diferentes opções e critérios de acesso aos dados, diferentes prazos para atendimento e diferentes formatos, podendo, inclusive, negar o pedido de acesso.\nA dificuldade para acessar os dados do judiciário é a principal barreira para realização de pesquisas pela Associação Brasileira de Jurimetria (ABJ), empresa na qual o autor desta tese trabalha. A entidade tem como missão principal a realização de estudos para implementar políticas públicas utilizando dados do judiciário.\nDos 16 projetos disponibilizados na página de pesquisas no site da ABJ, pelo menos 12 (75%) apresentaram dificuldades na obtenção dos dados via pedidos de acesso aos órgãos. Três exemplos icônicos são o da pesquisa sobre Tempo dos processos relacionados à adoção no Brasil («Tempo dos processos relacionados à adoção», [s.d.]), o Observatório da Insolvência: Rio de Janeiro («Observatório da insolvência», [s.d.]) e o Diagnóstico do Contencioso Tributário Administrativo («Diagnóstico do Contencioso Tributário Administrativo», [s.d.]). No primeiro caso, dois tribunais enviaram os dados em arquivos em papel, sendo que um deles ultrapassou mil páginas com números de processos impressos. No segundo caso, o pedido foi respondido com uma planilha de contagens ao invés da lista de processos. No último caso, até mesmo órgãos que faziam parte do grupo de trabalho da pesquisa negaram pedido de acesso a dados de processos tributários em primeira instância, com argumentos que variavam desde a dificuldade técnica de levantar os dados até a Lei Geral de Proteção de Dados (LGPD).\nEm muitas situações, portanto, a única alternativa para realizar as pesquisas é acessando os dados via coleta automatizada nos sites. Todos os tribunais possuem ferramentas de consulta individualizadas de processos, por conta do que está previsto na CF. A solução, portanto, passa a ser construir uma ferramenta que obtém todos os dados automaticamente. Tal conceito é conhecido como raspagem de dados (ZHAO, 2017) e será desenvolvido com maiores detalhes no Capítulo Capítulo 2.\nOs Captchas se tornam prejudiciais à sociedade quando o acesso automatizado é necessário para realizar pesquisas científicas. Infelizmente, boa parte dos tribunais utilizam a barreira do Captcha. Alguns tribunais, inclusive, têm o entendimento de que o acesso automatizado é prejudicial, como o TJRS, que emitiu um comunicado sobre o tema.\nUma justificativa comum para implementar Captchas em consultas públicas é a estabilidade dos sistemas. Ao realizar muitas consultas de forma automática, um robô pode tornar o sistema instável e, em algumas situações, até mesmo derrubar o servidor que disponibiliza as consultas.\nO problema é que utilizar Captchas não impede o acesso automatizado. As empresas que fazem acesso automatizado em tribunais podem construir ferramentas ou utilizar serviços externos de resolução de Captchas. Ou seja, ao utilizar Captchas, o acesso não é impedido, e sim especializado.\nAlém disso, utilizar Captchas é uma solução ineficiente. Do ponto de vista técnico, a solução mais eficiente para disponibilizar os dados é através de ferramentas de dados abertos como o Comprehensive Knowledge Archive Network (CKAN). Ao disponibilizar os dados de forma aberta, as consultas automatizadas ficariam isoladas dos sites de consulta pública, o que garantiria o acesso das pessoas sem problemas de indisponibilidade.\nNão é só para as pessoas que fazem pesquisa com dados públicos que o uso de Captchas pode ser prejudicial. No mercado, existem serviços de resolução de Captcha que utilizam mão de obra humana, em regimes que pagam muito menos do que um salário mínimo a 8 horas de trabalho. Um exemplo é o 2Captcha3, que funciona como um Uber dos Captchas: o algoritmo automatizado envia o Captcha para a plataforma, que é acessado e resolvido por uma pessoa, retornando a solução para o algoritmo. O 2Captcha é operado pela ALTWEB LLC-FZ, uma empresa com base em Dubai4.\nSegundo o site, o valor pago pelo 2Captcha é de US$ 0.5 para 1 a 2 horas de trabalho. No regime da Consolidação das Leis do Trabalho (Decreto-Lei 5.452/1943, CLT) as horas mensais de trabalho são 220. Trabalhando continuamente no 2Captcha, isso daria um salário de 55 a 110 dólares por mês, valor bem abaixo do salário mínimo, que no ano de 2022 era de R$ 1.100,005. Ou seja, os serviços públicos acabam, indiretamente, incentivando um mercado que paga abaixo do salário mínimo. Luis von Ahn, um dos criadores dos Captchas, define o 2Captcha como um sweatshop, um termo utilizado para caracterizar empresas que têm condições de trabalho inaceitáveis.\nA solução definitiva para os problemas gerado pelos Captchas é a disponibilização dos dados públicos de forma aberta. Na ausência dessa solução, seja por falta de interesse ou iniciativa dos órgãos públicos, a alternativa é desenvolver uma solução para resolver Captchas que seja gratuita e aberta. Tal solução desincentivaria economicamente o uso de sistemas como o 2Captcha, protegendo as pessoas que fazem as resoluções e permitindo que as pessoas pesquisadoras realizem seus levantamentos.\nO presente trabalho busca avançar nesse sentido. A solução desenvolvida envolve um modelo que resolve alguns Captchas automaticamente, reduzindo significativamente a necessidade de rotulação manual.\nPara compreender completamente o avanço que a tese representa, no entanto, é necessário apresentar o histórico de desenvolvimento dos Captchas. O histórico é apresentado na próxima Seção, através da luta de geradores e resolvedores de Captchas, que pode ser dada como encerrada no ano de 2018, com o advento do reCaptcha v3."
  },
  {
    "objectID": "introducao.html#uma-luta-entre-geradores-e-resolvedores",
    "href": "introducao.html#uma-luta-entre-geradores-e-resolvedores",
    "title": "1  Introdução",
    "section": "Uma luta entre geradores e resolvedores",
    "text": "Uma luta entre geradores e resolvedores\nO primeiro texto técnico sobre Captchas foi publicado por AHN; BLUM; LANGFORD (2002). O texto apresenta o Captcha e seu significado através do problema de geração de emails automáticos no Yahoo. Em seguida, apresenta alguns exemplos de candidatos a Captcha, com tarefas de reconhecimento de padrões ou textos. Uma característica interessante que os autores colocam sobre o Captcha é que suas imagens devem ser disponíveis publicamente. O texto também faz a conexão entre a tarefa dos Captchas e os desafios da inteligência artificial. Um ponto a destacar é que os autores defendem que os Captchas devem ser resolvidos, pois isso implica em avanços na inteligência artificial. O site original do projeto, The Captcha Project, foi lançado em 2000.\nO relatório técnico de AHN; BLUM; LANGFORD (2002) não foi o primeiro a apresentar o nome Captcha, nem suas aplicações. RESHEF; RAANAN; SOLAN (2005) foi o primeiro registro de patente com o termo e LILLIBRIDGE et al. (2001) foi o primeiro registro de patente que implementou uma solução aos sistemas de Captchas. No entanto, o relatório de 2002 é o primeiro que reconhecidamente trata do tema como um problema de inteligência artificial como um teste de Turing automatizado.\nOs artigos mais conhecidos de introdução aos Captchas são VON AHN et al. (2003) e VON AHN; BLUM; LANGFORD (2004). O conteúdo dos trabalhos é o mesmo, sendo o primeiro deles na forma de apresentação e o segundo na forma de relatório. A apresentação é a primeira a mostrar o projeto reCaptcha, que será comentado em uma subseção própria. Um detalhe interessante é a ênfase dos autores no termo Public dos Captchas, mostrando a preocupação em manter os códigos públicos.\nOs autores também defendem que o Captcha é uma forma de fazer com que pessoas mal intencionadas contribuam com os avanços da inteligência artificial. Se uma pessoa (ainda que mal intencionada) resolve um Captcha e publica essa solução, isso significa que a comunidade científica avançou na área de inteligência artificial.\nNão demorou para surgirem os primeiros resolvedores de Captchas6. MORI; MALIK (2003) foi um dos primeiros trabalhos publicados sobre o tema e utiliza diversas técnicas de processamento de imagens para obter os rótulos corretos. Também não demorou para a comunidade científica perceber que redes neurais eram úteis nesse contexto (CHELLAPILLA; SIMARD, 2004). No artigo de 2004, Chellapilla e Simard desenvolvem um algoritmo baseado em heurísticas para segmentar a imagem e redes neurais para identificar as imagens individuais.\nA partir desse ponto, foi iniciada uma luta entre geradores e resolvedores de Captchas. Do lado dos geradores, as pessoas envolvidas foram tanto acadêmicos tentando desenvolver desafios cada vez mais difíceis para avançar na pesquisa em inteligência artificial, quanto empresas de tecnologia tentando se proteger contra programas avançados. Do lado dos resolvedores, as pessoas envolvidas foram tanto acadêmicos tentando desenvolver novas técnicas para avançar nos modelos de reconhecimento de imagens, quanto spammers buscando novas formas de realizar ataques cibernéticos.\nUm dos geradores de Captchas mais conhecidos é Luis von Ahn, que também é um dos criadores do Captcha. Um pedaço da história está disponível nos primeiros cinco minutos da entrevista com Luis Von Ahn em um programa chamado Spark7. Na entrevista, Von Ahn conta um pouco da origem dos Captchas em Carnegie Mellon, contando que ficou frustrado com o fato das pessoas perderem tempo de inteligência humana ao resolver Captchas, o que deu origem ao reCaptcha. Outro vídeo instrutivo é uma palestra de Von Ahn na Thinking Digital Conference sobre a história do reCaptcha8. Segundo ele, a startup foi criada em maio de 20079, depois de von Ahn perceber que aproximadamente 200 milhões de Captchas eram resolvidos diariamente.\nO reCaptcha v1 foi uma solução de aproveitar o tempo das pessoas que resolvem Captchas para digitalizar livros (AHN et al., 2008). A ideia do reCaptcha, como demonstrada na Figura 1.1, foi apresentar duas palavras distorcidas para a pessoa: a primeira seria utilizada para verificar se a pessoa era um humano, e a segunda seria utilizada para decifrar um texto que os robôs na época não conseguiam ler. Em 2009, a empresa foi comprada pela Google, que utilizou o reCaptcha para digitalizar os Google Books.\n\n\n\n\n\nFigura 1.1: Explicação de von Ahn sobre o funcionamento do reCaptcha\n\n\n\n\nCuriosamente, foi com a própria Google que os resolvedores ficaram em vantagem na luta. Os modelos de inteligência artificial continuaram avançando, notadamente com o avanço dos modelos de redes neurais profundas (LECUN; BENGIO; HINTON, 2015). No trabalho de GOODFELLOW et al. (2013), todos funcionários da Google na época, foi apresentado um modelo de redes neurais convolucionais que resolvia o reCaptcha v1 com 99.8% de acurácia. No ano seguinte, em 2014, a Google descontinuou o reCaptcha v1, lançando o reCaptcha v2.10\nO reCaptcha v2 apresentou duas inovações importantes. O primeiro foi o botão “I’m not a robot”, um verificador automático do navegador que utiliza heurísticas para detectar se o padrão de acesso ao site se assemelha com um robô ou humano. O segundo foi a mudança no tipo de tarefa: ao invés de rotular um texto distorcido, o desafio passou a ser identificar objetos e animais, como na Figura 1.2.\nA mudança do tipo de tarefa de visão computacional mudança foi importante para o sucesso do reCaptcha v2. Isso ocorre porque o desafio é mais difícil, já que existem muito mais objetos e imagens do que letras e números, aumentando significativamente o suporte da variável resposta. Por exemplo, um modelo para identificar um reCaptcha de gatos pode ser facilmente desenvolvido a partir de uma base pré-classificada, potencialmente custosa para ser construída. O reCaptcha v2, no entanto, pode facilmente mudar a tarefa para identificar leões, cães, hidrantes e semáforos, inutilizando o modelo criado para classificar gatos. O reCaptcha v2 também foi um sucesso para treinar os modelos desenvolvidos pela própria Google: usando o mesmo princípio do reCaptcha v1, a humanidade era verificada com apenas uma parte das imagens. As outras imagens eram utilizadas para rotular imagens, utilizadas para aprimorar os modelos utilizados nos projetos de carros autônomos, Google Street View e outras iniciativas da empresa.\n\n\n\n\n\nFigura 1.2: Exemplo do reCaptcha v2 com a imagens de perus\n\n\n\n\nCom o advento do reCaptcha v2, a pergunta dos resolvedores de Captcha passou a ser: como criar modelos que funcionam razoavelmente bem nos Captchas sem a necessidade de rotular vários casos? Se esse desafio fosse resolvido, dois avanços aconteceriam: i) um grande avanço na inteligência artificial, especificamente na área de visão computacional, e ii) uma nova forma de vencer a luta.\nAté o momento de escrita da tese, não existia um modelo geral que resolvesse com alta acurácia todos os desafios colocados pelo reCaptcha v2 e seus concorrentes. No entanto, vários avanços apareceram no sentido de reduzir a quantidade de imagens rotuladas para criar candidatos a resolvedores. Dentre eles, o mais significativos são os baseados nas redes generativas adversariais (Generative Adversarial Networks, ou GANs), propostas no famoso trabalho de GOODFELLOW et al. ([s.d.]). O primeiro trabalho que utiliza modelos generativos no contexto de Captchas mostrou uma redução de 300x na quantidade de dados classificados necessária para resolver um Captcha (GEORGE et al. (2017); nesse caso, os autores propõem uma rede diferente do GAN, chamada Recursive Cortical Network, ou RCN). Outros trabalhos mais recentes (WANG et al., 2021; YE et al., 2018) avançam ainda mais na pesquisa, reduzindo o trabalho de classificação para um novo Captcha de texto para aproximadamente 2 horas.\nMas foi em 2018, com o reCaptcha v3, que a Google deu a palavra final. Com a nova versão, as verificações de navegador passaram a ser muito mais poderosas, sendo raros os casos em que o site fica em dúvidas se a pessoa é ou não um robô. Versões mais recentes, como o reCaptcha Enterprise, de 2020, ainda permitem que as pessoas que mantêm os sites façam o ajuste de modelos de detecção de robôs. Os desafios de reconhecimento de texto, objetos ou imagens perderam a importância.\nEntão, no final, quem venceu a luta de geradores e resolvedores? Na verdade, nenhuma das duas! O que ocorreu com o reCaptcha v3 e seus sucessores foi, no fundo, uma mudança de perspectiva: o Captcha deixou de ser um sistema passivo e passou a ser um sistema ativo de verificação. Ao invés de criar uma tarefa difícil de resolver por robôs e fácil de resolver por pessoas, os sistemas criaram uma camada de verificação da sessão de acesso do usuário, incluindo análises do navegador, dos cookies e dos padrões de cliques. Antes mesmo de chegar no desafio de reconhecimento, o algoritmo de acesso precisa enganar os verificadores. Essa tarefa é muito mais parecida com um problema de cyberataque do que uma tarefa de inteligência artificial.\nA guerra entre sites e spammers continua, mas não é mais uma luta entre geradores e resolvedores. Por conta disso, os desafios dos Captchas, sejam de texto ou de imagem, são hoje muito mais uma questão acadêmica do que uma questão de segurança. A pesquisa sobre Captchas ainda é promissora e pode gerar muitos resultados importantes para a área de inteligência artificial.\nInfelizmente, Captchas de textos em imagens continuam sendo populares na internet. Isso é especialmente evidente nos serviços públicos – objeto deste trabalho –, já que os serviços raramente são atualizados com ferramentas mais recentes. Desenvolver uma ferramenta que facilita a resolução de Captchas em sites públicos é uma forma de incentivar os sites a serem atualizados. Se o Captcha inseguro parar de fazer efeito prático, os sites terão de atualizar a tecnologia, seja colocando Captchas mais poderosos, que é o resultado indesejado, ou disponibilizando os dados públicos de forma aberta, que é o resultado desejado.\nEssa é a lacuna identificada a partir da observação do estado atual dos serviços públicos e dos trabalhos acadêmicos analisados. Nesta pesquisa, será apresentado um fluxo de trabalho que pode ser facilmente aplicado a diferentes modelos de resolução de Captchas, incluindo arquiteturas que ainda não foram desenvolvidas. O fluxo de trabalho funcionará como um acelerador do aprendizado, possibilitando a criação de modelos que não precisam de intervenção humana. O resultado será encontrado explorando o potencial de uso do oráculo, apresentado na próxima seção."
  },
  {
    "objectID": "introducao.html#oráculo",
    "href": "introducao.html#oráculo",
    "title": "1  Introdução",
    "section": "Oráculo",
    "text": "Oráculo\nModelos de aprendizagem profunda usuais, quando ajustados sem cuidado, são muito sensíveis a perturbações pequenas nas imagens (YUAN et al., 2019). Por isso, se o site de um tribunal, por exemplo, mudar o Captcha utilizado, seria necessário baixar e anotar uma nova base de dados para treinar o modelo. Os avanços em técnicas de regularização fazem com que o modelo seja menos afetado por mudanças nos desafios gerados. Uma técnica de regularização que ajuda na capacidade de generalização é a aumentação de dados com adição de ruídos (NOH et al., 2017). No entanto, nenhuma técnica garante que o modelo terá excelentes resultados em novos desafios.\nOutra alternativa é desenvolver modelos que aprendem com poucos dados anotados. Como comentado anteriormente, GANs e modelos relacionados podem apresentar bons resultados na resolução de tarefas de imagens, mesmo com uma base de dados anotada. Nesse sentido, ainda que um site mude seu Captcha, é possível ajustar um modelo que resolve esse Captcha sem a necessidade de anotar muitos exemplos para construir uma nova base de treino.\nNessa tese, apresenta-se uma nova técnica para resolver Captchas com poucos dados anotados, chamada de oráculo. A técnica consiste em aproveitar o fato de que o Captcha aplica um teste de Turing automático para gerar bases de dados automaticamente. Ou seja, a técnica resolve o problema não com modelos mais sofisticados, mas com a utilização eficiente dos recursos disponíveis. Qualquer modelo pode se aproveitar dessa característica dos Catpchas, incluindo arquiteturas que ainda não foram desenvolvidas.\nOráculo é a resposta do site pesquisado, afirmando se o rótulo enviado está correto. Eles estão disponíveis em todos os sites com Captchas, já que, por definição, o Captcha precisa apresentar o resultado do teste para o usuário. O nome “oráculo” foi inspirado na mitologia grega, partindo do fato de que o site já possui a informação correta, como um deus. O site, no entanto, se comunica com o usuário através de um intermediário (o oráculo) que apresenta a resposta de forma limitada.\nOráculos se manifestam de diversas formas nos sites com Captchas. Por exemplo, pode dar a possibilidade de realizar apenas um teste por imagem, vários testes por imagem, ou ainda retornar informações ruidosas. Um exemplo de oráculo ruidoso é o reCaptcha v1, que pode retornar com um “bom o suficiente” quando o rótulo não está totalmente correto (AHN et al., 2008).\nO oráculo é uma forma de obter uma base virtualmente infinita. Do ponto de vista de modelagem, é similar a um problema de aprendizado por reforço (SUTTON; BARTO, 2018), mas com uma resposta binária (acertou ou errou) no lugar de um escore.\nA técnica consiste em utilizar um modelo inicial, possivelmente fraco. Em seguida, o site é acessado múltiplas vezes, gerando uma nova base de dados virtualmente infinita, que é completamente anotada nos casos de acerto e que apresenta o histórico de erros no caso de erro. O modelo inicial poderia ser ajustado com as técnicas usuais de modelagem, ou utilizando um modelo mais sofisticado como GAN.\nInfelizmente, utilizar somente os casos classificados corretamente, obtidos dos acertos no teste do oráculo, induz viés de seleção na amostra (NA et al., 2020). Como o modelo só tem acesso aos casos em que já funciona bem, a informação obtida não é tão relevante. O desafio de modelagem da tese reside em como considerar a informação fornecida pelo oráculo nos casos em que o modelo inicial erra.\nDo ponto de vista estatístico, a informação produzida pelo oráculo pode ser entendida como uma informação censurada (COLOSIMO; GIOLO, 2006). Isso acontece pois a informação existe e é correta, mas não está completa. No entanto, como a informação é resultado do teste de um rótulo produzido por um modelo, faz sentido afirmar que a censura não é gerada por acaso.\nNa área de aprendizado de máquinas, um modelo apresenta resposta censurada ou incompleta é colocado na classe de problemas do aprendizado fracamente supervisionado (ZHOU, 2018). Trata-se de uma área ainda pouco investigada estudada na literatura, mas bastante ampla, englobando não só os métodos supervisionados como também os métodos semi-supervisionados. A tese apresentará os conceitos de aprendizado fracamente supervisionado, com foco na classe de problemas que a modelagem utilizando Captchas representa.\nPara criar uma base de dados usando o oráculo, é necessário utilizar técnicas de raspagem de dados, imitando repetidamente o que um usuário faria para acessar o site. Por isso, a raspagem de dados se torna fundamental para a construção do modelo, tornando-se um dos objetivos da pesquisa."
  },
  {
    "objectID": "introducao.html#objetivos",
    "href": "introducao.html#objetivos",
    "title": "1  Introdução",
    "section": "Objetivo",
    "text": "Objetivo\nO objetivo geral da tese é desenvolver uma solução inovadora, chamada WAWL (Web Automatic Weak Learning) para resolver Captchas, misturando técnicas de aprendizado profundo com raspagem de dados e aproveitando os dados fornecidos pelo oráculo.\nEspecificamente, a pesquisa tem como objetivos:\n\nDescrever o modelo proposto e estudar suas propriedades.\nConstruir e disponibilizar um repositório de dados para realização de mais pesquisas no ramo.\nAjustar e testar a eficácia do modelo proposto.\nDisponibilizar um pacote computacional aberto, possibilitando a resolução de Captchas presentes em serviços públicos."
  },
  {
    "objectID": "introducao.html#justificativa",
    "href": "introducao.html#justificativa",
    "title": "1  Introdução",
    "section": "Justificativa",
    "text": "Justificativa\nO presente trabalho é relevante para a ciência por conta de sua importância prática, importância teórica e viabilidade técnica. Os pontos são explicados abaixo.\nCaptchas em serviços públicos causam desequilíbrio de mercado e incentivam o uso de serviços com formas de remuneração duvidosas. O objetivo 4 vai de encontro direto com esse problema, disponibilizando uma ferramenta gratuita e aberta para resolução de Captchas que, pelo menos até a escrita da tese, pode ser utilizada em dezenas de serviços públicos.\nDo ponto de vista teórico, a tese é importante por apresentar uma aplicação muito elegante do aprendizado fracamente supervisionado. No caso do Captcha, como a base de dados fracamente supervisionada é virtualmente infinita, trata-se de uma excelente oportunidade para testar novas técnicas e como elas se comportam empiricamente. Os objetivos 1 e 2 estão relacionadas a essa justificativa.\nFinalmente, com relação à viabilidade técnica, o trabalho parte de uma lista de Captchas que já foram resolvidos utilizando aprendizado profundo. Como os Captchas já estão resolvidos, mesmo que a WAWL não apresentasse bons resultados – e apresenta – o projeto ainda teria como subprodutos as bases de dados e o pacote computacional disponibilizados abertamente. O objetivo 3 é o que torna a proposta tecnicamente viável."
  },
  {
    "objectID": "introducao.html#hipóteses",
    "href": "introducao.html#hipóteses",
    "title": "1  Introdução",
    "section": "Hipóteses",
    "text": "Hipóteses\n\nO projeto foi desenvolvido em torno de duas hipóteses principais. Tais hipóteses são oriundas tanto do levantamento bibliográfico realizado para desenvolver a pesquisa, quanto da experiência pessoal do autor em projetos de pesquisa aplicados.\n\nA utilização de aprendizado fracamente supervisionado com oráculo permite a criação de modelos que resolvem Captchas de textos em imagens sem a necessidade de criar grandes bases anotadas.\n\nSub-hipótese: É possível criar um modelo genérico que funciona bem e se adapta com o uso do oráculo.\nSub-hipótese: Com a teoria de aprendizado fracamente supervisionado, é possível demonstrar que modelos criados dessa forma apresentam desempenho análogo ao que seria obtido com bases totalmente supervisionadas.\n\nÉ possível aliar a área de raspagem de dados com a área de modelagem estatística.\n\nSub-hipótese: O uso de raspagem de dados como passo intermediário do processo de modelagem apresenta resultados positivos no poder preditivo dos Captchas.\nSub-hipótese: É possível criar um modelo com aprendizado ativo, que melhora continuamente conforme é utilizado nos sites."
  },
  {
    "objectID": "introducao.html#organização-do-trabalho",
    "href": "introducao.html#organização-do-trabalho",
    "title": "1  Introdução",
    "section": "Organização do trabalho",
    "text": "Organização do trabalho\nO segundo capítulo, “metodologia” contém todos os passos dados para construção da tese, tanto do ponto de vista teórico como prático. Parte-se da definição técnica dos Captchas, chegando até as redes neurais e a classe problema trabalhada de forma ampla. Em seguida, apresenta-se o método WAWL e suas características. Depois, a base de dados é descrita, mostrando as fontes de dados consideradas e as técnicas de raspagem de dados utilizadas. Por último, descreve-se, com detalhes, as simulações realizadas para obtenção dos resultados empíricos.\nO terceiro capítulo, “resultados”, apresenta os resultados da pesquisa. Do ponto de vista teórico, são apresentadas as demonstrações das propriedades do modelo. Do ponto de vista empírico, são apresentados os resultados das simulações e outros experimentos realizados com a técnica WAWL.\nNo quarto e último capítulo, “conclusão”, a pesquisa é concluída, com apresentação das considerações finais e próximos passos. Também foi incluído um apêndice descrevendo e documentando o pacote {captcha}, criado atingir o objetivo 4 da pesquisa.\n\n\n\n\nAHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web Security Measures. Science, v. 321, n. 5895, p. 1465–1468, 12 set. 2008. Disponível em: <https://www.science.org/doi/10.1126/science.1160379>.\n\n\nAHN, L. VON; BLUM, M.; LANGFORD, J. Telling humans and computers apart automatically or how lazy cryptographers do AI (Tech. Rep. No. CMU-CS-02-117). Disponível em: <http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf>.\n\n\nCHELLAPILLA, K. et al. Designing human friendly human interaction proofs (HIPs). : CHI ’05.New York, NY, USA: Association for Computing Machinery, 2 abr. 2005. Disponível em: <https://doi.org/10.1145/1054972.1055070>.\n\n\nCHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human interaction proofs (HIPs). Advances in neural information processing systems, v. 17, 2004.\n\n\nCOLOSIMO, E. A.; GIOLO, S. R. Análise de sobrevivência aplicada. Editora Blucher, 2006.\n\n\nDiagnóstico do Contencioso Tributário Administrativo., [s.d.]. Disponível em: <https://abj.org.br/pesquisas/bid-tributario/>.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, v. 358, n. 6368, p. eaag2612, 2017.\n\n\nGOODFELLOW, I. J. et al. Multi-digit number recognition from street view imagery using deep convolutional neural networks. arXiv preprint arXiv:1312.6082, 2013.\n\n\nGOODFELLOW, I. J. et al. Generative Adversarial Networks. [s.d.].\n\n\nInaccessibility of CAPTCHA., [s.d.]. Disponível em: <https://www.w3.org/TR/turingtest/>.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning. nature, v. 521, n. 7553, p. 436444, 2015.\n\n\nLILLIBRIDGE, M. D. et al. Method for Selectively Restricting Access to Computer Systems., fev. 2001.\n\n\nMICHENER, G.; MONCAU, L. F.; VELASCO, R. B. Estado brasileiro e transparência avaliando a aplicação da Lei de Acesso à Informação.\n\n\nMORI, G.; MALIK, J. Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA. IEEE, 2003.\n\n\nMURRAY-RUST, P. Open data in science. Nature Precedings, p. 11, 2008.\n\n\nNA, B. et al. Deep Generative Positive-Unlabeled Learning under Selection Bias. : CIKM ’20.New York, NY, USA: Association for Computing Machinery, 19 out. 2020. Disponível em: <https://doi.org/10.1145/3340531.3411971>.\n\n\nNOH, H. et al. Regularizing deep neural networks by noise: Its interpretation and optimization. Advances in Neural Information Processing Systems, v. 30, 2017.\n\n\nObservatório da insolvência: Rio de Janeiro., [s.d.]. Disponível em: <https://abj.org.br/pesquisas/obsrjrj/>.\n\n\nRESHEF, E.; RAANAN, G.; SOLAN, E. Method and System for Discriminating a Human Action from a Computerized Action., 2005.\n\n\nSUTTON, R. S.; BARTO, A. G. Reinforcement learning: An introduction. MIT press, 2018.\n\n\nTempo dos processos relacionados à adoção., [s.d.]. Disponível em: <https://abj.org.br/pesquisas/adocao/>.\n\n\nTURING, A. M. Computing machinery and intelligence. Em: Springer, 2009. p. 2365.\n\n\nVON AHN, L. et al. Captcha: Telling Humans and Computers Apart Automatically. Proceedings of Eurocrypt. Anais...2003.\n\n\nVON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart Automatically. Communications of the ACM, v. 47, n. 2, p. 56–60, 2004.\n\n\nWANG, Y. et al. Make complex captchas simple: a fast text captcha solver based on a small number of samples. Information Sciences, v. 578, p. 181194, 2021.\n\n\nYE, G. et al. Yet another text captcha solver: A generative adversarial network based approach. 2018.\n\n\nYUAN, X. et al. Adversarial examples: Attacks and defenses for deep learning. IEEE transactions on neural networks and learning systems, v. 30, n. 9, p. 28052824, 2019.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13, 2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning. National science review, v. 5, n. 1, p. 4453, 2018."
  },
  {
    "objectID": "metodologia.html#definição-do-problema",
    "href": "metodologia.html#definição-do-problema",
    "title": "2  Metodologia",
    "section": "Definição do problema",
    "text": "Definição do problema\n\nO problema a ser trabalhado é um caso de aprendizado fracamente supervisionado (ZHOU, 2018). Trata-se de uma generalização do aprendizado supervisionado e também do aprendizado semi-supervisionado. Usualmente, a área de aprendizado estatístico (ou aprendizado de máquinas) se concentra em dois tipos de problemas principais: o aprendizado supervisionado e o aprendizado não supervisionado. Isso ocorre principalmente por fins didáticos, pois é mais fácil passar os modelos que fazem parte de cada área.\nNo entanto, a estatística evolui com os problemas que ocorrem no mundo. E, no mundo, os problemas nem sempre recaem em uma ou outra categoria. O que temos, na verdade, é que os problemas não supervisionados e supervisionados estão conectados, desde que o objetivo de uma pesquisa seja o de predizer valores (regressão) ou categorias (classificação).\nNesse sentido, uma área que ficou popular nos últimos anos, até por conta dos avanços na área de Deep Learning, é o aprendizado semi-supervisionado (ZHU, 2005). Trata-se de uma classe de problemas contendo uma amostra completamente anotada e uma amostra sem anotações. A amostra sem anotações é usada para compreender como os dados foram gerados, e os parâmetros podem ser compartilhados com a parte supervisionada do modelo. Isso poderia indicar que existem três classes de problemas: o não supervisionado, o supervisionado e o semi-supervisionado.\nMas isso também não representa todas as classes de problemas. Em muitas aplicações reais, obter uma anotação completa e correta pode ser custoso ou até impraticável. Além disso por envolver trabalho humano, é comum que classificações contenham erros. Para lidar com esses casos existe uma área, que generaliza as anteriores, que é o aprendizado fracamente supervisionado.\nAprendizado fracamente supervisionado é um termo guarda-chuva. Dentro da área existem diversos tipos de problemas, como aprendizado semi-supervisionado, aprendizado de múltiplas instâncias (BLUM; KALAI, 1998) e o aprendizado com rótulos incorretos ou incompletos (ZHOU, 2018). O caso dos Captchas com o uso do oráculo será apresentado como outra classe de problemas, chamada aprendizado com rótulos parciais (partial label learning, PLL, (JIN; GHAHRAMANI, 2002)). Essa classe apresenta uma especialização ainda mais próxima do problema estudado, chamado aprendizado com rótulos complementares (complementary label learning, (ISHIDA et al., 2017a)).\nA intepretação do Captcha como um problema de PLL será apresentada no final do capítulo. A jornada começa de onde deve começar, com aqueles que são objeto de análise deste trabalho: os Captchas.\n\nCaptcha\nCaptcha é um desafio do tipo desafio-resposta usado para determinar se a usuário do sistema é um humano. Existem diversos tipos de Captcha diferentes, que envolvem desde identificar textos em imagens até resolver expressões matemáticas complexas.\nO foco deste trabalho reside nos Captchas baseados em imagens rotuladas, que é o tipo mais comum. Em seguida, a menos que se mencione ao contrário, todos os Captchas apresentados são desse tipo.\nO fluxo completo de um Captcha envolve cinco componentes: um rótulo, um gerador, uma imagem, um agente e um oráculo. Um ciclo do Captcha é completado ao seguir os passos:\n\nO rótulo é definido, usualmente com algum procedimento aleatório, ocultado do agente.\nA imagem é gerada a partir do rótulo e apresentada para o agente.\nO agente preenche sua resposta a partir da imagem (que pode estar certa ou errada)\nO oráculo verifica se a resposta está correta.\nDependendo da resposta, o agente é direcionado para a página autenticada ou para uma página de erro.\n\nA Figura 2.1 esquematiza o fluxo do Captcha.\n\n\n\n\n\nFigura 2.1: Fluxo do Captcha\n\n\n\n\n\nImagem, rótulo e variável resposta\nA imagem é uma matriz \\(\\mathbf x = \\{x_{nmr} \\in [0,1]\\}_{N\\times M \\times R}\\), contendo padrões que, a partir da análise humana, levam ao rótulo do Captcha. O rótulo é dado por um vetor de caracteres \\(\\mathbf c = [c_1,\\dots,c_L]^\\top\\). O comprimento \\(L\\) pode ser fixo ou variável, ou seja, duas imagens criadas pelo mesmo gerador podem vir com comprimentos diferentes. Nas definições que seguem considerou-se \\(L\\) como fixo, por simplicidade.\nCaptchas costumam ter dimensões relativamente pequenas, com a altura \\(N\\) variando entre 30 e 200 pixels e a largura \\(M\\) variando entre 100 e 300 pixels. As imagens costumam ser retangulares para comportar várias letras lado a lado, ou seja, geralmente \\(M > N\\). O valor de \\(R\\) é 1 para imagens em escala de cinza e 3 para imagens coloridas.\nOs elementos do vetor \\(\\mathbf c\\) fazem parte de um alfabeto \\(\\mathcal A\\), com cardinalidade \\(|\\mathcal A|\\), finito e conhecido. O alfabeto contém todos os possíveis caracteres que podem aparecer na imagem. Na maioria dos casos, \\(\\mathcal A\\) corresponde a uma combinação de algarismos arábicos (0-9) e letras do alfabeto latino (a-z), podendo diferenciar ou não as letras maiúsculas e minúsculas1.\nO elemento da matriz \\(x_{nm\\cdot}\\) é denominado pixel. Um pixel representa a menor unidade possível da imagem. Em uma imagem colorida, por exemplo, \\(R=3\\). Nesse caso, um pixel é um vetor de três dimensões com valores entre zero e um, representando a intensidade de vermelho, verde e azul da coordenada \\((n, m)\\) da imagem. Em imagens em escala de cinza, \\(R=1\\) e o pixel, de uma dimensão, representa a intensidade do cinza, sendo 1 o equivalente da cor branca e 0 da cor preta.\nA Figura 2.2 mostra um exemplo Captcha do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, tem-se \\(L=5\\) e \\(|\\mathcal A|=10\\), apenas os dez algarismos arábicos. A imagem tem dimensões \\(N=110\\), \\(M=40\\) e \\(R=3\\). O rótulo da imagem é \\([5,2,4,3,2]^\\top\\).\n\n\n\n\n\nFigura 2.2: Exemplo de Captcha no TJMG.\n\n\n\n\nA variável resposta é uma matriz binária \\(\\mathbf y_{L \\times |\\mathcal A|}\\), em que cada linha representa um dos valores do vetor \\(\\mathbf c\\), enquanto as colunas possuem um representante para cada elemento de \\(\\mathcal A\\). Um elemento \\(y_{ij}\\) vale 1 se o elemento \\(i\\) do rótulo \\(\\mathbf c\\) corresponde ao elemento \\(j\\) do alfabeto \\(\\mathcal A\\), valendo zero caso contrário. A variável resposta pode ser pensada também como o one-hot encoding do rótulo.\nUma maneira alternativa de definir a variável resposta seria com um vetor de índices representando cada elemento do alfabeto em um vetor. O problema de trabalhar dessa forma é que a variável resposta \\(\\mathbf y\\) tem um número exponencial de combinações: o rótulo possui \\(L\\) caracteres, sendo que cada caractere pode ter \\(|\\mathcal A|\\) valores, totalizando \\(|\\mathcal A|^L\\) combinações.\nPor exemplo, um Captcha com \\(L=6\\) letras e \\(|\\mathcal A| = 36\\) possibilidades em cada letra (26 letras do alfabeto latino e 10 algarismos arábicos), possui um total de 2.176.782.336 (\\(>\\) 2 bilhões) combinações. Por isso, modelar as imagens diretamente através de uma única variável resposta categórica é tecnicamente inviável.\nA forma one-hot da resposta pode ser entendida como uma multinomial multivariada (LI; TSUNG; ZOU, 2014). A resposta é multivariada porque temos \\(L\\) caracteres na imagem e multinomial porque temos \\(|\\mathcal A|\\) possíveis caracteres em cada posição. Dessa forma, podemos pensar que um modelo que resolve o Captcha envolve \\(L\\) classificadores com resposta multinomial, cada um dando conta de um dos caracteres. Os classificadores podem ser independentes e podem até contar com etapas de pré-processamento separadas.\nSeguindo o exemplo da Figura 2.2, é possível representar o rótulo da seguinte forma:\n\\[\n\\mathbf c = \\left[\\begin{array}{c}\n     5  \\\\\n     2 \\\\\n     4 \\\\\n     3 \\\\\n     2\n\\end{array}\\right] \\rightarrow \\mathbf{y} = \\left[\\begin{array}{cccccccccc}\n    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{array}\\right]\n\\]\nA forma dummy da resposta facilita os trabalhos que seguem. Como será visto mais adiante, o modelo de rede neural gerará uma matriz de probabilidades que somam \\(1\\) em cada linha, com as probabilidades de cada caractere em cada posição.\n\n\nGerador\nO gerador é uma função \\(g\\) que recebe um rótulo como entrada e devolve uma imagem como saída. Um bom gerador é aquele que é capaz de gerar uma imagem fácil de interpretar por humanos, mas difícil de se resolver por máquinas.\nUm exemplo de gerador é a função captcha_generate() criada no pacote {captcha}, como descrito no Apêndice A. A função foi criada para realizar simulações do sistema de resolução proposto na tese, a partir do pacote {magick} (OOMS, 2021), que utiliza o software ImageMagick. A função aplica uma série de distorções e efeitos comuns no contexto de Captchas, gerando imagens como a da Figura 2.3.\n\n\n\n\n\nFigura 2.3: Exemplo de captcha gerado pela função captcha::captcha_generate()\n\n\n\n\nO gerador segue os passos abaixo, a partir do momento em que um rótulo \\(\\mathbf c\\) existe:\n\nÉ criada uma matriz \\(N\\times M \\times R\\), com valores entre zero e um gerados por simulações de uma \\(\\mathcal U(0,1)\\).\nÉ adicionada uma cor base ao ruído, definida de forma aleatória.\nA matriz é transformada em um objeto do tipo magick-image.\nA imagem é preenchida com o valor do rótulo, adicionando-se efeitos como rotação, uma linha unindo as letras e variação de cores.\nA imagem recebe outros tipos de distorções, como adição de ruído, alteração de cores e outros efeitos.\n\nNo final, o gerador retorna a imagem, que é a única informação enviada ao agente. O rótulo fica escondido para verificação do oráculo.\n\n\nOráculo\nPara definir o oráculo, utilizou-se uma terminologia que é facilmente encaixada com a teoria de aprendizado fracamente supervisionado. Seja \\(g\\) um classificador utilizado para predizer o rótulo de uma imagem e seja \\(\\mathbf X_{n+1}\\) uma nova imagem que é observada, com sua resposta \\(\\mathbf Y_{n+1}\\), desconhecida. A operação \\(g(\\mathbf X_{n+1}) = \\hat {\\mathbf Y}_{n+1}\\) retorna um candidato para \\(\\mathbf Y_{n+1}\\), que pode estar correto ou errado.\nO oráculo é uma função \\(\\mathcal O: \\mathcal Y \\rightarrow 2^{\\mathcal Y}\\), ou seja, uma função que recebe um elemento do domínio da resposta \\(\\mathcal Y\\) (ou seja, do conjunto de todas as combinações de rótulos) para o conjunto de subconjuntos (as partes) de \\(\\mathcal Y\\). Na prática, a função retorna uma lista de possíveis valores de \\({\\mathbf Y}_{n+1}\\), da seguinte forma:\n\\[\n\\mathcal O(\\hat {\\mathbf Y}_{n+1}) = \\left\\{\\begin{array}{ll}\n    \\{\\mathbf Y_{n+1}\\}, & \\text{ se } \\mathbf Y_{n+1} = \\hat {\\mathbf Y}_{n+1}  \\\\\n    \\mathcal Y \\setminus \\{\\hat {\\mathbf Y}_{n+1}\\}, & \\text{ se } \\mathbf Y_{n+1} \\neq \\hat {\\mathbf Y}_{n+1}\n\\end{array}\\right.\n\\]\nQuando o classificador \\(g\\) acerta o rótulo, o oráculo retorna uma lista que contém apenas um elemento: o próprio rótulo. Para simplificar, também é possível utilizar a notação de rótulo complementar \\(\\mathbf Y_{n+1} \\neq \\hat {\\mathbf Y}_{n+1} = \\bar{\\mathbf Y}\\). Quando o classificador \\(g\\) retorna o rótulo errado, o oráculo retorna uma lista com todos os outros possíveis rótulos do rótulo, o que inclui o verdadeiro valor \\(\\mathbf Y_{n+1}\\).\nA Figura 2.4 mostra o funcionamento do oráculo no exemplo do TJMG. Quando a predição é igual ao rótulo, o resultado apresentado é o valor um, indicando que o rótulo está correto. Quando a predição é diferente do rótulo, o resultado apresentado é o valor zero, indicando que o valor testado está incorreto e que, portanto, o rótulo real é um dentre todos os outros possíveis rótulos.\n\n\n\n\n\nFigura 2.4: Esquema mostrando o funcionamento do oráculo.\n\n\n\n\nÉ possível generalizar naturalmente o oráculo para múltiplos chutes mudando a definição da função que faz predições. Seja \\(h\\) uma função que retorna um conjunto de \\(k\\) respostas possíveis, \\(k\\in \\mathbb N\\), \\(k\\geq 1\\), com \\(\\mathbf x_{n+1}\\) e \\(\\mathbf y_{n+1}\\) iguais aos definidos definidos anteriormente. Então o oráculo tem o funcionamento definido abaixo:\n\\[\n\\mathcal O(h(\\mathbf x_{n+1})) = \\left\\{\\begin{array}{ll}\n    \\{\\mathbf y_{n+1}\\}, & \\text{ se } \\mathbf y_{n+1} \\in h(\\mathbf x_{n+1})  \\\\\n   \\mathcal Y \\setminus h(\\mathbf x_{n+1}), & \\text{ se } \\mathbf y_{n+1} \\notin h(\\mathbf x_{n+1})\n\\end{array}\\right..\n\\]\nNesse caso, o oráculo também retorna uma lista com a resposta \\(\\mathbf y_{n+1}\\). A única diferença é que, quando o Captcha aceita múltiplos chutes, a lista retornada em caso de erro tem um comprimento menor.\nO oráculo tem um papel fundamental na solução proposta. O fato do oráculo sempre retornar a resposta correta na lista de opções faz com que ela necessariamente reduza o espaço de respostas a serem buscadas em uma tentativa futura. Esse fato será explorado a partir de um método iterativo para encontrar o valor real do rótulo.\n\n\nFatos estilizados\nHistoricamente, uma alternativa para resolver Captchas é separando o problema em duas tarefas: segmentar e classificar. A tarefa de segmentação consiste em receber uma imagem com várias letras e detectar pontos de corte, separando-a em várias imagens de uma letra. Já a classificação consiste em receber uma imagem com uma letra e identificar o caractere correspondente. Nesse caso, a resposta é reduzida para \\(|\\mathcal A|\\) categorias, que cresce linearmente e, portanto, tratável.\nA tarefa de resolver Captchas também poderia ser vista como um problema de reconhecimento óptico de caracteres (Optical Character Recognition, OCR). No entanto, as distorções encontradas em Captchas são bem diferentes das distorções encontradas em textos escaneados, que são o objeto de aplicação de ferramentas de OCR. Por esse motivo, as ferramentas usuais de OCR apresentam resultados pouco satisfatórios em vários Captchas.\nAs distorções encontradas em Captchas podem ser agrupadas em distorções para dificultar a segmentação e distorções para dificultar a classificação. Na parte de classificação, as principais formas de dificultar o trabalho dos modelos são i) mudar as fontes (serifa ou sem serifa ou negrito/itálico, por exemplo), ii) mudar letras minúsculas para maiúsculas e iii) adicionar distorções nos caracteres. Já na parte de segmentação, as principais formas são i) colar os caracteres e ii) adicionar linhas ligando os dígitos. Essas técnicas são combinadas com a adição de ruído e distorção nas imagens completas para compor a imagem final.\n\n\n\nRedes neurais\nA abordagem discutida ao longo da tese utiliza redes neurais convolucionais. Para explicar o funcionamento dessa técnica, apresenta-se as definições para redes neurais e para a operação de convolução no contexto de Captchas, construindo o modelo utilizado nas simulações do modelo proposto.\n\nA ideia abaixo é apresentar como funcionam as redes neurais no contexto de Captchas. O modelo apresentado é o que foi utilizado nas simulações, que é um modelo de redes neurais convolucionais simples, similar ao LeNet, com três camadas convolucionais e duas camadas densas (LECUN et al., 1998).\nA técnica proposta pela tese pode utilizar diversas arquiteturas de redes neurais. A escolha de uma arquitetura mais simples foi feita para demonstrar a eficácia do procedimento de forma mais contundente. Outras arquiteturas mais rebuscadas, como as apresentadas no referencial teórico (GEORGE et al., 2017; YE et al., 2018) podem melhorar a aplicação do modelo. A única restrição é que ela possa receber uma função de perda modificada, como será mostrado a seguir.\nÉ possível organizar a estrutura de uma rede neural em três componentes: a arquitetura da rede, a função de perda e o otimizador. Os componentes são detalhados nas próximas subseções.\nComo uma rede neural possui muitos componentes e subcomponentes, é usual apresentar sua estrutura na forma de um diagrama. Redes neurais costumam ser fáceis de representar através de grafos, que podem ser utilizados de forma mais ou menos detalhada, dependento do interesse.\nA Figura 2.5 mostra, de forma esquemática, os componentes (retângulos tracejados) e subcomponentes (partes internas dos componentes) do modelo utilizado.\n\n\n\n\n\nFigura 2.5: Diagrama representando o modelo utilizado de forma genérica, com todos os componentes e subcomponentes apresentados de forma esquemática. As partes de fora dos componentes são entradas de dados ou decisões de parada do ajuste.\n\n\n\n\n\nArquitetura da rede\nA arquitetura da rede é uma função que leva os dados de entrada na estrutura de dados da variável resposta. A arquitetura tem papel similar ao exercido pelo componente sistemático em um modelo linear generalizado (NELDER; WEDDERBURN, 1972). Trata-se da parte mais complexa da rede neural, carregando todos os parâmetros que serão otimizados.\nA arquitetura da rede possui três componentes principais, separados em dois itens cada:\n\nas camadas ocultas: camadas convolucionais e camadas densas;\nas técnicas de regularização: normalização em lote (batch normalization), dropout e junção de pixels (max pooling);\nas funções de ativação: função de ativação linear retificada (rectified linear unit, ReLU) e a função de normalização exponencial (softmax).\n\nAbaixo, apresenta-se as definições seguindo-se a ordem de aplicação das operações na arquitetura da rede neural: camada convolucional, ReLU, max pooling, batch normalization, dropout, camada densa e softmax.\nA convolução é uma operação linear que recebe como entrada uma matriz e retorna outra matriz. Ela é diferente de uma operação usual de multiplicação de matrizes vista no contexto de modelos lineares generalizados, por envolver uma operação nos elementos na vizinhança de cada pixel.\nUma forma organizada de fazer essa soma ponderada é criando uma matriz de pesos. Com ela, não é necessário procurar os pontos da vizinhança. Para cada ponto \\((i,j)\\), obtem-se a matriz de vizinhança, multiplica-se pontualmente pela matriz de pesos e soma-se os valores resultantes. A matriz de pesos é chamada de núcleo, ou kernel.\nConsidere\n\\[\nK = \\left[\\begin{array}{rrr}-1&-1&-1\\\\0&0&0\\\\1&1&1\\end{array}\\right]\n\\]\ne a imagem da Figura 2.6. Como visto anteriormente, trata-de de uma matriz de dimensão \\(40\\times110\\times3\\).\n\n\n\n\n\nFigura 2.6: Imagem de Captcha utilizado em exemplos anteriores.\n\n\n\n\nTome por exemplo a primeira dimensão do pixel \\((i,j,k) = (12,16,1)\\). A vizinhança 3x3 em torno desse ponto é dada por\n\n\n\n\\[\nP_{i,j,k} = \\left[\\begin{array}{rrr}\n0.094 & 0.412 & 0.686 \\\\\n0.051 & 0.063 & 0.529 \\\\\n0.071 & 0.000 & 0.086\n\\end{array}\\right]\n\\]\nA operação de convolução é feita da seguinte forma:\n\\[\n\\begin{aligned}\n(P_{12,16,1} *K )_{12,16,1}\n&= k_{1,1}p_{11,15,1} + k_{1,2}p_{11,16,1} + k_{1,3}p_{11,17,1} + \\\\\n&+ k_{2,1}p_{12,15,1} + k_{2,2}p_{12,16,1} + k_{2,3}p_{12,17,1} + \\\\\n&+ k_{3,1}p_{13,15,1} + k_{3,2}p_{13,16,1} + k_{3,3}p_{13,17,1}\n\\end{aligned}\n\\]\nEsse é o valor a ser colocado no ponto \\((i,j,k)\\). Isso funciona em todos os pontos que não estão na borda da imagem.\nExistem duas formas de trabalhar com as bordas da imagem. A primeira é preenchendo as bordas com zeros, de forma a considerar apenas os pontos da imagem. A segunda é descartar os pontos da borda e retornar uma imagem menor, contendo somente os pixels em que foi possível aplicar todo o kernel.\nNo caso do exemplo, o resultado da convolução fica como na Figura 2.7. A matriz não foi escolhida por acaso: ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada por \\(-1\\) e a última é formada por \\(1\\), a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (\\(\\text{grande} * 1 + \\text{pequeno} * (-1)\\)). A parte destacada da imagem acabou sendo a parte de baixo dos números e, principalmente, a linha que une os números.\n\n\n\n\n\n\n\n\nFigura 2.7: Aplicação de uma convolução com kernel horizontal.\n\n\n\n\nAplicando o kernel vertical abaixo\n\\[\nK = \\left[\\begin{array}{rrr}-1&0&1\\\\-1&0&1\\\\-1&0&1\\end{array}\\right],\n\\]\nas partes destacadas são as laterais dos números, conforme Figura 2.8.\n\n\n\n\n\nFigura 2.8: Aplicação de uma convolução com kernel horizontal.\n\n\n\n\nO resultado da convolução pode ter números negativos ou maiores que um. Para que seja possível visualizar, as imagens mostradas acima foram normalizadas.\nUma característica das imagens mostradas acima é que elas ficaram escuras, ou seja, com muitos valores próximos de zero. Uma técnica para modificar a imagem é adicionar uma constante numérica ao resultado da convolução. Esse é o chamado viés (bias) da convolução.\nA Figura 2.9 mostra o efeito de adicionar um viés de 0.6 após aplicação da convolução com kernel vertical. É possível idenificar claramente a diferença entre os números (mais suaves) e as curvas usadas para conectar os números (mais proeminetes).\n\n\n\n\n\nFigura 2.9: Aplicação de uma convolução com kernel horizontal.\n\n\n\n\nUma camada convolucional envolve a aplicação de convoluções com \\(d\\) kernels em uma matriz, além da adição do bias. O resultado da aplicação de uma camada convolucional com preenchimento das bordas é uma matriz com as mesmas dimensões \\(N\\) e \\(M\\) da matriz de entrada, mas com \\(d\\) entradas na dimensão das cores. Como o valor de \\(d\\) pode ser diferente de 1 ou 3, não faz mais sentido tratar essa dimensão como cores, por isso essa dimensão é chamada de canais da imagem resultante.\nÉ importante notar que, nos exemplos apresentados anteriormente, a convolução foi aplicada a apenas um dos canais da imagem: o primeiro. Quando a imagem de entrada possui vários canais, camada convolucional aplica cada kernel em cada canal da imagem e, depois, faz a soma dos valores resultantes.\nA Figura 2.10 mostra um exemplo de aplicação de camada convolucional para a imagem utilizada nos exemplos anteriores. Os kernels foram escolhidos com base em um modelo que já foi ajustado para o Captcha. Note que os canais capturam a informação dos números e dos ruídos, focando em detalhes diferentes.\n\n\n\n\n\n\n\n\nFigura 2.10: Resultado da aplicação da primeira convolução à imagem.\n\n\n\n\nAntes da aplicação da camada convolucional, a operação de batch normalization foi aplicada. Essa operação normaliza os números da matriz de entrada antes da aplicação da convolução, retirando a média e dividindo pelo desvio padrão.\n\\[\nx_z = \\left(\\frac{x-\\bar x}{\\sqrt{\\sigma^2_x + \\epsilon}}\\right) \\gamma + \\beta\n\\]\nO valor \\(\\epsilon\\), geralmente um valor pequeno, é adicionado para evitar problemas numéricos quando a variância é muito baixa. Os parâmetros \\(\\gamma\\) e \\(\\beta\\) podem ser adicionados no passo da normalização, fazendo parte do fluxo de aprendizagem do modelo. Apesar de não ser uma teoria fechada, alguns resultados indicam que o uso de batch normalization reduz o tempo de aprendizado dos modelos (IOFFE; SZEGEDY, 2015). O passo foi adicionado nos modelos por apresentar bons resulados nas simulações.\nApós a aplicação da convolução, também é aplicada a função não linear ReLU. A transformação ReLU é a mais simples das funções da ativação, sendo igual à função identidade quando a entrada é positiva e zero caso contrário:\n\\[\n\\text{ReLU}(x) = x\\mathbb I_{(x>0)}.\n\\]\nA função ReLU serve para tornar a arquitetura do modelo uma operação não linear. Qualquer operação não linear poderia ser utilizada, mas a mais simples e mais popular é a ReLU.\nEm seguida, aplica-se uma operação para reduzir a dimensão da imagem, chamada max pooling. Trata-se de uma operação que recebe a imagem e um kernel, retornando, para cada janela, o maior valor dos pixels. Usualmente, a técnica também utiliza strides fazendo com que cada pixel seja avaliado apenas uma vez. Por exemplo, para uma matriz com dimensões \\(M_{10\\times10}\\) e kernel com dimensões \\(2\\times2\\), o resultado é uma matriz \\(M^p_{5\\times5}\\) onde cada elemento é o valor máximo da janela correspondente ao pixel.\nA operação max pooling é muito comum no contexto de redes neurais convolucionais. Sua aplicação é importante para que os kernels sejam aplicados em diferentes níveis da imagem de entrada.\nA aplicação das camadas convolucionais é repetida três vezes. Ou seja, as seguintes operações são aplicadas a partir da imagem original:\n\nbatch normalization: 6 parâmetros\ncamada convolucional: 896 parâmetros\nReLU\nmax pooling\nbatch normalization: 64 parâmetros\ncamada convolucional: 18.496 parâmetros\nReLU\nmax pooling\nbatch normalization: 128 parâmetros\ncamada convolucional: 36.928 parâmetros\nReLU\nmax pooling\nbatch normalization: 128 parâmetros\n\nA dimensão da imagem de entrada, bem como quantidade de canais gerados por cada camada convolucional foram fixadas. Tais números podem ser considerados como hiperparâmetros do modelo, mas foram fixados para facilitar as simulações, que já contam com diversos hiperparâmetros.\nA imagem de entrada foi fixada na dimensão \\(32\\times192\\). O valor foi definido dessa forma porque um dos Captchas de referência, da Receita Federal do Brasil (RFB), possui 6 letras e \\(32*6=192\\). Ou seja, é como se a imagem fosse a colagem lado a lado de 6 imagens \\(32\\times32\\).\nA quantidade de canais gerados pelas camadas convolucionais foram fixadas em 32, 64 e 64. A utilização de números crescentes de canais nas camadas convolucionais é comum (LECUN et al., 1998), bem como a utilização de números que são potências de 2 (LECUN; BENGIO; HINTON, 2015). Nesse sentido, um possível valor para a terceira camada era de 128 canais, mas optou-se por 64 canais para que a quantidade de parâmetros não ficasse grande demais, já que isso exigiria mais tempo de computação e computadores mais poderosos.\nO total de parâmetros que podem ser otimizados até o final das camadas convolucionais é 56.646. Esse número pode parecer grande no contexto de modelos estatísticos tradicionais como uma regressão linear, que teria, considerando cada pixel como uma covariável, 4.401 parâmetros (\\(40\\times110\\) e o intercepto). No entanto, é uma quantidade relativamente pequena no contexto de redes neurais. Redes neurais recentes aplicadas a imagens, como o DALL-E 2 possui 3,5 bilhões de parâmetros (RAMESH et al., [s.d.]).\nEm seguida, o resultado é transformado para um formato retangular, similar ao que se encontra em modelos de regressão. Aqui, as dimensões da imagem não são mais importantes e os pixels de cada canal são tratados como variáveis preditoras. Esse passo pode ser interpretado da seguinte forma: as camadas convolucionais funcionam como um pré-processamento aplicado às imagens, como uma engenharia de variáveis (KUHN; JOHNSON, 2019) otimizada, já que os parâmetros são ajustados no modelo.\nUma vez obtidas as variáveis preditoras com o pré-processamento, é a hora de aplicar as camadas densas. Tais camadas são as mais comuns no contexto de redes neurais. Nesse caso, a operação linear aplicada é uma multiplicação de matrizes, similar ao que é feito em um modelo linear generalizado. Na verdade, o componente sistemático de um modelo linear generalizado é equivalente a uma camada densa com a aplicação de viés, com a função de ativação da fazendo o papel da função de ligação.\nAssim como existem os canais das camadas convolucionais, existem os filtros das camadas densas. A quantidade de filtros define a dimensão do vetor de saída. O número de parâmetros da camada densa é igual ao número de itens no vetor de entrada multiplicado pelo número de filtros, somado à quantidade de filtros novamente, por conta do bias. No caso do exemplo, a saída das camadas convolucionais tem dimensão \\(2\\times22\\times64\\) , ou seja, 64 canais de imagens \\(2\\times 22\\). Com a transformação em vetor, a quantidade de colunas da base passa a ser a multiplicação das dimensões, ou 2.816. No modelo ajustado que foi utilizado como exemplo, aplicou-se 200 filtros na camada densa, totalizando 563.400 parâmetros. Nas simulações, a quantidade de filtros foi variada para produzir modelos com menor ou maior capacidade.\nÉ no contexto da grande quantidade de parâmetros que entra o conceito do dropout (BALDI; SADOWSKI, 2013). Trata-se de uma regra de regularização muito simples de implementar, mas que possui grande impacto no ajuste dos modelos. A técnica consiste em selecionar uma amostra dos parâmetros em uma das camadas e apagá-los, forçando que os valores sejam fixados em zero. Na prática, essa técnica obriga o modelo a ser ajustado de forma que amostras aleatórias dos parâmetros sejam boas para predizer a variável resposta. Quando o modelo ajustado é usado para inferências, o dropout é desativado e o modelo pode utilizar todos os parâmetros, obtendo-se, na prática, uma média ponderada das predições de cada sub-modelo. Dessa forma, o dropout tem um efeito similar à aplicação da técnica de bagging (GALAR et al., 2011), muito utilizada na área de árvores de decisão.\nO dropout é aplicado após a finalização das camadas convolucionais. Em seguida, vem a primeira camada densa, um ReLU e um batch normalization. Depois, é aplicada mais um dropout e mais uma camada densa. Com isso, a aplicação de operações é finalizada. O total de parâmetros na configuração do modelo apresentado foi de 630.496. Os modelos mais simples utilizados nas simulações, com 100 filtros na camada densa, têm 343.696. Os mais complexos, com 300 filtros na camada densa, têm 917.396 parâmetros.\nPara finalizar a arquitetura do modelo, as quantidades resultantes devem ser ajustadas ao formato da variável resposta. O número de filtros da segunda camada densa precisa ser escolhido cuidadosamente, pois deve ser igual à multiplicação das dimensões da variável resposta. No caso do TJMG, os rótulos têm comprimento igual a 5 e vocabulário de comprimento 10 (algarismos arábicos), organizados em uma matriz \\(5\\times10\\), com 50 entradas. Por isso, a quantidade de filtros da última camada densa também é 50, e o vetor de saída é formatado para uma matriz de dimensão \\(5\\times10\\).\nNo final, o resultado precisa ser normalizado para que fique no mesmo escopo de variação da resposta. A resposta possui apenas zeros e uns, sendo que cada linha da matriz tem somente um número “1”, correspondendo ao índice do rótulo no alfabeto e, nas outras entradas, o valor zero. A saída do modelo deve, portanto, apresentar números entre zero e um que somam 1 em cada linha.\nIsso é feito através da função softmax, aplicada a cada linha da matriz de saída. A função softmax é uma normalização que utiliza a função exponencial no denominador, forçando que a soma dos valores do vetor seja um.\n\\[\n\\text{soft}\\max(y_i) = \\frac{e^{y_i}}{\\sum_{j=1}^{|\\mathcal A|} e^{y_j}}\n\\]\nNo exemplo, a saída do modelo é a matriz abaixo:\n\\[\n\\hat{\\mathbf z} = \\left[\\begin{array}{rrrrrrrrrr}\n  -17.5 & -13.5 & -15.4 & -6.6 & -9.9 & 9.9 & -11.4 & -10.9 & -11.8 & -9.3 \\\\\n  -10.9 & -15.6 & 8.3 & -6.5 & -11.0 & -10.3 & -10.0 & -5.8 & -11.4 & -15.1 \\\\\n  -10.5 & -13.6 & -9.6 & -11.4 & 11.2 & -14.3 & -9.9 & -11.3 & -9.9 & -10.0 \\\\\n  -18.1 & -9.6 & -10.9 & 5.3 & -10.1 & -6.6 & -15.5 & -13.3 & -6.8 & -10.8 \\\\\n  -11.3 & -8.7 & 6.4 & -7.0 & -6.1 & -9.2 & -18.9 & -10.3 & -16.1 & -9.6 \\\\\n\\end{array}\\right].\n\\]\nNote que a matriz apresenta valores negativos e positivos. Na primeira linha, por exemplo, o valor positivo está na sexta coluna, correspondendo ao algarismo “5”. De fato, esse é o valor do primeiro elemento do rótulo para esta imagem. Após a aplicação do softmax, a matriz de predições obtida é a matriz abaixo. O modelo de exemplo aparenta ter confiança nas respostas, já que dá probabilidades bem altas para alguns valores e quase zero para outros valores.\n\\[\n\\hat{\\mathbf y}\\times 1000 = \\left[\\begin{array}{rrrrrrrrrr}\n  0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 0.00 & 999.99 & 0.00 & 0.01 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 999.99 & 0.00 & 0.00 & 0.00 & 0.00 & 0.01 & 0.00 & 0.00 \\\\\n\\end{array}\\right].\n\\]\nVale notar que, dependendo da implementação, nem sempre é necessário aplicar a função softmax. Em alguns pacotes computacionais como o torch2, utilizado nesta tese, a normalização pode ser feita diretamente na função de perda, que aproveita a expressão completa para realizar algumas simplificações matemáticas e, com isso, melhorar a precisão das computações. O uso da função de perda ficará claro na próxima subseção.\n\n\nPerda\nA função de perda utilizada em um problema de classificação deve levar em conta as probabilidades (ou log-probabilidades) associadas aos rótulos. A perda deve ser pequena se a probabilidade associada ao rótulo correto for alta e a perda deve ser grande se a probabilidade associada ao rótulo correto for baixa.\nUma função de perda natural e popular nesse sentido é a de entropia cruzada, ou cross-entropy. Trata-se de uma perda com a formulação\n\\[\n\\ell(g(x), y) = -\\sum_{i=1}^c \\mathbb I(y=i)\\log(g_i(x)),\n\\]\nem que \\(g_i(x)\\) é a probabilidade dada ao rótulo \\(i\\) pela função \\(g\\). Se o rótulo \\(i\\) é diferente do rótulo correto \\(y\\), a função de perda vale zero por conta da função indicadora. Quando \\(i=y\\), a perda é igual ao oposto do logaritmo da probabilidade associada ao rótulo \\(i\\). Quanto menor a probabilidade, maior o valor da perda.\nAo trabalhar com o oráculo, a entropia cruzada passa a não fazer sentido nos casos em que o modelo inicial erra. Por isso, a função de perda terá de ser adaptada no método WAWL.\n\n\nOtimizador\nO otimizador utilizado para os modelos ajustados na tese foi o ADAM (KINGMA; BA, [s.d.]). A sigla significa Adaptive Moment Estimator e funciona como uma extensão da descida de gradiente estocástica (LECUN et al., 2012), atualizando os parâmetros da seguinte forma:\n\\[\n\\begin{array}{cl}\nm_{\\theta}^{(t+1)} &\\leftarrow \\beta_1m_{\\theta}^{(t)} + (1-\\beta_1)\\nabla_\\theta L^{(t)} \\\\\nv_{\\theta}^{(t+1)} &\\leftarrow \\beta_2v_{\\theta}^{(t)} + (1-\\beta_2)(\\nabla_\\theta L^{(t)})^2 \\\\\n\\hat{m}_{\\theta} &= \\frac{m_\\theta^{(t+1)}}{1-\\beta_1^t} \\\\\n\\hat{v}_{\\theta} &= \\frac{v_\\theta^{(t+1)}}{1-\\beta_2^t} \\\\\n\\theta^{(t+1)} &\\leftarrow \\theta^{(t)} - \\eta \\frac{\\hat{m}_{\\theta}}{\\sqrt{\\hat{v}_{\\theta}} + \\epsilon},\n\\end{array}\n\\]\nonde \\(m\\) e \\(v\\) são médias moveis para atualização dos parâmetros, ponderando a perda e a perda ao quadrado com o passo anterior usando pesos \\(\\beta_1\\) e \\(\\beta_2\\), respectivamente. Nessa notação \\(\\eta\\) é a taxa de aprendizado, um hiperparâmetro a ser ajustado. Por último, o valor de \\(\\epsilon\\) é uma constante, usualmente pequena, para evitar divisão por zero.\n\n\n\nAprendizado estatístico\nApresentados o objeto de estudo, as redes neurais utilizadas e a proposta da pesquisa, passa-se a discutir o significado disso tudo no contexto de aprendizado estatístico. Essa parte foi escrita para proporcionar a base teórica e a notação para apresentar as propriedades do modelo WAWL.\nO aprendizado fracamente supervisionado pode ser dividido em três tipos principais. A supervisão com erros, a supervisão com rótulos incompletos e a supervisão de grupos de observações. O caso do Captcha pode ser entendido como uma sub-área do aprendizado fracamente supervisionado com rótulos incompletos chamada aprendizado com dados parcialmente rotulados (partial label learning, PLL), já que uma parte da base pode ser anotada sem erros e uma parte da base é a resposta do oráculo indicando uma lista de rótulos possíveis incluindo o correto.\nA área de PLL não é nova (GRANDVALET, 2002) e aparece com outros nomes, como aprendizado com rótulos ambíguos (HÜLLERMEIER; BERINGER, 2006) e aprendizado de rótulos em superconjuntos (superset-label learning) (LIU; DIETTERICH, 2012). Um caso particular de PLL, aplicável ao tema do Captcha são rótulos complementares (ISHIDA et al., 2017b), que considera os chutes errados na notação do problema.\nAs definições seguem uma terminologia adaptada a partir da leitura de JIN; GHAHRAMANI (2002), COUR; SAPP; TASKAR (2011) e FENG et al. (2020a). Sempre que possível, os casos são adaptados para o problema do Captcha diretamente. Quando necessário, apresenta-se primeiro a definição genérica e depois a formulação para o Captcha.\nEm um problema de aprendizado supervisionado tradicional, tem-se um conjunto de casos rotulados \\(S=\\{(\\mathbf x_i,y_i), i=1,\\dots, m\\}\\) com uma distribuição \\(p(\\mathbf X,Y)\\) desconhecida, onde \\(\\mathbf X\\in \\mathcal X\\) é uma imagem e \\(\\mathbf Y\\) é o rótulo, que possui \\(|A|^L\\) possíveis valores. O objetivo é obter um classificador \\(g\\) que leva um valor de \\(\\mathbf x\\) para o rótulo correto \\(\\mathbf y\\).\nPara delimitar se o resultado da aplicação do classificador está bom ou ruim, utiliza-se uma função de perda. No caso do Captcha, como o interesse é simplesmente acertar o rótulo inteiro (não importa se o classificador acerta só uma parte do rótulo), utiliza-se uma função chamada 0-1:\n\\[\n\\mathcal L(g(\\mathbf x),\\mathbf y) = \\mathbb I (g(\\mathbf x) \\neq \\mathbf y),\n\\tag{2.1}\\]\nem que \\(\\mathbb I(\\cdot)\\) é uma função indicadora. Como a função de perda é aplicada a apenas um par \\((\\mathbf x,y)\\), define-se formalmente que o objetivo do problema de aprendizado é minimizar o risco, que é o valor esperado da função de perda:\n\\[\n\\mathcal R(g) = \\mathbb E_{p(\\mathbf X,Y)}[\\mathcal L(g(\\mathbf X),Y)].\n\\tag{2.2}\\]\nA função de risco, no entanto, não é observada, já que depende da distribuição desconhecida de \\(p(\\mathbf X,Y)\\). Para lidar com esse problema, usualmente é utilizado um estimador do risco, calculado tanto em bases usadas na validação cruzada quanto na base de teste.\n\\[\n\\hat{\\mathcal R}(g) = \\sum_{i=1}^n \\ell(g(\\mathbf x),y))\n\\]\nNa base de teste, utilizada para estimar o risco, a função de perda 0-1 é apropriada. Na etapa de validação cruzada de um modelo de aprendizado profundo, é útil considerar uma aproximação da função de perda que seja contínua e derivável, funcionando como uma versão suavizada da perda 0-1. A partir de um vetor de parâmetros \\(\\boldsymbol \\theta\\) originados da arquitetura do modelo, uma escolha de função de perda é a entropia cruzada, como mostrado anteriormente. Os parâmetros são estimados a partir de um otimizador, como o ADAM, apresentado na Seção 2.1.2.3.\nAs definições começam a precisar de ajustes quando \\(y\\) deixa de ser um rótulo fixado. Como descrito na Seção 2.1.1.3, a base de dados observada contém tanto rótulos observados de forma exata quanto rótulos apenas parcialmente informados. Nesse caso, os dados são gerados por uma distribuição\n\\[\np(\\mathbf X,\\mathbf Y,\\bar{\\mathbf Y})=p(\\mathbf X, \\mathbf Y)p(\\bar{\\mathbf Y}|\\mathbf X,\\mathbf Y),\n\\]\nem que \\(\\bar{\\mathbf Y}\\) é um conjunto de rótulos incorretos. Nesse caso observam-se, além das instâncias \\((\\mathbf x_i,\\mathbf y_i)\\) quando o modelo inicial acerta, as instâncias \\((\\mathbf x_j, \\bar{\\mathbf {y}}_j)\\) quando o modelo inicial erra. Supondo que \\(\\bar{\\mathbf Y}\\) é condicionalmente independente de \\({\\mathbf Y}\\) dado \\({\\mathbf X}\\), temos que\n\\[\np(\\mathbf X,\\mathbf Y,\\bar{\\mathbf Y})=p(\\mathbf X, \\mathbf Y)p(\\bar{\\mathbf Y}|\\mathbf Y).\n\\]\nNo caso dos Captchas, essa suposição é verificada. A probabilidade do modelo inicial errar depende apenas do rótulo e não das distorções realizadas pela imagem gerada a partir do rótulo. Além disso, a partir do modelo inicial, é possível estimar os valores de \\(p(\\bar{\\mathbf Y}|\\mathbf Y)\\) a partir da base de teste utilizada para medir a acurácia do modelo.\nNos casos em que \\(|\\hat{\\mathbf Y}|=1\\), as probabilidades \\(p(\\bar{\\mathbf Y}|\\mathbf Y)\\) podem ser organizadas em uma matriz de transição \\(\\mathbf Q\\), contendo as probabilidades de se obter um rótulo incorreto para cada possível valor do rótulo. Isso acontece nos Captchas em que não é possível realizar múltiplos chutes. Para resolver problemas desse tipo, é possível realizar um ajuste na função de predição que a torna a função de perda consistente e com taxa de convergência conhecida (YU et al., 2018):\n\\[\nf_{\\text{adj}} (\\mathbf X) = \\mathbf Q ^{\\top}f(\\mathbf X)\n\\]\nO tipo de problema apresentado acima é conhecido como biased complementary label, ou seja, rótulo complementar com viés. Também é possível considerar um caso sem viés, ou seja, quando \\(p(\\bar{\\mathbf Y}|\\mathbf Y) = \\frac{1}{c-1}\\) para todos os valores de \\(\\mathbf Y\\). Esse caso também foi resolvido do ponto de vista teórico(ISHIDA et al., 2017a). As conclusões são parecidas, ou seja, é possível encontrar taxas de convergência para que o problema com rótulos complementares se aproxime de um problema com observações completas.\nQuando os rótulos complementares não apresentam viés, existe ainda uma extensão para rótulos complementares múltiplos (FENG et al., 2020b). Neste caso, é possível derivar uma função de risco empírica que, novamente, converge para a função de risco do problema completamente supervisionado, além de apresentar taxas de convergência para essa função de risco.\nO caso do oráculo e dos Captchas é um problema com múltiplos rótulos complementares e com viés. Até o momento, não existe uma solução geral para este tipo de problema. No entanto, espera-se que as soluções para problemas desse tipo tenham taxas de convergência mais estreitas do que o caso de rótulos complementares, com ou sem viés, já que rótulos complementares múltiplos trazem mais informação do que rótulos complementares simples."
  },
  {
    "objectID": "metodologia.html#sec-wawl",
    "href": "metodologia.html#sec-wawl",
    "title": "2  Metodologia",
    "section": "Método WAWL",
    "text": "Método WAWL\nO método WAWL (Web Automatic Weak Learning) é a solução proposta na pesquisa. Trata-se da técnica baixar dados da web para compor parte da amostra que é utilizada no ajuste do modelo.\nO método WAWL é inovador por dois motivos. Primeiro, porque o método faz a ponte entre áreas que até o momento eram partes separadas do ciclo da ciência de dados: a raspagem de dados e o aprendizado estatístico. Além disso, o método é uma nova alternativa para resolver Captchas com pouca ou nenhuma intervenção humana.\nExistem duas formas principais de aplicar o método WAWL. A primeira criando novas bases de treino a partir de um modelo inicial e atualizando os modelos com os dados baixados. A segunda é baixando os dados dentro do próprio ciclo de ajuste do modelo, acessando a web no momento de construção de um minibatch.\nA arquitetura do modelo WAWL pode ser a mesma de um modelo ajustado com uma base completamente anotada. O modelo pode, inclusive, aproveitar os parâmetros já ajustados em uma eventual versão inicial do modelo para acelerar o aprendizado. Nada impede, no entanto, que uma arquitetura diferente seja utilizada, desde que a entrada seja uma imagem e a saída seja uma matriz com as dimensões da variável resposta. O WAWL é agnóstico à arquitetura do modelo.\nA função de perda deve ser adaptada para considerar a informação limitada fornecida pelo oráculo. Quando o rótulo fornecido pelo modelo está correto, a informação é considerada normalmente, através da função de perda da regressão multinomial multivariada. Já quando o rótulo fornecido pelo modelo é incorreto, a função de perda é calculada com base na probabilidade do rótulo estar incorreto:\n\\[\n1 - p(\\mathbf y|\\boldsymbol \\theta),\n\\]\nConsiderando o rótulo complementar \\(\\bar y\\) e a função \\(\\hat f\\) dada pela rede neural, a fórmula para descrever a função de perda é descrita da seguinte forma:\n\\[\nl(\\bar y, \\hat f(\\mathbf x)) = -\\log\\left[1 - \\sum_{y}\\hat {f_y}(\\mathbf x) \\mathbb I(y=\\bar y)\\right]\n\\]\nA função de perda proposta pode ser explicada de maneira intuitiva através de um exemplo. Considere um problema com apenas \\(c\\) possíveis valores para o rótulo (ou seja, uma resposta multinomial, sem ser multivariada). Considere também que a rede neural retorna uma alta probabilidade, por exemplo, \\(0.99\\), para o valor \\(i\\), que o oráculo identificou como incorreta. Nesse caso, a função de perda é dada por\n\\[\nl(i,\\hat f(\\mathbf x)) = -\\log\\left[1-\\hat {f_i}(\\mathbf x)\\right] = -\\log\\left[1-0.99 \\right] = 4.61\n\\]\nComo é possível ver no exemplo, quanto maior a probabilidade dada a um rótulo identificado como incorreto pelo oráculo, mais a função de perda penaliza essa predição. Dessa forma, a função de perda consegue incorporar completamente a informação dada pelo oráculo.\nQuando o Captcha aceita múltiplos chutes, a mesma conta é válida, bastando subtrair as probabilidades de todos os rótulos incorretos:\n\\[\nl(\\bar {\\mathbf y}, \\hat f(\\mathbf x)) = -\\log\\left[1 - \\sum_{y}\\hat {f_y}(\\mathbf x) \\mathbb I(y \\in \\bar {\\mathbf y})\\right]\n\\]\nNo final, o valor que é passado para a função de perda é a soma das perdas para todas as observações do minibatch. A soma considera tanto as perdas calculadas com base nos rótulos corretos quanto as perdas calculadas com base nos rótulos incorretos.\nO otimizador que obtém novas estimativas dos parâmetros também não precisa ser modificado. Basta aplicar a mesma técnica utilizada na modelagem usual, como descida de gradiente estocástica ou métodos adaptativos, como RMSProp ou Adam.\nUm detalhe importante sobre o método é sobre a implementação. Com a utilização de ferramentas que fazem diferenciação automática como o torch e o TensorFlow3, basta implementar a parte da arquitetura, a função de perda e especificar o otimizador, já que o processo de atualização dos parâmetros é feito automaticamente. No entanto, dependendo da implementação, não é possível fazer a atualização dos parâmetros usando o componente de computação gráfica, que potencialmente acelera o ajuste dos modelos de forma significativa. Na implementação atual, a função de perda apresentada não permite utilização desse componente, sendo uma melhoria possível em futuros trabalhos.\nO ajuste dos modelos, tanto para simulações quanto para construção dos modelos finais, utilizou o pacote {torch} (FALBEL; LURASCHI, 2022), que é uma implementação do PyTorch para a linguagem de programação R (R CORE TEAM, 2021). O pacote {luz} (FALBEL, 2022a) foi utilizado para organizar as funções de perda e hiperparâmetros, enquanto o pacote {torchvision} (FALBEL, 2022b) foi utilizado para utilidades no tratamento de imagens."
  },
  {
    "objectID": "metodologia.html#dados",
    "href": "metodologia.html#dados",
    "title": "2  Metodologia",
    "section": "Dados",
    "text": "Dados\nNesta seção, descreve-se em detalhes como foi a obtenção dos dados para realizar a pesquisa. Como comentado anteriormente, a base foi construída do zero para os fins do projeto, sendo uma parte significativa dos esforços para chegar nos resultados.\nNo total, foram construídas bases de dados de dez Captchas que estavam disponíveis publicamente no período de realização da pesquisa. Os Captchas foram revisados pela última vez no dia 14/09/2022, para verificar se ainda estavam ativos. Além disso, foram construídas duas bases de dados de Captchas desenvolvidos internamente para fins de teste.\nParte dos dados foram obtidos como um passo intermediário das simulações. A presente seção descreve como os robôs de coleta foram construídos, bem como a metodologia para obter rótulos via classificação manual. Na subseção de dados da seção de simulação, é possível acessar informações sobre os dados baixados para realizar as simulações.\n\nEscolha dos Captchas analisados\nPara selecionar os Captchas, foram adotados alguns critérios objetivos. Os critérios foram:\n\nO site acessado é de um serviço público (governo federal, tribunal, etc).\nO Captcha contém letras (A a Z) e números (0 a 9) em uma imagem com extensão jpeg ou png.\nO comprimento do Captcha é fixo, ou seja, dois Captchas da mesma origem devem ter sempre o mesmo comprimento.\n\nA primeira restrição para escolha dos Captchas é de ordem principiológica. Um serviço público não deveria restringir o acesso aos dados para robôs. Como já discutido anteriormente, nesses casos, a existência do Captcha não tem como finalidade dar maior segurança ao serviço prestado, mas sim limitar o acesso aos servidores por robôs.\nAs restrições 2 e 3 foram escolhidas com o objetivo de facilitar as simulações para obtenção dos resultados. Em princípio, nada impede que os modelos desenvolvidos trabalhem com outros tipos de rótulos, desde que exista uma lista prévia de rótulos. Além disso, é possível realizar adaptações no pré-processamento base de dados para lidar com diferentes comprimentos de Captchas.\nA Tabela 2.1 mostra os Captchas trabalhados. Dos 10 exemplos trabalhados, 6 têm origem em tribunais, que são conhecidos por não disponibilizarem os dados de forma aberta.\n\n\n\n\nTabela 2.1:  Lista de captchas analisados. CaptchaExemploDescriçãotrf5Tribunal Regional Federal 5tjmgTribunal de Justiça de Minas GeraistrtTribunal Regional do Trabalho 3esajTribunal de Justiça da BahiajucespJunta Comercial de São PaulotjpeTribunal de Justiça de PernambucotjrsTribunal de Justiça do Rio Grande do SulcadespCentro de Apoio ao Desenvolvimento da Saúde PúblicaseiSistema Eletrônico de Informações - MErfbReceita Federal\n\n\n\nAlém dos Captchas de sites, também foram consideradas imagens geradas artificialmente. O motivo de criar Captchas artificiais é a facilidade de rodar modelos e simulações, já que nos casos reais é necessário ter acesso à internet e também construir bases de dados de cada Captcha.\nForam gerados dois tipos de Captchas artificiais. O primeiro, chamado MNIST-Captcha, é simplesmente uma adaptação da conhecida base MNIST para ficar no formato de um Captcha. A partir da escolha do comprimento e dos caracteres que fazem parte da imagem, o gerador simplesmente faz uma amostra aleatória da base do MNIST e compõe as imagens horizontalmente.\nA Figura 2.11 mostra um exemplo do Captcha gerado a partir da base MNIST. No exemplo, o comprimento escolhido para o Captcha foi de 4 valores.\n\n\n\n\n\nFigura 2.11: Exemplo de MNIST-Captcha\n\n\n\n\nO problema do MNIST-Captcha é que a base de dados original é finita. Apesar de possuir por volta de 60 mil observações e de um Captcha crescer em ordem exponencial, o MNIST-Captcha pode gerar Captchas repetidos. Além disso, é necessário tomar cuidado com as bases de treino e teste, já que os elementos de teste não poderiam fazer parte de nenhuma observação de treino.\nPelos motivos supracitados, também foi criado um Captcha gerado inteiramente por programação, chamado R-Captcha. O Captcha é gerado utilizando a ferramenta ImageMagick, com a possibilidade de customizar diversos parâmetros, como\n\nQuais caracteres usar na imagem\nO comprimento do Captcha\nDimensões da imagem\nProbabilidade de rotação da imagem\nProbabilidade de adicionar um risco entre as letras\nProbabilidade de adicionar uma borda nas letras\nProbabilidade de adicionar uma caixa (retângulo) em torno das letras\nProbabilidade de adicionar um ruído branco no fundo da imagem\nProbabilidade de adicionar efeitos de tinta óleo e implosão\n\nA Figura 2.12 mostra um exemplo de R-Captcha. O exemplo apresenta uma linha ligando as letras, comprimento 4, dígitos maiúsculos e minúsculos e distorções.\n\n\n\n\n\nFigura 2.12: Exemplo de MNIST-Captcha\n\n\n\n\nPor ser uma versão mais flexível e completa, optou-se por trabalhar principalmente com o R-Captcha nas simulações. O MNIST-Captcha foi implementado mas não foi utilizado nas simulações.\n\n\nConstrução dos dados\nPara obter os dados da pesquisa, foram utilizadas técnicas de raspagem de dados (ZHAO, 2017). A raspagem de dados é uma área da ciência da computação responsável por criar rotinas que automatizam a coleta de dados provenientes da web. Trata-se de uma atividade muito comum em pesquisas aplicadas, especialmente as que envolvem análise de dados públicos que não estão disponíveis de forma aberta, como os dados do Judiciário.\nDentro do ciclo da ciência de dados, pode-se considerar que a raspagem de dados está inserida nas tarefas de coleta e arrumação de dados. De certa forma, é possível comparar a raspagem com uma consulta a um banco de dados remoto, ou mesmo à obtenção de informações através de uma Application Programming Interface (API).\nPara raspar uma página da web, usualmente se segue o fluxo descrito na Figura 2.13. Nem todos os passos foram seguidos na obtenção dos dados necessários para realizar as simulações, mas é importante conhecê-los para compreender bem a origem da ideia de utilizar raspagem em conjunto com métodos de aprendizado de máquinas. O exemplo da RFB foi utilizado para dar contexto aos passos.\n\n\n\n\n\nFigura 2.13: Ciclo da raspagem de dados. Fonte: curso de Web Scraping da Curso-R.\n\n\n\n\nNo caso da RFB, o trabalho é iniciado acessando-se a página inicial de busca de CNPJ, como mostrado na Figura 2.14. É possível notar que o desafio disponível é do tipo hCaptcha, que não é o Captcha de interesse da pesquisa. No entanto, ao clicar em “Captcha Sonoro”, é possível acessar o Captcha de interesse, como mostrado na Figura 2.15. O motivo pelo qual o Captcha de texto em imagem foi mantido após a implementação do hCaptcha é desconhecido pelo autor.\n\n\n\n\n\nFigura 2.14: Página de busca de CNPJ da RFB.\n\n\n\n\n\n\n\n\n\nFigura 2.15: Página de busca de CNPJ da RFB, com Captcha de texto.\n\n\n\n\nA segunda tarefa é a de navegar pelo site, registrando as requisições realizadas pelo navegador para realizar a consulta. Isso envolve abrir o inspetor de elementos do navegador, na aba Rede (ou Network, em inglês), anotando as requisições que são realizadas.\nNo exemplo, testamos o CNPJ 13.612.840/0001-57, da Associação Brasileira de Jurimetria. Ao preencher o CNPJ e o rótulo do Captcha, algumas requisições aparecem na aba “Rede”, como mostrado na Figura 2.16. A primeira requisição é do tipo POST4, responsável por enviar os dados de CNPJ e do rótulo da imagem para o servidor, que retorna com os dados da empresa.\n\n\n\n\n\nFigura 2.16: Resultado da busca por CNPJ, mostrando a aba Rede.\n\n\n\n\nInvestigando a requisição POST, na sub-aba “Requisição”, é possível observar os dados da consulta. Trata-se de um conjunto de parâmetros enviados na forma de lista, com as informações abaixo. Para replicar a requisição na linguagem de programação, estes são os dados enviados.\n{\n    \"origem\": \"comprovante\",\n    \"cnpj\": \"13.612.840/0001-57\",\n    \"txtTexto_captcha_serpro_gov_br\": \"7hkhze\",\n    \"search_type\": \"cnpj\"\n}\nAs etapas de replicar, parsear e validar envolvem baixar e processar os dados na linguagem de programação. No caso do Captcha da RFB, essa tarefa envolve os passos abaixo.\n\nAcessar a página inicial de busca com Captcha sonoro, através de uma requisição GET.\nBaixar a imagem do Captcha com uma requisição GET, usando o link gerado ao clicar no botão de atualizar o Captcha.\nObter o rótulo a partir da imagem do Captcha.\nRealizar a requisição POST com os dados do exemplo e o rótulo correto da imagem, baixando arquivo resultante em um HTML.\nUtilizar técnicas de raspagem de arquivos HTML para obter os dados de interesse (como, por exemplo, a razão social da empresa) e validar os resultados, verificando, por exemplo, se o resultado estava completo e disponível.\n\nTodos os passos descritos acima devem ser realizados em uma sessão persistente. Isso significa que a biblioteca utilizada para realizar as requisições deve ser capaz de guardar os cookies entre a requisição GET do primeiro passo e a requisição POST do quarto passo, de forma que as requisições sejam interligadas.\nO quinto passo da lista acima descreve a parte de parsear, que é a responsável pelo nome “raspagem” nessa área do conhecimento. O nome é adequado porque usualmente os arquivos baixados estão em um formato bruto, inadequado para realização de análises. Os dados precisam ser então extraídos – raspados – do arquivo HTML, através de ferramentas de transformação de arquivos como a libxml2 (WICKHAM; HESTER; OOMS, 2021), técnicas para acessar pedaços do documento, como o XPath (WICKHAM, 2022a) e técnicas de manipulação de textos, como expressões regulares (WICKHAM, 2022b).\nA iteração encerra o fluxo da raspagem de dados. Nessa etapa, as operações de replicar, parsear e validar o resultado são reaplicadas iterativamente, com o fim de baixar dados para compor uma base maior. No exemplo da RFB, isso significaria montar uma base de dados a partir de uma lista de CNPJs.\nNo contexto dos Captchas, o interesse está nos passos de Replicar e Validar. Estes são os passos em que a imagem é baixado e o rótulo é anotado e testado no servidor. Esses são os passos relacionados à classificação manual, e também à implementação do oráculo.\nA classificação manual dos Captchas envolve o trabalho de baixar, anotar (manualmente) e verificar se a anotação está correta. Trata-se de um trabalho repetitivo e dispendioso, utilizado para gerar as simulações do trabalho.\nO oráculo envolve a possibilidade de checar, de forma automática, se uma predição do rótulo de uma imagem está correta. Por ser um teste de Turing inverso, o Captcha é obrigado a mencionar se uma predição está correta: se a predição foi correta, a página de interesse é acessada; se a predição está incorreta, o site envia uma mensagem de erro. As etapas de replicar, parsear e validar para qualquer site de interesse envolvem os passos a seguir.\n\nAcessar a página do site de interesse.\nPreencher o formulário de pesquisa com a informação a ser consultada. Por exemplo, no site da RFB, a informação é o CNPJ da empresa a ser consultada. Em um site de tribunal, a informação é um número identificador de processo.\nBaixar a imagem do Captcha da busca.\nObter o rótulo da imagem, aplicando um modelo na imagem baixada ou classificado manualmente.\nSubmeter a consulta no site, informando o rótulo.\nVerificar o resultado. Se acessou a página desejada, o rótulo está correto. Caso contrário, o rótulo está incorreto.\n\nO procedimento descrito pode ser reproduzindo indefinidamente. Isso significa que é possível criar uma base de dados virtualmente infinita de imagens rotuladas, com a informação adicional do rótulo estar correto ou incorreto. Isso foi feito para gerar os dados utilizados na simulação.\nO problema do uso de oráculos é que a informação adicional recebida quando o modelo erra é incompleta. A única informação nova disponível é que o rótulo testado está incorreto, dentre todos os rótulos possíveis daquela imagem. Como existe uma grande quantidade de rótulos possíveis em um Captcha, muitas vezes na ordem de milhões, a informação que o oráculo fornece é fraca.\nUma possível abordagem para lidar com o segundo problema seria simplesmente descartar os Captchas classificados incorretamente. É possível criar uma base de dados (virtualmente infinita) somente com os rótulos corretos e ajustar um novo modelo. Essa abordagem, no entanto, tem sérios problemas, já que considera somente os casos em que o classificador já funciona bem. O trabalho realizado na tese incorpora a informação fornecida pelo oráculo quando o modelo erra.\nOutra oportunidade que o oráculo oferece em parte dos casos é a possibilidade de testar mais de uma predição. Sites com essa característica permitem que a pessoa ou robô teste mais de uma predição caso o Captcha tenha fracassado. Como é possível observar na Tabela 2.1, dos 10 Captchas trabalhados, 7 permitem a realização desses testes.\nNeste momento, cabe uma observação sobre oráculos e força bruta. O poder de testar vários rótulos para o mesmo Captcha implica na possibilidade teórica de resolver um Captcha por força bruta. Bastaria testar todos os rótulos possíveis para acessar a página de interesse. Na prática, no entanto, essa estratégia não funciona, já que a quantidade de rótulos possíveis é muito grande para testar no site, seja por demorar muito tempo ou pelo site forçar a troca do desafio após a passagem de determinado tempo ou quantidade de tentativas.\nVoltando ao ciclo da raspagem, ao longo do procedimento de baixar imagens de Captchas e aplicar o oráculo, pelo menos duas funções devem ser criadas: acesso e teste. A operação de acesso é responsável por preencher o formulário de busca e baixar o Captcha (passos 1 a 3 da lista acima). A operação de teste é responsável por submeter um rótulo do Captcha e verificar retornar se o rótulo está correto ou incorreto (passos 4 a 6 da lista acima). Em alguns casos, as funções de acesso e teste precisam compartilhar parâmetros que contêm a sessão do usuário, para garantir que o teste envolva o mesmo Captcha da etapa de acesso.\nOs Captchas foram anotados manualmente com o procedimento chamado de semi-automático, definido a seguir. No pacote {captchaDownload} (ver Apêndice A.2), foram desenvolvidas ferramentas para baixar e organizar cada Captcha, utilizando o oráculo para garantir que as imagens eram corretamente classificadas.\nCada Captcha teve as primeiras 100 observações classificadas manualmente. Isso foi feito a partir do próprio RStudio, utilizando a ferramenta de classificação manual do pacote {captcha}.\nA partir das classificações iniciais, um modelo foi ajustado com a quantidade de observações disponível. Esse passo também foi feito a partir do pacote {captcha}, que cria um projeto de classificação para um Captcha específico.\nO modelo, então, foi utilizado como uma ferramenta para otimizar a classificação manual, funcionando da seguinte forma. Primeiro, o modelo tenta realizar a predição automaticamente e o oráculo avisa se a predição está correta ou não. Se estiver incorreto e o site aceitar várias tentativas, o modelo tenta novamente, mas com uma segunda alternativa de predição. Caso o site não aceite várias tentativas ou o modelo não consiga acertar o Captcha em \\(N\\) tentativas (abritrado como dez), a imagem do Captcha aparece para classificação manual.\nCom o procedimento destacado acima, é criada uma nova base de dados, que por sua vez é utilizada para ajustar um novo modelo. O modelo, atualizado, é utilizado para classificar novos Captchas, e assim por diante, até que o modelo ajustado alcance uma acurácia razoável, que foi arbitrada em 80%. Com isso o procedimento de anotação é finalizado.\nO único problema do procedimento de classificação diz respeito aos Captchas que não aceitam várias tentativas. Nesses casos, não é possível verificar com certeza absoluta que um caso classificado manualmente (após a tentativa do modelo) foi classificado corretamente, já que a classificação manual seria a segunda tentativa. No entanto, esse problema aparece somente em três Captchas (cadesp, jucesp e trf5). A classificação manual dos 100 primeiros Captchas, no entanto, mostrou que pelo menos 95% dos Captchas foram classificados corretamente quando classificados manualmente. A proporção máxima de 5% de erro é negligenciável considerando que a maior parte das bases de dados foi construída com verificação do oráculo.\nEm alguns casos, os rótulos dos Captchas podem ser obtidos sem intervenção humana, utilizando técnicas de raspagem de dados e processamento de sinais. Um exemplo é o Captcha do SEI, que mostra informações suficientes para resolver o Captcha na própria URL que gera a imagem. Outro exemplo é o TJMG, que libera, além da imagem, um áudio contendo o mesmo rótulo da imagem, sem a adição de ruídos. Como o áudio não tem ruídos, basta ler o áudio, separar os áudios de cada caractere e calcular uma estatística simples (como a soma das amplitudes, ao quadrado). Essa estatística é utilizada para associar um pedaço de áudio a um caractere.\nA Tabela 2.2 caracteriza os Captchas anotados. Todos os Captchas possuem comprimento entre 4 e 6 dígitos e, com exceção do SEI, não são sensíveis a maiúsculas e minúsculas.\n\n\n\n\nTabela 2.2:  Lista de captchas analisados e suas características. CaptchaVários chutesCaracteresComprimentoColorido# Rótulos anotadostrf5Não0:96não1000tjmgSim0:95sim1000trtSima-z0:96não1500esajSima-z5sim3000jucespNãoa-z0-95não4000tjpeSima-z0-95não4000tjrsSim0-94sim2000cadespNãoa-z4sim3000seiSima-zA-Z0-94sim10000rfbSima-z0-96não4000\n\n\n\nAs bases de dados com imagens anotadas foram disponibilizadas na aba de lançamentos (releases) do repositório principal do projeto de pesquisa. As bases com imagens e modelos ajustados estão disponíveis para quem tiver interesse em fazer novas pesquisas e utilizar os resultados em suas aplicações, sem restrições de uso."
  },
  {
    "objectID": "metodologia.html#simulacoes",
    "href": "metodologia.html#simulacoes",
    "title": "2  Metodologia",
    "section": "Simulações",
    "text": "Simulações\nPara verificar o poder do uso do oráculo para o aprendizado do modelo, uma série de simulações foi desenvolvidas. As simulações foram organizadas em três passos: modelo inicial, dados e modelo final. Os passos foram descritos em maior detalhe a seguir.\n\nPrimeiro passo: modelo inicial\nA simulação do modelo inicial teve como objetivo obter modelos preditivos de Captchas com acurácias distintas. O modelo inicial seria usado, então, para baixar dados diretamente do site usando o oráculo e, por fim, ajustar um modelo final com os novos dados provenientes do oráculo.\nOs modelos iniciais foram construídos em dois passos. O primeiro foi montar a base de dados completa, suficiente para ajustar um modelo com alta acurácia, que arbitrados em 80%, como descrito anteriormente. Depois, montou-se 10 amostras de dados com subconjuntos das bases completas, cada uma contendo 10%, 20%, e assim por diante, até a base completa. Por exemplo: no Captcha da Jucesp, construiu-se um modelo com acurácia maior que 80% com 4000 Captchas. A partir disso, foi feita uma partição dos dados com 400 imagens (10% do total), 800 imagens (20% do total) e assim por diante, até o modelo com 4000 Captchas.\nPara cada tamanho de amostra \\(A\\), aplicou-se uma bateria de 27 modelos. Isso foi feito porque para diferentes quantidades de amostra, a configuração dos hiperparâmetros que resulta no melhor modelo pode ser diferente. Os modelos seguiram uma grade de hiperparâmetros considerando três informações:\n\nA quantidade de unidades computacionais na primeira camada densa após as camadas convolucionais, com os valores considerados: 100, 200 e 300.\nO valor do dropout aplicado às camadas densas, com os valores considerados: 10%, 30% e 50%.\nO fator de decaimento na taxa de aprendizado a cada época, com os valores considerados: 1%, 2% e 3%.\n\nCombinando os três valores dos três hiperparâmetros, tem-se um total de \\(27=3^3\\) hiperparâmetros. Com isso, foi possível identificar, para cada tamanho de amostra \\(A\\), o classificador \\(C_A\\) com a melhor acurácia dentre os modelos ajustados.\nNo final do primeiro passo, portanto, considera-se apenas o melhor modelo para cada tamanho de amostra, dentre os 27 ajustados. É claro que os modelos encontrados por essa técnica não são, necessariamente, os melhores modelos possíveis. No entanto, como a técnica é a mesma para todos os Captchas, é possível fazer comparações através de uma metodologia mais transparente.\n\n\nSegundo passo: dados\nO segundo passo teve como objetivo construir as bases de dados utilizando o oráculo. Primeiro, foi necessário decidir quais modelos, dentre os 10 ajustados para cada Captcha, seriam utilizados para construir novas bases. Não faria sentido, por exemplo, considerar um modelo com acurácia de 0%, já que ele não produziria nenhuma observação comparado com um modelo que chuta aleatoriamente. Também não faria sentido considerar um classificador com acurácia de 100%, já que nesse caso não há o que testar com a técnica do oráculo.\nDecidiu-se que seria necessário considerar somente os modelos que resultaram em acurácias maiores de 1% e menores de 50%. O valor máximo foi decidido após realizar alguns testes empíricos e verificar, informalmente, que a técnica do oráculo realmente resultava em ganhos expressivos, mesmo com modelos de baixa acurácia. Concluiu-se então que não seria necessário testar a eficácia da técnica para classificadores com alta acurácia. Já o valor mínimo foi decidido de forma arbitrária, retirando-se os classificadores com acurácia muito baixa.\nA segunda decisão a ser tomada para construção dos dados foi a quantidade de imagens que seria baixada para cada Captcha. Como são Captchas de diferentes dificuldades, a quantidade de dados seria diferente. Optou-se por baixar a quantidade de dados de forma a montar uma base de treino que contém a quantidade de observações necessária para obter o melhor modelo daquele Captcha. Por exemplo, no TJRS, um modelo com acurácia próxima de 100% foi identificado com 2000 observações. O melhor modelo com 300 imagens (240 para treino, 60 para teste) resultou em uma acurácia de 35%. Foram, então, baixadas 1760 observações para compor o total de 2000 na base de treino. As imagens de teste do modelo inicial poderiam até ser utilizadas, mas optamos por descartar para garantir que o modelo não ficasse sobreajustado para a primeira base.\nO motivo de baixar a mesma quantidade de observações que o melhor modelo inicial foi feita por dois motivos. O primeiro é que existem evidências de que é possível construir um bom modelo com essa quantidade de imagens, ainda que em um caso as informações são completas e, no outro, incompletas. O segundo é que isso permite a comparação do resultado do modelo completamente anotado contra o modelo que é parcialmente anotado e com anotações incompletas provenientes do oráculo.\nA terceira e última decisão tomada para baixar os dados foi a quantidade de chutes que o modelo poderia fazer, nos casos em que isso é permitido pelo site. Optou-se, de forma arbitrária, por três valores: 1, que é equivalente a um site que não permite múltiplos chutes, 5 chutes e 10 chutes.\nPortanto, o procedimento de coleta dos dados foi feito, para cada Captcha, da seguinte forma:\n\nListou-se todos os melhores modelos ajustados para cada tamanho de amostra.\nFiltrou-se os modelos para os que apresentavam acurácia de 5% até 50%\nDefiniu-se o tamanho da base a ser obtida, com base no tamanho da base de treino utilizada no modelo e a quantidade total que se objetivou obter.\nPara cada quantidade de tentativas disponível (1, 5 e 10), baixou-se as imagens, anotando com o valor “1” se o rótulo de alguma das tentativas estivesse correto e com o valor “0” caso contrário.\nNos casos com erros, armazenou-se um arquivo de log para cada Captcha com o histórico de tentativas incorretas, que é a informação mais importante a ser passada para o modelo final.\n\nNo final, obteve-se bases de dados de treino para todos os Captchas analisados, com quantidades de imagens variadas de acordo com os parâmetros definidos anteriormente, variando também pela quantidade de tentativas. A quantidade total de bases de dados geradas foi 65.\nAlém das bases de treino, foi construída uma base de teste para cada Captcha. As bases de teste foram construídas completamente do zero, sem utilizar informações de bases anteriores. Para construir as bases, utilizou-se a mesma técnica semi-automática definida anteriormente, usando o melhor modelo disponível para classificar a maioria das imagens e classificando manualmente em caso de falha. Em alguns casos, como TJMG e TJRS, a classificação humana quase não foi necessária, pois os classificadores obtidos apresentaram acurácia próxima de 100%.\nComo o único objetivo da base de teste foi o de estimar a acurácia dos modelos finais, a quantidade de observações poderia ser arbitrada. O tamanho das bases de teste foi, então, arbitrado em 1000 imagens para cada Captcha.\n\n\nTerceiro passo: modelo final\nO modelo final foi ajustado para cada uma das 65 bases de treino disponíveis após a realização dos passos 1 e 2. Nesse caso, utilizou-se o modelo proposto na Seção 2.2. Caso a imagem tenha sido corretamente classificada, a função de perda é calculada normalmente. Caso ela tenha sido classificada incorretamente, considera-se a probabilidade de não observar nenhum dos chutes.\nAlém de modificar a forma de calcular a função de perda do modelo, foi necessário realizar uma nova busca de hiperparâmetros. Optou-se por utilizar os mesmos hiperparâmetros dos modelos iniciais para manter a consistência. O único detalhe nesse ponto é que, como os parâmetros de partida são os do modelo inicial, optou-se por não modificar a quantidade de unidades na camada densa, variando somente os valores de dropout e de decaimento na taxa de aprendizado. Portanto, ajustou-se 9 e não 27 modelos para cada base de dados.\nNo final, assim como no primeiro passo, os classificadors com melhor acurácia foram selecionados para cada modelo. Obteve-se, então, com 65 modelos no final para comparar com os modelos iniciais e estimar a efetividade do oráculo. As comparações foram feitas através de gráficos de barras, explorando o efeito do uso do oráculo para diferentes Captchas, diferentes modelos iniciais e diferentes quantidades de chutes, além de um gráfico de dispersão para relacionar as acurácias iniciais e finais.\nAlém do terceiro passo, outros experimentos foram realizados para verificar se, ao aplicar a técnica do oráculo iterativamente, os resultados continuariam melhorando. Ou seja, é possível considerar os modelos obtidos no passo 3 como os modelos iniciais do passo 1, aplicar novamente o passo 2 (baixar dados) e o passo 3 (rodar modelo com os novos dados). Isso foi feito para apenas um conjunto selecionado de Captchas para verificar essa possibilidade, não fazendo parte das simulações principais do estudo.\nAs bases de dados das simulações também foram disponibilizadas na aba de lançamentos (releases) do repositório principal do projeto de pesquisa. As bases podem ser utilizadas para aumentar as bases de treino e para testar outras arquiteturas de redes neurais ao tema dos Captchas com uso de aprendizado fracamente supervisionado.\n\n\n\n\nBALDI, P.; SADOWSKI, P. J. Understanding dropout. Advances in neural information processing systems, v. 26, 2013.\n\n\nBLUM, A.; KALAI, A. A note on learning from multiple-instance examples. Machine learning, v. 30, n. 1, p. 2329, 1998.\n\n\nCOUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. The Journal of Machine Learning Research, v. 12, p. 15011536, 2011.\n\n\nFALBEL, D. luz: Higher Level ’API’ for ’torch’. a2022. Disponível em: <https://CRAN.R-project.org/package=luz>.\n\n\nFALBEL, D. torchvision: Models, Datasets and Transformations for Images. b2022. Disponível em: <https://CRAN.R-project.org/package=torchvision>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’ Acceleration. 2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nFENG, L. et al. Provably consistent partial-label learning. Advances in Neural Information Processing Systems, v. 33, p. 1094810960, a2020.\n\n\nFENG, L. et al. Learning with multiple complementary labels. PMLR, b2020.\n\n\nGALAR, M. et al. A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybrid-based approaches. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), v. 42, n. 4, p. 463484, 2011.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, v. 358, n. 6368, p. eaag2612, 2017.\n\n\nGRANDVALET, Y. Logistic regression for partial labels. 2002.\n\n\nHÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled examples. Intelligent Data Analysis, v. 10, n. 5, p. 419439, 2006.\n\n\nIOFFE, S.; SZEGEDY, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. PMLR, 2015.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances in neural information processing systems, v. 30, b2017.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances in neural information processing systems, v. 30, a2017.\n\n\nJIN, R.; GHAHRAMANI, Z. Learning with multiple labels. Advances in neural information processing systems, v. 15, 2002.\n\n\nKAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review. International Journal of Computer Science and Information Technologies, v. 5, 1 jan. 2014.\n\n\nKINGMA, D. P.; BA, J. Adam: A Method for Stochastic Optimization. [s.d.].\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A practical approach for predictive models. CRC Press, 2019.\n\n\nLECUN, Y. et al. Gradient-based learning applied to document recognition. Proceedings of the IEEE, v. 86, n. 11, p. 22782324, 1998.\n\n\nLECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning. nature, v. 521, n. 7553, p. 436444, 2015.\n\n\nLI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control chart. IIE Transactions, v. 46, n. 5, p. 526542, 2014.\n\n\nLIU, L.; DIETTERICH, T. A conditional multinomial mixture model for superset label learning. Advances in neural information processing systems, v. 25, 2012.\n\n\nNELDER, J. A.; WEDDERBURN, R. W. Generalized linear models. Journal of the Royal Statistical Society: Series A (General), v. 135, n. 3, p. 370384, 1972.\n\n\nOOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021. Disponível em: <https://CRAN.R-project.org/package=magick>.\n\n\nR CORE TEAM. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing, 2021. Disponível em: <https://www.R-project.org/>.\n\n\nRAMESH, A. et al. Hierarchical Text-Conditional Image Generation with CLIP Latents. [s.d.].\n\n\nWICKHAM, H. stringr: Simple, Consistent Wrappers for Common String Operations. b2022. Disponível em: <https://CRAN.R-project.org/package=stringr>.\n\n\nWICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível em: <https://CRAN.R-project.org/package=rvest>.\n\n\nWICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em: <https://CRAN.R-project.org/package=xml2>.\n\n\nYE, G. et al. Yet another text captcha solver: A generative adversarial network based approach. 2018.\n\n\nYU, X. et al. Learning with biased complementary labels. 2018.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13, 2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning. National science review, v. 5, n. 1, p. 4453, 2018.\n\n\nZHU, X. J. Semi-supervised learning literature survey. 2005."
  },
  {
    "objectID": "resultados.html#sec-result-theory",
    "href": "resultados.html#sec-result-theory",
    "title": "3  Resultados",
    "section": "Resultados teóricos",
    "text": "Resultados teóricos\nNesta seção, buscou-se demonstrar que o uso dos dados fornecidos pelo oráculo com adaptação da função de perda i) não piora o poder preditivo do modelo e ii) converge para o modelo preditivo ótimo. Para isso, é necessário retomar algumas definições para avançar."
  },
  {
    "objectID": "resultados.html#sec-result-sim",
    "href": "resultados.html#sec-result-sim",
    "title": "3  Resultados",
    "section": "Resultados empíricos",
    "text": "Resultados empíricos\n\n\n\nNesta seção são revelados os resultados das simulações realizadas. Como comentado anteriormente, foram realizadas 65 simulações no total, variando no tipo de Captcha, a acurácia do modelo inicial e a quantidade de tentativas no oráculo.\nPara realizar os cálculos, montou-se uma base de dados com os resultados das simulações. A base está disponível publicamente no repositório da tese e contém colunas para o Captcha ajustado (captcha), a quantidade de observações do modelo inicial (n), a quantidade de tentativas do oráculo (ntry), a etapa da simulação (fase, inicial ou oráculo), o caminho do modelo ajustado (model) e a acurácia obtida (acc).\nEm média, foi observado um ganho de 333% na acurácia após a aplicação da técnica do oráculo. Ou seja, em média a acurácia do modelo com aplicação do oráculo foi de mais de três vezes a acurácia do modelo inicial. Em termos absolutos (diferença entre as acurácias), o ganho foi de 33%, ou seja, depois da aplicação do oráculo os modelos ganharam, em média, 33% na acurácia.\n\n\n\nSeparando os resultados gerais por quantidade de tentativas, observa-se os ganhos relativos e absolutos nas Figuras 3.1 e 3.2. Cada ponto é uma simulação e o ponto em destaque é o valor médio, acompanhado de intervalo \\(m \\mp 2*s/\\sqrt(n)\\), com \\(m\\) sendo a média, \\(s\\) o desvio padrão e \\(n\\) a quantidade de dados. A linha pontilhada indica se a acurácia aumentou ou diminuiu após a aplicação da técnica.\nNa Figura 3.1 é possível notar que os ganhos em acurácia apresentam alta variabilidade, mas que apresentam uma tendência positiva com relação ao número de tentativas. O ganho entre aplicar 5 e 10 tentativas é menos expressivo do que o ganho entre aplicar 1 e 5 tentativas, indicando que a oportunidade oferecida por sites que aceitam vários chutes é relevante e que não há necessidade de fazer tantos chutes para aproveitar essa oportunidade.\n\n\n\n\n\nFigura 3.1: Ganho percentual ao utilizar a técnica do oráculo, dividido por quantidade de tentativas.\n\n\n\n\nA Figura Figura 3.2, com as os ganhos absolutos, mostra a mesma informação mas em quantidades mais fáceis de interpretar. O ganho médio absoluto em Captchas mais de um chute girou em torno de 40%, enquanto que o ganho com apenas um chute ficou um pouco acima de 25%. Importante notar também que o uso do oráculo só piorou a acurácia do modelo (e pouco) em casos que com apenas um chute, mostrando que a técnica é consistentemente efetiva.\n\n\n\n\n\nFigura 3.2: Ganhos absolutos ao utilizar a técnica do oráculo, dividido por quantidade de tentativas.\n\n\n\n\n\n\n\nAs Figuras 3.3 e 3.4 apresentam os resultados gerais separando por acurácia inicial do modelo. A estrutura do gráfico é similar às visualizações separando por quantidade de tentativas. As categorias escolhidas foram de até 10%, mais de 10% até 35% e mais de 35% de acurácia no modelo inicial. A escolha dos intervalos se deram pela quantidade de observações em cada categoria.\nA Figura 3.3 mostra os ganhos relativos. É possível notar uma tendência de queda no ganho de acurácia com uso do oráculo conforme aumenta a acurácia do modelo inicial. Esse resultado é esperado, pois, como a acurácia é um número entre zero e um, um modelo que já possui alta acurácia não tem a possibilidade de aumentar tanto.\n\n\n\n\n\nFigura 3.3: Ganho percentual ao utilizar a técnica do oráculo, dividido por acurácia do modelo inicial.\n\n\n\n\nA Figura 3.4 mostra os ganhos absolutos. O gráfico apresenta o mesmo problema que o anterior, já que o ganho máximo depende da acurácia inicial do modelo. Mesmo assim, é possível notar que, em termos absolutos, modelos com acurácia inicial entre 10% e 35% apresentaram um ganho maior que modelos com acurácia inicial de até 10%.\n\n\n\n\n\nFigura 3.4: Ganho absoluto ao utilizar a técnica do oráculo, dividido por acurácia do modelo inicial.\n\n\n\n\nPara lidar com o fato da acurácia ser um número limitado, fizemos o mesmo gráficos de antes, mas ajustado pelo máximo possível que a técnica do oráculo poderia proporcionar. O ganho absoluto ajustado de uma simulação é dado por\n\\[\n\\text{ganho} = \\frac{\\text{oráculo } - \\text{ inicial}}{1\\; - \\text{ inicial}}.\n\\] A Figura 3.5 mostra os ganhos ajustados. Pelo gráfico, é possível notar que existe um ganho expressivo da técnica do oráculo para modelos iniciais com mais do que 10% de acurácia com relação a modelos iniciais com até 10% de acurácia. Ou seja, quando o modelo inicial é fraco, o ganho ao usar a técnica é menor. É importante notar, no entanto, que as simulações mostram a aplicação da técnica apenas uma vez – é possível baixar mais dados e atualizar o modelo indefinidamente. O menor efeito da técnica para modelos iniciais fracos não significa, portanto, que a técnica não funciona para modelos iniciais fracos; pelo contrário: ela ajuda o modelo a sair do estado inicial e o leva para uma acurácia maior, de onde poderíamos aplicar a técnica novamente para obter resultads ainda mais expressivos.\n\n\n\n\n\nFigura 3.5: Ganho absoluto ao utilizar a técnica do oráculo, dividido por acurácia do modelo inicial.\n\n\n\n\nNa Figura 3.6, mostramos os resultados separando por Captcha. Cada linha é uma combinação de Captcha, quantidade de tentativas e acurácia modelo inicial, que foi classificado em três categorias. As linhas pontilhadas indicam modelos ajustados com mais de uma tentativa, enquanto as linhas contínuas mostram modelos ajustados com apenas uma tentativa. A primeira extremidade de cada linha, do lado esquerdo, indica a acurácia do modelo inicial e a segunda extremidade, do lado direito, a acurácia do modelo usando a técnica do oráculo.\n\n\n\n\n\nFigura 3.6: Resultados da simulação por captcha, quantidade de tentativas e modelo inicial.\n\n\n\n\nPelo gráfico, é possível identificar duas informações relevantes. Como já verificado anteriormente, os modelos ajustados com mais de uma tentativa apresentam maiores ganhos do que os modelos ajustados com apenas uma tentativa. Verifica-se também que modelos com acurácia inicial menores não necessariamente apresentam ganhos menores quando separados por Captcha.\nPelas análises das simulações, é possível concluir que a técnica do oráculo foi bastante bem sucedida. Primeiro, ela apresenta resultados expressivos e de forma consistente, mesmo dando apenas um passo de obtenção de dados e ajuste de novo modelo. Além disso, a técnica é capaz de se aproveitar de sites que permitem a verificação do oráculo múltiplas vezes para o mesmo Captcha. Por último, a técnica apresenta ganhos mesmo para modelos iniciais muito fracos (com acurácias de até 10%), indicando que sua aplicação é indicada para qualquer modelo inicial com mais de 5% de acurácia, o que é bastante factível de atingir com bases pequenas ou com modelos genéricos.\n\nAplicação iterada\nUm possível problema em aplicar a técnica do oráculo é que a técnica pode introduzir viés no modelo, o que impediria de ser aprimorado indefinidamente. Mesmo que os teoremas dêem uma boa base para acreditar que isso não seja verdade, foi feito um teste empírico, com apenas um Captcha, para verificar se a aplicação da técnica múltiplas vezes apresenta bons resultados.\nO Captcha escolhido para a simulação foi o trf5, por ser um Captcha que não aceita múltiplos chutes, em uma tentativa de obter um pior caso. Para esse Captcha, o melhor modelo obtido com a técnica do oráculo foi considerado como modelo inicial e usado para baixar novos dados do site do Tribunal. Os novos dados foram adicionados à base de treino, ajustando-se um novo modelo.\nA Figura 3.7 mostra os resultados da aplicação iterada. A utilização da técnica não só funcionou como levou o modelo a uma acurácia de 100%.\n\n\n\n\n\nFigura 3.7: Resultados da aplicação iterada da técnica.\n\n\n\n\nO resultado sugere que a técnica pode sim ser utilizada indefinidamente para auxiliar no aprendizado do modelo. Ela sugere, ainda, que uma técnica de aprendizado ativo com feedback automático do oráculo pode dar bons resultados, já que a forma de obter os dados não introduz viés no ajuste do modelo."
  },
  {
    "objectID": "resultados.html#sec-discussao",
    "href": "resultados.html#sec-discussao",
    "title": "3  Resultados",
    "section": "Discussão",
    "text": "Discussão"
  },
  {
    "objectID": "conclusoes.html",
    "href": "conclusoes.html",
    "title": "4  Conclusões",
    "section": "",
    "text": "Concluir sobre a parte mais política (captchas e dados abertos etc)\n\n\nConcluir sobre o avanço científico na modelagem estatística\n\n\nReforçar a contribuição técnica para a comunidade com o pacote e o app"
  },
  {
    "objectID": "bibliografia.html",
    "href": "bibliografia.html",
    "title": "Bibliografia",
    "section": "",
    "text": "AHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web\nSecurity Measures. Science, v. 321, n. 5895, p.\n1465–1468, 12 set. 2008. Disponível em: <https://www.science.org/doi/10.1126/science.1160379>.\n\n\nAHN, L. VON; BLUM, M.; LANGFORD, J. Telling humans and computers\napart automatically or how lazy cryptographers do AI (Tech. Rep. No.\nCMU-CS-02-117). Disponível em: <http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf>.\n\n\nALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022.\nDisponível em: <https://CRAN.R-project.org/package=tensorflow>.\n\n\nBALDI, P.; SADOWSKI, P. J. Understanding dropout. Advances in\nneural information processing systems, v. 26, 2013.\n\n\nBLUM, A.; KALAI, A. A note on learning from multiple-instance examples.\nMachine learning, v. 30, n. 1, p. 2329, 1998.\n\n\nBOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub\nRepository. 2022. Disponível em: <https://CRAN.R-project.org/package=piggyback>.\n\n\nCHELLAPILLA, K. et al. Designing human friendly human\ninteraction proofs (HIPs). : CHI ’05.New York, NY, USA:\nAssociation for Computing Machinery, 2 abr. 2005. Disponível em: <https://doi.org/10.1145/1054972.1055070>.\n\n\nCHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human\ninteraction proofs (HIPs). Advances in neural information\nprocessing systems, v. 17, 2004.\n\n\nCOLOSIMO, E. A.; GIOLO, S. R. Análise de sobrevivência\naplicada. Editora Blucher, 2006.\n\n\nCOUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. The\nJournal of Machine Learning Research, v. 12, p. 15011536, 2011.\n\n\nDiagnóstico do Contencioso Tributário Administrativo.,\n[s.d.]. Disponível em: <https://abj.org.br/pesquisas/bid-tributario/>.\n\n\nFALBEL, D. luz: Higher Level ’API’ for ’torch’. a2022. Disponível em:\n<https://CRAN.R-project.org/package=luz>.\n\n\nFALBEL, D. torchvision: Models, Datasets and Transformations for Images.\nb2022. Disponível em: <https://CRAN.R-project.org/package=torchvision>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’\nAcceleration. a2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’\nAcceleration. b2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nFENG, L. et al. Provably consistent partial-label learning.\nAdvances in Neural Information Processing Systems, v.\n33, p. 1094810960, a2020.\n\n\nFENG, L. et al. Learning with multiple complementary\nlabels. PMLR, b2020.\n\n\nGALAR, M. et al. A review on ensembles for the class imbalance problem:\nbagging-, boosting-, and hybrid-based approaches. IEEE\nTransactions on Systems, Man, and Cybernetics, Part C (Applications and\nReviews), v. 42, n. 4, p. 463484, 2011.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data\nefficiency and breaks text-based CAPTCHAs. Science, v.\n358, n. 6368, p. eaag2612, 2017.\n\n\nGOODFELLOW, I. J. et al. Multi-digit number recognition from street view\nimagery using deep convolutional neural networks. arXiv preprint\narXiv:1312.6082, 2013.\n\n\nGOODFELLOW, I. J. et al. Generative Adversarial\nNetworks. [s.d.].\n\n\nGRANDVALET, Y. Logistic regression for partial labels.\n2002.\n\n\nHÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled\nexamples. Intelligent Data Analysis, v. 10, n. 5, p.\n419439, 2006.\n\n\nInaccessibility of CAPTCHA., [s.d.]. Disponível em:\n<https://www.w3.org/TR/turingtest/>.\n\n\nIOFFE, S.; SZEGEDY, C. Batch normalization: Accelerating deep\nnetwork training by reducing internal covariate shift. PMLR,\n2015.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances\nin neural information processing systems, v. 30, a2017.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances\nin neural information processing systems, v. 30, b2017.\n\n\nJIN, R.; GHAHRAMANI, Z. Learning with multiple labels. Advances\nin neural information processing systems, v. 15, 2002.\n\n\nKAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review.\nInternational Journal of Computer Science and Information\nTechnologies, v. 5, 1 jan. 2014.\n\n\nKINGMA, D. P.; BA, J. Adam: A Method for\nStochastic Optimization. [s.d.].\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A\npractical approach for predictive models. CRC Press, 2019.\n\n\nLECUN, Y. et al. Gradient-based learning applied to document\nrecognition. Proceedings of the IEEE, v. 86, n. 11, p.\n22782324, 1998.\n\n\nLECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning.\nnature, v. 521, n. 7553, p. 436444, a2015.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning.\nnature, v. 521, n. 7553, p. 436444, b2015.\n\n\nLI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control\nchart. IIE Transactions, v. 46, n. 5, p. 526542, 2014.\n\n\nLILLIBRIDGE, M. D. et al. Method for Selectively Restricting\nAccess to Computer Systems., fev. 2001.\n\n\nLIU, L.; DIETTERICH, T. A conditional multinomial mixture model for\nsuperset label learning. Advances in neural information\nprocessing systems, v. 25, 2012.\n\n\nMICHENER, G.; MONCAU, L. F.; VELASCO, R. B. Estado brasileiro e\ntransparência avaliando a aplicação da Lei de Acesso à\nInformação.\n\n\nMORI, G.; MALIK, J. Recognizing objects in adversarial clutter:\nBreaking a visual CAPTCHA. IEEE, 2003.\n\n\nMURRAY-RUST, P. Open data in science. Nature\nPrecedings, p. 11, 2008.\n\n\nNA, B. et al. Deep Generative Positive-Unlabeled Learning under\nSelection Bias. : CIKM ��20.New York, NY, USA: Association for\nComputing Machinery, 19 out. 2020. Disponível em: <https://doi.org/10.1145/3340531.3411971>.\n\n\nNELDER, J. A.; WEDDERBURN, R. W. Generalized linear models.\nJournal of the Royal Statistical Society: Series A\n(General), v. 135, n. 3, p. 370384, 1972.\n\n\nNOH, H. et al. Regularizing deep neural networks by noise: Its\ninterpretation and optimization. Advances in Neural Information\nProcessing Systems, v. 30, 2017.\n\n\nObservatório da insolvência: Rio de Janeiro., [s.d.].\nDisponível em: <https://abj.org.br/pesquisas/obsrjrj/>.\n\n\nOOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021.\nDisponível em: <https://CRAN.R-project.org/package=magick>.\n\n\nR CORE TEAM. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical\nComputing, 2021. Disponível em: <https://www.R-project.org/>.\n\n\nRAMESH, A. et al. Hierarchical\nText-Conditional Image Generation with CLIP Latents. [s.d.].\n\n\nRESHEF, E.; RAANAN, G.; SOLAN, E. Method and System for\nDiscriminating a Human Action from a Computerized Action.,\n2005.\n\n\nSUTTON, R. S.; BARTO, A. G. Reinforcement learning: An\nintroduction. MIT press, 2018.\n\n\nTempo dos processos relacionados à adoção., [s.d.].\nDisponível em: <https://abj.org.br/pesquisas/adocao/>.\n\n\nTRECENTI, J. et al. decryptr: An extensible API for breaking captchas.\n2022.\n\n\nTURING, A. M. Computing machinery and intelligence. Em: Springer, 2009.\np. 2365.\n\n\nUSHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’.\n2022. Disponível em: <https://CRAN.R-project.org/package=reticulate>.\n\n\nVON AHN, L. et al. Captcha: Telling Humans and\nComputers Apart Automatically. Proceedings of Eurocrypt.\nAnais...2003.\n\n\nVON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart\nAutomatically. Communications of the ACM, v. 47, n. 2,\np. 56–60, 2004.\n\n\nWANG, Y. et al. Make complex captchas simple: a fast text captcha solver\nbased on a small number of samples. Information\nSciences, v. 578, p. 181194, 2021.\n\n\nWICKHAM, H. stringr: Simple, Consistent Wrappers for Common String\nOperations. b2022. Disponível em: <https://CRAN.R-project.org/package=stringr>.\n\n\nWICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível\nem: <https://CRAN.R-project.org/package=rvest>.\n\n\nWICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and\nProject Setup. 2022. Disponível em: <https://CRAN.R-project.org/package=usethis>.\n\n\nWICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em:\n<https://CRAN.R-project.org/package=xml2>.\n\n\nYE, G. et al. Yet another text captcha solver: A generative\nadversarial network based approach. a2018.\n\n\nYE, G. et al. Yet another text captcha solver: A generative\nadversarial network based approach. b2018.\n\n\nYU, X. et al. Learning with biased complementary\nlabels. 2018.\n\n\nYUAN, X. et al. Adversarial examples: Attacks and defenses for deep\nlearning. IEEE transactions on neural networks and learning\nsystems, v. 30, n. 9, p. 28052824, 2019.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13,\na2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13,\nb2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning.\nNational science review, v. 5, n. 1, p. 4453, 2018.\n\n\nZHU, X. J. Semi-supervised learning literature survey. 2005."
  },
  {
    "objectID": "pacote.html#sec-pacote-captcha",
    "href": "pacote.html#sec-pacote-captcha",
    "title": "Appendix A — Pacotes",
    "section": "Pacote captcha",
    "text": "Pacote captcha\nO pacote {captcha} foi construído para funcionar como uma caixa de ferramentas para pessoas que desejam trabalhar com Captchas. O pacote possui funções de leitura, visualização, classificação, preparação de dados, modelagem, carregamento de modelos pré-treinados e predição. O pacote também permite a construção de um fluxo de trabalho para resolver um novo Captcha, criando um pacote para orquestrar o passo-a-passo.\n\nUso básico\nA utilização básica do {captcha} envolve as funções read_captcha(), plot(), captcha_annotate(), captcha_load_model() e decrypt(). As funções são explicadas abaixo.\nA função read_captcha() lê um vetor de arquivos de imagens e armazenar na memória. Por trás, a função utiliza o pacote {magick} para lidar com os tipos de arquivos que podem aparecer (JPEG, PNG, entre outros).\n\n\nCódigo\nlibrary(captcha)\nexemplo <- \"assets/img/dados_tjmg.jpeg\"\ncaptcha <- read_captcha(exemplo)\n\ncaptcha\n#>   format width height colorspace matte filesize density\n#> 1   JPEG   100     50       sRGB FALSE     4530   72x72\n\n\n\n\n\nA função retorna um objeto com a classe captcha, que pode ser utilizada por outros métodos.\n\n\nCódigo\nclass(captcha)\n#> [1] \"captcha\"\n\n\nO objeto é uma lista com três elementos: $img, que contém imagem lida com o pacote {magick}, $lab, que contém o rótulo da imagem (por padrão, NULL) e $path, que contém o caminho da imagem que foi lida.\n\n\nCódigo\nstr(captcha)\n#> Class 'captcha'  hidden list of 3\n#>  $ img :Class 'magick-image' <externalptr> \n#>  $ lab : NULL\n#>  $ path: chr \"assets/img/dados_tjmg.jpeg\"\n\n\nA função read_captcha() possui um parâmetro ans_in_path=, que indica se o rótulo está contido no caminho da imagem. Se ans_in_path=TRUE, a função tentará extrair o rótulo do arquivo (obtendo o texto que vem depois do último _ do caminho) e armazenar no elemento $lab.\n\n\nCódigo\nexemplo <- \"assets/img/mnist128c49c36e13_6297.png\"\ncaptcha <- read_captcha(exemplo, ans_in_path = TRUE)\n\nstr(captcha)\n#> Class 'captcha'  hidden list of 3\n#>  $ img :Class 'magick-image' <externalptr> \n#>  $ lab : chr \"6297\"\n#>  $ path: chr \"assets/img/mnist128c49c36e13_6297.png\"\n\n\nA função plot plot() é um método de classe S3 do R básico. A função foi implementada para facilitar a visualização de Captchas. A função recebe uma lista de imagens obtida pela função read_captcha() e mostra o Captcha visualmente, como na Figura A.1.\n\n\nCódigo\nexemplo <- \"assets/img/dados_tjmg.jpeg\"\ncaptcha <- read_captcha(exemplo)\nplot(captcha)\n\n\n\n\n\nFigura A.1: Exemplo de aplicação da função plot a um objeto captcha.\n\n\n\n\nUm aspecto interessante da função plot() é que ela lida com uma lista de Captchas. Isso é útil quando o interesse é visualizar vários Captchas de uma vez na imagem. A Figura A.2 mostra um exemplo de aplicação\n\n\nCódigo\nexemplos <- paste0(\"assets/img/\", c(\n  \"dados_tjmg.jpeg\",\n  \"dados_esaj.png\",\n  \"dados_rfb.png\",\n  \"dados_sei.png\"\n))\ncaptchas <- read_captcha(exemplos)\nplot(captchas)\n\n\n\n\n\nFigura A.2: Exemplo de aplicação da função plot a um objeto captcha com várias imagens.\n\n\n\n\nPor padrão, a função plot dispõe as imagens em quatro colunas. Para mudar o padrão, é possível modificar as opções usando options(captcha.print.cols = N), onde N é o número de colunas desejado. A Figura A.3 mostra um exemplo com duas colunas.\n\n\n\n\n\nCódigo\noptions(captcha.print.cols = 2)\nplot(captchas)\n\n\n\n\n\nFigura A.3: Exemplo de aplicação da função plot a um objeto captcha com várias imagens, disponibilizadas em duas colunas.\n\n\n\n\n\n\n\nQuando o vetor de Captchas é muito grande, a função plot() mostra um número máximo d imagens, acompanhado de uma mensagem. Por padrão, esse número é 100, com 25 linhas e 4 colunas. A opção pode ser sobrescrita combinando as opções captcha.print.cols= e captcha.print.rows=. A Figura A.4 mostra um exemplo do comportamento da função quando o número de imagens excede 100.\n\n\nCódigo\n# mais de 100 imagens:\nexemplos <- rep(\"assets/img/dados_tjmg.jpeg\", 110)\ncaptchas <- read_captcha(exemplos)\nplot(captchas)\n#> ℹ Too many images, printing first 100. To override, run\n#> • options('captcha.print.rows' = MAX_ROWS)\n#> • options('captcha.print.cols' = COLUMNS)\n\n\n\n\n\nFigura A.4: Demonstração da função plot() com muitas imagens.\n\n\n\n\nUm detalhe interessante é que é possível criar subconjuntos de um objeto de classe captcha simplesmente utilizando o operador [. A função length() também pode ser utilizada para medir a quantidade de imagens lidas. A Figura A.5 mostra um exemplo dessas operações.\n\n\nCódigo\ncaptchas_subset <- captchas[1:20]\nlength(captchas_subset) # 20\n#> [1] 20\nplot(captchas_subset)\n\n\n\n\n\nFigura A.5: Demonstração das funções de subset e length aplicadas a um objeto do tipo captcha.\n\n\n\n\nPor fim, se a imagem possui um rótulo, por padrão, a função plot() mostra o rótulo no canto da imagem. A Figura A.6 mostra um exemplo.\n\n\nCódigo\nexemplo <- \"assets/img/mnist128c49c36e13_6297.png\"\ncaptcha <- read_captcha(exemplo, ans_in_path = TRUE)\nplot(captcha)\n\n\n\n\n\nFigura A.6: Demonstração da função plot() quando o Captcha possui um rótulo\n\n\n\n\nA função captcha_annotate() serve para classificar uma imagem de Captcha, manual ou automaticamente. Isso é feito modificando o caminho da imagem, adicionando o texto _rotulo ao final do caminho do arquivo. A função possui os parâmetros listados abaixo:\n\nfiles=: objeto de classe captcha lido com a função read_captcha() (recomendado) ou vetor de caminhos de arquivos.\nlabels=: (opcional) vetor com os rótulos das imagens. Deve ter o mesmo length() do que files=. Por padrão, o valor é NULL, indicando que deve ser aberto um prompt para que o usuário insira a resposta manualmente.\npath=: (opcional) caminho da pasta onde os arquivos classificados serão salvos. Por padrão, salva os arquivos com nomes modificados na mesma pasta dos arquivos originais.\nrm_old=: (opcional) deletar ou não os arquivos originais. Por padrão, é FALSE.\n\nA função, depois de aplicada, retorna um vetor com os caminhos dos arquivos modificados. O parâmetro labels= é útil para lidar com situações em que sabemos o rótulo do Captcha. Por exemplo, em um fluxo de trabalho que utiliza o oráculo, pode ser que um modelo inicial já forneça o valor correto do rótulo.\nQuando não existe um rótulo, a função captcha_annotate(), que abre o prompt para classificação e aplica plot() para visualizar a imagem. A Figura A.7 mostra um exemplo de aplicação da função captcha_annotate() no software RStudio.\n\n\n\n\n\nFigura A.7: Exemplo de aplicação da função classify. O rótulo bhusp5 foi inserido manualmente.\n\n\n\n\nPor último, a função decrypt() tem o papel de obter o rótulo de uma imagem utilizando um modelo já treinado para aquele tipo de imagem. A função recebe dois argumentos: file= que pode ser tanto o caminho do arquivo quanto um objeto de classe captcha, e um argumento model=, que contém um modelo de classe luz_module_fitted, ajustado utilizando as ferramentas que serão apresentadas na próxima subseção.\nPara a tese, foram desenvolvidos modelos para vários Captchas diferentes. É possível carregar um modelo já treinado usando a função captcha_load_model(), podendo receber em seu único parâmetro path= o caminho de um arquivo contendo um modelo ajustado ou uma string com o nome de um modelo já treinado, como \"rfb\", por exemplo. Os modelos treinados são armazenados nos releases do repositório do pacote captcha, são baixados e controlados pelo pacote {piggyback} (BOETTIGER; HO, 2022) e são lidos utilizando o pacote {luz}, que será descrito em maiores detalhes na próxima subseção. No momento de submissão da tese, os Captchas com modelos desenvolvidos eram trf5, tjmg, trt, esaj, jucesp, tjpe, tjrs, cadesp, sei e rfb.\nA Figura A.8 resume visualmente as funções apresentadas até o momento. As setas indicam a dependência das funções de objetos gerados por outras funções.\n\n\n\n\n\nflowchart LR\n  B(\"<b><span style='color:blue;'>captcha</span></b> <- <b>read_captcha</b>('path/to/file.png')\")\n  B --> C(\"<b>plot</b>(<b><span style='color:blue;'>captcha</span></b>)\")\n  B --> D(\"<b>captcha_annotate</b>(<b><span style='color:blue;'>captcha</span></b>)\")\n  B --> F(\"<b>decrypt</b>(<b><span style='color:blue;'>captcha</span></b>, <b><span style='color:green;'>model</span></b>)\")  \n  G(\"<b><span style='color:green;'>model</span></b> <- <b>captcha_load_model</b>('model_name')\") --> F\nstyle B fill:#d3ddf1,stroke:#333,stroke-width:2px\n\n\n\n\n\nFigura A.8: Diagrama das funções básicas do pacote {captcha}\n\n\n\n\n\n\nModelagem\nO pacote {captcha} também fornece uma interface básica para o desenvolvimento de modelos a partir de uma base completamente classificada. A classificação pode ser feita manualmente pela função captcha_annotate(), apresentada anteriormente, ou por outro método desenvolvido pelo usuário.\nA parte de modelagem parte de algumas premissas sobre a base de dados. As imagens precisam estar em uma pasta e ter o padrão caminho/do/arquivo/<id>_<lab>.<ext>, onde:\n\n<id>: pode ser qualquer nome, de preferência sem acentuação ou outros caracteres especiais, para evitar problemas de encoding. Geralmente, é um hash identificando o tipo e id do captcha. Observação: ao classificar um caso, é importante que o id seja único, já que dois Captchas podem ter o mesmo rótulo.\n<lab>: é o rótulo do Captcha. Pode ser um conjunto de caracteres entre [a-zA-Z0-9], diferenciando maiúsculas e minúsculas se necessário. No momento, todos os arquivos em uma pasta devem ter a mesma quantidade de caracteres (comprimento homogêneo). Futuramente, o pacote poderá considerar Captchas de comprimento heterogêneo.\n<ext>: extensão do arquivo. Pode ser .png, .jpeg ou .jpg. As operações também funcionam para o formato .svg, mas pode apresentar problemas por conta da transparência da imagem.\n\nAtendidas as premissas da base classificada, é possível ajustar um modelo de redes neurais usando o pacote {captcha}. No entanto, como o ajuste de modelos de redes neurais envolve uma série de nuances e pequenas adaptações, optou-se por exportar funções em dois níveis de aprofundamento. A primeira é a automatizada, utilizando a função captcha_fit_model() descrito a seguir, enquanto a segunda é a procedimental, utilizando o passo a passo descrito na Subseção A.1.3.\nA função captcha_fit_model() ajusta um modelo a partir de uma pasta com arquivos classificados. A função recebe os parâmetros: dir=, contendo o caminho dos arquivos classificados; dir_valid=, (opcional) contendo o caminho dos arquivos classificados para validação; prop_valid=, contendo a proporção da base de treino a ser considerada como validação, ignorada quando dir_valid= é fornecida (por padrão, considera-se 20% da base para validação).\nA função captcha_fit_model() também possui alguns parâmetros relacionados à modelagem. São eles: dropout=, especificando o percentual de dropout aplicado às camadas ocultas da rede (por padrão, 0.25); dense_units=, especificando a quantidade de unidades na camada oculta que vem depois das camadas convolucionais (por padrão, 200); decay=, especificando o percentual de decaimento da taxa de aprendizado (por padrão, 0.99); epochs= número de épocas para ajuste do modelo (por padrão 100). Uma observação importante é que o modelo está configurado para parar o ajuste após 20 iterações sem redução significativa na função de perda (arbitrado em 1%; para mais detalhes ver a Subseção A.1.3).\nNo final, a função retorna um modelo ajustado com classe luz_module_fitted, que pode ser salvo em disco utilizando-se a função luz_save(). O modelo também pode ser serializado para utilização em outros pacotes como pytorch. Um tutorial sobre serialização pode ser encontrado na documentação do pacote torch.\nO pacote {captchaOracle} possui uma interface similar para trabalhar com bases parcialmente classificadas. Como a estrutura de dados nesse caso é mais complexa e pode evoluir no futuro, os códigos foram organizados em outro pacote. Mais detalhes na Seção A.3.\nNa documentação do pacote {captcha}, foi adicionado um exemplo de aplicação. O exemplo utiliza captchas gerados usando a função captcha_generate(), que gera Captchas utilizando o pacote {magick}. O Captcha foi criado para a construção da tese, apelidado de R-Captcha, e possui os seguintes parâmetros:\n\nwrite_disk=: salvar os arquivos em disco? Por padrão, é falso.\npath=: Caminho para salvar arquivos em disco, caso o parâmetro anterior seja verdadeiro.\nchars=: Quais caracteres usar na imagem.\nn_chars=: O comprimento do Captcha.\nn_rows=: Altura da imagem, em pixels.\nn_cols=: Largura da imagem, em pixels.\np_rotate=: Probabilidade de rotação da imagem.\np_line=: Probabilidade de adicionar um risco entre as letras.\np_stroke=: Probabilidade de adicionar uma borda nas letras.\np_box=: Probabilidade de adicionar uma caixa (retângulo) em torno das letras.\np_implode=: Probabilidade de adicionar efeitos de implosão.\np_oilpaint=: Probabilidade de adicionar efeitos de tinta a óleo.\np_noise=: Probabilidade de adicionar um ruído branco no fundo da imagem.\np_lat=: Probabilidade de aplicar o algoritmo local adaptive thresholding à imagem.\n\n\n\nResolvendo um novo Captcha do zero\nEm algumas situações, pode ser desejável rodar modelos de forma customizada. Isso acontece pois modelos de aprendizagem profunda costumam precisar de diversos pequenos ajustes, como a taxa de aprendizado, utilização de outras funções de otimização, camadas computacionais e funções de pré-processamento.\nA função captcha_fit_model(), apresentada na subseção anterior, é engessada. Ela aceita alguns parâmetros para estruturar o modelo, mas não possui elementos suficientes para customização. É para isso que pacotes como {torch} e {luz} existem, pois criam ambientes de computação mais flexíveis para operar os modelos de aprendizado profundo.\nOutra desvantagem da utilização do captcha_fit_model() é a disponibilização dos modelos. Um modelo pode ser utilizado localmente, mas a tarefa de disponibilizar as bases de dados e o modelo para outras pessoas não tem um procedimento bem definido.\nPara organizar o fluxo de trabalho, implementou-se um fluxo de classificação de Captchas dentro do pacote {captcha}. A função que orquestra esse fluxo é a new_captcha(). A função possui apenas um parâmetro, path=, que é o caminho de uma nova pasta a ser criada.\nA função também pode ser chamada criando-se um projeto dentro do próprio RStudio. A Figura A.9 mostra um exemplo de utilização do template dentro do RStudio, após clicar em Novo Projeto > Novo Diretório.\n\n\n\n\n\nFigura A.9: Exemplo de criação de um novo projeto de Captcha utilizando o RStudio.\n\n\n\n\nAo criar um novo projeto, pelo comando new_captcha() ou pela interface do RStudio, uma nova janela é aberta. O projeto contém quatro arquivos:\n\n01_download.R: Contém algumas funções para auxiliar no desenvolvimento de funções que baixam Captchas em um caso real. Na prática, as funções que baixam Captchas precisam ser adaptadas porque os sites são organizados de formas muito diferentes.\n02_annotate.R: Contém um template para classificação manual de Captchas. A classificação manual pode tanto ser realizada usando a interface criada pelo pacote {captcha} quanto externamente. No final, os arquivos classificados devem ser salvos na pasta img, no formato descrito na Subseção A.1.2.\n03_model.R: Contém um template para modelagem, permitindo a customização completa do procedimento de ajuste. O script contém comandos para carregar os dados, especificar o modelo, realizar o ajuste e salvar o modelo ajustado.\n04_share.R: Contém funções para criar um repositório git da solução e disponibilizar o modelo ajustado. O modelo poderá ser lido e aplicado utilizando-se a função captcha_load_model(), para utilização em diferentes contextos, sem a necessidade de copiar arquivos localmente.\n\nSobre a parte de modelagem, cabe uma descrição mais detalhada. O primeiro passo do script é criar objetos do tipo dataset (objeto que armazena os dados de forma consistente) e dataloader (objeto que obtém amostras do dataset, que são utilizadas como os minibatches do modelo), com uma estrutura orquestrada pelo pacote {torch}.\nA função captcha_dataset() cria o dataset recebe como parâmetro uma pasta de arquivos e gera um objeto com classes my_captcha, dataset e R6. A função é, na verdade, um objeto do tipo dataset_generator, criada utilizando-se a função dataset() do pacote {torch}. O objeto é chamado da mesma forma que uma função usual do R, aceitando alguns parâmetros adicionais:\n\ncaptcha=: (opcional) fornecer um nome para o captcha.\ntransform_image=: operação de transformação a ser aplicada à imagem. Por padrão, utiliza a função captcha_transform_image(), que lê a imagem e redimensiona para ficar com dimensões 32x192. A dimensão foi escolhida para facilitar a implementação das camadas convolucionais e para lidar com o fato de que usualmente os Captchas são imagens retangulares.\ntransform_label=: operação de transformação para gerar a variável resposta. Por padrão, utiliza a função captcha_transform_label(), que recebe um vetor de todos os possíveis caracteres do Captcha e aplica a operação one_hot(), obtendo-se a versão matricial da resposta com zeros e uns, como descrito na Seção 2.1.1.\naugmentation=: operações para aumentação de dados . Por exemplo, pode ser uma função que adiciona um ruído aleatório à imagem original para que, ao gerar uma nova amostra, os dados utilizados sejam sempre diferentes.\n\nA função captcha_dataset() deve ser aplicada duas vezes, uma para criar a base de treino e outra para criar a base de validação. A separação de bases de treino e validação deve ser feita de forma manual, copiando parte dos Captchas classificados para uma nova pasta, com aleatorização. É papel do usuário separar as bases em pastas distintas carregá-as em um dataset.\nEm seguida, os dataloaders são criados utilizando-se a função dataloader() do pacote {torch}. Nessa parte é definido o tamanho do minibatch, além de outros possíveis parâmetros disponíveis na função do {torch}. Para mais detalhes, o usuário pode acessar a documentação da função neste link. Devem ser criados dataloaders tanto para a base de treino quanto para a base de validação.\nA próxima etapa é a especificação do modelo. No script de modelagem, o modelo é fornecido pelo objeto net_captcha do pacote {captcha}. Assim como no caso do dataset, o net_captcha é um objeto especial do {torch}, com classes CAPTCHA-CNN, nn_module e nn_module_generator, O objeto pode ser utilizado como uma função, gerando um módulo do torch, similar a uma função de predição. No entanto, por conta da forma que o objeto é utilizado em passos posteriores pelo pacote {luz}, o objeto a ser considerado é mesmo o nn_module_generator, como colocado no script.\nPara customizar o modelo, o usuário deve modificar os métodos initialize() e forward(), acessados dentro do objeto net_captcha$public_methods. O primeiro é responsável pela inicialização do modelo, contendo a descrição das operações que são realizadas, como convoluções. O segundo é a função feed forward das redes neurais, que recebe uma imagem e retorna um objeto contendo os logitos ou probabilidades, no formato da variável resposta.\nPor padrão, o código de inicialização do modelo é o descrito abaixo. Os parâmetros input_dim=, output_ndigits=, output_vocab_size= e vocab= descrevem, respectivamente, as dimensões da imagem, o comprimeiro da resposta, o comprimento do alfabeto e os elementos do alfabeto. Os parâmetros transform=, dropout= e dense_units= controlam, respectivamente, a função de transformação da imagem, os hiperparâmetros de dropout e a quantidade de unidades na camada densa. É possível notar que os parâmetros das convoluções são fixos, já preparados para funcionar bem com uma imagem de dimensões 32x192.\n\n\nCódigo\ninitialize = function(input_dim,\n                      output_ndigits,\n                      output_vocab_size,\n                      vocab,\n                      transform,\n                      dropout = c(.25, .25),\n                      dense_units = 400) {\n  \n  # in_channels, out_channels, kernel_size, stride = 1, padding = 0\n  self$batchnorm0 <- torch::nn_batch_norm2d(3)\n  self$conv1 <- torch::nn_conv2d(3, 32, 3)\n  self$batchnorm1 <- torch::nn_batch_norm2d(32)\n  self$conv2 <- torch::nn_conv2d(32, 64, 3)\n  self$batchnorm2 <- torch::nn_batch_norm2d(64)\n  self$conv3 <- torch::nn_conv2d(64, 64, 3)\n  self$batchnorm3 <- torch::nn_batch_norm2d(64)\n  self$dropout1 <- torch::nn_dropout2d(dropout[1])\n  self$dropout2 <- torch::nn_dropout2d(dropout[2])\n  \n  self$fc1 <- torch::nn_linear(\n    # must be the same as last convnet\n    in_features = prod(calc_dim_conv(input_dim)) * 64,\n    out_features = dense_units\n  )\n  self$batchnorm_dense <- torch::nn_batch_norm1d(dense_units)\n  self$fc2 <- torch::nn_linear(\n    in_features = dense_units,\n    out_features = output_vocab_size * output_ndigits\n  )\n  self$output_vocab_size <- output_vocab_size\n  self$input_dim <- input_dim\n  self$output_ndigits <- output_ndigits\n  self$vocab <- vocab\n  self$transform <- transform\n}\n\n\nA função de feed forward foi descrita abaixo. A função aplica o passo-a-passo descrito na Seção 2.1.2.1, recebendo uma imagem x como entrada e retornando uma matriz de logitos, que dão os pesos do modelo para cada letra da resposta. O modelo retorna os logitos e não as probabilidades porque, no passo seguinte, a função de perda considera como entrada os logitos. Se o usuário decidir modificar o método forward para retornar probabilidades, precisará também adaptar a função de perda utilizada.\n\n\n\nDefinida a arquitetura do modelo, o penúltimo passo é o ajuste. O ajuste do modelo é orquestrado pelo pacote {luz}, que facilita a criação do loop de ajuste dos parâmetros, desempenhando um papel similar ao que o keras realiza para o tensorflow puro.\nNo caso dos Captchas, o código {luz} para ajuste do modelo segue quatro passos, encadeados pelo operador pipe, ou |>:\n\nsetup(): serve para determinar a função de perda, o otimizador e as métricas a serem acompanhadas. No script, a função de perda utilizada é a nn_multilabel_soft_margin_loss() do {torch}, o otimizador é o optim_adam() do {torch} e a métrica é a captcha_accuracy(), desenvolvida no pacote {captcha} para apresentar a acurácia considerando a imagem completa do Captcha e não a acurácia de cada letra da imagem, que seria o resultado se fosse utilizada a função luz_metric_accuracy(), do pacote {luz}\nset_hparams(): serve para informar os hiperparâmetros e outras informações do modelo. Os parâmetros colocados dentro dessa função são exatamente os parâmetros do método initialize() da rede neural criada no passo anterior.\nset_opt_hparams(): serve para informar os hiperparâmetros da otimização. Os parâmetros colocados nessa função são passados para a função de otimização. No script, o único parâmetro informado é a taxa de aprendizado, fixada em 0.01.\nfit(): serve para inicializar o loop de ajuste do modelo. Aqui, é necessário passar os dataloaders de treino e validação, a quantidade de épocas (fixada em 100), e os callbacks, que são operações a serem aplicadas em diferentes momentos do ajuste (por exemplo, ao final de cada iteração). Por padrão, os callbacks são:\n\nO decaimento da taxa de aprendizado utilizando uma taxa multiplicativa. A cada iteração, a taxa de aprendizado decai em um fator determinado pela função definida em lr_lambda, que por padrão é 0.99. Ou seja, em cada época, a taxa de aprendizado fica 1% menor.\nA parada precoce, ou early stopping. Por padrão, está configurado para parar o ajuste do modelo se forem passadas 20 épocas sem que o modelo melhore a acurácia em 1% na base de validação. Por exemplo, se em 20 épocas consecutivas o modelo permanecer com acurácia em 53%, o ajuste será encerrado, mesmo que não tenha passado pelas 100 épocas.\nO arquivo de log. Por padrão, o modelo guarda o histórico de ajuste em um arquivo do tipo comma separated values (CSV), contendo a perda e a acurácia do modelo na base de treino e na base de validação, ao final de cada época. O arquivo de log é importante para acompanhar o ajuste do modelo e verificar sua performance ao longo das épocas, podendo dar insights sobre possíveis ajustes nos hiperparâmetros.\n\n\nNo final do fluxo definido pelo pacote {luz}, será obtido um modelo ajustado. O modelo possui a classe luz_module_fitted e pode ser investigado ao rodar o objeto no console do R. No exemplo do R-Captcha apresentado na subseção anterior, o objeto possui as características abaixo. O objeto contém um relatório conciso e bastante informativo, mostrando o tempo de ajuste, as métricas obtidas no treino e na validação e a arquitetura do modelo ajustado.\nA `luz_module_fitted`\n── Time ────────────────────────────────────────────────\n• Total time: 10m 48.1s\n• Avg time per training batch: 415ms\n• Avg time per validation batch 217ms\n\n── Results ─────────────────────────────────────────────\nMetrics observed in the last epoch.\n\nℹ Training:\nloss: 0.0049\ncaptcha acc: 0.996\nℹ Validation:\nloss: 0.0356\ncaptcha acc: 0.905\n\n── Model ───────────────────────────────────────────────\nAn `nn_module` containing 628,486 parameters.\n\n── Modules ─────────────────────────────────────────────\n• batchnorm0: <nn_batch_norm2d> #6 parameters\n• conv1: <nn_conv2d> #896 parameters\n• batchnorm1: <nn_batch_norm2d> #64 parameters\n• conv2: <nn_conv2d> #18,496 parameters\n• batchnorm2: <nn_batch_norm2d> #128 parameters\n• conv3: <nn_conv2d> #36,928 parameters\n• batchnorm3: <nn_batch_norm2d> #128 parameters\n• dropout1: <nn_dropout> #0 parameters\n• dropout2: <nn_dropout> #0 parameters\n• fc1: <nn_linear> #563,400 parameters\n• batchnorm_dense: <nn_batch_norm1d> #400 parameters\n• fc2: <nn_linear> #8,040 parameters\nPor último, o modelo deve ser salvo em um arquivo local. Isso é feito utilizando-se a função luz_save() do pacote {luz}, guardando um objeto com extensão .pt, que será disponibilizado no 04_share.R.\nCabe também um detalhamento do script disponibilizado em 04_share.R. O script utiliza o pacote {usethis} (WICKHAM; BRYAN; BARRETT, 2022) para organizar o repositório, configurando o Git (software de versionamento de códigos) e o GitHub (sistema web de organização de repositórios). Além disso, o script utiliza o pacote {piggyback} (BOETTIGER; HO, 2022) para disponibilizar o modelo ajustado nos releases do repositório criado. Opcionalmente, o usuário poderá também disponibilizar a base com os arquivos classificados em um arquivo .zip, o que é recomendado, pois permite que outras pessoas possam trabalhar com os mesmos dados e aprimorar os modelos.\nUm detalhe importante é sobre a inserção de arquivos pesados no repositório. O script utiliza releases para disponibilizar as soluções porque não é uma boa prática subir arquivos como modelos ajustados ou arquivos brutos (imagens) diretamente no repositório. Isso acontece porque o repositório pode ficar demasiadamente pesado e o histórico do Git fica alterado.\nUma vez compartilhado nos releases do repositório, o modelo poderá ser lido por qualquer pessoa, em outras máquinas utilizando o pacote {captcha}. Basta rodar o código abaixo e o modelo será carregado.\n\n\n\nCom isso, o trabalho pode ser compartilhado e Captchas podem ser resolvidos de forma colaborativa pelas pessoas interessadas. Utilizando o fluxo do new_captcha(), as pessoas têm flexibilidade para construir modelos customizados e utilizá-los de forma eficiente."
  },
  {
    "objectID": "pacote.html#sec-pacote-download",
    "href": "pacote.html#sec-pacote-download",
    "title": "Appendix A — Pacotes",
    "section": "Pacote captchaDownload",
    "text": "Pacote captchaDownload\nO pacote {captchaDownload} foi construído para armazenar os códigos de baixar dados de Captchas de forma consistente. O pacote também inclui funções para trabalhar com oráculos.\nO pacote não foi criado para ser usado por muitas pessoas. O intuito de criar o pacote foi o de organizar as funções utilizadas para realizar as simulações e obter os resultados empíricos da tese.\nAs funções do pacote {captchaDownload} são organizadas em dois tipos principais. As funções de acesso, identificadas pelo termo _access, fazem o download da imagem do Captcha e retornam todas as informações necessárias para fazer a verificação do oráculo, como, por exemplo, cookies e dados da sessão do usuário. Já as funções de teste, identificadas pelo termo _test, servem para verificar se um rótulo fornecido para o Captcha está correto ou não.\nAs funções ficam mais claras através de um exemplo. No caso do TRF5, por exemplo, o acesso é feito pela página do sistema PJe. A função captcha_access_trf5() recebe o parâmetro path=, que é a pasta para salvar a imagem, retornando uma lista com o caminho da imagem que foi salva e de componentes da sessão do usuário.\n\n\nCódigo\nacesso <- captchaDownload:::captcha_access_trf5(\"assets/img\")\nacesso\n\n\n$f_captcha\nassets/img/trf5ac031dafbd.jpeg\n\n$j_id\n[1] \"j_id1\"\n\n$u\n[1] \"https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam\"\n\n\n\nEm seguida, obtém-se o rótulo do modelo. Isso pode ser feito manualmente ou através de um modelo.\n\n\nCódigo\nlibrary(magrittr) # TODO remove\ncaptcha <- read_captcha(acesso$f_captcha)\nplot(captcha)\nmodelo_trf5 <- captcha_load_model(\"trf5\")\n(lab <- decrypt(acesso$f_captcha, modelo_trf5))\n#> [1] \"949588\"\n\n\n\n\n\nFigura A.10: Exemplo de Captcha baixado diretamente do TRF5.\n\n\n\n\nAgora, aplica-se a função captcha_test_trf5() para verificar se o rótulo está correto ou incorreto. A verificação é feita de forma automática, diretamente da internet, através do oráculo. A função recebe dois parâmetros: obj= com as informações obtidas da função de acesso; e label=, o rótulo obtido. A função retorna TRUE se o rótulo está correto e FALSE caso contrário.\n\n\nCódigo\n(acertou <- captchaDownload:::captcha_test_trf5(acesso, lab))\n\n\n[1] TRUE\nCada Captcha possui uma função de acesso e uma função de teste. Na prática, se uma pessoa desejar resolver um novo Captcha usando a técnica do oráculo, são essas funções que ela precisar desenvolver. Todas as outras operações podem ser generalizadas para diferentes casos de uso e estão implementadas nos pacotes {captchaDownload} e {captchaOracle}. Vale notar que a construção dessas funções geralmente é necessária para a construção de web scrapers, ou seja, elas não criam dificuldades adicionais para pessoas interessadas em resolver Captchas para acessar dados da internet.\nA função principal do pacote {captchaDownload} é a captcha_oracle(). A função é responsável por realizar a classificação parcial automática dos Captchas utilizando um modelo inicial e o oráculo. A função possui os seguintes parâmetros:\n\npath=: caminho em que os arquivos serão salvos.\nmodel=: modelo para predizer o rótulo de uma imagem.\nmax_ntry=: quantidade máxima de chutes até desistir.\nmanual=: caso o máximo de tentativas seja alcançado, abrir o prompt para classificar manualmente? Por padrão, sim.\ncaptcha_access=: função que baixa um Captcha e retorna dados da sessão para validar o Captcha, como mostrada anteriormente.\ncaptcha_test=: função que testa se um Captcha está correto a partir de um rótulo específico, como mostrado anteriormente.\n\nA função amarra todos os conceitos necessários para criar novas bases de dados de forma automática. Primeiro, considera o caminho para salvar os dados. Em seguida, considera o modelo e formas de lidar com o oráculo. Por último, recebe as funções de acesso e de teste do Captcha. A função escreve um arquivo de log com os resultados dos testes. O arquivo contém max_ntry linhas, podendo ter uma linha adicional se manual=TRUE, já que, se o modelo errar todas os chutes, a classificação manual deve ser adicionada.\nNo exemplo do TRF5, a chamada da função captcha_oracle() com um chute ficaria da seguinte forma:\n\n\nCódigo\nmodelo_trf5 <- captcha_load_model(\"trf5\")\n\ncaptchaDownload::captcha_oracle(\n  path = \"assets/img/\",\n  model = modelo_trf5, \n  max_ntry = 1,\n  manual = TRUE, \n  captcha_access = captchaDownload:::captcha_access_trf5,\n  captcha_test = captchaDownload:::captcha_test_trf5\n)\n\n\n✔ Acertou!!!\nNo teste do exemplo, a função acertou, salvando o seguinte arquivo de log. Espaços foram adicionados para facilitar a visualização.\nntry, label , type, result\n1,    569328, auto, TRUE\nAbaixo, foi colocado um modelo ruim para o TRT, para forçar o modelo a errar todos os chutes. O resultado é o log abaixo\n\n\nCódigo\nmodelo <- captcha_load_model(\"assets/modelo_ruim.pt\")\n\ncaptchaDownload::captcha_oracle(\n  path = \"assets/img/\",\n  model = modelo, \n  max_ntry = 10,\n  manual = TRUE, \n  captcha_access = captchaDownload:::captcha_access_trt,\n  captcha_test = captchaDownload:::captcha_test_trt\n)\n\n\nℹ Temos 10 candidatos...\nℹ Errou! O chute foi: v2su7w\nℹ Errou! O chute foi: t2su7w\nℹ Errou! O chute foi: v2su7y\nℹ Errou! O chute foi: t2su7y\nℹ Errou! O chute foi: y2su7w\nℹ Errou! O chute foi: v2su7h\nℹ Errou! O chute foi: t2su7h\nℹ Errou! O chute foi: y2su7y\nℹ Errou! O chute foi: v2wu7w\nLabel: v2xu7w\nNo novo exemplo, a função errou todos os dez chutes, salvando o seguinte arquivo de log. Espaços foram adicionados para facilitar a visualização. O último valor é um rótulo inserido manualmente.\nntry,  label,   type, result\n   1, v2su7w,   auto,  FALSE\n   2, t2su7w,   auto,  FALSE\n   3, v2su7y,   auto,  FALSE\n   4, t2su7y,   auto,  FALSE\n   5, y2su7w,   auto,  FALSE\n   6, v2su7h,   auto,  FALSE\n   7, t2su7h,   auto,  FALSE\n   8, y2su7y,   auto,  FALSE\n   9, v2wu7w,   auto,  FALSE\n  10, 92su7w,   auto,  FALSE\n  NA, v2xu7w, manual,   TRUE\nSe o parâmetro manual=FALSE e o modelo não consegue acertar o rótulo, a função também adiciona a mensagem:\n✖ Errado depois de todas as tentativas...\nEm alguns casos, é possível que a função realize menos do que max_ntry chutes. Isso acontece quando a probabilidade do melhor rótulo depois do chute errado é muito pequena, segundo o modelo. Isso é feito pela função captcha_candidates(), que considera como padrão o corte de 0.01 de probabilidade. Ou seja, na prática, a função testa no máximo os max_ntry rótulos com probabilidades maior que 0.01 segundo o modelo.\nEm resumo, o pacote {captchaDownload} contém toda a parte de web scraping utilizada no desenvolvimento da tese. Adicionalmente, o pacote contém funções para orquestrar o download automático de Captchas parcialmente rotulados, a partir de um modelo inicial e um oráculo.\nOs dados fornecidos pelo pacote ficam tanto na forma de imagens rotuladas quanto na forma de arquivos de log, disponibilizados em arquivos CSV. Para lidar com essa estrutura de dados, mais um pacote foi desenvolvido: o {captchaOracle}, definido a seguir."
  },
  {
    "objectID": "pacote.html#sec-pacote-oracle",
    "href": "pacote.html#sec-pacote-oracle",
    "title": "Appendix A — Pacotes",
    "section": "Pacote captchaOracle",
    "text": "Pacote captchaOracle\nO pacote {captchaOracle}, assim como o {captchaDownload}, foi desenvolvido para a construção da tese. O pacote, portanto, não apresenta documentação extensiva e suas funções podem não estar com a sintaxe final. Futuramente, o pacote poderá funcionar como novo backend para o pacote {captcha}, aplicando o WAWL como uma alternativa no fluxo de resolução de Captchas definido na Subseção A.1.3.\nO pacote possui quatro funções principais: captcha_dataset_oracle(), net_captcha_oracle(), oracle_loss() e captcha_accuracy_oracle(). Cada função desempenha um papel similar a seus pares do pacote {captcha}, mas conseguem lidar com a estrutura de dados fornecida pelo oráculo.\nA primeira função a ser utilizada é a captcha_dataset_oracle(). Trata-se de uma função similar à captcha_dataset() do pacote {captcha}, mas com um parâmetro adicional, path_logs=, que recebe o caminho dos arquivos de log.\nA estrutura de dados no caso do oráculo é mais complexa do que no caso canônico. Na resposta, ao invés de guardar uma matriz one hot para cada Captcha, é armazenada uma lista com várias matrizes one hot, uma para cada tentativa do Captcha. Além disso, é armazenado um vetor z, com zeros e uns, informando se algum rótulo está correto ou se todos os rótulos estão incorretos. A variável z é construída a partir dos nomes dos arquivos, que contém um _1 caso o rótulo esteja correto e _0 caso contrário. Por último, a imagem de entrada é armazenada da mesma forma que na função captcha_dataset().\nO módulo net_captcha_oracle() faz poucos ajustes à estrutura inicial fornecida pelo módulo net_captcha() do pacote {captcha}. A única modificação da função é que ela recebe um modelo inicial de entrada, transferindo os pesos ajustados do modelo ao novo módulo. O módulo net_captcha_oracle(), inclusive, poderia ser utilizado fora do contexto do WAWL, já que só utiliza os dados de input, que não são alterados.\nA função captcha_accuracy_oracle() é utilizada para estimar a acurácia do modelo. Para isso, a função precisa lidar com o fato de que os dados de validação apresentam uma estrutura diferente dos dados de treino, já que estão completamente classificados. No treino, a acurácia é calculada considerando apenas os casos em que a resposta é conhecida. Na validação, a acurácia é calculada considerando-se todas as observações.\nPor último, a função oracle_loss() é a que contém a proposta de função de perda do método WAWL. Nos casos corretos, a função de perda é obtida calculando-se uma entropia cruzada simples. Nos casos incorretos, a perda é calculada pela estratégia 1-p, ou seja, considerando o complementar da probabilidade de observar os chutes que foram apresentados segundo o modelo.\nEm resumo, o pacote {captchaOracle} é o que contém os principais avanços da tese do ponto de vista estatístico. Na prática, é utilizado como backend computacional para ajuste dos modelos que utilizam o oráculo, dentro de um fluxo de trabalho igual ao que é construído para ajuste dos modelos canônicos.\nOs códigos para realizar as simulações do modelo foram adicionados na pasta data-raw do pacote {captchaOracle}. Os códigos foram organizados da seguinte forma:\n\npasso_01_*.R. Contêm os códigos utilizados para ajustar os modelos iniciais. Os códigos são organizados de forma a permitir que vários modelos sejam rodados em paralelo, aproveitando o máximo do poder computacional da máquina utilizada para realizar os ajustes.\npasso_02_*.R. Contêm os códigos utilizados para construir as bases de treino e validação para o passo 03. Foi o passo mais demorado da simulação, já que envolveu acessar os sites dos tribunais pela internet para obtenção dos Captchas anotados automaticamente. Para realizar a simulação, foram baixados mais de 500.000 Captchas da internet.\npasso_03_*.R. Contêm os códigos utilizados para ajustar os modelos finais. Os códigos foram organizados de forma similar ao passo 01, mas utilizando as funções desenvolvidas no pacote {captchaOracle} para considerar os dados fornecidos pelo oráculo.\n\nPor fim, foi adicionado também um script report.R, que monta as bases principais e os resumos dos modelos ajustados. As bases fornecidas pelo último script foram adicionadas ao repositório da tese.\n\n\n\n\nALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022. Disponível em: <https://CRAN.R-project.org/package=tensorflow>.\n\n\nBOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub Repository. 2022. Disponível em: <https://CRAN.R-project.org/package=piggyback>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’ Acceleration. 2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A practical approach for predictive models. CRC Press, 2019.\n\n\nTRECENTI, J. et al. decryptr: An extensible API for breaking captchas. 2022.\n\n\nUSHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’. 2022. Disponível em: <https://CRAN.R-project.org/package=reticulate>.\n\n\nWICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and Project Setup. 2022. Disponível em: <https://CRAN.R-project.org/package=usethis>."
  }
]