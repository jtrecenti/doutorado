[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Resolvendo Captchas",
    "section": "",
    "text": "Sobre este documento\nEste documento foi construído utilizando o Quarto, um sistema de publicação científica de código aberto desenvolvido com base no Pandoc. Os códigos foram escritos com o software estatístico R na versão 4.2.2.\nO documento foi escrito em duas versões: PDF e HTML. A versão em HTML foi construída com Quarto Books. A versão em PDF incorpora o template do IME-USP, mantido pelo Centro de Competência de Software Livre.\nTodos os códigos e textos da tese podem ser acessados publicamente neste link. Boa leitura!"
  },
  {
    "objectID": "introducao.html#sec-captchas-publicos",
    "href": "introducao.html#sec-captchas-publicos",
    "title": "1  Introdução",
    "section": "Captchas em serviços públicos",
    "text": "Captchas em serviços públicos\nA Constituição Federal de 1988 (CF), em seu inciso XXXIII do art. 5º, prevê que “todos têm direito a receber dos órgãos públicos informações de seu interesse particular, ou de interesse coletivo ou geral, que serão prestadas no prazo da lei, sob pena de responsabilidade, ressalvadas aquelas cujo sigilo seja imprescindível à segurança da sociedade e do Estado;”. Essa previsão é implementada pela Lei de Acesso à Informação (Lei 12.527/2011; LAI), que se aplica “aos órgãos públicos integrantes da administração direta dos Poderes Executivo, Legislativo, incluindo as Cortes de Contas, e Judiciário e do Ministério Público”, bem como “as autarquias, as fundações públicas, as empresas públicas, as sociedades de economia mista e demais entidades controladas direta ou indiretamente pela União, Estados, Distrito Federal e Municípios” (Art. 1º).\nA LAI, apesar de trazer diversos benefícios à sociedade, tem dois problemas. O primeiro é o esforço: tanto a pessoa/órgão que solicita os dados, quanto o órgão que retorna os dados precisam trabalhar para disponibilizar as informações, sendo necessário deslocar equipes para realizar os levantamentos pedidos. O segundo é o formato: os dados enviados como resultado de pedidos de LAI podem chegar em formatos inadequados para consumo da solicitante, muitas vezes em Portable Document Format (PDF), que dificulta a leitura e análise dos dados (MICHENER; MONCAU; VELASCO, 2015, pág. 55); além disso, como o levantamento é realizado de forma individualizada, o mesmo pedido feito em diferentes períodos (e.g. uma atualização mensal dos dados) pode vir em formatos diferentes, dificultando a leitura e arrumação dos dados.\nUma forma eficiente de evitar os problemas de esforço e formato em pedidos de LAI é disponibilizar os dados de forma aberta. Como definido pela Open Knowledge Foundation (OKFN), a base de dados “deve ser fornecida em uma forma conveniente e modificável, isenta de obstáculos tecnológicos desnecessários para a realização dos direitos licenciados. Especificamente, os dados devem ser legíveis por máquina, disponíveis em todo o seu volume, e fornecidos em um formato aberto (ou seja, um formato com sua especificação livremente disponível, e publicada sem quaisquer restrições, monetárias ou não, da sua utilização) ou, no mínimo, podem ser processados com pelo menos uma ferramenta de software livre e gratuita.”2\nAs vantagens ao disponibilizar dados públicos de forma aberta para a sociedade é um tema pacífico na comunidade científica (MURRAY-RUST, 2008). No Brasil, existem plataformas dedicadas à abertura de dados governamentais, como o dados.gov.br. No entanto, existem diversos dados públicos que ainda não estão disponíveis de forma aberta.\nA dificuldade de acesso é particularmente evidente no Poder Judiciário, que além de não disponibilizar um portal de dados abertos, impõe barreiras aos pedidos de acesso à informação por utilizar diversos sistemas para armazenar os dados. Por exemplo, para pedir uma lista de todos os processos judiciais relacionados à recuperação judicial de empresas, as únicas alternativas são i) pedir os dados ao Conselho Nacional de Justiça (CNJ), que não possui informações suficientes para obter a lista3 ou ii) expedir ofícios aos 27 Tribunais Estaduais. Cada tribunal apresentaria diferentes opções e critérios de acesso aos dados, diferentes prazos para atendimento e diferentes formatos, podendo, inclusive, negar o pedido de acesso.\nA dificuldade para acessar os dados do judiciário é a principal barreira para realização de pesquisas pela Associação Brasileira de Jurimetria (ABJ), empresa na qual o autor desta tese trabalha. A entidade tem como missão principal realizar estudos empíricos para implementar políticas públicas utilizando dados do judiciário.\nDos 16 projetos disponibilizados na página de pesquisas no site da ABJ, pelo menos 12 (75%) apresentaram dificuldades na obtenção dos dados via pedidos de acesso aos órgãos. Três exemplos emblemáticos são o da pesquisa sobre Tempo dos processos relacionados à adoção no Brasil (ABJ, 2014), o Observatório da Insolvência: Rio de Janeiro (ABJ, 2021) e o Diagnóstico do Contencioso Tributário Administrativo (ABJ, 2022). No primeiro caso, dois tribunais enviaram os dados em arquivos em papel, sendo que um deles ultrapassou mil páginas com números de processos impressos. No segundo caso, o pedido foi respondido com uma planilha de contagens ao invés da lista de processos. No último caso, até mesmo órgãos que faziam parte do grupo de trabalho da pesquisa negaram pedido de acesso a dados de processos tributários em primeira instância, com argumentos que variavam desde a dificuldade técnica de levantar os dados até a Lei Geral de Proteção de Dados (LGPD).\nEm muitas situações a única alternativa para realizar as pesquisas é acessando os dados via coleta automatizada nos sites. Todos os tribunais possuem ferramentas de consulta individualizadas de processos, por conta do que está previsto na CF. A solução, portanto, passa a ser construir uma ferramenta que obtém todos os dados automaticamente. Tal conceito é conhecido como raspagem de dados (ZHAO, 2017) e será desenvolvido com maiores detalhes no Capítulo 2.\nOs Captchas se tornam prejudiciais à sociedade quando o acesso automatizado é necessário para realizar pesquisas científicas. Infelizmente, vários tribunais utilizam a barreira do Captcha. Alguns tribunais, inclusive, têm o entendimento de que o acesso automatizado é prejudicial, como o Tribunal de Justiça do Rio Grande do Sul (TJRS), que emitiu um comunicado sobre o tema.\nUma justificativa comum para implementar Captchas em consultas públicas é a estabilidade dos sistemas. Ao realizar muitas consultas de forma automática, um robô que faz consultas automatizadas pode tornar o sistema instável e, em algumas situações, até mesmo derrubar o servidor ou banco de dados que disponibiliza as consultas.\nO problema é que utilizar Captchas não impede o acesso automatizado. As empresas que fazem acesso automatizado em tribunais podem construir ferramentas ou utilizar serviços externos de resolução de Captchas. Ou seja, ao utilizar Captchas, o acesso não é impedido, apenas especializado.\nUtilizar Captchas também é uma solução ineficiente. Do ponto de vista técnico, a solução mais eficiente para disponibilizar os dados é através de ferramentas de dados abertos como o Comprehensive Knowledge Archive Network (CKAN). Ao disponibilizar os dados de forma aberta, as consultas automatizadas ficariam isoladas dos sites de consulta pública, o que garantiria o acesso das pessoas sem problemas de indisponibilidade.\nNão é só quem faz pesquisa com dados públicos que o uso de Captchas pode ser prejudicial. No mercado, existem serviços de resolução de Captchas que utilizam mão de obra humana, em regimes que pagam muito menos do que um salário-mínimo a 8 horas de trabalho. Um exemplo é o 2Captcha4, que funciona como um Uber dos Captchas: o algoritmo automatizado envia o Captcha para a plataforma, que é acessado e resolvido por uma pessoa, retornando a solução para o algoritmo. O 2Captcha é operado pela ALTWEB LLC-FZ, uma empresa com base em Dubai5.\nSegundo o site, o valor pago pelo 2Captcha é de US$ 0,5 para 1 a 2 horas de trabalho. No regime da Consolidação das Leis do Trabalho (Decreto-Lei 5.452/1943, CLT) as horas mensais de trabalho são 220. Trabalhando continuamente no 2Captcha, isso daria um salário de 55 a 110 dólares por mês, valor bem abaixo do salário-mínimo do Brasil, que no ano de 2022 era de R$ 1.100,006, mesmo considerando os valores mais altos de taxa de câmbio. Ou seja, os serviços públicos acabam, indiretamente, incentivando um mercado que paga abaixo do salário-mínimo. Luis von Ahn, um dos criadores dos Captchas, define o 2Captcha como um sweatshop, um termo utilizado para caracterizar empresas que têm condições de trabalho inaceitáveis.\nA solução definitiva para os problemas gerados pelos Captchas é a disponibilização dos dados públicos de forma aberta. Na ausência dessa solução, seja por falta de interesse ou iniciativa dos órgãos públicos, a alternativa é desenvolver uma solução para resolver Captchas que seja gratuita e aberta. Tal solução desincentivaria economicamente o uso de sistemas como o 2Captcha, protegendo as pessoas que fazem as resoluções e auxiliando pesquisadores em seus estudos.\nO presente trabalho busca avançar nesse sentido. A solução desenvolvida envolve um modelo que resolve alguns Captchas automaticamente, reduzindo significativamente a necessidade de anotação manual.\nPara compreender completamente o avanço que a tese representa, no entanto, é necessário apresentar o histórico de desenvolvimento dos Captchas. A descrição é feita através de uma luta entre geradores e resolvedores de Captchas, que pode ser dada como encerrada no ano de 2018, com o advento do reCaptcha v3."
  },
  {
    "objectID": "introducao.html#sec-historia",
    "href": "introducao.html#sec-historia",
    "title": "1  Introdução",
    "section": "Uma luta entre geradores e resolvedores",
    "text": "Uma luta entre geradores e resolvedores\nO primeiro texto técnico sobre Captchas foi publicado por AHN; BLUM; LANGFORD (2002). O texto apresenta o Captcha e seu significado através do problema de geração de emails automáticos no Yahoo. Em seguida, apresenta alguns exemplos de candidatos a Captcha, com tarefas de reconhecimento de padrões ou textos. Uma característica interessante dos autores sobre o Captcha é que suas imagens devem ser disponíveis publicamente. O texto também faz a conexão entre a tarefa dos Captchas e os desafios da inteligência artificial. Um ponto a destacar é que os autores incentivam pesquisas para resolver Captchas, pois isso implica em avanços na inteligência artificial. O site original do projeto, The Captcha Project, foi lançado em 2000.\nO relatório técnico de AHN; BLUM; LANGFORD (2002) não foi o primeiro a apresentar o nome Captcha, nem suas aplicações. RESHEF; RAANAN; SOLAN (2005) foi o primeiro registro de patente com o termo e LILLIBRIDGE et al. (2001) foi o primeiro registro de patente que implementou uma solução aos sistemas de Captchas. No entanto, o relatório técnico de 2002 é o primeiro que reconhecidamente trata do tema como um problema de inteligência artificial.\nOs artigos mais conhecidos de introdução aos Captchas são VON AHN et al. (2003) e VON AHN; BLUM; LANGFORD (2004). O conteúdo dos trabalhos é o mesmo, sendo o primeiro deles na forma de apresentação e o segundo na forma de relatório. Um detalhe interessante é a ênfase dos autores no termo Public dos Captchas, mostrando a preocupação em manter os códigos públicos.\nOs autores também defendem que o Captcha é uma forma de fazer com que pessoas mal-intencionadas contribuam com os avanços da inteligência artificial. Se uma pessoa (ainda que mal-intencionada) resolve um Captcha e publica essa solução, isso significa que a comunidade científica avançou na área de inteligência artificial.\nNão demorou para surgirem os primeiros resolvedores de Captchas7. MORI; MALIK (2003) foi um dos primeiros trabalhos publicados sobre o tema e utiliza diversas técnicas de processamento de imagens para obter os rótulos corretos. Também não demorou para a comunidade científica perceber que redes neurais eram úteis nesse contexto (CHELLAPILLA; SIMARD, 2004). No artigo de 2004, Chellapilla e Simard desenvolvem um algoritmo baseado em heurísticas para segmentar a imagem e redes neurais para identificar as imagens individuais.\nA partir desse ponto, foi iniciada uma luta entre geradores e resolvedores de Captchas. Do lado dos geradores, as pessoas envolvidas foram tanto acadêmicos tentando desenvolver desafios cada vez mais difíceis para avançar na pesquisa em inteligência artificial, quanto empresas de tecnologia tentando se proteger contra robôs sofisticados. Do lado dos resolvedores, as pessoas envolvidas foram tanto acadêmicos tentando desenvolver novas técnicas para avançar nos modelos de reconhecimento de imagens, quanto spammers buscando novas formas de realizar ataques cibernéticos.\nUma das pessoas envolvidas com geradores de Captchas mais conhecidas é Luis von Ahn, um dos criadores do artigo original do Captcha. Um pedaço da história dos Captchas está disponível nos primeiros cinco minutos de sua entrevista em um programa britânico chamado Spark8. Na entrevista, Von Ahn conta um pouco sobre origem dos Captchas em Carnegie Mellon, contando que ficou frustrado com o fato de as pessoas perderem tempo de inteligência humana ao resolver Captchas, o que deu origem ao reCaptcha. Outro vídeo instrutivo é uma palestra de Von Ahn na Thinking Digital Conference sobre a história do reCaptcha9. Segundo ele, a startup foi criada em maio de 200710, depois de Von Ahn verificar que aproximadamente 200 milhões de Captchas eram resolvidos diariamente.\nO reCaptcha v1 aproveitou o tempo das pessoas que resolvem Captchas para digitalizar livros (AHN et al., 2008). A ideia do reCaptcha, como demonstrada na Figura 1.1, foi apresentar duas palavras distorcidas para a pessoa. Imagine que uma ferramenta de OCR (Optical Character Recognition) está digitalizando a página de um livro que foi escaneada de um documento físico, ou seja, está transformando a foto da página do livro em um arquivo de texto. Na Figura, “upon” seria uma palavra que a ferramenta de OCR conseguiu transformar a imagem em texto com sucesso, enquanto “between” seria uma palavra em que a ferramenta de OCR falhou. A primeira palavra seria utilizada para verificar se o agente era ou não humano, e a segunda seria utilizada para decifrar a palavra e aprimorar as ferramentas de OCR. Em 2009, a empresa foi comprada pela Google, que utilizou o reCaptcha v1 para digitalizar os livros que estão presentes no site Google Books.\n\n\n\n\n\nFigura 1.1: Explicação de von Ahn sobre o funcionamento do reCaptcha\n\n\n\n\nCuriosamente, foi com a própria Google que os resolvedores ficaram em vantagem na luta contra geradores. Os modelos de inteligência artificial continuaram avançando, notadamente com o avanço dos modelos de redes neurais profundas (LECUN; BENGIO; HINTON, 2015). No trabalho de GOODFELLOW et al. (2013), foi apresentado um modelo de redes neurais convolucionais que resolvia o reCaptcha v1 com 99,8% de acurácia. No ano seguinte, em 2014, a Google descontinuou o reCaptcha v1, lançando o reCaptcha v2.11\nO reCaptcha v2 apresentou duas inovações importantes. O primeiro foi o botão “I’m not a robot”, um verificador automático do navegador que utiliza heurísticas para detectar se o padrão de acesso ao site se assemelha com um robô ou humano. O segundo foi a mudança no tipo de tarefa: ao invés de rotular um texto distorcido, o desafio passou a ser identificar objetos e animais, como na Figura 1.2.\n\n\n\n\n\nFigura 1.2: Exemplo do reCaptcha v2 com a imagens de perus\n\n\n\n\nA mudança do tipo de tarefa de visão computacional foi importante para o sucesso do reCaptcha v2. O desafio é mais difícil, já que existem muito mais objetos e imagens do que letras e números, aumentando significativamente o suporte da variável resposta. Por exemplo, um modelo para identificar perus pode ser facilmente desenvolvido a partir de uma base anotada, potencialmente custosa para ser construída. O reCaptcha v2, no entanto, pode facilmente mudar a tarefa para identificar leões, cães, hidrantes e semáforos, inutilizando o modelo criado para classificar perus.\nO reCaptcha v2 também foi usado para gerar novas bases de dados para a Google, usando o mesmo princípio do reCaptcha v1. A humanidade do agente é verificada apenas com uma parte das imagens. As outras imagens eram utilizadas para anotar imagens, utilizadas para aprimorar modelos utilizados nos projetos de carros autônomos, Google Street View e outras iniciativas da empresa.\nCom o advento do reCaptcha v2, a pergunta de interesse dos resolvedores de Captcha passou a ser: como criar modelos que funcionam razoavelmente bem sem a necessidade de anotar muitas imagens? Se esse desafio fosse resolvido, dois avanços aconteceriam: i) um grande avanço na inteligência artificial, especificamente na área de visão computacional, e ii) uma nova forma de vencer a luta de geradores e resolvedores.\nAté o momento de escrita da tese, não existia um modelo geral que resolvesse com alta acurácia todos os desafios colocados pelo reCaptcha v2 e seus concorrentes. No entanto, vários avanços apareceram no sentido de reduzir a quantidade de imagens anotadas para criar candidatos a resolvedores. Dentre eles, os mais significativos são os baseados nas redes generativas adversariais (Generative Adversarial Networks, ou GANs), propostas no famoso trabalho de GOODFELLOW et al. (2014). O primeiro trabalho que utiliza modelos generativos no contexto de Captchas mostrou uma redução de 300x na quantidade de dados anotados necessários para resolver um Captcha (GEORGE et al., 2017). Nesse caso, os autores propõem uma rede diferente do GAN, chamada Recursive Cortical Network, ou RCN. Outros trabalhos mais recentes (WANG et al., 2021; YE et al., 2018) avançam ainda mais na pesquisa, reduzindo o trabalho de classificação para um novo Captcha de texto para aproximadamente 2 horas.\nMas foi em 2018, com o reCaptcha v3, que a Google fez um passo definitivo. Com a nova versão, as verificações do navegador web passaram a ser muito mais poderosas, sendo raros os casos em que o site fica em dúvidas se a pessoa é ou não um robô. Versões mais recentes, como o reCaptcha Enterprise, de 2020, ainda permitem que as mantenedoras dos sites façam o ajuste fino de modelos de detecção de robôs. Dessa forma, desafios de reconhecimento de texto e objetos em imagens perderam a importância.\nEntão, no final, quem venceu a luta de geradores e resolvedores? Na verdade, nenhuma das duas! O que ocorreu com o reCaptcha v3 e seus sucessores foi, no fundo, uma mudança de perspectiva: o Captcha deixou de ser um sistema passivo e passou a ser um sistema ativo de verificação do agente. Ao invés de criar uma tarefa difícil de resolver por robôs e fácil de resolver por pessoas, os sistemas criaram uma camada de verificação da sessão de acesso do usuário, incluindo análises do navegador, dos cookies e dos padrões de cliques. Antes mesmo de chegar no desafio de reconhecimento, o algoritmo de acesso precisa enganar os verificadores. Essa tarefa é muito mais parecida com um problema de cyberataque do que uma tarefa de inteligência artificial.\nA luta entre sites e spammers continua, mas não é mais uma luta entre geradores e resolvedores. Por conta disso, os desafios dos Captchas, sejam de texto ou de imagem, são hoje muito mais uma questão acadêmica do que uma questão de segurança. A pesquisa sobre Captchas ainda é promissora e pode gerar muitos resultados importantes para a área de inteligência artificial.\nApesar dos avanços do reCaptcha v3, Captchas de textos em imagens continuam sendo populares na internet. Isso é especialmente evidente nos serviços públicos – objeto deste trabalho –, já que os serviços raramente são atualizados com ferramentas mais recentes. Desenvolver uma ferramenta que facilita a resolução de Captchas em sites públicos é uma forma de incentivar os sites a serem atualizados, disponibilizando os dados públicos de forma mais eficiente.\nDesenvolver e disponibilizar novos métodos para resolução de Captchas de textos em imagens pode ter um impacto positivo na transparência dos serviços públicos. Essa é a lacuna identificada a partir da observação do estado atual dos serviços públicos e dos trabalhos acadêmicos analisados.\nA pesquisa apresenta um fluxo de trabalho que pode ser facilmente aplicado a diferentes modelos de resolução de Captchas, incluindo arquiteturas que ainda não foram desenvolvidas. O fluxo de trabalho funcionará como um acelerador do aprendizado, possibilitando a criação de modelos que não precisam de intervenção humana.\nO resultado será encontrado explorando o potencial de uso do oráculo, disponível em todos os Captchas de textos em imagens. Para definir e contextualizar o uso do oráculo, no entanto, é necessário apresentar algumas características sobre o problema estudado."
  },
  {
    "objectID": "introducao.html#sec-intro-oraculo",
    "href": "introducao.html#sec-intro-oraculo",
    "title": "1  Introdução",
    "section": "Oráculo",
    "text": "Oráculo\nModelos de aprendizagem profunda usuais podem ser sensíveis a perturbações pequenas nas imagens (YUAN et al., 2019). Por isso, para resolver o Captcha de um tribunal, um modelo que resolve o Captcha de outro tribunal pode não ser eficaz, sendo necessário baixar e anotar uma nova base e treinar um novo modelo.\nAvanços em técnicas de regularização fazem com que o modelo seja menos afetado por mudanças nos desafios gerados. Uma técnica de regularização que ajuda na capacidade de generalização é a aumentação de dados com adição de ruídos (NOH et al., 2017). No entanto, nenhuma técnica garante que o modelo terá excelentes resultados em novos desafios.\nUma alternativa é desenvolver modelos que aprendem com poucos dados anotados. Como comentado anteriormente, GANs e modelos relacionados podem apresentar bons resultados na resolução de tarefas de imagens, mesmo com uma base de dados pequena. Nesse sentido, ainda que um site mude seu Captcha, é possível ajustar um modelo que resolve esse Captcha sem a necessidade de anotar muitos exemplos para construir uma nova base de treino.\nNessa tese, apresenta-se uma nova técnica para resolver Captchas com poucas ou nenhuma imagem anotada, chamada Web Automatic Weak Learning (WAWL). A técnica alia técnicas de raspagem de dados com técnicas de aprendizado fracamente supervisionado, especificamente o aprendizado com rótulos parciais, explorando uma característica específica dos Captchas, que é a presença de um oráculo.\nOráculo é a resposta do site pesquisado, afirmando se o rótulo enviado está correto ou errado. Eles estão disponíveis em todos os sites com Captchas, já que, por definição, o Captcha precisa apresentar o resultado do teste para o usuário. O nome “oráculo” foi inspirado na mitologia grega, partindo do fato de que o site já possui a informação correta, como um deus. O site, no entanto, se comunica com o usuário através de um intermediário (o oráculo) que apresenta a resposta de forma limitada.\nOráculos se manifestam de diversas formas nos sites com Captchas. Por exemplo, pode dar a possibilidade de realizar apenas um teste por imagem, vários testes por imagem, ou ainda retornar informações ruidosas. Um exemplo de oráculo ruidoso é o reCaptcha v1, que pode retornar com um “bom o suficiente” quando o rótulo não está totalmente correto (AHN et al., 2008).\nO oráculo é uma forma de obter uma base de dados virtualmente infinita. Do ponto de vista de modelagem, é similar a um problema de aprendizado por reforço (SUTTON; BARTO, 2018), mas com uma resposta binária (acertou ou errou) no lugar de um escore.\nO método WAWL consiste em aproveitar o fato de que o Captcha, por definição, aplica um teste de Turing automático para gerar bases de dados parcialmente anotadas. Ou seja, a técnica resolve o problema não com modelos mais sofisticados, mas com a utilização eficiente dos recursos disponíveis. Qualquer modelo pode se aproveitar dessa característica dos Captchas, incluindo as arquiteturas mais sofisticadas ou técnicas que ainda não foram desenvolvidas.\nA metodologia parte de um modelo inicial, que pode ter baixo poder preditivo. O modelo inicial pode ser ajustado com as técnicas usuais de modelagem, ou utilizando um modelo mais sofisticado como GAN. Em seguida, o site na web é acessado múltiplas vezes, gerando uma nova base de dados virtualmente infinita, que é completamente anotada nos casos de acerto e que apresenta o histórico de erros no caso de erro. Os dados gerados automaticamente são então aproveitados para aprimorar o modelo inicial.\nUm ponto importante do WAWL é como aproveitar a informação oferecida pelo oráculo. Utilizar somente os casos anotados corretamente, obtidos de acertos no teste do oráculo, induz viés de seleção na amostra (NA et al., 2020). Como o modelo só tem acesso aos casos em que já funciona bem, a informação obtida não é tão relevante. O desafio de modelagem da tese reside em como considerar a informação fornecida pelo oráculo nos casos em que o modelo inicial erra.\nDo ponto de vista estatístico, a informação produzida pelo oráculo pode ser entendida como uma informação censurada (COLOSIMO; GIOLO, 2006). Isso acontece pois a informação existe e é correta, mas não está completa. No entanto, como a informação é resultado do teste de um rótulo produzido por um modelo, faz sentido afirmar que a censura não é gerada por acaso.\nNa área de aprendizado de máquinas, um modelo que apresenta resposta censurada ou incompleta faz parte da classe de aprendizado fracamente supervisionado (ZHOU, 2018). Trata-se de uma área ainda pouco investigada na literatura, mas bastante ampla, englobando não só os métodos supervisionados como também os métodos semi-supervisionados. A tese apresentará os conceitos de aprendizado fracamente supervisionado, com foco na classe de problemas que a modelagem utilizando Captchas representa.\nO custo técnico de implementar o WAWL está na necessidade de utilizar técnicas de raspagem de dados para criar uma nova base usando o oráculo. Essas técnicas imitam repetidamente o que um humano faria para acessar o site, precisando ser desenvolvidas de forma customizada para cada Captcha analisado.\nNo entanto, resolver Captchas é uma tarefa meio, não uma tarefa fim. Na prática, o interesse é construir ferramentas que acessam os sites e realizar pesquisas com os dados obtidos. E as ferramentas que acessam os sites para obter dados já envolvem a construção de raspadores de dados. Como o desenvolvimento de raspadores de dados é necessário em todas as pesquisas, a parte de raspagem de dados no método WAWL possui tempo de desenvolvimento negligenciável.\nA tese tem como foco principal descrever e testar a eficácia do método WAWL. Mas a tese também tem objetivos práticos, relacionados à resolução de Captchas que estão presentes em serviços públicos e disponibilização das soluções desenvolvidas para a comunidade de programadores. A seguir, apresenta-se a lista de objetivos completa, de forma concisa."
  },
  {
    "objectID": "introducao.html#sec-objetivos",
    "href": "introducao.html#sec-objetivos",
    "title": "1  Introdução",
    "section": "Objetivo",
    "text": "Objetivo\nO objetivo geral da tese é desenvolver um método inovador, chamado WAWL (Web Automatic Weak Learning) para resolver Captchas, misturando técnicas de aprendizado profundo com raspagem de dados e aproveitando os dados fornecidos pelo oráculo.\nEspecificamente, a pesquisa tem como objetivos:\n\nDescrever o método proposto e estudar suas características.\nConstruir e disponibilizar um repositório de dados para realização de mais pesquisas no ramo.\nAjustar modelos e testar a eficácia do método.\nDisponibilizar um pacote computacional aberto que possibilita a implementação de soluções para resolver Captchas presentes em serviços públicos."
  },
  {
    "objectID": "introducao.html#sec-justificativa",
    "href": "introducao.html#sec-justificativa",
    "title": "1  Introdução",
    "section": "Justificativa",
    "text": "Justificativa\nO presente trabalho é relevante para a ciência por três motivos: importância teórica, viabilidade técnica e importância prática. Os pontos são explicados abaixo.\nDo ponto de vista teórico, a tese é importante por apresentar uma aplicação muito especial do aprendizado fracamente supervisionado. No caso do Captcha, como a base de dados fracamente supervisionados é virtualmente infinita, trata-se de uma excelente oportunidade para testar novas técnicas e verificar como elas se comportam empiricamente. Os objetivos 1 e 2 estão relacionados a essa justificativa.\nCom relação à viabilidade técnica, o trabalho parte de uma lista de Captchas que já foram resolvidos utilizando técnicas tradicionais de aprendizado profundo. Como os Captchas já foram resolvidos previamente, mesmo que a WAWL não apresentasse bons resultados – e apresenta – o projeto ainda teria como subprodutos as bases de dados e o pacote computacional disponibilizados abertamente. O objetivo 3 é o que torna a proposta tecnicamente viável.\nFinalmente, do ponto de vista prático, Captchas em serviços públicos causam desequilíbrio de mercado e incentivam o uso de serviços com formas de remuneração duvidosas. O objetivo 4 vai de encontro direto com esse problema, ao disponibilizar uma ferramenta gratuita e aberta para resolução de Captchas que pode ser utilizada em diversos serviços públicos."
  },
  {
    "objectID": "introducao.html#sec-hipoteses",
    "href": "introducao.html#sec-hipoteses",
    "title": "1  Introdução",
    "section": "Hipóteses",
    "text": "Hipóteses\nO projeto foi desenvolvido em torno de duas hipóteses principais. As hipóteses têm origem tanto do levantamento bibliográfico realizado para desenvolver a pesquisa, quanto da experiência pessoal do autor em projetos de pesquisa aplicados.\n\nA utilização do WAWL gera modelos que resolvem Captchas de textos em imagens sem a necessidade de criar grandes bases anotadas.  \nÉ possível aliar a área de raspagem de dados com a área de modelagem estatística."
  },
  {
    "objectID": "introducao.html#sec-organizacao",
    "href": "introducao.html#sec-organizacao",
    "title": "1  Introdução",
    "section": "Organização do trabalho",
    "text": "Organização do trabalho\nO segundo capítulo, “metodologia”, contém todos os passos dados para construção da tese, tanto do ponto de vista teórico como prático. Parte-se da definição técnica dos Captchas, chegando até as redes neurais e a classe problema trabalhada de forma ampla. Em seguida, apresenta-se o método WAWL e suas características. Depois, a base de dados é descrita, mostrando as fontes de dados consideradas e as técnicas de raspagem de dados utilizadas. Por último, descreve-se, com detalhes, as simulações realizadas para obter os resultados empíricos.\nO terceiro capítulo, “resultados”, apresenta os resultados da pesquisa. Primeiro são apresentados os resultados das simulações e outros experimentos realizados com a técnica WAWL. Em seguida, descreve-se o pacote {captcha}, criado para atingir o objetivo 4 da pesquisa. O capítulo também apresenta uma breve discussão dos resultados obtidos.\nNo quarto e último capítulo, “conclusão”, a pesquisa é concluída, com apresentação das considerações finais e próximos passos. No final, também foi incluído um apêndice descrevendo e documentando os pacotes {captchaDownload} e {captchaOracle}, criados para atuar em conjunto com o pacote {captcha} para implementar o método WAWL.\n\n\n\n\nABJ. Tempo dos processos relacionados à adoção., 2014. Disponível em: <https://abj.org.br/pesquisas/adocao/>.\n\n\nABJ. Observatório da insolvência: Rio de Janeiro., 2021. Disponível em: <https://abj.org.br/pesquisas/obsrjrj/>.\n\n\nABJ. Diagnóstico do Contencioso Tributário Administrativo., 2022. Disponível em: <https://abj.org.br/pesquisas/bid-tributario/>.\n\n\nAHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web Security Measures. Science, v. 321, n. 5895, p. 1465–1468, 12 set. 2008. Disponível em: <https://www.science.org/doi/10.1126/science.1160379>.\n\n\nAHN, L. VON; BLUM, M.; LANGFORD, J. Telling humans and computers apart automatically or how lazy cryptographers do AI (Tech. Rep. No. CMU-CS-02-117). Disponível em: <http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf>.\n\n\nCHELLAPILLA, K. et al. Designing human friendly human interaction proofs (HIPs). : CHI ’05.New York, NY, USA: Association for Computing Machinery, 2 abr. 2005. Disponível em: <https://doi.org/10.1145/1054972.1055070>.\n\n\nCHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human interaction proofs (HIPs). Advances in neural information processing systems, v. 17, 2004.\n\n\nCOLOSIMO, E. A.; GIOLO, S. R. Análise de sobrevivência aplicada. Editora Blucher, 2006.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, v. 358, n. 6368, p. eaag2612, 2017.\n\n\nGOODFELLOW, I. J. et al. Multi-digit number recognition from street view imagery using deep convolutional neural networks. arXiv preprint arXiv:1312.6082, 2013.\n\n\nGOODFELLOW, I. J. et al. Generative Adversarial Networks. arXiv, jun. 2014. Disponível em: <https://arxiv.org/abs/1406.2661>.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning. nature, v. 521, n. 7553, p. 436444, 2015.\n\n\nLILLIBRIDGE, M. D. et al. Method for Selectively Restricting Access to Computer Systems., fev. 2001.\n\n\nMICHENER, G.; MONCAU, L. F.; VELASCO, R. B. Estado brasileiro e transparência avaliando a aplicação da Lei de Acesso à Informação.\n\n\nMORI, G.; MALIK, J. Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA. IEEE, 2003.\n\n\nMURRAY-RUST, P. Open data in science. Nature Precedings, p. 11, 2008.\n\n\nNA, B. et al. Deep Generative Positive-Unlabeled Learning under Selection Bias. : CIKM ’20.New York, NY, USA: Association for Computing Machinery, 19 out. 2020. Disponível em: <https://doi.org/10.1145/3340531.3411971>.\n\n\nNOH, H. et al. Regularizing deep neural networks by noise: Its interpretation and optimization. Advances in Neural Information Processing Systems, v. 30, 2017.\n\n\nRESHEF, E.; RAANAN, G.; SOLAN, E. Method and System for Discriminating a Human Action from a Computerized Action., 2005.\n\n\nSUTTON, R. S.; BARTO, A. G. Reinforcement learning: An introduction. MIT press, 2018.\n\n\nTURING, A. M. Computing machinery and intelligence. Em: Springer, 2009. p. 2365.\n\n\nVON AHN, L. et al. Captcha: Telling Humans and Computers Apart Automatically. Proceedings of Eurocrypt. Anais...2003.\n\n\nVON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart Automatically. Communications of the ACM, v. 47, n. 2, p. 56–60, 2004.\n\n\nW3C. Inaccessibility of CAPTCHA., 2021. Disponível em: <https://www.w3.org/TR/turingtest/>.\n\n\nWANG, Y. et al. Make complex captchas simple: a fast text captcha solver based on a small number of samples. Information Sciences, v. 578, p. 181194, 2021.\n\n\nYE, G. et al. Yet another text captcha solver: A generative adversarial network based approach. 2018.\n\n\nYUAN, X. et al. Adversarial examples: Attacks and defenses for deep learning. IEEE transactions on neural networks and learning systems, v. 30, n. 9, p. 28052824, 2019.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13, 2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning. National science review, v. 5, n. 1, p. 4453, 2018."
  },
  {
    "objectID": "metodologia.html#definição-do-problema",
    "href": "metodologia.html#definição-do-problema",
    "title": "2  Metodologia",
    "section": "Definição do problema",
    "text": "Definição do problema\n\nO problema a ser trabalhado é um caso de aprendizado fracamente supervisionado (ZHOU, 2018). Trata-se de uma generalização do aprendizado supervisionado e do aprendizado semi-supervisionado. Usualmente, a área de aprendizado estatístico (ou aprendizado de máquinas) se concentra em dois tipos de problemas principais: o aprendizado supervisionado e o aprendizado não supervisionado. Isso ocorre principalmente por fins didáticos, pois é mais fácil passar os modelos que fazem parte de cada área.\nNo entanto, a estatística evolui com os problemas que ocorrem no mundo. No mundo, os problemas nem sempre recaem em uma ou outra categoria. O que temos, na verdade, é que os problemas não supervisionados e supervisionados estão conectados quando o objetivo da pesquisa é predizer valores (regressão) ou categorias (classificação).\nNesse sentido, uma área que ficou popular nos últimos anos, até por conta dos avanços na área de deep learning, é o aprendizado semi-supervisionado (ZHU, 2005). Trata-se de uma classe de problemas contendo uma amostra completamente anotada e uma amostra sem anotações. A amostra sem anotações é usada para compreender como os dados foram gerados, e os parâmetros podem ser compartilhados com a parte supervisionada do modelo. Isso poderia indicar que existem três classes de problemas: o não supervisionado, o supervisionado e o semi-supervisionado.\nMas isso também não representa todas as classes de problemas. Em muitas aplicações reais, obter uma anotação completa e correta pode ser custoso ou até impraticável. Além disso, por envolver trabalho humano, é comum que classificações contenham erros. A área que generaliza os casos anteriores é o aprendizado fracamente supervisionado.\nAprendizado fracamente supervisionado é um termo guarda-chuva. Dentro da área existem diversos tipos de problemas, como aprendizado semi-supervisionado, aprendizado de múltiplas instâncias (BLUM; KALAI, 1998) e o aprendizado com rótulos incorretos ou incompletos (ZHOU, 2018). O método WAWL é um exemplo de aplicação de uma classe chamada aprendizado com rótulos parciais (partial label learning, PLL, JIN; GHAHRAMANI (2002)). Essa classe apresenta uma especialização ainda mais próxima do problema estudado, chamado aprendizado com rótulos complementares (complementary label learning, ISHIDA et al. (2017)).\nA interpretação do Captcha como um problema de PLL será apresentada no final do capítulo. A jornada começa descrevendo um pouco melhor os Captchas, que são o objeto de análise do trabalho.\n\nCaptcha\nCaptcha é um desafio do tipo desafio-resposta usado para determinar se o usuário do sistema é um humano. Existem diversos tipos de Captcha diferentes, que envolvem a identificação de textos em imagens até a resolução de expressões matemáticas complexas.\nO foco deste trabalho reside nos Captchas baseados em imagens rotuladas, que é o tipo mais comum. Em seguida, a menos que se mencione ao contrário, todas as menções a Captchas se referem a este tipo.\nO fluxo completo de um Captcha envolve cinco componentes: um rótulo, um gerador, uma imagem, um agente e um oráculo. O ciclo de um Captcha é completado ao seguir os passos:\n\nO rótulo (segredo) é definido, usualmente com algum procedimento aleatório, ocultado do agente.\nA imagem é gerada a partir do rótulo e apresentada para o agente.\nO agente produz uma ou mais respostas a partir da imagem (que pode estar certa ou errada)\nO oráculo verifica se a resposta está correta.\nDependendo da resposta, o agente é direcionado para a página autenticada ou para uma página de erro.\n\nA Figura 2.1 esquematiza o fluxo do Captcha. As caixas com fundo azul são passos realizados pelo servidor, de forma oculta ao agente. As caixas em branco são interações do agente com o site. O agente pode ser tanto um ser humano quanto um robô imitando um ser humano.\n\n\n\n\n\nFigura 2.1: Fluxo do Captcha\n\n\n\n\nDependendo da forma que um Captcha foi construído, existe a possibilidade de realizar múltiplas tentativas (chutes) para acertar o rótulo. Isso pode ocorrer tanto por uma escolha deliberada dos desenvolvedores do Captcha quanto por falhas na construção do site. A possibilidade de realizar múltiplos chutes pode ter impactos positivos nos resultados do método WAWL, como será visto no Capítulo 3.\n\nImagem, rótulo e variável resposta\nA imagem é uma matriz \\(\\mathbf x = \\{x_{nmr} \\in [0,1]\\}_{N\\times M \\times R}\\), contendo padrões que levam ao rótulo do Captcha. O rótulo é dado por um vetor de caracteres \\(\\mathbf c = [c_1,\\dots,c_L]^\\top\\). O comprimento \\(L\\) pode ser fixo ou variável, ou seja, duas imagens criadas pelo mesmo gerador podem vir com comprimentos diferentes. Nas definições que seguem considerou-se \\(L\\) como fixo, por simplicidade.\nCaptchas costumam ter dimensões relativamente pequenas, com a altura \\(N\\) variando entre 30 e 200 pixels e a largura \\(M\\) variando entre 100 e 300 pixels. As imagens costumam ser retangulares para comportar várias letras lado a lado, ou seja, geralmente \\(M > N\\). O valor de \\(R\\) é 1 para imagens em escala de cinza e 3 para imagens coloridas.\nO elemento da matriz \\(x_{nm\\cdot}\\) é denominado pixel. Um pixel é um vetor de comprimento \\(R\\) que representa a menor unidade da imagem. Em uma imagem colorida, por exemplo, \\(R=3\\), sendo o pixel um vetor de três dimensões com valores entre zero e um, representando a intensidade de vermelho, verde e azul da coordenada \\((n, m)\\) da imagem. Em imagens em escala de cinza, \\(R=1\\) e o pixel, de uma dimensão, representa a intensidade do cinza, sendo 1 o equivalente da cor branca e 0 da cor preta.\nOs elementos do vetor \\(\\mathbf c\\) fazem parte de um alfabeto \\(\\mathcal A\\), com cardinalidade \\(|\\mathcal A|\\), finito e conhecido. O alfabeto contém todos os possíveis caracteres que podem aparecer na imagem. Na maioria dos casos, \\(\\mathcal A\\) corresponde a uma combinação de algarismos arábicos (0-9) e letras do alfabeto latino (a-z), podendo diferenciar ou não as letras maiúsculas e minúsculas1.\nA Figura 2.2 mostra um exemplo Captcha do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, tem-se \\(L=5\\) e \\(|\\mathcal A|=10\\), apenas os dez algarismos arábicos. A imagem tem dimensões \\(N=110\\), \\(M=40\\) e \\(R=3\\). O rótulo da imagem é \\([5,2,4,3,2]^\\top\\).\n\n\n\n\n\nFigura 2.2: Exemplo de Captcha no TJMG\n\n\n\n\nA variável resposta é uma matriz binária \\(\\mathbf y_{L \\times |\\mathcal A|}\\), em que cada linha representa um dos valores do vetor \\(\\mathbf c\\), enquanto as colunas possuem um representante para cada elemento de \\(\\mathcal A\\). Um elemento \\(y_{ij}\\) vale 1 se o elemento \\(i\\) do rótulo \\(\\mathbf c\\) corresponde ao elemento \\(j\\) do alfabeto \\(\\mathcal A\\), valendo zero caso contrário. A variável resposta é uma transformação do rótulo conhecida comumente na área de aprendizado estatístico como one-hot encoding.\nUma maneira alternativa de definir a variável resposta seria com um vetor de índices representando cada elemento do alfabeto em um vetor. O problema de trabalhar dessa forma é que a variável resposta \\(\\mathbf y\\) tem um número exponencial de combinações: o rótulo possui \\(L\\) caracteres, sendo que cada caractere pode ter \\(|\\mathcal A|\\) valores, totalizando \\(|\\mathcal A|^L\\) combinações. Por exemplo, um Captcha com \\(L=6\\) letras e \\(|\\mathcal A| = 36\\) possibilidades em cada letra (26 letras do alfabeto latino e 10 algarismos arábicos), possui um total de 2.176.782.336 (\\(>\\) 2 bilhões) combinações. Por isso, modelar as imagens diretamente através de uma única variável resposta categórica é tecnicamente inviável.\nA forma one-hot da resposta pode ser entendida como uma multinomial multivariada (LI; TSUNG; ZOU, 2014). A resposta é multivariada porque existem \\(L\\) caracteres na imagem e multinomial porque existem \\(|\\mathcal A|\\) possíveis caracteres em cada posição. Dessa forma, é possível pensar que um modelo que resolve o Captcha envolve \\(L\\) classificadores com resposta multinomial, cada um dando conta de um dos caracteres. Os classificadores podem ser independentes e podem até contar com etapas de pré-processamento separadas.\nSeguindo o exemplo da Figura 2.2, é possível representar o rótulo da seguinte forma:\n\\[\n\\mathbf c = \\left[\\begin{array}{c}\n     5  \\\\\n     2 \\\\\n     4 \\\\\n     3 \\\\\n     2\n\\end{array}\\right] \\rightarrow \\mathbf{y} = \\left[\\begin{array}{cccccccccc}\n    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{array}\\right]\n\\]\nA forma da variável resposta facilita os trabalhos que seguem. Como será visto mais adiante, o modelo de rede neural gerará uma matriz de probabilidades que somam \\(1\\) em cada linha, contendo as probabilidades atribuídas a cada caractere nas posições da matriz.\n\n\nGerador\nO gerador é uma função que recebe um rótulo como entrada e devolve uma imagem como saída. Um bom gerador é aquele que é capaz de gerar uma imagem fácil de interpretar por humanos, mas difícil de interpretar por robôs.\nUm exemplo de gerador é a função captcha_generate() criada no pacote {captcha}, que foi descrito em maiores detalhes na Seção 3.2. A função foi criada para realizar simulações do sistema de resolução proposto na tese, a partir do pacote {magick} (OOMS, 2021), que utiliza o software ImageMagick. A função aplica uma série de distorções e efeitos comuns no contexto de Captchas, gerando imagens como a da Figura 2.3.\n\n\n\n\n\nFigura 2.3: Exemplo de captcha gerado pela função captcha::captcha_generate()\n\n\n\n\nO gerador segue os passos abaixo, a partir do momento em que um rótulo \\(\\mathbf c\\) existe:\n\nÉ criada uma matriz \\(N\\times M \\times R\\), com valores entre zero e um gerados por simulações de uma \\(\\mathcal U(0,1)\\).\nÉ adicionada uma cor base ao ruído, definida de forma aleatória.\nA matriz é transformada em um objeto do tipo magick-image.\nA imagem é preenchida com o valor do rótulo, adicionando-se efeitos como rotação, uma linha unindo as letras e variação de cores.\nA imagem recebe outros tipos de distorções, como adição de ruído, alteração de cores e outros efeitos.\n\nNo final, o gerador retorna a imagem, que é a única informação enviada ao agente. O rótulo fica escondido para verificação do oráculo.\n\n\nOráculo\nPara definir o oráculo, utilizou-se uma terminologia que é facilmente encaixada com a teoria de aprendizado fracamente supervisionado. Neste caso, para facilitar a notação, considera-se uma resposta como uma variável multinomial, sem ser multivariada, denotada por \\(y\\). Seja \\(f\\) um classificador utilizado para predizer o rótulo de uma imagem e seja \\(\\mathbf x_{n+1}\\) uma nova imagem que é observada, com sua resposta \\(y_{n+1}\\), desconhecida. A operação \\(f(\\mathbf x_{n+1})\\) retorna um candidato para \\(y_{n+1}\\), que pode estar correto ou errado.\nO oráculo é uma função \\(\\mathcal O: \\mathcal Y \\rightarrow 2^{\\mathcal Y}\\), que recebe um elemento do domínio da resposta \\(\\mathcal Y\\) (do conjunto de todas as combinações de rótulos) para o conjunto de subconjuntos (partes) de \\(\\mathcal Y\\). Na prática, a função retorna uma lista de possíveis valores de \\({y}_{n+1}\\), da seguinte forma:\n\\[\n\\mathcal O(f(\\mathbf x_{n+1})) = \\left\\{\\begin{array}{ll}\n    \\{ y_{n+1}\\}, & \\text{ se } y_{n+1} = f(\\mathbf x_{n+1})  \\\\\n    \\mathcal Y \\setminus \\{f(\\mathbf x_{n+1})\\}, & \\text{ se } y_{n+1} \\neq f(\\mathbf x_{n+1})\n\\end{array}\\right..\n\\]\nQuando o classificador \\(f\\) acerta o rótulo, o oráculo retorna o valor “1”, acompanhado de uma lista que contém apenas um elemento: o próprio rótulo. Quando o classificador \\(f\\) retorna o rótulo errado, o oráculo retorna o valor “0”, acompanhado de uma lista com todos os outros possíveis rótulos do rótulo, o que inclui o verdadeiro valor \\(y_{n+1}\\). Para simplificar a notação, também é possível chamar essa informação como o rótulo complementar \\(\\bar{\\mathbf y} = \\mathcal Y \\setminus \\{ \\hat {y}_{n+1}\\}\\). Neste caso utiliza-se o símbolo \\(\\bar{\\mathbf y}\\), indicando que é uma lista valores possíveis de \\(y\\).\nA Figura 2.4 mostra o funcionamento do oráculo no exemplo do TJMG. Quando a predição é igual ao rótulo, o resultado apresentado é o valor “1”, indicando que o rótulo está correto. Quando a predição é diferente do rótulo, o resultado apresentado é o valor “0”, indicando que o valor testado está incorreto e que, portanto, o rótulo real é um dentre todos os outros possíveis rótulos.\n\n\n\n\n\nFigura 2.4: Esquema mostrando o funcionamento do oráculo\n\n\n\n\nÉ possível generalizar naturalmente o oráculo para Captchas que aceitam múltiplos chutes mudando a definição da função que faz predições. Seja \\(\\mathbf f\\) uma função que retorna um conjunto de \\(k\\) respostas possíveis, \\(k\\in \\mathbb N\\), \\(k\\geq 1\\), com \\(\\mathbf x_{n+1}\\) e \\(y_{n+1}\\) iguais aos definidos anteriormente. Então o oráculo tem o funcionamento definido abaixo:\n\\[\n\\mathcal O(\\mathbf f(\\mathbf x_{n+1})) = \\left\\{\\begin{array}{ll}\n    \\{y_{n+1}\\}, & \\text{ se } y_{n+1} \\in \\mathbf f(\\mathbf x_{n+1})  \\\\\n   \\mathcal Y \\setminus \\mathbf f(\\mathbf x_{n+1}), & \\text{ se } y_{n+1} \\notin \\mathbf f(\\mathbf x_{n+1})\n\\end{array}\\right..\n\\]\nNesse caso, o oráculo também retorna uma lista contendo a resposta \\(y_{n+1}\\), além de outros valores. A única diferença é que, quando o Captcha aceita múltiplos chutes, a lista retornada em caso de erro tem um comprimento menor.\nO oráculo tem um papel fundamental na elaboração do método WAWL. O fato do oráculo sempre retornar a resposta correta na lista de opções faz com que ele necessariamente reduza o espaço de respostas a serem buscadas em uma tentativa futura.\n\n\nFatos estilizados dos Captchas\nAbaixo, listou-se três características e discussões comuns no contexto dos Captchas, chamados fatos estilizados. Estes pontos vão além da evolução histórica dos Captchas e ajudam a contextualizar melhor o problema.\n\nUma alternativa para resolver Captchas é separando o problema em duas tarefas: segmentar e classificar. A tarefa de segmentação consiste em receber uma imagem com várias letras e detectar pontos de corte, separando-a em várias imagens de uma letra. Já a classificação consiste em receber uma imagem com uma letra e identificar o caractere correspondente. Nesse caso, a resposta é reduzida para \\(|\\mathcal A|\\) categorias. Como \\(|\\mathcal A|\\) cresce linearmente, o problema é tratável pelos algoritmos tradicionais de aprendizado.\nA tarefa de resolver Captchas também poderia ser vista como um problema de reconhecimento óptico de caracteres (Optical Character Recognition, OCR). No entanto, as distorções encontradas em Captchas são bem diferentes das distorções encontradas em textos escaneados, que são o objeto de aplicação de ferramentas de OCR. Por esse motivo, as ferramentas usuais de OCR apresentam resultados pouco satisfatórios em vários Captchas.\nAs distorções encontradas em Captchas podem ser agrupadas em distorções para dificultar a segmentação e distorções para dificultar a classificação. Na parte de classificação, as principais formas de dificultar o trabalho dos modelos são i) mudar as fontes (serifa ou sem serifa ou negrito/itálico, por exemplo), ii) mudar letras minúsculas para maiúsculas e iii) adicionar distorções nos caracteres. Já na parte de segmentação, as principais formas são i) colar os caracteres e ii) adicionar linhas ligando os dígitos. Essas técnicas são combinadas com a adição de ruído e distorção nas imagens completas para compor a imagem final.\n\n\n\n\nRedes neurais\nO método WAWL apresentado na Seção 2.2 utiliza uma arquitetura básica de redes neurais convolucionais. Por isso, é importante apresentar as definições sobre redes neurais e sobre a operação de convolução no contexto de Captchas.\nO método WAWL pode utilizar diversas arquiteturas de redes neurais. A escolha de uma arquitetura mais simples foi feita para demonstrar a eficácia do procedimento de forma mais contundente. Outras arquiteturas mais rebuscadas, como as apresentadas na introdução (GEORGE et al., 2017; YE et al., 2018) podem melhorar os resultados do modelo. A única restrição é que ela possa receber uma função de perda modificada, como será mostrado na na Seção 2.2.\n\nA seguir, apresenta-se como funcionam as redes neurais no contexto de Captchas. O modelo descrito é o que foi utilizado nas simulações, que é um modelo de redes neurais convolucionais simples, similar ao LeNet, com três camadas convolucionais e duas camadas densas (LECUN et al., 1998).\nÉ possível organizar a estrutura de uma rede neural em três componentes: a arquitetura da rede, a função de perda e o otimizador. Os componentes são detalhados nas próximas subseções.\nComo uma rede neural possui muitos componentes e subcomponentes, é usual apresentar sua estrutura na forma de um diagrama. Redes neurais costumam ser fáceis de representar através de grafos, que podem ser utilizados de forma mais ou menos detalhada, dependendo do interesse.\nA Figura 2.5 mostra, de forma esquemática, os componentes (retângulos tracejados) e subcomponentes (partes internas dos componentes) do modelo utilizado. As partes de fora dos componentes são entradas de dados ou decisões de parada do ajuste.\n\n\n\n\n\nFigura 2.5: Diagrama representando o modelo utilizado de forma genérica, com todos os componentes e subcomponentes apresentados de forma esquemática\n\n\n\n\n\nArquitetura da rede\nA arquitetura da rede é uma função que leva os dados de entrada na estrutura de dados (dimensões) da variável resposta. A arquitetura tem papel similar ao exercido pelo componente sistemático em um modelo linear generalizado (NELDER; WEDDERBURN, 1972). Trata-se da parte mais complexa da rede neural, carregando todos os parâmetros que serão otimizados.\nA arquitetura da rede possui três componentes principais, com algumas subdivisões:\n\nas camadas ocultas: camadas convolucionais e camadas densas;\nas técnicas de regularização: normalização em lote (batch normalization), dropout e junção de pixels (max pooling);\nas funções de ativação: função de ativação linear retificada (rectified linear unit, ReLU) e a função de normalização exponencial (softmax).\n\nAbaixo, apresenta-se as definições seguindo-se a ordem de aplicação das operações na arquitetura da rede neural: camada convolucional, ReLU, max pooling, batch normalization, dropout, camada densa e softmax.\nA convolução é uma operação linear que recebe como entrada uma matriz e retorna outra matriz. Ela é diferente de uma operação usual de multiplicação de matrizes vista no contexto de modelos lineares generalizados, por envolver uma soma ponderada dos elementos na vizinhança de cada pixel.\nUma forma organizada de fazer a soma ponderada da convolução é criando uma matriz de pesos. Com ela, não é necessário procurar os pontos da vizinhança. Para cada ponto \\((i,j)\\), obtém-se a matriz de vizinhança, multiplica-se pontualmente pela matriz de pesos e soma-se os valores resultantes. A matriz de pesos é chamada de núcleo, ou kernel.\nConsidere o kernel\n\\[\nK = \\left[\\begin{array}{rrr}-1&-1&-1\\\\0&0&0\\\\1&1&1\\end{array}\\right]\n\\]\ne a imagem da Figura 2.6. Como visto anteriormente, trata-se de uma matriz de dimensão \\(40\\times110\\times3\\).\n\n\n\n\n\nFigura 2.6: Imagem de Captcha utilizado em exemplos anteriores\n\n\n\n\nTome por exemplo a primeira dimensão do pixel \\((n,m,r) = (12,16,1)\\). A vizinhança 3x3 em torno desse ponto é dada por\n\n\n\n\\[\nP_{n,m,r} = \\left[\\begin{array}{rrr}\n0.094 & 0.412 & 0.686 \\\\\n0.051 & 0.063 & 0.529 \\\\\n0.071 & 0.000 & 0.086\n\\end{array}\\right].\n\\]\nA operação de convolução é feita da seguinte forma:\n\\[\n\\begin{aligned}\n(P_{12,16,1} *K )_{12,16,1}\n&= k_{1,1}p_{11,15,1} + k_{1,2}p_{11,16,1} + k_{1,3}p_{11,17,1} + \\\\\n&+ k_{2,1}p_{12,15,1} + k_{2,2}p_{12,16,1} + k_{2,3}p_{12,17,1} + \\\\\n&+ k_{3,1}p_{13,15,1} + k_{3,2}p_{13,16,1} + k_{3,3}p_{13,17,1} \\\\\n& = -1.035.\n\\end{aligned}\n\\]\nEsse é o valor resultante da convolução, a ser colocado no ponto \\((i,j,k)\\). A operação funciona da mesma forma em todos os pontos que não estão na borda da imagem.\nExistem duas formas de trabalhar com as bordas da imagem. A primeira é preenchendo as bordas com zeros, de forma a considerar apenas os pontos que estão na imagem na conta. A segunda é descartar os pontos da borda e retornar uma imagem menor, contendo somente os pixels em que foi possível aplicar todo o kernel.\nNo caso do exemplo, o resultado da convolução fica como na Figura 2.7. Como a imagem resultante tem apenas uma dimensão, ela aparenta ficar em preto e branco. Na prática, no entanto, serão aplicados vários núcleos diferentes, resultando em uma imagem com várias cores, que são chamados de canais.\nA matriz de exemplo não foi escolhida por acaso: ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada por \\(-1\\) e a última é formada por \\(1\\), a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (\\(\\text{grande} * 1 + \\text{pequeno} * (-1)\\)). A parte destacada da imagem acabou sendo a parte de baixo dos números e, principalmente, a linha que une os números.\n\n\n\n\n\n\n\n\nFigura 2.7: Aplicação de uma convolução com kernel horizontal\n\n\n\n\nAplicando o kernel vertical abaixo\n\\[\nK = \\left[\\begin{array}{rrr}-1&0&1\\\\-1&0&1\\\\-1&0&1\\end{array}\\right],\n\\]\nas partes destacadas são as laterais dos números, conforme Figura 2.8.\n\n\n\n\n\nFigura 2.8: Aplicação de uma convolução com kernel vertical\n\n\n\n\nO resultado da convolução pode ter números negativos ou maiores que um. Para que seja possível visualizar, os números das imagens mostradas acima foram ajustados para que ficassem no intervalo \\([0,1]\\).\nUma característica das imagens mostradas acima é que elas ficaram escuras, ou seja, com muitos valores próximos de zero. Uma técnica para modificar a imagem é adicionar uma constante numérica ao resultado da convolução. Esse é o chamado viés (bias) da convolução.\nA Figura 2.9 mostra o efeito de adicionar um viés de 0.6 após aplicação da convolução com kernel vertical. É possível identificar claramente a diferença entre os números (mais suaves) e as curvas usadas para conectar os números (mais proeminentes).\n\n\n\n\n\nFigura 2.9: Aplicação de uma convolução com kernel vertical e viés\n\n\n\n\nUma camada convolucional envolve a aplicação de convoluções com \\(d\\) kernels em uma matriz, além da adição do bias. Tais kernels, bem como o intercepto, terão seus valores ajustados ao longo do processo de otimização do modelo. O resultado da aplicação de uma camada convolucional com preenchimento das bordas é uma matriz com as mesmas dimensões \\(N\\) e \\(M\\) da matriz de entrada, mas com \\(d\\) entradas na dimensão das cores. Como o valor de \\(d\\) pode ser diferente de 1 ou 3, não faz mais sentido tratar essa dimensão como responsável pelas cores. Por isso essa dimensão é chamada de canais da matriz resultante.\nA Figura 2.10 mostra a aplicação de uma camada convolucional para a imagem utilizada nos exemplos anteriores. Os kernels foram escolhidos com base em um modelo que já foi ajustado para o Captcha. Note que os canais capturam a informação dos números e dos ruídos, focando em detalhes diferentes.\n\n\n\n\n\n\n\n\nFigura 2.10: Resultado da aplicação da primeira convolução à imagem\n\n\n\n\nAntes da aplicação da camada convolucional, a operação de batch normalization é aplicada. Essa operação normaliza os números da matriz de entrada antes da aplicação da convolução, retirando a média e dividindo pelo desvio padrão, conforme equação abaixo.\n\\[\nx_z = \\left(\\frac{x-\\bar x}{\\sqrt{\\sigma^2_x + \\epsilon}}\\right) \\gamma + \\beta\n\\]\nNa equação acima, o valor \\(\\epsilon\\), geralmente um valor pequeno, é adicionado para evitar problemas numéricos quando a variância é muito baixa. Os parâmetros \\(\\gamma\\) e \\(\\beta\\) podem ser adicionados no passo da normalização, fazendo parte do fluxo de aprendizagem do modelo. Apesar de não ser uma teoria fechada, alguns resultados indicam que o uso de batch normalization reduz o tempo de aprendizado dos modelos (IOFFE; SZEGEDY, 2015). O passo foi adicionado nos modelos por apresentar bons resultados nas simulações.\nApós a aplicação da convolução, também é aplicada a função não linear ReLU. A transformação ReLU é a mais simples das funções da ativação na teoria de redes neurais, sendo igual à função identidade quando a entrada é positiva e zero caso contrário:\n\\[\n\\text{ReLU}(x) = xI_{(x>0)}.\n\\]\nA função ReLU serve para tornar a arquitetura do modelo uma operação não linear. Qualquer operação não linear poderia ser utilizada, mas a mais simples e mais popular é a ReLU.\nEm seguida, aplica-se uma operação para reduzir a dimensão da imagem, chamada max pooling. Trata-se de uma operação que recebe a imagem e um kernel, retornando, para cada janela, o maior valor dos pixels presentes neste kernel. Usualmente, a técnica também utiliza strides, pulando as interseções entre janelas e fazendo com que cada pixel seja avaliado apenas uma vez. Por exemplo, para uma matriz com dimensões \\(M_{10\\times10}\\) e kernel com dimensões \\(2\\times2\\), aplica-se uma redução pelo fator de \\(2\\) tanto nas linhas quanto nas colunas, resultando em uma matriz \\(M^p_{5\\times5}\\), onde cada elemento é o valor máximo de cada janela \\(2\\times2\\) correspondente ao pixel.\nA Figura 2.11 mostra um exemplo de operação max pooling aplicada ao Captcha. É possível notar que a imagem fica simplificada se comparada com a original. A operação max pooling é muito comum no contexto de redes neurais convolucionais, pois permite que os kernels sejam aplicados em diferentes níveis de zoom da imagem de entrada.\n\n\n\n\n\nFigura 2.11: Resultado da aplicação da primeira convolução à imagem e da operação de max pooling\n\n\n\n\nA aplicação das camadas convolucionais é repetida três vezes. Ou seja, as seguintes operações são aplicadas a partir da imagem original:\n\nbatch normalization: 6 parâmetros\ncamada convolucional: 896 parâmetros\nReLU\nmax pooling\nbatch normalization: 64 parâmetros\ncamada convolucional: 18.496 parâmetros\nReLU\nmax pooling\nbatch normalization: 128 parâmetros\ncamada convolucional: 36.928 parâmetros\nReLU\nmax pooling\nbatch normalization: 128 parâmetros.\n\nA dimensão da imagem de entrada, bem como quantidade de canais gerados por cada camada convolucional foram fixadas. Tais números podem ser considerados como hiperparâmetros do modelo, mas foram fixados para facilitar as simulações, que já contam com diversos hiperparâmetros.\nA imagem de entrada foi fixada na dimensão \\(32\\times192\\). O valor foi definido dessa forma porque um dos Captchas de referência, da Receita Federal do Brasil (RFB), possui 6 letras e porque \\(32*6=192\\). Ou seja, é como se a imagem fosse a colagem lado a lado de 6 imagens \\(32\\times32\\).\nA quantidade de canais gerados pelas camadas convolucionais foram fixadas em 32, 64 e 64, respectivamente. Ou seja, a primeira camada convolucional retorna uma imagem com 32 canais, a segunda camada convolucional retorna uma imagem com 64 canais, e a terceira camada convolucional retorna uma imagem com 64 canais. A utilização de números não-decrescentes de canais nas camadas convolucionais é comum (LECUN et al., 1998), bem como a utilização de números que são potências de 2 (LECUN; BENGIO; HINTON, 2015), apesar dessa última escolha não ser necessária. Nesse sentido, um possível valor para a terceira camada era de 128 canais, mas optou-se por 64 canais para que a quantidade de parâmetros não ficasse grande demais, já que isso exigiria mais tempo de computação ou computadores mais poderosos.\nO total de parâmetros que podem ser otimizados até o final das camadas convolucionais é 56.646. Esse número pode parecer grande no contexto de modelos estatísticos tradicionais como uma regressão linear, que teria, considerando cada pixel como uma covariável, 4.401 parâmetros (\\(40\\times110\\) e o intercepto). No entanto, é uma quantidade relativamente pequena no contexto de redes neurais. Redes neurais recentes aplicadas a imagens, como o DALL-E 2 possui 3,5 bilhões de parâmetros (RAMESH et al., 2022).\nEm seguida, o resultado é transformado para um formato retangular, similar ao que se encontra em modelos de regressão. Aqui, as dimensões da imagem não são mais importantes e os pixels de cada canal são tratados como variáveis preditoras. Esse passo pode ser interpretado da seguinte forma: as camadas convolucionais funcionam como um pré-processamento aplicado às imagens, aplicando uma engenharia de variáveis (KUHN; JOHNSON, 2019). No entanto, trata-se de uma engenharia de variáveis otimizada, já que os parâmetros da operação fazem parte do ajuste do modelo.\nUma vez obtidas as variáveis preditoras com o pré-processamento, é hora de aplicar as camadas densas. Tais camadas são as mais comuns no contexto de redes neurais. Nesse caso, a operação linear aplicada é uma multiplicação de matrizes, similar ao que é feito em um modelo linear generalizado. Na verdade, o componente sistemático de um modelo linear generalizado é equivalente a uma camada densa com a aplicação de viés, com a função de ativação (como, por exemplo, uma ativação sigmoide) fazendo o papel da função de ligação. Na rede neural utilizada no modelo, todas as camadas possuem ativação ReLU, com exceção da última, que utiliza ativação softmax.\nAssim como existem os canais das camadas convolucionais, existem os filtros das camadas densas. A quantidade de filtros define a dimensão do vetor de saída. O número de parâmetros da camada densa é igual ao número de itens no vetor de entrada multiplicado pelo número de filtros, somado à quantidade de filtros novamente, por conta do bias. No caso do exemplo, a saída das camadas convolucionais tem dimensão \\(2\\times22\\times64\\), ou seja, 64 canais de imagens \\(2\\times 22\\). Com a transformação em vetor, concatenando lado a lado os dados dos canais resultantes, a quantidade de colunas da base passa a ser a multiplicação das dimensões, ou 2.816. No modelo ajustado que foi utilizado como exemplo, aplicou-se 200 filtros na camada densa, totalizando 563.400 parâmetros. Esses parâmetros são os pesos que multiplicam os valores em cada camada convolucional, passando pela função de ativação ReLU e pelas camadas densas. Nas simulações, a quantidade de filtros foi variada para produzir modelos com mais ou menos parâmetros de ajuste.\nÉ no contexto da grande quantidade de parâmetros que entra o conceito do dropout (BALDI; SADOWSKI, 2013). Muitos parâmetros podem levar a sobreajuste do modelo, que acaba precisando de técnicas de regularização para funcionar bem. O dropout é uma regra de regularização simples de implementar, mas que possui boas propriedades de regularização. A técnica consiste em selecionar uma amostra dos parâmetros em uma das camadas e apagá-los, forçando que os valores sejam fixados em zero. Na prática, essa técnica obriga o modelo a ser ajustado de forma que amostras aleatórias dos parâmetros sejam boas para predizer a variável resposta. Quando o modelo é usado para predições, o dropout é desativado e o modelo pode utilizar todos os parâmetros, obtendo-se, na prática, uma média ponderada das predições de cada submodelo.\nO primeiro dropout é aplicado após a finalização das camadas convolucionais. Em seguida, vem a primeira camada densa, um ReLU e um batch normalization. Depois, é aplicada mais um dropout e mais uma camada densa. Com isso, a aplicação de operações é finalizada. O total de parâmetros na configuração do modelo apresentado foi de 630.496. Os modelos mais simples utilizados nas simulações, com 100 filtros na camada densa, têm 343.696 parâmetros. Os mais complexos, com 300 filtros na camada densa, têm 917.396 parâmetros.\nPara finalizar a arquitetura do modelo, as quantidades resultantes devem ser ajustadas ao formato da variável resposta. O número de filtros da segunda camada densa precisa ser escolhido cuidadosamente, pois deve ser igual à multiplicação das dimensões da variável resposta. No caso do TJMG, os rótulos têm comprimento igual a 5 e vocabulário de comprimento 10 (algarismos arábicos), organizados em uma matriz \\(5\\times10\\), com 50 entradas. Por isso, a quantidade de filtros da última camada densa também é 50, e o vetor de saída é formatado para uma matriz de dimensão \\(5\\times10\\).\nNo final, o resultado precisa ser normalizado para que fique no mesmo escopo de variação da resposta. A resposta possui apenas zeros e uns, sendo que cada linha da matriz tem somente um número “1”, correspondendo ao índice do rótulo no alfabeto e, nas outras entradas, o valor zero. A saída do modelo deve, portanto, apresentar números entre zero e um que somam 1 em cada linha.\nIsso é feito através da função softmax, aplicada a cada linha da matriz de saída. A função softmax é uma normalização que utiliza a função exponencial no denominador, forçando que a soma dos valores do vetor seja um.\n\\[\n\\text{soft}\\max(y_i) = \\frac{e^{y_i}}{\\sum_{j=1}^{|\\mathcal A|} e^{y_j}}.\n\\]\nNo exemplo, a saída do modelo é a matriz abaixo:\n\\[\n\\hat{\\mathbf z} = \\left[\\begin{array}{rrrrrrrrrr}\n  -17.5 & -13.5 & -15.4 & -6.6 & -9.9 & 9.9 & -11.4 & -10.9 & -11.8 & -9.3 \\\\\n  -10.9 & -15.6 & 8.3 & -6.5 & -11.0 & -10.3 & -10.0 & -5.8 & -11.4 & -15.1 \\\\\n  -10.5 & -13.6 & -9.6 & -11.4 & 11.2 & -14.3 & -9.9 & -11.3 & -9.9 & -10.0 \\\\\n  -18.1 & -9.6 & -10.9 & 5.3 & -10.1 & -6.6 & -15.5 & -13.3 & -6.8 & -10.8 \\\\\n  -11.3 & -8.7 & 6.4 & -7.0 & -6.1 & -9.2 & -18.9 & -10.3 & -16.1 & -9.6 \\\\\n\\end{array}\\right].\n\\]\nNote que a matriz apresenta valores negativos e positivos. Na primeira linha, por exemplo, o valor positivo está na sexta coluna, correspondendo ao algarismo “5”. De fato, esse é o valor do primeiro elemento do rótulo para esta imagem. Após a aplicação do softmax, a matriz de predições obtida é a matriz abaixo2. O modelo de exemplo aparenta ter confiança nas respostas, já que dá probabilidades bem altas para alguns valores e quase zero para outros valores.\n\\[\n\\hat{\\mathbf Y}\\times 1000 = \\left[\\begin{array}{rrrrrrrrrr}\n  0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 0.00 & 999.99 & 0.00 & 0.01 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n  0.00 & 0.00 & 999.99 & 0.00 & 0.00 & 0.00 & 0.00 & 0.01 & 0.00 & 0.00 \\\\\n\\end{array}\\right].\n\\]\nVale notar que, dependendo da implementação, nem sempre é necessário aplicar a função softmax. Em alguns pacotes computacionais como o torch3, utilizado nesta tese, a normalização pode ser feita diretamente na função de perda, que aproveita a expressão completa para realizar algumas simplificações matemáticas e, com isso, melhorar a precisão das computações. O uso da função de perda ficará claro na próxima subseção.\n\n\nPerda\nA função de perda utilizada em um problema de classificação deve levar em conta as probabilidades (ou pesos) associadas aos rótulos. A perda deve ser pequena se a probabilidade associada ao rótulo correto for alta e deve ser grande se a probabilidade associada ao rótulo correto for baixa.\nUma função de perda natural e popular nesse sentido é a de entropia cruzada, ou cross-entropy. Trata-se de uma perda com a formulação\n\\[\n\\mathcal L(g(x), y) = -\\sum_{i=1}^c I(y=i)\\log(g_i(x)).\n\\tag{2.1}\\]\nNa equação, \\(g_i(x)\\) é a probabilidade dada ao rótulo \\(i\\) pela função \\(g\\). Se o rótulo \\(i\\) é diferente do rótulo correto \\(y\\), a função de perda vale zero por conta da função indicadora. Quando \\(i=y\\), a perda é igual ao oposto do logaritmo da probabilidade associada ao rótulo \\(i\\). Quanto menor a probabilidade, maior o valor da perda.\nAo trabalhar com o oráculo, a entropia cruzada passa a não fazer sentido nos casos em que o modelo inicial erra. Por isso, a função de perda será adaptada no método WAWL. Essa é a única modificação estritamente necessária para aplicar o método.\n\n\nOtimizador\nO otimizador utilizado para os modelos ajustados na tese foi o ADAM (KINGMA; BA, 2017). A sigla significa Adaptive Moment Estimator e funciona como uma extensão da descida de gradiente estocástica (LECUN et al., 2012). Considere que \\(\\theta\\) é o conjunto de todos os parâmetros do modelo, ou seja, os parâmetros das camadas convolucionais, densas e batch normalization. Os parâmetros são atualizados da seguinte forma:\n\\[\n\\begin{array}{cl}\nm_{\\theta}^{(t+1)} &\\leftarrow \\beta_1m_{\\theta}^{(t)} + (1-\\beta_1)\\nabla_\\theta \\mathcal{L}^{(t)} \\\\\nv_{\\theta}^{(t+1)} &\\leftarrow \\beta_2v_{\\theta}^{(t)} + (1-\\beta_2)(\\nabla_\\theta \\mathcal{L}^{(t)})^2 \\\\\n\\hat{m}_{\\theta} &= \\frac{m_\\theta^{(t+1)}}{1-\\beta_1^t} \\\\\n\\hat{v}_{\\theta} &= \\frac{v_\\theta^{(t+1)}}{1-\\beta_2^t} \\\\\n\\theta^{(t+1)} &\\leftarrow \\theta^{(t)} - \\eta \\frac{\\hat{m}_{\\theta}}{\\sqrt{\\hat{v}_{\\theta}} + \\epsilon}.\n\\end{array}\n\\]\nNa equação, \\(m\\) e \\(v\\) são médias móveis para atualização dos parâmetros, ponderando a perda e a perda ao quadrado com o passo anterior usando pesos \\(\\beta_1\\) e \\(\\beta_2\\), respectivamente. Nessa notação \\(\\eta\\) é a taxa de aprendizado, um hiperparâmetro a ser ajustado. Por último, o valor de \\(\\epsilon\\) é uma constante, usualmente pequena, para evitar divisão por zero.\nAinda que o ADAM seja um método adaptativo, pode ser vantajoso considerar uma taxa de decaimento no parâmetro \\(\\eta\\). Esse fator pode ser desnecessário em alguns casos, mas pode auxiliar o modelo a dar passos menores quando o modelo já está com uma acurácia razoável. Neste trabalho, foram consideradas alguns valores de decaimento na taxa de aprendizado, como 1% ou 3% de decaimento ao final de cada época, ou seja, ao final de cada ciclo de particionamento da base.\n\n\n\nAprendizado estatístico\nApresentados o objeto de estudo e as redes neurais utilizadas, passa-se a discutir o significado disso tudo no contexto de aprendizado estatístico. Essa parte foi escrita para proporcionar a base teórica para apresentar o modelo WAWL.\nO aprendizado fracamente supervisionado pode ser dividido em três tipos principais. A supervisão com erros, a supervisão com rótulos incompletos e a supervisão de grupos de observações. O caso do Captcha pode ser entendido como uma subárea do aprendizado fracamente supervisionado com rótulos incompletos chamada aprendizado com dados parcialmente rotulados (PLL), já que uma parte da base pode ser anotada sem erros e uma parte da base é a resposta do oráculo indicando uma lista de rótulos possíveis, incluindo o correto.\nA área de PLL não é nova (GRANDVALET, 2002) e aparece com outros nomes, como aprendizado com rótulos ambiguos (HÜLLERMEIER; BERINGER, 2006) e aprendizado de rótulos em superconjuntos (superset-label learning) (LIU; DIETTERICH, 2012). Um caso particular de PLL, aplicável ao tema do Captcha são rótulos complementares (ISHIDA et al., 2017), que considera os chutes errados na notação do problema.\nAs definições seguem uma terminologia adaptada a partir da leitura de JIN; GHAHRAMANI (2002), COUR; SAPP; TASKAR (2011) e FENG et al. (2020a). Sempre que possível, os casos são adaptados para o problema do Captcha diretamente. Para simplificar a notação, no entanto, foi considerado o problema univariado do Captcha, ou seja, como se uma imagem tivesse apenas uma letra. Não há perda de generalidade nessa escolha, já que o problema do Captcha pode ser, de fato, separado em vários problemas, um para cada letra da imagem.\nEm um problema de aprendizado supervisionado tradicional, tem-se um conjunto de \\(S\\) casos rotulados \\(\\{(\\mathbf x_i,y_i), i=1,\\dots, S\\}\\) com uma distribuição \\(p(\\mathbf x,y)\\) desconhecida, onde \\(\\mathbf x\\) é uma imagem e \\(y\\) é o rótulo, que possui \\(|\\mathcal A|\\) possíveis valores. O objetivo é obter um classificador \\(f\\) que leva um valor de \\(\\mathbf x\\) para o rótulo correto \\(y\\).\nPara delimitar se o classificador está bom ou ruim, utiliza-se uma função de perda. No caso do Captcha, como o interesse é simplesmente acertar o rótulo inteiro (não importa se o classificador acerta só uma parte do rótulo), utiliza-se uma função chamada 0-1:\n\\[\n\\mathcal L(f(\\mathbf x),y) = I (f(\\mathbf x) \\neq y).\n\\tag{2.2}\\]\nNa equação, \\(I(\\cdot)\\) é uma função indicadora. Como a função de perda é aplicada a apenas um par \\((\\mathbf x,y)\\), define-se que o objetivo do problema de aprendizado é minimizar o risco, que é o valor esperado da função de perda, calculado para as variáveis aleatórias \\(\\mathbf X\\) e \\(Y\\):\n\\[\n\\mathcal R(g) = \\mathbb E_{p(\\mathbf x,y)}[\\mathcal L(g(\\mathbf X),Y)].\n\\tag{2.3}\\]\nA função de risco, no entanto, não é observada, já que depende da distribuição desconhecida de \\(p(\\mathbf x,y)\\). Por isso, utiliza-se um estimador do risco, que pode ser calculado em uma amostra, como uma base usada na validação cruzada ou na base de teste. Para uma amostra com \\(S\\) observações, tem-se\n\\[\n\\hat{\\mathcal R}(g) = \\sum_{s=1}^S \\mathcal L(g(\\mathbf x_s),y_s))\n\\]\nNa base de teste, utilizada para estimar o risco, a função de perda 0-1 é apropriada. Na etapa de validação cruzada de um modelo de aprendizado profundo, é útil considerar uma função de perda que seja contínua e derivável, funcionando como uma versão suavizada da perda 0-1. A partir de um vetor de parâmetros \\(\\boldsymbol \\theta\\) originados da arquitetura do modelo, uma escolha de função de perda é a entropia cruzada, como na Equação 2.1. Os parâmetros são estimados a partir de um otimizador, como o ADAM, apresentado na Seção 2.1.2.3.\nAs definições começam a precisar de ajustes quando \\(y\\) deixa de ser um rótulo fixado. Como descrito na Seção 2.1.1.3, quando o modelo inicial erra, o que se observa é uma lista de possíveis valores para \\(y\\), que contém o rótulo correto e outros incorretos. Se o Captcha aceita apenas um chute, essa lista contém todos os possíveis valores do rótulo, menos o valor incorreto que foi utilizado no oráculo. Se o Captcha aceita vários chutes, a lista contém todos os valores possíveis de \\(y\\) menos os valores que foram testados.\nPara isso, utiliza-se a notação do \\(\\bar {\\mathbf y}\\). A notação utiliza negrito para enfatizar que o objeto contém uma lista de possíveis valores, e não apenas um valor. Por exemplo, considere \\(\\mathcal A = \\{0,1,\\dots,9\\}\\) um alfabeto com os algarismos de zero até nove, como no MNIST, e um Captcha que aceita múltiplos chutes. Nesse caso, para uma imagem \\(\\mathbf x\\) com rótulo \\(3\\), seguindo as definições da Seção 2.1.1, o valor de \\(y\\) seria dado pela matriz\n\\[\ny = [0\\;0\\;0\\;1\\;0\\;0\\;0\\;0\\;0\\;0].\n\\]\nAqui, o valor \\(3\\) é colocado na quarta posição da primeira (e única) linha da matriz. Como o problema está sendo trabalhado na forma univariada, para simplificar a notação, pode-se considerar apenas os valores dos rótulos, ou seja, \\(y=3\\).\nConsidere, agora, que o modelo inicial produziu as tentativas incorretas \\(\\mathbf g(\\mathbf x) = \\{6,8\\}\\). O valor observado \\(\\bar{\\mathbf y}\\) envolve todos os valores de \\(y\\) menos as tentativas incorretas:\n\\[\n\\bar{\\mathbf y} = \\{0,1,2,3,4,5,7,9\\}.\n\\]\nNa prática, o que se observa, então, são pares \\((\\mathbf x,y)\\), nos casos corretos, ou pares \\((\\mathbf x,\\bar{\\mathbf y})\\), nos casos incorretos. Para generalizar a notação, é possível considerar uma variável indicadora de acerto do modelo inicial \\(z\\) e a lista \\(\\mathbf y\\), definida da seguinte forma:\n\\[\n\\mathbf y = \\left\\{\\begin{array}{cl}\\{y\\}&,\\text{ se }z=1\\\\\\bar{\\mathbf y}&,\\text{ se }z=0\\end{array}\\right..\n\\]\nAssim, observa-se uma amostra de \\(\\{(\\mathbf x_s,\\mathbf y_s, z_s)\\}, s = 1,\\dots,S\\). A distribuição desses dados está diretamente relacionada com a acurácia do modelo inicial. Por exemplo, se o modelo inicial acerta todos os chutes, o resultado será sempre o valor correto \\(y\\), e o problema recai em um caso supervisionado tradicional. Quando o modelo inicial erra todos os casos, todos os rótulos são parciais e o problema recai em um caso de PLL puro. Na prática, o que se espera é que a amostra tenha uma mistura de rótulos corretos e de rótulos parciais.\nÉ possível desconsiderar o valor \\(z\\) na notação. Como os rótulos parciais sempre incluem o rótulo correto \\(y\\), quanto o conjunto contém apenas um elemento, este é o rótulo correto. Ou seja:\n\\[\nz=1 \\iff |\\mathbf y|=1.\n\\]\nPortanto, basta considerar os pares \\((\\mathbf x_s, \\mathbf y_s)\\) da amostra para definir o problema. Definida a estrutura de dados da amostra, passa-se a discutir a forma de obter um classificador com boas propriedades.\nUma estratégia eficaz para derivar propriedades de classificadores na área de PLL é escrever a distribuição dos dados de forma explícita (FENG et al., 2020a, 2020b; ISHIDA et al., 2017; YU et al., 2018). A partir dessa distribuição, a função de risco do problema completamente supervisionado é reescrita em termos da função de risco do problema com rótulos parciais. Depois, é criado um estimador para essa função de risco, a partir de uma amostra observada. Finalmente, utilizando funções de perda adequadas, demonstra-se que a função de risco do problema com rótulos parciais se aproxima da função de risco com dados completamente supervisionados, conforme a base de dados aumenta.\nA forma mais fácil de definir a distribuição dos dados com rótulos parciais é considerando que os valores dos rótulos parciais aparecem ao acaso. Por exemplo, considere que as imagens são geradas com uma distribuição \\(p(\\mathbf x, y)\\), que não precisa ser conhecida. Então a distribuição dos rótulos parciais \\(\\tilde p (\\mathbf x, \\mathbf y)\\) é dada por (FENG et al., 2020a):\n\\[\n\\tilde p (\\mathbf x, \\mathbf y) = \\sum_{y}p(\\mathbf y|y)p(\\mathbf x, y), \\text{ onde } p(\\mathbf y|y)=\\left\\{\\begin{array}{ll}\\frac{1}{2^{|\\mathcal A|-1}-1},&\\text{ se } y\\in\\mathbf y,\\\\0,&\\text{ se } y\\notin \\mathbf y\\end{array}\\right..\n\\tag{2.4}\\]\nA distribuição pode ser interpretada da seguinte forma. Os valores possíveis de \\(\\mathbf y\\) são todos os possíveis subconjuntos do alfabeto, menos os casos extremos (vazio e o alfabeto completo). Por exemplo, no caso de um alfabeto com os 10 algarismos, os valores de \\(\\mathbf y\\) podem ser todas as combinações dos algarismos, menos o conjunto vazio e o conjunto \\(\\{0,\\dots,9\\}\\). Isso dá \\(2^{|\\mathcal A|}-2\\) combinações no total.\nConsiderando a restrição de PLL de que a resposta \\(\\mathbf y\\) sempre contém o verdadeiro rótulo, é intuitivo que \\(p(\\mathbf y|y)=0\\) quando \\(y\\notin \\mathbf y\\). Ou seja, a probabilidade de observar \\(\\mathbf y\\) quando se sabe que o \\(y\\) correto foi observado e este \\(y\\) não está no conjunto \\(\\mathbf y\\) é zero. Agora, quando \\(y \\in \\mathbf y\\), a probabilidade é calculada considerando todos os possíveis subconjuntos do alfabeto que contêm \\(y\\), que são \\(2^{|\\mathcal A|-1}-1\\). Por exemplo, de todos os subconjuntos válidos do conjunto \\(\\{0,\\dots,2\\}\\), ou seja, \\(\\{0\\},\\{1\\},\\{2\\}, \\{0,1\\}, \\{0,2\\}\\) e \\(\\{1,2\\}\\), tem-se \\(2^{3-1}-1=3\\) conjuntos que contêm o valor \\(2\\). Por isso, a probabilidade atribuída a \\(p(\\mathbf y|y)\\) é uma uniforme, dando pesos iguais para todos os possíveis rótulos.\nUma suposição implícita da distribuição na Equação 2.4 é que \\({\\mathbf y}\\) é condicionalmente independente de \\({\\mathbf x}\\) dado \\(y\\). Ou seja, para qualquer valor de \\(y\\),\n\\[\np(\\mathbf y|\\mathbf x, y) = p(\\mathbf y| y).\n\\]\nEssa suposição significa que o valor do rótulo complementar não depende da imagem quando se sabe o rótulo da imagem. No caso dos Captchas, essa suposição é verificada, porque a imagem é simplesmente uma representação do rótulo, então a probabilidade do modelo inicial errar depende apenas do rótulo e não das distorções realizadas pela imagem gerada a partir do rótulo.\nComo comentado anteriormente, a partir da distribuição dos dados é possível reescrever a função de risco do problema completamente supervisionado em termos do problema de rótulos parciais (FENG et al., 2020a, eq (6)). A partir de um estimador desse risco, utiliza-se um método de aprendizado de máquinas (como redes neurais) para obter um classificador \\(\\hat f\\). Considerando que \\(f^*\\) é a função obtida em um problema completamente supervisionado e seguindo algumas suposições adicionais, é possível demonstrar que\n\\[\n|\\mathcal R(\\hat f) - \\mathcal R(f^*)|\n\\] é limitada e converge para zero quando tamanho da amostra vai para infinito. Mais do que isso, é possível obter a taxa de convergência do risco, em função da complexidade de Rademacher. Os detalhes e a demonstração podem ser encontrados no artigo de FENG et al. (2020a).\nNas descrições dadas acima, a única suposição que não é satisfeita é a de que os valores de \\(\\mathbf y\\) são distribuídos uniformemente. Essa suposição é inválida porque os valores observados de \\(\\mathbf y\\) são resultado dos erros do modelo inicial aplicado ao oráculo e porque o número de tentativas geralmente é limitado. Como o modelo inicial não tem distribuição uniforme, o resultado também não é uniforme.\nO tipo de problema nesse caso é conhecido como biased partial label (YU et al., 2018). Um dos artigos estudados apresenta uma solução para o caso em que o rótulo parcial é um rótulo complementar (ou seja, quando o Captcha aceita apenas um chute). Nesse caso as probabilidades \\(p(\\mathbf y| y)\\) podem ser organizadas em uma matriz de transição \\(\\mathbf Q\\), contendo as probabilidades de se obter um rótulo incorreto para cada possível valor do rótulo. Para resolver problemas desse tipo, é possível realizar um ajuste na função de predição:\n\\[\nf_{\\text{adj}} (\\mathbf x) = \\mathbf Q ^{\\top}f(\\mathbf x).\n\\]\nO caso do oráculo e dos Captchas é um problema com múltiplos rótulos complementares e com viés. Até o momento, não existe uma solução geral para este tipo de problema. No entanto, espera-se que as soluções para problemas desse tipo tenham taxas de convergência mais estreitas do que o caso de rótulos complementares, com ou sem viés, já que rótulos complementares múltiplos trazem mais informação do que rótulos complementares simples."
  },
  {
    "objectID": "metodologia.html#sec-wawl",
    "href": "metodologia.html#sec-wawl",
    "title": "2  Metodologia",
    "section": "Método WAWL",
    "text": "Método WAWL\nO método WAWL (Web Automatic Weak Learning) é a solução proposta na pesquisa. Trata-se da técnica baixar dados da web para compor parte da amostra que é utilizada no ajuste do modelo.\nO método WAWL é inovador por dois motivos. Primeiro, porque o método faz a ponte entre áreas que até o momento eram partes separadas no ciclo da ciência de dados: a raspagem de dados e o aprendizado estatístico. Além disso, o método é uma nova alternativa para resolver Captchas com pouca ou nenhuma intervenção humana.\nA Figura 2.12 mostra o funcionamento básico do WAWL. Primeiro, ajusta-se um modelo inicial para o Captcha desejado, que pode ser uma adaptação de modelos existentes ou um modelo construído com base em uma pequena amostra completamente anotada. Em seguida, aplica-se as predições do modelo inicial no oráculo para obter uma nova base de dados parcialmente anotada da internet. Finalmente, um novo modelo é ajustado com os dados obtidos, utilizando uma adaptação na função de perda.\n\n\n\n\n\nFigura 2.12: Esquema mostrando o funcionamento do método WAWL\n\n\n\n\n\nA arquitetura do modelo WAWL pode ser a mesma de um modelo ajustado com uma base completamente anotada. O modelo pode, inclusive, aproveitar os parâmetros já ajustados do modelo inicial, acelerando o aprendizado. Nada impede, no entanto, que uma arquitetura diferente seja utilizada, desde que a entrada seja uma imagem e a saída seja uma matriz com as dimensões da variável resposta. O WAWL é agnóstico à arquitetura do modelo.\nA função de perda deve ser adaptada para considerar a informação limitada fornecida pelo oráculo. Quando o rótulo fornecido pelo modelo está correto, a informação é considerada normalmente, através da função de perda da regressão multinomial multivariada. Já quando o rótulo fornecido pelo modelo é incorreto, a função de perda é calculada com base na probabilidade do rótulo estar incorreto:\n\\[\n1 - p(y|\\boldsymbol \\theta).\n\\]\nConsidere o rótulo parcial \\({\\mathbf y}\\) e a função \\(g\\), dada pela rede neural, que retorna um vetor de probabilidades \\([g_y], y \\in \\mathcal A\\). Os valores de \\(g_y\\) somam 1 e têm os pesos relacionados a cada possível rótulo a partir da imagem \\(\\mathbf x\\). O WAWL modifica a entropia cruzada (função de perda original) nos casos anotados pelo oráculo como errados, e mantém a função de perda original nos casos corretamente anotados. A fórmula para descrever a função de perda modificada é:\n\\[\n\\mathcal L(g(\\mathbf x), {\\mathbf y}) = -\\log\\left[1 - \\sum_{y \\in \\mathcal A} {g_y}(\\mathbf x) I(y\\notin {\\mathbf y})\\right].\n\\]\nPor conta da função indicadora, a perda só é calculada nos pontos que estão de fora do rótulo parcial observado \\(\\mathbf y\\). Ou seja, o valor é calculado somente nos casos que o modelo inicial errou. Outra forma de escrever a mesma função de perda é fazendo:\n\\[\n\\mathcal L(g(\\mathbf x), {\\mathbf y}) = -\\log\\left[ \\sum_{y \\in \\textbf{y}} g_y(\\mathbf x)\\right].\n\\]\nA função proposta pode ser explicada de maneira intuitiva através de exemplos. Considere um problema com apenas \\(10\\) possíveis valores para o rótulo e uma resposta multinomial, sem ser multivariada, como considerado na Seção 2.1.3. Considere também que a rede neural retorna uma alta probabilidade, por exemplo, \\(0.99\\), para o valor \\(j\\), que o oráculo identificou como incorreta. Logo, \\(\\mathbf {\\bar y} = \\{1,\\dots,10\\}\\setminus \\{j\\}\\), e a função de perda é dada por\n\\[\n\\mathcal L(g(\\mathbf x), \\{1,\\dots,10\\}\\setminus \\{j\\}) = -\\log\\left[1-{g_j}(\\mathbf x)\\right] = -\\log\\left[1-0.99 \\right] = 4.61.\n\\]\nComo é possível ver no exemplo, quanto maior a probabilidade dada a um rótulo identificado como incorreto pelo oráculo, mais a função de perda penaliza essa predição. Dessa forma, a função de perda consegue incorporar a informação dada pelo oráculo adequadamente.\nConsidere, agora, que a rede neural retorna uma probabilidade pequena, por exemplo, \\(0.01\\), para o valor \\(k\\), que o oráculo identificou como incorreta. Logo, \\(\\mathbf {\\bar y} = \\{1,\\dots,10\\}\\setminus \\{k\\}\\), e a função de perda é um valor pequeno:\n\\[\n\\mathcal L(g(\\mathbf x), \\{1,\\dots,10\\}\\setminus \\{k\\}) = -\\log\\left[1-{g_k}(\\mathbf x)\\right] = -\\log\\left[1-0.01 \\right] = 0.01.\n\\]\nQuando o Captcha aceita múltiplos chutes, a mesma conta é válida, bastando subtrair as probabilidades de todos os rótulos incorretos. No final, o valor da função de perda é a soma das perdas para todas as observações do minibatch. A soma considera tanto as perdas calculadas com base nos rótulos corretos quanto as perdas calculadas com base nos rótulos incorretos.\nO otimizador que obtém novas estimativas dos parâmetros também não precisa ser modificado. Basta aplicar a mesma técnica utilizada na modelagem usual, como descida de gradiente estocástica ou métodos adaptativos, como o ADAM.\nUm detalhe importante sobre o método é sobre a implementação. Com a utilização de ferramentas que fazem diferenciação automática como o torch e o TensorFlow4, basta implementar a parte da arquitetura, a função de perda e especificar o otimizador, já que o processo de atualização dos parâmetros é feito automaticamente. No entanto, dependendo da implementação, não é possível fazer a atualização dos parâmetros usando o componente de computação gráfica, que potencialmente acelera o ajuste dos modelos de forma significativa. Na implementação atual, a função de perda apresentada não permite utilização deste componente, sendo uma melhoria possível em futuros trabalhos.\nO ajuste dos modelos, tanto para simulações quanto para construção dos modelos finais, utilizou o pacote {torch} (FALBEL; LURASCHI, 2022), que é uma implementação do PyTorch para a linguagem de programação R (R CORE TEAM, 2021). O pacote {luz} (FALBEL, 2022a) foi utilizado para organizar as funções de perda e hiperparâmetros, enquanto o pacote {torchvision} (FALBEL, 2022b) foi utilizado para utilidades no tratamento de imagens."
  },
  {
    "objectID": "metodologia.html#dados",
    "href": "metodologia.html#dados",
    "title": "2  Metodologia",
    "section": "Dados",
    "text": "Dados\nNesta seção, descreve-se em detalhes como foi a obtenção dos dados para realizar a pesquisa. Como comentado anteriormente, a base foi construída do zero para os fins do projeto, sendo uma parte significativa dos esforços para chegar nos resultados.\nNo total, foram construídas bases de dados de dez Captchas que estavam disponíveis publicamente no período de realização da pesquisa. Os Captchas foram revisados pela última vez no dia 14/09/2022, para verificar se ainda estavam ativos. Além disso, foram construídas duas bases de dados de Captchas desenvolvidos internamente para fins de teste.\nParte dos dados foram obtidos como um passo intermediário das simulações. A presente seção descreve como os robôs de coleta foram construídos, bem como a metodologia para obter os modelos iniciais. Na Seção 2.3.2, são apresentadas informações sobre os dados baixados para realizar as simulações.\n\nEscolha dos Captchas analisados\nPara selecionar os Captchas, foram adotados alguns critérios objetivos. Os critérios foram:\n\nO site acessado é de um serviço público (governo federal, tribunal etc).\nO Captcha contém letras (A a Z) e números (0 a 9) em uma imagem com extensão jpeg ou png.\nO comprimento do Captcha é fixo, ou seja, dois Captchas da mesma origem devem ter sempre o mesmo comprimento.\n\nA primeira restrição para escolha dos Captchas é de ordem principiológica: um serviço público não deveria restringir o acesso aos dados para robôs. Como já discutido na Seção 1.1, nesses casos, a existência do Captcha pode ser prejudicial para a sociedade.\nAs restrições 2 e 3 foram escolhidas com o objetivo de facilitar as simulações e comparações dos resultados. Em princípio, nada impede que os modelos desenvolvidos trabalhem com caracteres diferentes de [a-zA-Z0-9], desde que exista uma lista prévia de caracteres. Além disso, é possível realizar adaptações no tratamento das bases para lidar com diferentes comprimentos de Captchas.\nA Tabela 2.1 mostra os Captchas trabalhados. Dos 10 exemplos trabalhados, 6 têm origem no judiciário, que são conhecidos por não disponibilizarem os dados de forma aberta. Vale notar que alguns dos Captchas da tabela são utilizados por vários tribunais. O Captcha TRT, por exemplo, existe em todos os Tribunais Regionais do Trabalho que compartilham a mesma versão do sistema do Processo Judicial eletrônico (PJe) do TRT3 (TRT da terceira região).\n\n\n\n\nTabela 2.1:  Lista de captchas analisados CaptchaExemploDescriçãotrf5Tribunal Regional Federal 5tjmgTribunal de Justiça de Minas GeraistrtTribunal Regional do Trabalho 3esajTribunal de Justiça da BahiajucespJunta Comercial de São PaulotjpeTribunal de Justiça de PernambucotjrsTribunal de Justiça do Rio Grande do SulcadespCentro de Apoio ao Desenvolvimento da Saúde PúblicaseiSistema Eletrônico de Informações - MErfbReceita Federal\n\n\n\nAlém dos Captchas de sites, também foram consideradas imagens geradas artificialmente. O motivo de criar Captchas artificiais é a facilidade de rodar modelos e simulações, já que nos casos reais é necessário ter acesso à internet e construir bases de dados de cada Captcha.\nForam gerados dois tipos de Captchas artificiais. O primeiro, chamado MNIST-Captcha, é simplesmente uma adaptação da conhecida base MNIST para ficar no formato de um Captcha. A partir da escolha do comprimento e dos caracteres que fazem parte da imagem, o gerador simplesmente faz uma amostra aleatória da base do MNIST e compõe as imagens horizontalmente.\nA Figura 2.13 mostra um exemplo do Captcha gerado a partir da base MNIST. No exemplo, o comprimento escolhido para o Captcha foi de 4 valores.\n\n\n\n\n\nFigura 2.13: Exemplo de MNIST-Captcha\n\n\n\n\nO problema do MNIST-Captcha é que a base de dados original é finita. Apesar de possuir por volta de 60 mil observações, o MNIST-Captcha pode gerar Captchas repetidos. Além disso, é necessário tomar cuidado com as bases de treino e teste, já que os elementos de teste não poderiam fazer parte de nenhuma observação de treino.\nUm novo tipo de Captcha também foi gerado inteiramente por programação, chamado R-Captcha. O Captcha é gerado utilizando a ferramenta ImageMagick, com a possibilidade de customizar diversos parâmetros, como\n\nQuais caracteres usar na imagem\nO comprimento do Captcha\nDimensões da imagem\nProbabilidade de rotação da imagem\nProbabilidade de adicionar um risco entre as letras\nProbabilidade de adicionar uma borda nas letras\nProbabilidade de adicionar uma caixa (retângulo) em torno das letras\nProbabilidade de adicionar um ruído branco no fundo da imagem\nProbabilidade de adicionar efeitos de tinta óleo e implosão\n\nA Figura 2.14 mostra um exemplo de R-Captcha. O exemplo apresenta uma linha ligando as letras, comprimento 4, dígitos maiúsculos e minúsculos e distorções.\n\n\n\n\n\nFigura 2.14: Exemplo de R-Captcha\n\n\n\n\nPor ser uma versão mais flexível e completa, optou-se por trabalhar principalmente com o R-Captcha nas simulações. O MNIST-Captcha foi implementado mas não foi utilizado nas simulações.\n\n\nConstrução dos dados\nPara obter os dados da pesquisa, foram utilizadas técnicas de raspagem de dados (ZHAO, 2017). A raspagem de dados é uma área da ciência da computação responsável por criar rotinas que automatizam a coleta de dados provenientes da web. Trata-se de uma atividade muito comum em pesquisas aplicadas, especialmente as que envolvem análise de dados públicos que não estão disponíveis de forma aberta, como os dados do Judiciário.\nDentro do ciclo da ciência de dados, pode-se considerar que a raspagem de dados está inserida nas tarefas de coleta e arrumação de dados. É possível comparar a raspagem com uma consulta a um banco de dados remoto, ou mesmo à obtenção de informações através de uma Application Programming Interface (API).\nPara raspar uma página da web, o fluxo descrito na Figura 2.15 é seguido. O exemplo da RFB foi utilizado para dar contexto aos passos.\n\n\n\n\n\nFigura 2.15: Ciclo da raspagem de dados. Fonte: curso de Web Scraping da Curso-R\n\n\n\n\nNo caso da RFB, a etapa de identificação é realizada acessando-se a página inicial de busca de CNPJ, como mostrado na Figura 2.16. É possível notar que o desafio disponível é do tipo hCaptcha, que não é o Captcha de interesse da pesquisa. No entanto, ao clicar em “Captcha Sonoro”, é possível acessar o Captcha de interesse, como mostrado na Figura 2.17. O motivo pelo qual o Captcha de texto em imagem foi mantido após a implementação do hCaptcha não foi encontrado.\n\n\n\n\n\nFigura 2.16: Página de busca de CNPJ da RFB\n\n\n\n\n\n\n\n\n\nFigura 2.17: Página de busca de CNPJ da RFB, com Captcha de texto\n\n\n\n\nA segunda tarefa é a de navegar pelo site, registrando as requisições realizadas pelo navegador para realizar a consulta. Isso envolve abrir o inspetor de elementos do navegador, na aba Rede (ou Network, em inglês), anotando as requisições que são realizadas.\nNo exemplo, testou-se o CNPJ 13.612.840/0001-57, da ABJ. Ao preencher o CNPJ e o rótulo do Captcha, algumas requisições aparecem na aba “Rede”, como mostrado na Figura 2.18. A primeira requisição é do tipo POST5, responsável por enviar os dados de CNPJ e do rótulo da imagem para o servidor, que retorna com os dados da empresa.\n\n\n\n\n\nFigura 2.18: Resultado da busca por CNPJ, mostrando a aba Rede\n\n\n\n\nInvestigando a requisição POST, na aba “Requisição”, é possível observar os dados da consulta. Trata-se de um conjunto de parâmetros enviados na forma de lista, com as informações abaixo. Para replicar a requisição na linguagem de programação, estes são os dados enviados.\n{\n    \"origem\": \"comprovante\",\n    \"cnpj\": \"13.612.840/0001-57\",\n    \"txtTexto_captcha_serpro_gov_br\": \"7hkhze\",\n    \"search_type\": \"cnpj\"\n}\nAs etapas de replicar e validar envolvem baixar e processar os dados obtidos no navegador, mas utilizando linguagem de programação. No caso do Captcha da RFB, essa tarefa envolve os passos abaixo.\n\nAcessar a página inicial de busca com Captcha sonoro, através de uma requisição GET.\nBaixar a imagem do Captcha com uma requisição GET, usando o link gerado ao clicar no botão de atualizar o Captcha.\nObter o rótulo a partir da imagem do Captcha.\nRealizar a requisição POST com os dados do exemplo e o rótulo correto da imagem, baixando arquivo resultante em um HTML.\nUtilizar técnicas de raspagem de arquivos HTML para obter os dados de interesse (como, por exemplo, a razão social da empresa) e validar os resultados, verificando, por exemplo, se o resultado estava completo e disponível.\n\nTodos os passos descritos acima devem ser realizados em uma sessão persistente. Isso significa que a biblioteca utilizada para realizar as requisições deve ser capaz de guardar os cookies entre a requisição GET do primeiro passo e a requisição POST do quarto passo, de forma que as requisições sejam interligadas.\nO quinto passo da lista acima descreve a parte de parsear, que é a responsável pelo nome “raspagem” nesta área do conhecimento. O nome parsear aparece porque os arquivos baixados estão em um formato bruto, inadequado para realização de análises. Os dados precisam ser então extraídos – raspados – do arquivo HTML, utilizando ferramentas como a libxml2 (WICKHAM; HESTER; OOMS, 2021) para acessar pedaços do documento, como o XPath (WICKHAM, 2022a) e posteriormente aplicar técnicas de manipulação de textos, como expressões regulares (WICKHAM, 2022b).\nA iteração encerra o fluxo da raspagem de dados. Nessa etapa, as operações de replicar, parsear e validar o resultado são repetidas, com o fim de baixar dados para compor uma base maior. No exemplo da RFB, isso significaria montar uma base de dados a partir de uma lista de CNPJs.\nNo contexto dos Captchas, o interesse principal está nos passos de replicar e validar. Primeiro, a imagem é baixada e o rótulo é anotado – replicar. Em seguida, o rótulo é testado pelo oráculo – validar.\nO oráculo envolve a possibilidade de checar, de forma automática, se uma predição do rótulo de uma imagem está correta. O Captcha é obrigado a mencionar se uma predição está correta: se a predição foi correta, a página de interesse é acessada; se a predição está incorreta, o site envia uma mensagem de erro.\nDe forma geral, as etapas de replicar e validar em todos os sites de interesse envolveram os passos a seguir.\n\nAcessar a página do site de interesse.\nPreencher o formulário de pesquisa com a informação a ser consultada. Por exemplo, no site da RFB, a informação é o CNPJ da empresa a ser consultada. Em um site de tribunal, a informação é um número identificador de processo.\nBaixar a imagem do Captcha da busca.\nObter o rótulo da imagem, aplicando um modelo na imagem baixada ou anotando manualmente.\nSubmeter a consulta no site, informando o rótulo.\nVerificar o resultado. Se acessou a página desejada, o rótulo está correto. Caso contrário, o rótulo está incorreto.\n\nO procedimento descrito pode ser reproduzido indefinidamente. Isso significa que é possível criar uma base de dados virtualmente infinita de imagens rotuladas, com a informação adicional do rótulo estar correto ou incorreto. Isso foi feito para gerar os dados utilizados na simulação.\nUma oportunidade que o oráculo pode oferecer é a possibilidade de testar mais de uma predição. Sites com essa característica permitem que a pessoa ou robô teste mais de uma predição caso a tentativa anterior tenha resultado em fracasso. Como é possível observar na Tabela 2.1, dos 10 Captchas trabalhados, 7 permitem a realização de múltiplos chutes.\nNeste momento, cabe uma nota sobre oráculos e força bruta. O poder de testar vários rótulos para o mesmo Captcha implica na possibilidade teórica de resolver um Captcha por força bruta. Bastaria testar todos os rótulos possíveis para acessar a página de interesse. Na prática, no entanto, essa estratégia não funciona, já que a quantidade de rótulos possíveis é muito grande para testar no site, seja por demorar muito tempo ou pelo site forçar a troca do desafio após a passagem de determinado tempo ou quantidade de tentativas.\nVoltando ao ciclo da raspagem, ao longo do procedimento de baixar imagens de Captchas e aplicar o oráculo, pelo menos duas operações devem ser implementadas: acesso e teste. A operação de acesso é responsável por preencher o formulário de busca e baixar o Captcha (passos 1, 2 e 3 da lista acima). A operação de teste é responsável por submeter um rótulo do Captcha e verificar se o rótulo está correto ou incorreto (passos 5 e 6 da lista acima). O passo 4 pode ser realizado de forma unificada, pois não depende de interação com o site específico. Em alguns casos, as funções de acesso e teste precisam compartilhar parâmetros que contêm a sessão do usuário, para garantir que o teste envolva o mesmo Captcha da etapa de acesso.\nOs Captchas foram anotados manualmente com um procedimento que foi chamado de semi-automático, definido a seguir. No pacote {captchaDownload} (ver Apêndice A.1), foram desenvolvidas ferramentas para baixar e organizar cada Captcha, utilizando o oráculo para garantir que as imagens eram corretamente anotadas.\nCada Captcha teve as primeiras 100 observações anotadas manualmente. Isso foi feito a partir do próprio RStudio, utilizando a ferramenta de anotação manual do pacote {captcha}.\nA partir das anotações iniciais, um modelo inicial foi ajustado. Esse passo também foi feito com o pacote {captcha}, que possui uma função de ajuste de modelos que usa redes neurais convolucionais, definidas da mesma forma que nas seções anteriores.\nO modelo, então, foi utilizado como uma ferramenta para otimizar a anotação manual, funcionando da seguinte forma. Primeiro, o modelo tenta realizar a predição automaticamente e o oráculo informa se a predição está correta ou não. Se estiver incorreto e o site aceitar vários chutes, o modelo tenta novamente, mas com uma segunda alternativa de predição. Caso o site não aceite vários chutes ou o modelo não consiga acertar o Captcha em \\(T\\) tentativas (arbitrado como dez), o Captcha é anotado manualmente.\nCom o procedimento destacado acima, é criada uma nova base de dados, que por sua vez é utilizada para ajustar um novo modelo. O modelo, atualizado, é utilizado para classificar novos Captchas, e assim por diante, até que o modelo ajustado alcance uma acurácia razoável, que foi arbitrada em 80%. Com isso o procedimento de anotação é finalizado.\nO único problema do procedimento de anotação descrito diz respeito aos Captchas que não aceitam várias tentativas. Nesses casos, não é possível verificar com certeza que um caso anotado manualmente (após a tentativa do modelo) foi anotado corretamente, já que a anotação manual seria a segunda tentativa. No entanto, esse problema aparece somente em três Captchas (cadesp, jucesp e trf5). A anotação manual dos 100 primeiros Captchas, no entanto, mostrou que pelo menos 95% dos Captchas foram anotados corretamente quando anotados manualmente. A proporção máxima de 5% de erro é negligenciável considerando que a maior parte das bases de dados foi construída com verificação do oráculo.\nEm alguns casos, os rótulos dos Captchas podem ser obtidos sem intervenção humana, utilizando técnicas de raspagem de dados ou processamento de sinais. Um exemplo é o Captcha do SEI, que mostra informações suficientes para resolver o Captcha na própria URL que gera a imagem. Outro exemplo é o TJMG, que libera, além da imagem, um áudio contendo o mesmo rótulo da imagem, sem a adição de ruídos. Como o áudio não tem ruídos, basta ler o áudio, separar os áudios de cada caractere e calcular uma estatística simples (como a soma dos valores absolutos das amplitudes). Essa estatística é utilizada para associar um pedaço de áudio a um caractere.\nA Tabela 2.2 caracteriza os Captchas anotados. Todos os Captchas possuem comprimento entre 4 e 6 dígitos e, com exceção do SEI, não são sensíveis a maiúsculas e minúsculas.\n\n\n\n\nTabela 2.2:  Lista de captchas analisados e suas características CaptchaVários chutesCaracteresComprimentoColorido# Rótulos anotadostrf5Não0-96não1000tjmgSim0-95sim1000trtSima-z0-96não1500esajSima-z5sim3000jucespNãoa-z0-95não4000tjpeSima-z0-95não4000tjrsSim0-94sim2000cadespNãoa-z4sim3000seiSima-zA-Z0-94sim10000rfbSima-z0-96não4000\n\n\n\nAs bases de dados com imagens anotadas foram disponibilizadas na aba de lançamentos (releases) do repositório principal do projeto de pesquisa. As bases com imagens e modelos ajustados estão disponíveis para quem tiver interesse em fazer novas pesquisas e utilizar os resultados em suas aplicações, sem restrições de uso."
  },
  {
    "objectID": "metodologia.html#sec-simulacoes",
    "href": "metodologia.html#sec-simulacoes",
    "title": "2  Metodologia",
    "section": "Simulações",
    "text": "Simulações\nPara verificar o poder do uso do oráculo para o aprendizado do modelo, uma série de simulações foram desenvolvidas. As simulações foram organizadas em três passos: modelo inicial, dados e modelo final. Os passos foram descritos em maior detalhe a seguir.\n\nPrimeiro passo: modelo inicial\nA simulação do modelo inicial teve como objetivo obter modelos preditivos de Captchas com acurácias distintas. O modelo inicial seria usado, então, para baixar dados diretamente do site usando o oráculo e, por fim, ajustar um modelo final com os novos dados provenientes do oráculo.\nOs modelos iniciais para cada Captcha foram construídos em dois passos. O primeiro foi montar a base de dados completa, suficiente para ajustar um modelo com alta acurácia, que arbitrados em 80%, como descrito anteriormente. Depois, montou-se 10 amostras de dados com subconjuntos das bases completas, cada uma contendo 10%, 20%, e assim por diante, até a base completa. Por exemplo: no Captcha da Jucesp, construiu-se um modelo com acurácia maior que 80% com 4000 Captchas. A partir disso, foi feita uma partição dos dados com 400 imagens (10% do total), 800 imagens (20% do total) e assim por diante, até o modelo com 4000 Captchas. A utilização de diferentes tamanhos de base de dados foi realizada para obter modelos com diferentes acurácias.\nPara cada tamanho de amostra \\(S\\), aplicou-se uma bateria de 27 modelos. Isso foi feito porque para diferentes quantidades de amostra, a configuração dos hiperparâmetros que resulta no melhor modelo pode ser diferente. Os modelos seguiram uma grade de hiperparâmetros considerando três informações:\n\nA quantidade de unidades computacionais na primeira camada densa após as camadas convolucionais, com os valores considerados: 100, 200 e 300.\nO valor do dropout aplicado às camadas densas, com os valores considerados: 10%, 30% e 50%.\nO fator de decaimento na taxa de aprendizado a cada época, com os valores considerados: 1%, 2% e 3%.\n\nOs diferentes valores de hiperparâmetros foram escolhidos com base em vários testes empíricos realizados antes da simulação. Nesses testes, foram considerados Captchas com diferentes complexidades e bases de dados com diferentes tamanhos. Os números escolhidos visaram proporcionar uma boa cobertura de modelos que poderiam ser os melhores, ao mesmo tempo que seria uma grade simples o suficiente para permitir a realização da simulação em tempo hábil.\nCombinando os três valores dos três hiperparâmetros, tem-se um total de \\(27=3^3\\) hiperparâmetros. Com isso, foi possível identificar, para cada tamanho de amostra \\(S\\), o classificador com a melhor acurácia dentre os modelos ajustados.\nTodos os modelos foram ajustados utilizando-se um computador com um processador Intel Core i7 10700KF, 3.80GHz (5.10GHz Turbo), 64GB de RAM e uma placa GeForce RTX 3080 Eagle OC 10G. Os códigos utilizaram a linguagem de programação R na versão 4.1.2 e o pacote {torch} na versão 0.7.1.\nNo final do primeiro passo, portanto, considera-se apenas o melhor modelo para cada tamanho de amostra, dentre os 27 ajustados. É claro que os modelos encontrados por essa técnica não são, necessariamente, os melhores modelos possíveis. No entanto, como a técnica é a mesma para todos os Captchas, é possível fazer comparações através de uma metodologia mais transparente.\nUma discussão interessante que aparece nesse contexto é a escolha de pacotes da linguagem de programação R no lugar de Python para o ajuste dos modelos. Para a construção deste trabalho, utilizou-se o R em todos os passos, seja na construção do pacote {captcha}, o ajuste dos modelos e raspadores de dados. No entanto, o Python é uma linguagem reconhecidamente popular para tarefas de aprendizado de máquina e raspagem de dados. Neste trabalho, optou-se utilizar o R por dois motivos: i) a experiência do autor nesta linguagem, que é muito maior em R do que em Python e ii) a possibilidade de utilizar o pacote {torch}, que foi desenvolvido por um ex-aluno do IME-USP, Daniel Falbel. A utilização do {torch} não só facilitou a construção da solução como também pode ser pensada como um incentivo para que outros pesquisadores da estatística utilizem esse pacote computacional.\nUma possível desvantagem ao utilizar o R é que isso poderia trazer dificuldades na velocidade da simulação. No entanto, isso não acontece na prática. No momento do ajuste dos modelos, existia uma diferença de performance do {torch} com relação ao PyTorch, do Python. No entanto, essa diferença é negligenciável ao considerar o tempo total de ajuste dos modelos, incluindo a parte de acesso à internet. O que torna o download dos dados lento não é a linguagem utilizada, e sim a própria conexão com a internet e potenciais bloqueios do site de origem. Por isso, os tempos para executar as simulações usando R ou Python seriam similares.\n\n\nSegundo passo: dados\nO segundo passo teve como objetivo construir as bases de dados utilizando o oráculo. Primeiro, foi necessário decidir quais modelos, dentre os 10 ajustados para cada Captcha, seriam utilizados para construir novas bases. Não faria sentido, por exemplo, considerar um modelo com acurácia de 0%, já que ele não produziria nenhuma observação comparado com um modelo que chuta aleatoriamente. Também não faria sentido considerar um classificador com acurácia de 100%, já que nesse caso não há o que testar com a técnica do oráculo.\nDecidiu-se que seria necessário considerar somente os modelos que resultaram em acurácias maiores de 5% e menores de 50%. O valor máximo foi decidido após realizar alguns testes empíricos e verificar, informalmente, que a técnica do oráculo realmente resultava em ganhos expressivos, mesmo com modelos de baixa acurácia. Concluiu-se então que não seria necessário testar a eficácia da técnica para classificadores com alta acurácia. Já o valor mínimo foi decidido de forma arbitrária, retirando-se os classificadores com acurácia muito baixa.\nA segunda decisão a ser tomada para construção dos dados foi a quantidade de imagens que seria baixada para cada Captcha. Como são Captchas de diferentes dificuldades, a quantidade de dados seria diferente para cada tipo. Optou-se por baixar a quantidade de dados de forma a montar uma base de treino que contém a quantidade de observações necessária para obter o melhor modelo daquele Captcha. Por exemplo, no TJRS, um modelo com acurácia próxima de 100% foi identificado com 2000 observações. O melhor modelo com 300 imagens (240 para treino, 60 para teste) resultou em uma acurácia de 35%. Foram, então, baixadas 1760 observações para compor o total de 2000 na base de treino. As imagens de teste do modelo inicial poderiam até ser utilizadas, mas optamos por descartar para garantir que o modelo não ficasse sobreajustado para a primeira base.\nO motivo de baixar a mesma quantidade de observações que o melhor modelo inicial foi feita por três motivos. O primeiro é que existem evidências de que é possível construir um bom modelo com essa quantidade de imagens, ainda que em um caso as informações são completas e, no outro, incompletas. O segundo é que isso permite a comparação do resultado do modelo completamente anotado contra o modelo que é parcialmente anotado e com anotações incompletas provenientes do oráculo. A terceira é que essa estratégia proporciona bases de dados com diferentes proporções de dados parcialmente anotados, o que pode trazer resultados empíricos de interesse, como avaliar se muitos casos parcialmente rotulados podem atrapalhar o ajuste do modelo.\nA terceira e última decisão tomada para baixar os dados foi a quantidade de chutes que o modelo poderia fazer, nos casos em que isso é permitido pelo site. Optou-se, de forma arbitrária, por três valores: 1, que é equivalente a um site que não permite múltiplos chutes, 5 chutes e 10 chutes.\nPortanto, o procedimento de coleta dos dados foi feito, para cada Captcha, da seguinte forma:\n\nListou-se todos os melhores modelos ajustados para cada tamanho de amostra.\nFiltrou-se os modelos para os que apresentaram acurácia de 5% até 50%.\nDefiniu-se o tamanho da base a ser obtida, com base no tamanho da base de treino utilizada no modelo e a quantidade total que se objetivou obter.\nPara cada quantidade de tentativas disponível (1, 5 e 10), baixou-se as imagens, anotando com o valor “1” se o rótulo de alguma das tentativas estivesse correto e com o valor “0” caso contrário.\nNos casos com erros, armazenou-se um arquivo de log para cada Captcha com o histórico de tentativas incorretas, que é a informação mais importante a ser passada para o modelo final.\n\nNo final, obteve-se bases de dados de treino para todos os Captchas analisados, com quantidades de imagens que variam de acordo com os parâmetros definidos anteriormente e pela quantidade de tentativas. A quantidade total de bases de dados geradas foi 65.\nAlém das bases de treino, foi construída uma base de teste para cada Captcha. O tamanho das bases de teste foi arbitrado em 1000 imagens para cada Captcha. As bases de teste foram construídas completamente do zero, sem utilizar informações de bases anteriores. Para construir as bases, utilizou-se a mesma técnica semiautomática definida anteriormente, usando o melhor modelo disponível para classificar a maioria das imagens e classificando manualmente em caso de falha. Em alguns casos, como TJMG e TJRS, a anotação humana quase não foi necessária, pois os melhores classificadores obtidos apresentaram acurácia próxima de 100%.\n\n\nTerceiro passo: modelo final\nO modelo final foi ajustado para cada uma das 65 bases de treino disponíveis após a realização dos passos 1 e 2. Nesse caso, utilizou-se o modelo proposto na Seção 2.2. Caso a imagem tenha sido corretamente anotada, a função de perda é calculada normalmente. Caso ela tenha sido anotada incorretamente, considera-se a probabilidade de não observar nenhum dos chutes.\nAlém de modificar a forma de calcular a função de perda do modelo, foi necessário realizar uma nova busca de hiperparâmetros. Optou-se por utilizar os mesmos hiperparâmetros dos modelos iniciais para manter a consistência. O único detalhe nesse ponto é que, como os parâmetros de partida são os do modelo inicial, optou-se por não modificar a quantidade de unidades na camada densa, variando somente os valores de dropout e de decaimento na taxa de aprendizado. Portanto, ajustou-se 9 e não 27 modelos para cada base de dados.\nNo final, assim como no primeiro passo, os classificadores com melhor acurácia foram selecionados para cada modelo. Obteve-se, então, uma lista de 65 modelos ajustados para comparar com os modelos iniciais e estimar a efetividade do oráculo. As comparações foram feitas através de gráficos de barras, explorando o efeito do uso do oráculo para diferentes Captchas, diferentes modelos iniciais e diferentes quantidades de chutes, além de um gráfico de dispersão para relacionar as acurácias iniciais e finais.\nAlém do terceiro passo, outros experimentos foram realizados para verificar se, ao aplicar a técnica do oráculo iterativamente, os resultados continuariam melhorando. Ou seja, é possível considerar os modelos obtidos no passo 3 como os modelos iniciais do passo 1, aplicar novamente o passo 2 (baixar dados) e o passo 3 (rodar modelo com os novos dados). Isso foi feito para apenas um conjunto selecionado de Captchas para verificar essa possibilidade, não fazendo parte das simulações principais do estudo.\nAs bases de dados das simulações também foram disponibilizadas na aba de lançamentos (releases) do repositório principal do projeto de pesquisa. As bases podem ser utilizadas para aumentar as bases de treino e para testar outras arquiteturas de redes neurais ao tema dos Captchas com uso de aprendizado fracamente supervisionado.\n\n\n\n\nBALDI, P.; SADOWSKI, P. J. Understanding dropout. Advances in neural information processing systems, v. 26, 2013.\n\n\nBLUM, A.; KALAI, A. A note on learning from multiple-instance examples. Machine learning, v. 30, n. 1, p. 2329, 1998.\n\n\nCOUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. The Journal of Machine Learning Research, v. 12, p. 15011536, 2011.\n\n\nFALBEL, D. luz: Higher Level ’API’ for ’torch’. a2022. Disponível em: <https://CRAN.R-project.org/package=luz>.\n\n\nFALBEL, D. torchvision: Models, Datasets and Transformations for Images. b2022. Disponível em: <https://CRAN.R-project.org/package=torchvision>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’ Acceleration. 2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nFENG, L. et al. Provably consistent partial-label learning. Advances in Neural Information Processing Systems, v. 33, p. 1094810960, a2020.\n\n\nFENG, L. et al. Learning with multiple complementary labels. PMLR, b2020.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, v. 358, n. 6368, p. eaag2612, 2017.\n\n\nGRANDVALET, Y. Logistic regression for partial labels. 2002.\n\n\nHÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled examples. Intelligent Data Analysis, v. 10, n. 5, p. 419439, 2006.\n\n\nIOFFE, S.; SZEGEDY, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. PMLR, 2015.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances in neural information processing systems, v. 30, 2017.\n\n\nJIN, R.; GHAHRAMANI, Z. Learning with multiple labels. Advances in neural information processing systems, v. 15, 2002.\n\n\nKAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review. International Journal of Computer Science and Information Technologies, v. 5, 1 jan. 2014.\n\n\nKINGMA, D. P.; BA, J. Adam: A Method for Stochastic Optimization. n. arXiv:1412.6980, jan. 2017. Disponível em: <https://arxiv.org/abs/1412.6980>.\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A practical approach for predictive models. CRC Press, 2019.\n\n\nLECUN, Y. et al. Gradient-based learning applied to document recognition. Proceedings of the IEEE, v. 86, n. 11, p. 22782324, 1998.\n\n\nLECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning. nature, v. 521, n. 7553, p. 436444, 2015.\n\n\nLI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control chart. IIE Transactions, v. 46, n. 5, p. 526542, 2014.\n\n\nLIU, L.; DIETTERICH, T. A conditional multinomial mixture model for superset label learning. Advances in neural information processing systems, v. 25, 2012.\n\n\nNELDER, J. A.; WEDDERBURN, R. W. Generalized linear models. Journal of the Royal Statistical Society: Series A (General), v. 135, n. 3, p. 370384, 1972.\n\n\nOOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021. Disponível em: <https://CRAN.R-project.org/package=magick>.\n\n\nR CORE TEAM. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing, 2021. Disponível em: <https://www.R-project.org/>.\n\n\nRAMESH, A. et al. Hierarchical Text-Conditional Image Generation with CLIP Latents. n. arXiv:2204.06125, abr. 2022. Disponível em: <https://arxiv.org/abs/2204.06125>.\n\n\nWICKHAM, H. stringr: Simple, Consistent Wrappers for Common String Operations. b2022. Disponível em: <https://CRAN.R-project.org/package=stringr>.\n\n\nWICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível em: <https://CRAN.R-project.org/package=rvest>.\n\n\nWICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em: <https://CRAN.R-project.org/package=xml2>.\n\n\nYE, G. et al. Yet another text captcha solver: A generative adversarial network based approach. 2018.\n\n\nYU, X. et al. Learning with biased complementary labels. 2018.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13, 2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning. National science review, v. 5, n. 1, p. 4453, 2018.\n\n\nZHU, X. J. Semi-supervised learning literature survey. 2005."
  },
  {
    "objectID": "resultados.html#sec-result-sim",
    "href": "resultados.html#sec-result-sim",
    "title": "3  Resultados",
    "section": "Resultados empíricos",
    "text": "Resultados empíricos\n\n\n\nOs resultados foram obtidos a partir das simulações com diversos Captchas. Foram realizadas 65 simulações no total, variando o tipo de Captcha, a acurácia do modelo inicial e a quantidade de tentativas no oráculo, como descrito na Seção 2.4.\nA base de dados com os resultados das simulações está disponível publicamente no repositório da tese1. A base contém informações do Captcha ajustado (captcha), da quantidade de observações do modelo inicial (n), da quantidade de tentativas do oráculo (ntry), da etapa de simulação (fase, inicial ou WAWL), do caminho do modelo ajustado (model) e da acurácia obtida (acc).\nOs resultados gerais mostram um ganho de 333% na acurácia após a aplicação do método WAWL. Ou seja, em média, a acurácia do modelo no terceiro passo da simulação (ver a Seção 2.4.3) foi de mais de três vezes a acurácia do modelo inicial. Em termos absolutos (diferença entre as acurácias), o ganho foi de 33%, ou seja, após o terceiro passo, os modelos ganharam, em média, 33% de acurácia.\n\n\n\nAs Figuras 3.1 e 3.2 mostram os ganhos relativos e absolutos, separando os resultados gerais por quantidade de tentativas. Cada ponto é o resultado de uma simulação e o ponto em destaque é o valor médio, acompanhado de intervalo \\(m \\mp 2*s/\\sqrt(n)\\), com \\(m\\) sendo a média, \\(s\\) o desvio padrão e \\(n\\) a quantidade de dados. A linha pontilhada indica se a acurácia aumentou ou diminuiu após a aplicação da técnica.\nNa Figura 3.1, é possível notar que os ganhos em acurácia apresentam alta variabilidade, mas que apresentam uma tendência positiva com relação ao número de tentativas. O ganho entre aplicar 5 e 10 tentativas é menos expressivo do que o ganho entre aplicar 1 e 5 tentativas, indicando que a oportunidade oferecida por sites que aceitam vários chutes é relevante, mas não há necessidade de realizar tantos chutes para aproveitar essa oportunidade. Uma possível explicação para isso é que o modelo ficaria indeciso entre poucas opções.\n\n\n\n\n\nFigura 3.1: Ganho percentual ao utilizar a técnica do oráculo, para cada quantidade de tentativas\n\n\n\n\nA Figura 3.2, com as os ganhos absolutos, mostra a mesma informação, mas em valores com interpretação mais direta. O ganho médio absoluto em sites que permitem mais de um chute ficou em torno de 40%, enquanto o ganho com apenas um chute ficou um pouco acima de 25%. Também é possível notar que a técnica é efetiva de forma consistente, já que resultou em pioras nas acurácias em poucos casos, sendo todos eles no cenário com apenas um chute.\n\n\n\n\n\nFigura 3.2: Ganhos absolutos ao utilizar a técnica do oráculo, para cada quantidade de tentativas\n\n\n\n\n\n\n\nAs Figuras 3.3 e 3.4 apresentam os resultados gerais separando por acurácia inicial do modelo. A estrutura do gráfico é similar às visualizações anteriores, que separaram os resultados por quantidade de tentativas. As categorias escolhidas foram: até 10%, mais de 10% até 35% e mais de 35% de acurácia no modelo inicial. A escolha dos intervalos se deram pela quantidade de observações em cada categoria.\nA Figura 3.3 mostra os ganhos relativos. É possível notar uma tendência de queda no ganho de acurácia com uso do oráculo conforme aumenta a acurácia do modelo inicial. Esse resultado é esperado, pois, como a acurácia é um número entre zero e um, um modelo que já possui alta acurácia não tem a possibilidade de aumentar muito de forma relativa.\n\n\n\n\n\nFigura 3.3: Ganho percentual ao utilizar a técnica do oráculo, para cada categoria de acurácia do modelo inicial\n\n\n\n\nA Figura 3.4 mostra os ganhos absolutos. O gráfico apresenta o mesmo problema que o anterior, já que o ganho máximo depende da acurácia inicial do modelo. Ainda assim, é possível notar que, em termos absolutos, modelos com acurácia inicial entre 10% e 35% apresentaram um ganho maior que modelos com acurácia inicial de até 10%.\n\n\n\n\n\nFigura 3.4: Ganho absoluto ao utilizar a técnica do oráculo, para cada categoria de acurácia do modelo inicial\n\n\n\n\nPara lidar com o fato de a acurácia ser um número limitado, fizemos o mesmo gráficos de antes, mas ajustado pelo máximo possível que a técnica do oráculo poderia proporcionar. O ganho absoluto ajustado de uma simulação é dado por\n\\[\n\\text{ganho} = \\frac{\\text{wawl } - \\text{ inicial}}{1\\; - \\text{ inicial}}.\n\\]\nA Figura 3.5 mostra os ganhos ajustados. Pelo gráfico, é possível notar que existe um ganho expressivo do WAWL para modelos iniciais com mais de 10% de acurácia com relação a modelos iniciais com até 10% de acurácia. Ou seja, quando o modelo inicial é fraco, o ganho ao usar o método é um pouco menor. É importante notar, no entanto, que as simulações consideram a aplicação do WAWL apenas uma vez – é possível baixar mais dados e atualizar o modelo indefinidamente, como mostrado mais adiante na Figura 3.7. O menor efeito do método para modelos iniciais fracos não significa, portanto, que a técnica não funciona para modelos iniciais fracos; pelo contrário: ela ajuda o modelo a sair do estado inicial e o leva para um estado com acurácia maior, de onde seria possível aplicar a técnica novamente para obter resultados mais expressivos.\n\n\n\n\n\nFigura 3.5: Ganho absoluto ao utilizar a técnica do oráculo, para cada categoria de acurácia do modelo inicial\n\n\n\n\nNa Figura 3.6, são apresentados os resultados separados por Captcha. Cada linha é uma combinação de Captcha, quantidade de tentativas e acurácia modelo inicial, classificados nas três categorias mostradas anteriormente. As linhas pontilhadas indicam modelos ajustados com mais de uma tentativa, enquanto as linhas contínuas mostram modelos ajustados com apenas uma tentativa. A primeira extremidade de cada linha, do lado esquerdo, indica a acurácia do modelo inicial e a segunda extremidade, do lado direito, a acurácia do modelo usando o método WAWL.\n\n\n\n\n\nFigura 3.6: Resultados da simulação por captcha, quantidade de tentativas e modelo inicial\n\n\n\n\nPelo gráfico, é possível identificar duas informações relevantes. Como já verificado anteriormente, os modelos ajustados com mais de uma tentativa apresentam maiores ganhos do que os modelos ajustados com apenas uma tentativa. Verifica-se também que modelos com acurácia inicial de até 10% só apresentam ganhos menores que os modelos com acurácia inicial maior que 10% nos casos com apenas um chute. Ou seja, existe interação entre a quantidade de chutes e a acurácia do modelo inicial ao avaliar o impacto nos ganhos empíricos do método WAWL.\nPelos resultados das simulações, é possível concluir que o método WAWL foi bem-sucedido. Primeiro, o método apresenta resultados expressivos e de forma consistente, mesmo sem realizar novas anotações manuais. Além disso, a técnica consegue aproveitar oportunidade oferecida pelos sites de obter o feedback oráculo múltiplas vezes na mesma imagem. Finalmente, o método apresenta, em média, resultados positivos mesmo para modelos iniciais muito fracos (com acurácia de até 10%), indicando que sua aplicação é possível para qualquer modelo inicial, o que é bastante factível de atingir com bases pequenas ou com modelos generalistas para resolver Captchas.\n\nUm possível problema em aplicar o WAWL é que a técnica poderia introduzir viés de seleção no modelo, impedindo-o de ser aprimorado indefinidamente. Mesmo que os resultados teóricos deem uma boa base para concluir que isso não seja verdade, foi feito um experimento adicional, com apenas um dos Captchas, para verificar se a aplicação da técnica múltiplas vezes apresenta bons resultados.\nO Captcha escolhido para a simulação foi o trf5, por ser um Captcha que não aceita múltiplos chutes, em uma tentativa de obter um pior caso. Para esse Captcha, o melhor modelo obtido com a técnica do oráculo foi considerado como modelo inicial, sendo usado para baixar novos dados do site do Tribunal. Os novos dados foram adicionados à base de treino, ajustando-se um novo modelo.\nA Figura 3.7 mostra os resultados da aplicação iterativa. A utilização da técnica não só funcionou como levou o modelo a uma acurácia de 100%.\n\n\n\n\n\nFigura 3.7: Resultados da aplicação iterativa do WAWL\n\n\n\n\nO resultado sugere que o método WAWL pode ser aplicado iterativamente para aprimorar o aprendizado do modelo. Ele sugere, ainda, que uma técnica de aprendizado ativo com feedback automático do oráculo pode dar bons resultados, já que a forma de obter os dados não introduz viés de seleção no ajuste do modelo.\nNesse sentido, foi aplicado também um experimento de uma ferramenta de online learning. A ferramenta funciona da seguinte forma: ao invés de aplicar os passos do WAWL (baixar dados e ajustar novo modelo) de forma separada, obtêm-se amostras do oráculo em cada passo do ajuste do modelo. Ou seja, as técnicas de raspagem de dados entram de forma direta no ciclo de aprendizagem.\nO experimento foi feito utilizando o Captcha do TJRS com os passos a seguir. O modelo, função de perda e base de testes são exatamente os mesmos utilizados na simulação completa. No entanto, os dados baixados pelo oráculo não são considerados. Ao invés disso, o minibatch é construído baixando dados diretamente da internet e aplicando o modelo inicial.\nPara permitir que o modelo aproveite casos baixados em minibatches anteriores, o modelo considera uma probabilidade de baixar novos casos, arbitrada em 80%. Assim, para cada elemento do minibatch, com 80% de probabilidade, a observação é baixada da internet, e com 20% de probabilidade, a observação é uma amostra dos casos anteriores já baixados. Como forma de obter um pior caso, o modelo não considera nem mesmo os dados utilizados para construir o modelo inicial.\nO valor do minibatch foi arbitrado em 40 observações, como na etapa de simulação. O número de minibatches de uma época é indefinido, porque não existe um número máximo de amostras. A época foi arbitrada como sendo a passagem de 2 minibatches, para permitir a atualização do modelo inicial.\nA atualização do modelo inicial é realizada ao fim de cada época. Se ao fim do ciclo (ou seja, ao fim de 2 minibatches) o modelo ajustado possui uma acurácia melhor na base de teste do que o modelo inicial, o modelo é atualizado para a versão atual. Se não, o modelo inicial é mantido. Dessa forma, os minibatches construídos ficam cada vez mais informativos, uma vez que vão acertar mais o rótulo da imagem.\nO experimento considerou um modelo inicial com apenas 11% de acurácia. O TJRS foi escolhido como exemplo porque o site é relativamente estável, além de permitir múltiplos chutes. O número de chutes permitidos ao modelo foi arbitrado em 5. Na parte dos hiperparâmetros, como a época é curta (apenas 80 observações por época), o decaimento na taxa de aprendizado considerado foi 0.999. Os valores de dropout e quantidade de unidades na camada densa foram as mesmas do modelo inicial.\nO resultado do experimento foi promissor. A partir do modelo inicial 11% de acurácia, após 100 épocas, o modelo baixou 6391 imagens e chegou em uma acurácia de 87% na base de teste. A Figura 3.8 mostra a evolução da acurácia do modelo ao longo das épocas. Como as épocas são relativamente curtas (apenas 80 observações), o ganho em acurácia é pequeno e apresenta variabilidade.\n\n\n\n\n\nFigura 3.8: Resultados do experimento com aprendizado online\n\n\n\n\nUm possível motivo do Captcha não ter chegado no máximo de acurácia (100% no caso do TJRS) é que a arquitetura e os hiperparâmetros considerados não eram poderosos o suficiente para alcançar o melhor modelo. De qualquer forma, a partir do experimento, conclui-se que a utilização de online learning também é muito promissora. A principal vantagem do método é ser menos burocrático para desenvolvedores, no sentido de que basta passar o modelo inicial e funções para baixar e testar os Captchas para aprimorar o modelo. A desvantagem é que o procedimento precisa de conexão ativa com a internet e o aprendizado é mais lento, já que os dados são baixados no processo de construção dos minibatches."
  },
  {
    "objectID": "resultados.html#sec-pacote-captcha",
    "href": "resultados.html#sec-pacote-captcha",
    "title": "3  Resultados",
    "section": "Pacote captcha",
    "text": "Pacote captcha\nO trabalho de resolução de Captchas pelo autor da tese surgiu no ano de 2016. Como foi comentado na introdução da tese, é muito comum se deparar com desafios de Captchas ao raspar dados do judiciário, já que estes dados não são abertos.\nO primeiro Captcha a ser investigado foi o do sistema e-SAJ. O desafio era utilizado no site do TJSP que, depois de alguns anos, passou a utilizar o sistema reCaptcha. O Captcha do e-SAJ faz parte da tese, mas tem como fonte de dados o TJBA, que continua utilizando o desafio até o momento que os sites foram investigados pela última vez, em setembro de 2022.\nA primeira abordagem para resolver o Captcha do e-SAJ foi utilizando heurísticas para separar as letras, em 2016. Infelizmente o pacote original, chamado {captchasaj}, foi removido da internet, mas um código legado construído para o TJRS está disponível neste link. Nessa abordagem, as letras primeiro são segmentadas, alimentando um modelo de florestas aleatórias que considera os pixels da imagem como variáveis preditoras e a letra como resposta. Esses trabalhos tiveram contribuições importantes de Fernando Corrêa e Athos Damiani, ambos do IME-USP.\nA segunda abordagem para resolver os Captchas foi utilizando o áudio, também em 2016. O código para resolver o Captcha da RFB utilizando áudio está disponível neste link. A ideia de resolução era parecida, passando pelo procedimento de segmentação e depois de modelagem, mas tinha um passo intermediário de processamento envolvendo engenharia de features (KUHN; JOHNSON, 2019). O trabalho teve contribuições importantes de Athos Damiani.\nCom o advento da ferramenta TensorFlow para o R (ALLAIRE; TANG, 2022), os modelos para resolver Captchas passaram a utilizar modelos de redes neurais. No início, por falta de conhecimento da área, a arquitetura das redes era demasiadamente complexa. Depois que os primeiros modelos começaram a funcionar, notou-se que as etapas de pré-processamento com segmentação e algumas camadas das redes eram desnecessárias para ajustar os modelos. Essa parte teve grande contribuição de Daniel Falbel, também do IME-USP, que foi a pessoa que introduziu o TensorFlow e a área de deep learning para a comunidade brasileira de R.\nDepois de resolver com sucesso alguns Captchas, notou-se que seria possível criar um ambiente completo de modelagem de Captchas. Isso deu origem ao pacote {decryptr} (TRECENTI et al., 2022), que foi construído em 2017. O trabalho teve grandes contribuições de Caio Lente, do curso de Ciência da Computação do IME-USP e outros colegas de faculdade.\nCom o passar do tempo, o pacote {decryptr} ficou cada vez mais estável, funcionando como dependência de várias ferramentas utilizadas em trabalhos de jurimetria. O pacote também ganhou um site: https://decryptr.xyz e uma API com acesso gratuito, precisando apenas de uma chave de acesso. A ferramenta ficou bastante popular, com 178 estrelas no GitHub no mês de dezembro de 2022. Essas ferramentas envolveram contribuições principalmente de Caio Lente e Daniel Falbel.\nA construção do pacote {captcha} separada do {decryptr} se deu por dois motivos. Primeiro, o pacote {decryptr}, por ser o primeiro a tratar do assunto, possui muitos códigos legados e dificuldades de instalação por conta da dependência do python, necessário para o funcionamento do TensorFlow, que é chamado através do pacote {reticulate} (USHEY; ALLAIRE; TANG, 2022). Além disso, a implementação das técnicas do oráculo envolviam modificações na função de perda, que são mais difíceis de implementar no ambiente do {tensorflow}, justamente por conta da necessidade de conhecer o código python que roda por trás dos códigos em R.\nCom o advento do pacote {torch} (FALBEL; LURASCHI, 2022), no entanto, tudo foi facilitado. O pacote não possui dependências com o python, além de ser bastante transparente e flexível na construção da arquitetura do modelo, funções de perda e otimização. O pacote, também construído por Daniel Falbel, é um grande avanço científico e facilitou muito a construção dos códigos desta tese.\nO pacote {captcha}, apesar de ter sido construído do zero, foi desenvolvido durante lives realizadas na plataforma Twitch. A construção em lives foi interessante porque era possível obter feedback e ideias da comunidade durante a construção da ferramenta, o que acelerou o desenvolvimento e auxiliou na arquitetura do pacote.\nO pacote {captcha} foi construído para funcionar como uma caixa de ferramentas para quem deseja trabalhar com Captchas. O pacote possui funções de leitura, visualização, anotação, preparação de dados, modelagem, carregamento de modelos pré-treinados e predição. O pacote também permite a construção de um fluxo de trabalho para resolver um novo Captcha, criando um novo repositório para orquestrar o passo-a-passo.\n\nUso básico\nA utilização básica do {captcha} envolve as funções read_captcha(), plot(), captcha_annotate(), captcha_load_model() e decrypt(). As funções são explicadas abaixo.\nA função read_captcha() lê um vetor de arquivos de imagens e armazena na memória do computador. Por trás, a função utiliza o pacote {magick} para lidar com os tipos de arquivos mais comuns (JPEG, PNG, entre outros).\n\n\nCódigo\nlibrary(captcha)\nexemplo <- \"assets/img/dados_tjmg.jpeg\"\ncaptcha <- read_captcha(exemplo)\n\ncaptcha\n#> # A tibble: 1 × 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 JPEG     100     50 sRGB       FALSE     4530 72x72\n\n\n\n\n\nFigura 3.9: Resultado observado ao imprimir um objeto de classe captcha\n\n\n\n\nA função retorna um objeto com a classe captcha, que pode ser utilizada por outros métodos do pacote.\n\n\nCódigo\nclass(captcha)\n#> [1] \"captcha\"\n\n\nO objeto de classe captcha é uma lista com três elementos: $img, que contém imagem lida com o pacote {magick}, $lab, que contém o rótulo da imagem (por padrão, NULL) e $path, que contém o caminho da imagem que foi lida.\n\n\nCódigo\nstr(captcha)\n#> Class 'captcha'  hidden list of 3\n#>  $ img :Class 'magick-image' <externalptr> \n#>  $ lab : NULL\n#>  $ path: chr \"assets/img/dados_tjmg.jpeg\"\n\n\nA função read_captcha() possui um parâmetro lab_in_path=, que indica se o rótulo está contido no caminho da imagem. Se lab_in_path=TRUE, a função tentará extrair o rótulo do arquivo, obtendo o texto que vem depois do último _ do caminho, armazenando o resultado no elemento $lab.\n\n\nCódigo\nexemplo <- \"assets/img/mnist128c49c36e13_6297.png\"\ncaptcha <- read_captcha(exemplo, lab_in_path = TRUE)\n\nstr(captcha)\n#> Class 'captcha'  hidden list of 3\n#>  $ img :Class 'magick-image' <externalptr> \n#>  $ lab : chr \"6297\"\n#>  $ path: chr \"assets/img/mnist128c49c36e13_6297.png\"\n\n\nA função plot() é um método de classe S3 do R básico. A função foi implementada para facilitar a visualização de Captchas. A função recebe uma lista de imagens obtida pela função read_captcha() e mostra o Captcha visualmente, como na Figura 3.10.\n\n\nCódigo\nexemplo <- \"assets/img/dados_tjmg.jpeg\"\ncaptcha <- read_captcha(exemplo)\nplot(captcha)\n\n\n\n\n\nFigura 3.10: Exemplo de aplicação da função plot a um objeto captcha\n\n\n\n\nUm aspecto interessante da função plot() é que ela lida com uma lista de Captchas. Isso é útil quando o interesse é visualizar vários Captchas de uma vez na imagem. A Figura 3.11 mostra um exemplo de aplicação.\n\n\nCódigo\nexemplos <- paste0(\"assets/img/\", c(\n  \"dados_tjmg.jpeg\",\n  \"dados_esaj.png\",\n  \"dados_rfb.png\",\n  \"dados_sei.png\"\n))\ncaptchas <- read_captcha(exemplos)\nplot(captchas)\n\n\n\n\n\nFigura 3.11: Exemplo de aplicação da função plot a um objeto captcha com várias imagens\n\n\n\n\nPor padrão, a função plot dispõe as imagens em quatro colunas. Para mudar o padrão, é possível modificar as opções usando options(captcha.print.cols = N), onde N é o número de colunas desejado. A Figura 3.12 mostra um exemplo com duas colunas.\n\n\n\n\n\nCódigo\noptions(captcha.print.cols = 2)\nplot(captchas)\n\n\n\n\n\nFigura 3.12: Exemplo de aplicação da função plot a um objeto captcha com várias imagens, disponibilizadas em duas colunas\n\n\n\n\n\n\n\nQuando o vetor de Captchas é muito grande, a função plot() mostra um número máximo de 100 imagens, acompanhado de uma mensagem. O padrão de 100 imagens está organizado em uma grade com 25 linhas e 4 colunas, podendo ser sobrescrito ao combinar as opções captcha.print.cols= e captcha.print.rows=. A Figura 3.13 mostra um exemplo do comportamento da função quando o número de imagens excede 100.\n\n\nCódigo\n# mais de 100 imagens:\nexemplos <- rep(\"assets/img/dados_tjmg.jpeg\", 110)\ncaptchas <- read_captcha(exemplos)\nplot(captchas)\n#> ℹ Too many images, printing first 100. To override, run\n#> • options('captcha.print.rows' = MAX_ROWS)\n#> • options('captcha.print.cols' = COLUMNS)\n\n\n\n\n\nFigura 3.13: Demonstração da função plot() com muitas imagens\n\n\n\n\nÉ possível criar subconjuntos de um objeto de classe captcha utilizando o operador [. A função length() também pode ser utilizada para medir a quantidade de imagens lidas. A Figura 3.14 mostra um exemplo dessas operações.\n\n\nCódigo\ncaptchas_subset <- captchas[1:20]\nlength(captchas_subset) # 20\n#> [1] 20\nplot(captchas_subset)\n\n\n\n\n\nFigura 3.14: Demonstração das funções de subset e length aplicadas a um objeto do tipo captcha\n\n\n\n\nSe a imagem possui um rótulo, por padrão, a função plot() mostra o rótulo no canto da imagem. A Figura 3.15 mostra um exemplo.\n\n\nCódigo\nexemplo <- \"assets/img/mnist128c49c36e13_6297.png\"\ncaptcha <- read_captcha(exemplo, lab_in_path = TRUE)\nplot(captcha)\n\n\n\n\n\nFigura 3.15: Demonstração da função plot() quando o Captcha possui um rótulo\n\n\n\n\nA função captcha_annotate() serve para anotar o rótulo de uma imagem de Captcha, manual ou automaticamente. Isso é feito modificando o caminho da imagem, adicionando o texto _rotulo ao final do caminho do arquivo. A função possui os parâmetros listados abaixo:\n\nfiles=: objeto de classe captcha lido com a função read_captcha() (recomendado) ou vetor de caminhos de arquivos.\nlabels=: (opcional) vetor com os rótulos das imagens. Deve ter o mesmo length() do que files=. Por padrão, o valor é NULL, indicando que deve ser aberto um prompt para que o usuário insira a resposta manualmente.\npath=: (opcional) caminho da pasta onde os arquivos anotados serão salvos. Por padrão, salva os arquivos com nomes modificados na mesma pasta dos arquivos originais.\nrm_old=: (opcional) deletar ou não os arquivos originais. Por padrão, é FALSE.\n\nA função, depois de aplicada, retorna um vetor com os caminhos dos arquivos modificados. O parâmetro labels= é útil para lidar com situações em que sabemos o rótulo do Captcha. Por exemplo, em um fluxo de trabalho que utiliza o oráculo, pode ser que um modelo inicial já forneça o valor correto do rótulo.\nQuando não existe um rótulo, a função captcha_annotate(), que abre o prompt para anotação e aplica plot() para visualizar a imagem. A Figura 3.16 mostra um exemplo de aplicação da função captcha_annotate() no software RStudio.\n\n\n\n\n\nFigura 3.16: Exemplo de aplicação da função captcha_annotate(). O rótulo bhusp5 foi inserido manualmente\n\n\n\n\nPor último, a função decrypt() tem o papel de obter o rótulo de uma imagem utilizando um modelo já treinado para aquele tipo de imagem. A função recebe dois argumentos: file= que pode ser tanto o caminho do arquivo quanto um objeto de classe captcha, e um argumento model=, que contém um modelo de classe luz_module_fitted, ajustado utilizando as ferramentas que serão apresentadas na próxima subseção.\nPara a tese, foram desenvolvidos modelos para vários Captchas diferentes. É possível carregar um modelo já treinado usando a função captcha_load_model(), podendo receber em seu único parâmetro path= o caminho de um arquivo contendo um modelo ajustado ou uma string com o nome de um modelo já treinado, como \"rfb\", por exemplo. Os modelos treinados são armazenados nos releases do repositório do pacote captcha, são baixados e controlados pelo pacote {piggyback} (BOETTIGER; HO, 2022) e são lidos utilizando o pacote {luz}, que será descrito em maiores detalhes na próxima subseção. No momento de submissão da tese, os Captchas com modelos desenvolvidos eram trf5, tjmg, trt, esaj, jucesp, tjpe, tjrs, cadesp, sei e rfb. Mais modelos serão adicionados no futuro.\nA Figura 3.17 resume visualmente as funções apresentadas até o momento. As setas indicam a dependência das funções de objetos gerados por outras funções.\n\n\n\n\n\nFigura 3.17: Diagrama das funções básicas do pacote {captcha}\n\n\n\n\n\n\nModelagem\nO pacote {captcha} também fornece uma interface básica para o desenvolvimento de modelos a partir de uma base completamente anotada. A anotação pode ser feita manualmente pela função captcha_annotate(), apresentada anteriormente, ou por outro método desenvolvido pelo usuário.\nA parte de modelagem parte de algumas premissas sobre a base de dados. As imagens precisam estar em uma pasta e ter o padrão caminho/do/arquivo/<id>_<lab>.<ext>, onde:\n\n<id>: pode ser qualquer nome, de preferência sem acentuação ou outros caracteres especiais, para evitar problemas de encoding. Geralmente, é um hash identificando o tipo e id do captcha. Nota: ao anotar um caso, é importante que o id seja único, já que dois Captchas podem ter o mesmo rótulo.\n<lab>: é o rótulo do Captcha. Pode ser um conjunto de caracteres entre [a-zA-Z0-9], diferenciando maiúsculas e minúsculas se necessário. No momento, todos os arquivos em uma pasta devem ter a mesma quantidade de caracteres (comprimento homogêneo). Futuramente, o pacote poderá considerar Captchas de comprimento heterogêneo.\n<ext>: extensão do arquivo. Pode ser .png, .jpeg ou .jpg. As operações também funcionam para o formato .svg, mas pode apresentar problemas por conta da transparência da imagem.\n\nAtendidas as premissas da base anotada, é possível ajustar um modelo de redes neurais usando o pacote {captcha}. No entanto, como o ajuste de modelos de redes neurais tem uma série de nuances e pequenas adaptações, optou-se por exportar funções em dois níveis de aprofundamento. A primeira é a automatizada, utilizando a função captcha_fit_model() descrita a seguir, enquanto a segunda é a procedimental, utilizando o passo a passo descrito na Subseção 3.2.3.\nA função captcha_fit_model() ajusta um modelo a partir de uma pasta com arquivos anotados. A função recebe os parâmetros: dir=, contendo o caminho dos arquivos anotados; dir_valid=, (opcional) contendo o caminho dos arquivos anotados para validação; prop_valid=, contendo a proporção da base de treino a ser considerada como validação, ignorada quando dir_valid= é fornecida (por padrão, considera-se 20% da base para validação).\nA função captcha_fit_model() também possui alguns parâmetros relacionados à modelagem. São eles: dropout=, especificando o percentual de dropout aplicado às camadas ocultas da rede (por padrão, 0.25); dense_units=, especificando a quantidade de unidades na camada oculta que vem depois das camadas convolucionais (por padrão, 200); decay=, especificando o percentual de decaimento da taxa de aprendizado (por padrão, 0.99); epochs= número de épocas (voltas completas na base de treino) para ajuste do modelo (por padrão 100). O modelo está configurado para parar o ajuste após 20 iterações sem redução significativa na função de perda (arbitrado em 1%; para mais detalhes ver a Subseção 3.2.3).\nNo final, a função retorna um modelo ajustado com classe luz_module_fitted, que pode ser salvo em disco utilizando-se a função luz_save(). O modelo também pode ser serializado para utilização em outros pacotes como pytorch. Um tutorial sobre serialização pode ser encontrado na documentação do pacote torch.\nO pacote {captchaOracle} possui uma interface similar para trabalhar com bases com rótulos parciais. Como a estrutura de dados nesse caso é mais complexa e pode evoluir no futuro, os códigos foram organizados em outro pacote. Mais detalhes na Seção A.2.\nNa documentação do pacote {captcha}, foi adicionado um exemplo de aplicação. O exemplo utiliza captchas gerados usando a função captcha_generate(), que gera Captchas utilizando o pacote {magick}. O Captcha foi criado para a construção da tese, apelidado de R-Captcha, e possui os seguintes parâmetros:\n\nwrite_disk=: salvar os arquivos em disco? Por padrão, é falso.\npath=: Caminho para salvar arquivos em disco, caso o parâmetro anterior seja verdadeiro.\nchars=: Quais caracteres usar na imagem.\nn_chars=: O comprimento do Captcha.\nn_rows=: Altura da imagem, em pixels.\nn_cols=: Largura da imagem, em pixels.\np_rotate=: Probabilidade de rotação da imagem.\np_line=: Probabilidade de adicionar um risco entre as letras.\np_stroke=: Probabilidade de adicionar uma borda nas letras.\np_box=: Probabilidade de adicionar uma caixa (retângulo) em torno das letras.\np_implode=: Probabilidade de adicionar efeitos de implosão.\np_oilpaint=: Probabilidade de adicionar efeitos de tinta a óleo.\np_noise=: Probabilidade de adicionar um ruído branco no fundo da imagem.\np_lat=: Probabilidade de aplicar o algoritmo local adaptive thresholding à imagem.\n\n\n\nResolvendo um novo Captcha do zero\nEm algumas situações, pode ser desejável rodar modelos de forma customizada. Isso acontece pois modelos de aprendizagem profunda costumam precisar de diversos pequenos ajustes, como na taxa de aprendizado, funções de otimização, camadas computacionais e funções de pré-processamento.\nA função captcha_fit_model(), apresentada na subseção anterior, é engessada. Ela aceita alguns parâmetros para estruturar o modelo, mas não possui elementos suficientes para customização. É para isso que pacotes como {torch} e {luz} existem, pois criam ambientes de computação mais flexíveis para operar os modelos de aprendizado profundo.\nOutra desvantagem da utilização do captcha_fit_model() é possibilidade de disponibilizar modelos. Um modelo pode ser utilizado localmente, mas a tarefa de disponibilizar as bases de dados e o modelo publicamente não tem um procedimento bem definido.\nPara organizar o fluxo de trabalho, implementou-se passo-a-passo de anotação e modelagem de Captchas dentro do pacote {captcha}. A função que orquestra as atividades é a new_captcha(). A função possui apenas um parâmetro, path=, que é o caminho de uma nova pasta a ser criada.\nA função também pode ser chamada criando-se um projeto dentro do próprio RStudio. A Figura 3.18 mostra um exemplo de utilização do template dentro do RStudio, após clicar em Novo Projeto > Novo Diretório.\n\n\n\n\n\nFigura 3.18: Exemplo de criação de um novo projeto de Captcha utilizando o RStudio\n\n\n\n\nAo criar um novo projeto, pelo comando new_captcha() ou pela interface do RStudio, uma nova janela é aberta. O projeto contém quatro arquivos:\n\n01_download.R: Contém códigos que auxiliam no desenvolvimento de funções para baixar Captchas de um site. Na prática, as funções que baixam Captchas precisam ser adaptadas porque os sites são organizados de formas muito diferentes.\n02_annotate.R: Contém um template para anotação manual de Captchas. A anotação manual pode tanto ser realizada usando a interface criada pelo pacote {captcha} quanto externamente. No final, os arquivos anotados devem ser salvos na pasta img, no formato descrito na Subseção 3.2.2.\n03_model.R: Contém um template para modelagem, permitindo a customização completa do procedimento de ajuste. O script contém comandos para carregar os dados, especificar o modelo, realizar o ajuste e salvar o modelo ajustado.\n04_share.R: Contém funções para criar um repositório git da solução e disponibilizar o modelo ajustado. O modelo poderá ser lido e aplicado utilizando-se a função captcha_load_model(), que pode ser aplicado em diferentes contextos, sem a necessidade de copiar arquivos localmente.\n\nSobre a parte de modelagem, cabe uma descrição mais detalhada com apresentação de parte do código. O primeiro passo do script é criar objetos do tipo dataset (objeto que armazena os dados de forma consistente) e dataloader (objeto que obtém amostras do dataset, que são utilizadas como os minibatches do modelo), com uma estrutura orquestrada pelo pacote {torch}.\nA função captcha_dataset() cria o dataset, recebendo como parâmetro uma pasta de arquivos e gera um objeto com classes my_captcha, dataset e R6. A função é, na verdade, um objeto do tipo dataset_generator, criada utilizando a função dataset() do pacote {torch}. O objeto é chamado da mesma forma que uma função usual do R, aceitando alguns parâmetros adicionais:\n\ntransform_image=: operação de transformação a ser aplicada à imagem. Por padrão, utiliza a função captcha_transform_image(), que lê a imagem e redimensiona para ficar com dimensões 32x192. A dimensão foi escolhida para facilitar a implementação das camadas convolucionais e para lidar com o fato de que usualmente os Captchas são imagens retangulares.\ntransform_label=: operação de transformação para gerar a variável resposta. Por padrão, utiliza a função captcha_transform_label(), que recebe um vetor de todos os possíveis caracteres do Captcha e aplica a operação one_hot(), obtendo-se a versão matricial da resposta com zeros e uns, como descrito na Seção 2.1.1.\naugmentation=: operações para aumentação de dados. Por exemplo, pode ser uma função que adiciona um ruído aleatório à imagem original para que, ao gerar uma nova amostra, os dados utilizados sejam sempre diferentes.\n\nA função captcha_dataset() deve ser aplicada duas vezes, uma para criar a base de treino e outra para criar a base de validação. A separação de bases de treino e validação deve ser feita de forma manual, copiando parte dos Captchas anotados para uma nova pasta, com aleatorização. É papel do usuário separar as bases em pastas distintas carregá-as em um dataset.\n\n\nCódigo\n# datasets\ncaptcha_ds <- captcha::captcha_dataset(\n  root = parm$path_img,\n  captcha = NULL,\n  download = FALSE\n)\n\n\nEm seguida, os dataloaders são criados utilizando-se a função dataloader() do pacote {torch}. Nessa parte é definido o tamanho do minibatch, além de outros possíveis parâmetros disponíveis na função do {torch}. Para mais detalhes, o usuário pode acessar a documentação da função neste link. Devem ser criados dataloaders tanto para a base de treino quanto para a base de validação.\n\n\nCódigo\n# dataloaders (training and validation)\ncaptcha_dl_train <- torch::dataloader(\n  dataset = torch::dataset_subset(captcha_ds, id_train),\n  batch_size = parm$batch_size,\n  shuffle = TRUE\n)\n\ncaptcha_dl_valid <- torch::dataloader(\n  dataset = torch::dataset_subset(captcha_ds, id_valid),\n  batch_size = parm$batch_size\n)\n\n\nA próxima etapa é a especificação do modelo. No script de modelagem, o modelo é fornecido pelo objeto net_captcha do pacote {captcha}. Assim como no caso do dataset, o net_captcha é um objeto especial do {torch}, com classes CAPTCHA-CNN, nn_module e nn_module_generator. O objeto pode ser utilizado como uma função, gerando um módulo do {torch}, similar a uma função de predição. No entanto, por conta da forma que o objeto é utilizado em passos posteriores pelo pacote {luz}, o objeto a ser considerado é mesmo o nn_module_generator, como colocado no script.\nPara customizar o modelo, o usuário deve criar um novo módulo modificando os métodos initialize() e forward(), acessados dentro do objeto net_captcha$public_methods. O primeiro é responsável pela inicialização do modelo, contendo a descrição das operações que são realizadas, como convoluções. O segundo é a função feed forward das redes neurais, que recebe uma imagem e retorna um objeto contendo os escores ou probabilidades, no formato da variável resposta.\nPor padrão, o código de inicialização do modelo é o descrito abaixo. Os parâmetros input_dim=, output_ndigits=, output_vocab_size= e vocab= descrevem, respectivamente, as dimensões da imagem, o comprimento da resposta, o comprimento do alfabeto e os elementos do alfabeto. Os parâmetros transform=, dropout= e dense_units= controlam, respectivamente, a função de transformação da imagem, os hiperparâmetros de dropout e a quantidade de unidades na camada densa. É possível notar que os parâmetros das convoluções são fixos, já preparados para funcionar bem com uma imagem de dimensões 32x192.\n\n\nCódigo\ninitialize = function(input_dim,\n                      output_ndigits,\n                      output_vocab_size,\n                      vocab,\n                      transform,\n                      dropout = c(.25, .25),\n                      dense_units = 400) {\n  \n  # in_channels, out_channels, kernel_size, stride = 1, padding = 0\n  self$batchnorm0 <- torch::nn_batch_norm2d(3)\n  self$conv1 <- torch::nn_conv2d(3, 32, 3)\n  self$batchnorm1 <- torch::nn_batch_norm2d(32)\n  self$conv2 <- torch::nn_conv2d(32, 64, 3)\n  self$batchnorm2 <- torch::nn_batch_norm2d(64)\n  self$conv3 <- torch::nn_conv2d(64, 64, 3)\n  self$batchnorm3 <- torch::nn_batch_norm2d(64)\n  self$dropout1 <- torch::nn_dropout2d(dropout[1])\n  self$dropout2 <- torch::nn_dropout2d(dropout[2])\n  \n  self$fc1 <- torch::nn_linear(\n    # must be the same as last convnet\n    in_features = prod(calc_dim_conv(input_dim)) * 64,\n    out_features = dense_units\n  )\n  self$batchnorm_dense <- torch::nn_batch_norm1d(dense_units)\n  self$fc2 <- torch::nn_linear(\n    in_features = dense_units,\n    out_features = output_vocab_size * output_ndigits\n  )\n  self$output_vocab_size <- output_vocab_size\n  self$input_dim <- input_dim\n  self$output_ndigits <- output_ndigits\n  self$vocab <- vocab\n  self$transform <- transform\n}\n\n\nA função de feed forward foi descrita abaixo. A função aplica o passo-a-passo descrito na Seção 2.1.2.1, recebendo uma imagem x como entrada e retornando uma matriz com números reais, que dão os pesos (positivos ou negativos) do modelo para cada letra da resposta. O modelo retorna os valores de forma irrestrita, e não os números no intervalo \\([0,1]\\) porque, no passo seguinte, a função de perda considera como entrada esses valores. Se o usuário decidir modificar o método forward para retornar probabilidades, precisará também adaptar a função de perda utilizada.\n\n\nCódigo\nforward = function(x) {\n\n  out <- x |>\n    # normalize\n    self$batchnorm0() |>\n    # layer 1\n    self$conv1() |>\n    torch::nnf_relu() |>\n    torch::nnf_max_pool2d(2) |>\n    self$batchnorm1() |>\n    \n    # layer 2\n    self$conv2() |>\n    torch::nnf_relu() |>\n    torch::nnf_max_pool2d(2) |>\n    self$batchnorm2() |>\n    \n    # layer 3\n    self$conv3() |>\n    torch::nnf_relu() |>\n    torch::nnf_max_pool2d(2) |>\n    self$batchnorm3() |>\n    \n    # dense\n    torch::torch_flatten(start_dim = 2) |>\n    self$dropout1() |>\n    self$fc1() |>\n    torch::nnf_relu() |>\n    self$batchnorm_dense() |>\n    self$dropout2() |>\n    self$fc2()\n  \n  out$view(c(\n    dim(out)[1],\n    self$output_ndigits,\n    self$output_vocab_size\n  ))\n  \n}\n\n\nDefinida a arquitetura do modelo, o penúltimo passo é o ajuste. O ajuste do modelo é conduzido pelo pacote {luz}, que facilita a criação do loop de ajuste dos parâmetros, desempenhando um papel similar ao que o keras realiza para o tensorflow puro.\nNo caso dos Captchas, o código {luz} para ajuste do modelo segue quatro passos, encadeados pelo operador pipe, ou |>:\n\nsetup(): serve para determinar a função de perda, o otimizador e as métricas a serem acompanhadas. No script, a função de perda utilizada é a nn_multilabel_soft_margin_loss() do {torch}, o otimizador é o optim_adam() do {torch} e a métrica é a captcha_accuracy(), desenvolvida no pacote {captcha} para apresentar a acurácia considerando a imagem completa do Captcha e não a acurácia de cada letra da imagem, que seria o resultado se fosse utilizada a função luz_metric_accuracy(), do pacote {luz}.\nset_hparams(): serve para informar os hiperparâmetros e outras informações do modelo. Os parâmetros colocados dentro dessa função são exatamente os parâmetros do método initialize() da rede neural criada no passo anterior.\nset_opt_hparams(): serve para informar os hiperparâmetros da otimização. Os parâmetros colocados nessa função são passados para a função de otimização. No script, o único parâmetro informado é a taxa de aprendizado, fixada em 0.01.\nfit(): serve para inicializar o loop de ajuste do modelo. Aqui, é necessário passar os dataloaders de treino e validação, a quantidade de épocas (fixada em 100), e os callbacks, que são operações a serem aplicadas em diferentes momentos do ajuste (por exemplo, ao final de cada iteração). Por padrão, os callbacks são:\n\nO decaimento da taxa de aprendizado, utilizando uma taxa multiplicativa. A cada iteração, a taxa de aprendizado decai em um fator determinado pela função definida em lr_lambda, que por padrão é 0.99. Ou seja, em cada época, a taxa de aprendizado fica 1% menor.\nA parada adiantada, ou early stopping. Por padrão, está configurado para parar o ajuste do modelo se forem passadas 20 épocas sem que o modelo melhore a acurácia em 1% na base de validação. Por exemplo, se em 20 épocas consecutivas o modelo permanecer com acurácia em 53%, o ajuste será encerrado, mesmo que não tenha passado pelas 100 épocas.\nO arquivo de log. Por padrão, o modelo guarda o histórico de ajuste em um arquivo do tipo comma separated values (CSV), contendo a perda e a acurácia do modelo na base de treino e na base de validação, ao final de cada época. O arquivo de log é importante para acompanhar o ajuste do modelo e verificar sua performance ao longo das épocas, podendo dar insights sobre possíveis ajustes nos hiperparâmetros.\n\n\nNo final do fluxo definido pelo pacote {luz}, é obtido um modelo ajustado. O modelo possui a classe luz_module_fitted e pode ser investigado ao rodar o objeto no console do R. No exemplo do R-Captcha apresentado na subseção anterior, o objeto possui as características abaixo. O objeto contém um relatório conciso e bastante informativo, mostrando o tempo de ajuste, as métricas obtidas no treino e na validação e a arquitetura do modelo.\nA `luz_module_fitted`\n── Time ────────────────────────────────────────────────\n• Total time: 10m 48.1s\n• Avg time per training batch: 415ms\n• Avg time per validation batch 217ms\n\n── Results ─────────────────────────────────────────────\nMetrics observed in the last epoch.\n\nℹ Training:\nloss: 0.0049\ncaptcha acc: 0.996\nℹ Validation:\nloss: 0.0356\ncaptcha acc: 0.905\n\n── Model ───────────────────────────────────────────────\nAn `nn_module` containing 628,486 parameters.\n\n── Modules ─────────────────────────────────────────────\n• batchnorm0: <nn_batch_norm2d> #6 parameters\n• conv1: <nn_conv2d> #896 parameters\n• batchnorm1: <nn_batch_norm2d> #64 parameters\n• conv2: <nn_conv2d> #18,496 parameters\n• batchnorm2: <nn_batch_norm2d> #128 parameters\n• conv3: <nn_conv2d> #36,928 parameters\n• batchnorm3: <nn_batch_norm2d> #128 parameters\n• dropout1: <nn_dropout> #0 parameters\n• dropout2: <nn_dropout> #0 parameters\n• fc1: <nn_linear> #563,400 parameters\n• batchnorm_dense: <nn_batch_norm1d> #400 parameters\n• fc2: <nn_linear> #8,040 parameters\nPor último, o modelo deve ser salvo em um arquivo local. Isso é feito utilizando-se a função luz_save() do pacote {luz}, guardando um objeto com extensão .pt, que será disponibilizado no 04_share.R.\nCabe também um detalhamento do script disponibilizado em 04_share.R. O script utiliza o pacote {usethis} (WICKHAM; BRYAN; BARRETT, 2022) para organizar o repositório, configurando o Git (software de versionamento de códigos) e o GitHub (sistema web de organização de repositórios). Além disso, o script utiliza o pacote {piggyback} (BOETTIGER; HO, 2022) para disponibilizar o modelo ajustado nos releases do repositório criado2. Opcionalmente, o usuário poderá também disponibilizar a base com os arquivos anotados em um arquivo .zip, o que é recomendado, pois permite que outras pessoas possam trabalhar com os mesmos dados e aprimorar os modelos.\nUma vez compartilhado nos releases do repositório, o modelo poderá ser lido por qualquer pessoa, em outras máquinas utilizando o pacote {captcha}. Basta rodar o código abaixo e o modelo será carregado.\n\n\nCódigo\nmodel <- captcha_load_model(\"<name>\", \"<user>/<repo>\")\n\n\nCom isso, o trabalho pode ser compartilhado e Captchas podem ser resolvidos de forma colaborativa. O fluxo do new_captcha() é flexível o suficiente para construir modelos customizados e consumidos com o pacote {captcha}.\nO fluxo também permite uma adaptação fácil ao método WAWL. Para isso, basta substituir a função de perda e de leitura dos dados pelas funções oferecidas pelo pacote {captchaOracle}, descrito no Apêndice A."
  },
  {
    "objectID": "resultados.html#sec-discussao",
    "href": "resultados.html#sec-discussao",
    "title": "3  Resultados",
    "section": "Discussão",
    "text": "Discussão\nOs resultados apresentados nas seções anteriores mostram que o método WAWL possui bons resultados empíricos. Nesta seção, os resultados foram confrontados com as hipóteses de pesquisa definidos na Seção 1.6 de forma crítica.\nA primeira hipótese de pesquisa diz respeito à pertinência de utilizar do aprendizado fracamente supervisionado como forma de ajustar modelos para resolver Captchas. A hipótese foi verificada, já que os resultados mostram um incremento significativo na acurácia do modelo em praticamente todas as simulações.\nDo ponto de vista teórico, várias pesquisas já apontavam que o aprendizado com rótulos parciais ou rótulos complementares têm boas propriedades. Por isso, já seria esperado que uma nova função de perda, desde que pensada com cuidado, traria resultados positivos.\n\nNo entanto, até o momento, não existiam evidências de que a utilização de rótulos parciais ou rótulos complementares teriam bons resultados empíricos em Captchas. Isso foi verificado em todos os 12 Captchas estudados, sendo 10 obtidos do mundo real. Em todos os casos, a função de perda proposta funcionou bem e trouxe ganhos significativos na acurácia do modelo, tanto em termos relativos quanto absolutos. Isso demonstra que a escolha do método se alia bem ao problema que deu origem à pesquisa, que são os Captchas.\nSobre a parte de aplicação iterada do WAWL, o resultado é positivo, mas inconclusivo. A acurácia de 100% encontrada pode sugerir que o método WAWL sempre chegará em um resultado de 100% para qualquer Captcha que surgir. No entanto, pode ser que exista uma limitação na capacidade do modelo, que é habilidade do modelo para se ajustar aos dados a partir dos parâmetros. Pode ser que a arquitetura de rede neural escolhida para resolver o Captcha não seja capaz de chegar a um modelo com 100% de acurácia, independente da quantidade de imagens observadas. É importante olhar o resultado apresentado de forma crítica e compreender que estes podem ser limitados, já que a arquitetura da rede neural não é parte do método WAWL.\nA segunda hipótese de pesquisa é a possibilidade de aliar a área de raspagem de dados com a área de modelagem estatística. A hipótese também foi verificada, já que o método WAWL, que utiliza técnicas de raspagem de dados, apresentou bons resultados empíricos.\nNeste momento, cabe um comentário sobre o ineditismo da utilização de raspagem de dados em estudos estatísticos. É verdade que existem muitas pesquisas que são possibilitadas por conta dos dados obtidos via raspagem de dados: as pesquisas da ABJ, mencionadas na Seção 1.1 são alguns exemplos. Também existem soluções que utilizam dados provenientes de raspagem de dados para construção de modelos: por exemplo, o DALL-E-2, que é parte de uma base de dados construída utilizando imagens baixadas da internet (MURRAY; MARCHESOTTI; PERRONNIN, 2012; RAMESH et al., 2022). No entanto, até o momento da realização da pesquisa, não foi encontrado nenhum trabalho que utiliza a raspagem de dados como parte do processo de aprendizado estatístico. O método WAWL conecta as áreas de forma intrínseca, podendo ser entendida como uma nova variação de aumentação de dados aplicada a redes neurais convolucionais.\nO fato de a raspagem de dados ser relevante para o ajuste de um modelo estatístico pode levar a algumas discussões sobre o ensino da estatística. Primeiro, é importante mencionar que:\n\nRaspagem de dados não faz parte dos currículos de Bacharelado em Estatística das principais universidades do país3. Logo, pode-se argumentar que raspagem de dados não é uma área de interesse da estatística.\nRaspagem de dados não é uma área de conhecimento bem definida, como álgebra ou análise de sobrevivência. A área é melhor desenvolvida através de aplicações práticas e utilização de ferramentas (como R ou python) do que através de aulas teóricas.\n\nOs resultados levam, então, a um problema de equilíbrio entre pertinência e oportunidade. De um lado, a área de raspagem não se encaixa muito bem no currículo de estatística. Por outro lado, a área expande as possibilidades de atuação de uma profissional da estatística.\nPara aliar a pertinência e a oportunidade, uma opção seria oferecer disciplinas optativas de raspagem de dados nos cursos de estatística. Para aumentar a quantidade de potenciais ministrantes, a disciplina poderia ser oferecida em parceria com outros cursos, como ciência da computação, matemática aplicada e engenharias. Dessa forma, as pessoas interessadas teriam a oportunidade de aprender um pouco sobre as técnicas principais, conectando a raspagem de dados com as áreas de conhecimento específicas, como é o caso do Captcha, que alia raspagem de dados com estatística e inteligência artificial. Com isso, conclui-se a discussão sobre a segunda hipótese de pesquisa.\nPortanto, as duas hipóteses de pesquisa foram verificadas. No processo de construção do trabalho, no entanto, um terceiro avanço muito importante foi realizado na parte computacional. O pacote {captcha} e os pacotes auxiliares {captchaDownload} e {captchaOracle} são frutos desse trabalho. Pela primeira vez, foi construída uma ferramenta aberta contendo um fluxo de trabalho adaptado para trabalhar com Captchas. Além disso, trata-se de uma das primeiras aplicações completas dos pacotes {torch} e {luz}, que têm potencial de revolucionar a forma em que os modelos estatísticos são desenvolvidos por pessoas que fazem pesquisa em estatística. Os pacotes foram descritos em detalhes no Apêndice A.\nPor fim, todos os modelos construídos foram disponibilizados no pacote {captcha}. Os códigos, dados e resultados das simulações estão disponíveis no pacote {captchaOracle}. Os dados utilizados para elaboração da tese estão disponíveis no repositório da tese no GitHub. Dessa forma, a pesquisa pode ser considerada como reprodutível, podendo servir como base para pesquisas futuras.\n\n\n\n\nALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022. Disponível em: <https://CRAN.R-project.org/package=tensorflow>.\n\n\nBOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub Repository. 2022. Disponível em: <https://CRAN.R-project.org/package=piggyback>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’ Acceleration. 2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A practical approach for predictive models. CRC Press, 2019.\n\n\nMURRAY, N.; MARCHESOTTI, L.; PERRONNIN, F. AVA: A large-scale database for aesthetic visual analysis. IEEE, 2012.\n\n\nRAMESH, A. et al. Hierarchical Text-Conditional Image Generation with CLIP Latents. n. arXiv:2204.06125, abr. 2022. Disponível em: <https://arxiv.org/abs/2204.06125>.\n\n\nTRECENTI, J. et al. decryptr: An extensible API for breaking captchas. 2022.\n\n\nUSHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’. 2022. Disponível em: <https://CRAN.R-project.org/package=reticulate>.\n\n\nWICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and Project Setup. 2022. Disponível em: <https://CRAN.R-project.org/package=usethis>."
  },
  {
    "objectID": "conclusoes.html",
    "href": "conclusoes.html",
    "title": "4  Conclusões",
    "section": "",
    "text": "Even robots need a break from the daily grind of solving captchas.\n– ChatGPT\n\n\nEste trabalho de doutorado teve como objeto de estudo os Captchas, que são desafios utilizados para identificar se o acesso à uma página na internet é realizado por uma pessoa ou um robô. A pesquisa apresentou um breve histórico dos Captchas, os problemas de sua utilização em serviços públicos e as abordagens existentes para resolução automática de Captchas. Em seguida, apresentou-se como um novo método, o WAWL, que alia técnicas de raspagem de dados e aprendizado estatístico com rótulos parciais para obter modelos poderosos de resolução de Captchas sem a necessidade de anotar vários casos manualmente. Por fim, foram apresentadas as propriedades do modelo proposto e os resultados empíricos através de uma série de simulações.\nOs resultados da pesquisa foram positivos. Na parte teórica, pesquisas já apontavam que o aprendizado com rótulos parciais ou rótulos complementares possuíam boas propriedades. O trabalho mostrou empiricamente que a técnica apresenta bons resultados, aumentando a acurácia dos modelos iniciais em mais de 3 vezes, sem a necessidade de anotar novos dados. Além disso, foram encontradas evidências de que o método pode ser aplicado iterativamente, resultando em modelos com poder preditivo ainda maior.\nAs contribuições do estudo podem ser organizadas em três tipos: contribuições para a sociedade em geral, contribuições para a pesquisa acadêmica e contribuições para a comunidade de programação. Os próximos parágrafos descrevem esses avanços.\nA contribuição para a sociedade em geral está na quebra de um mecanismo de incentivo nefasto, gerado pela utilização de Captchas em sites de serviços públicos. Como comentado na introdução, o uso de Captchas gera um incentivo para que pessoas e empresas que fazem raspagem de dados utilizem serviços que se aproveitam de mão de obra humana com baixíssima remuneração. Ao disponibilizar os modelos para resolução de Captchas publicamente e uma ferramenta que facilita seu uso, as pessoas e empresas interessadas podem resolver Captchas gratuitamente, afastando a necessidade de utilizar esses serviços. Dessa forma, espera-se que o trabalho possa ter um impacto positivo, ainda que pequeno, na qualidade das relações de trabalho na sociedade.\nA contribuição para a pesquisa acadêmica pode ser separada em três partes. A primeira é que o método proposto apresenta bons resultados empíricos, mostrando que pode ser um ponto de partida interessante para quem deseja trabalhar com aprendizado com rótulos parcialmente anotados. A segunda é relacionada ao uso da raspagem de dados como passo intermediário na construção de modelos estatísticos, que pode ser a base para o desenvolvimento de um novo campo de pesquisa. Espera-se que os resultados obtidos sirvam como incentivo para que as técnicas de raspagem de dados sejam ensinadas como disciplinas optativas em cursos de estatística e similares. A terceira é que a ideia de explorar um oráculo, ou seja, de obter informações parciais automaticamente pode abrir um novo campo de estudos estatísticos: é possível encontrar, futuramente, outras áreas do conhecimento em que oráculos estão disponíveis, e este trabalho pode ajudar a utilizar a informação fornecida pelo oráculo.\nA contribuição para a comunidade de programadoras e programadores está no pacote {captcha}. O pacote é uma caixa de ferramentas completa para quem tiver interesse em resolver Captchas, além de ser uma das primeiras aplicações que utilizam os pacotes {torch} e {luz} como motor computacional. O pacote possui uma interface que permite o compartilhamento de códigos, bases de dados e modelos publicamente, possibilitando a criação de soluções que vão muito além do próprio pacote.\nCom isso, pode-se concluir que os quatro objetivos descritos na Seção 1.4 foram atendidos. O modelo proposto foi descrito e suas propriedades estudadas. Um repositório de dados completo foi construído e disponibilizado no repositório do pacote {captcha}, contendo dados e modelos ajustados. O método foi utilizado e testado para diferentes Captchas e diferentes situações, com sucesso. Finalmente, foi disponibilizado um pacote computacional aberto, possibilitando a resolução de novos Captchas que aparecerem em serviços públicos.\nÉ evidente, no entanto, que o trabalho apresenta algumas limitações. Na parte teórica, os resultados matemáticos podem ser desenvolvidos com maior detalhamento. Especificamente, podem ser apresentadas e testadas outras propostas de função de perda, eventualmente com implementações que aceitem o uso de aceleradores com placas de vídeo. Além disso, seria interessante modificar as probabilidades fornecidas pelo modelo nos casos em que o rótulo está errado, para que o modelo nunca dê probabilidade zero para algum rótulo. A escolha de apenas uma alternativa de perda e do uso direto dos resultados fornecidos pelo oráculo foi feita por conta do foco em resolver o problema de pesquisa (os Captchas), no lugar da discussão mais aprofundada do aprendizado com rótulos parciais.\nOutra limitação importante do estudo está na aplicação iterada. A pesquisa apresentou essa parte como um resultado adicional, mas os limites da aplicação iterada ainda não foram estudados de forma completa. Essa limitação pode ser entendida também como um próximo passo, que seria a solução de online learning.\nUma extensão possível desta pesquisa é a criação de um modelo que aprende diretamente da web, sem a separação de passos descrita pelo WAWL. A técnica consiste em inserir as funções de acesso e teste do Captcha como método de obtenção de amostras do dataset do Captcha (mais detalhes na Seção 3.2.3). Dessa forma, o modelo pode obter novos dados em cada minibatch, indefinidamente. O experimento realizado com online learning apresentou resultados promissores, mas ainda carece de uma investigação sistemática. Se funcionar bem, a vantagem dessa abordagem é que não precisa de uma pessoa para escrever as aplicações iteradas, facilitando o método WAWL. A desvantagem é que o ajuste do modelo depende de uma conexão com a internet, mais suscetível a problemas de conexão, que precisam ser tratados com cuidado.\nOutra extensão oportuna seria a criação de um modelo geral de resolução de Captchas, desenvolvido a partir das bases que foram construídas durante a pesquisa. O modelo precisaria lidar com diferentes alfabetos e comprimentos dos Captchas, o que tornaria o aprendizado mais complicado. Esse modelo poderia ser utilizado como passo inicial do WAWL para a resolução de novos Captchas, podendo até afastar completamente a necessidade de anotação manual. No momento, não é possível saber se esse modelo funcionaria na prática de forma consistente, já que i) nada garante que ele tenha uma acurácia maior que 10% para um novo Captcha, mesmo se construído com base em Captchas de várias origens e ii) foram encontradas evidências de que os modelos com acurácia menor de 10% têm mais dificuldades em melhorar com o método WAWL quando o Captcha não aceita vários chutes.\nA presente tese foi fruto de um longo processo de análise e desenvolvimento, investigando os aspectos relevantes dos Captchas de textos em imagens. Espera-se que a metodologia proposta, os resultados obtidos e os pacotes computacionais desenvolvidos sejam úteis na luta pela abertura dos dados públicos, especialmente no judiciário. O uso de Captchas em sites de serviços públicos deve acabar."
  },
  {
    "objectID": "bibliografia.html",
    "href": "bibliografia.html",
    "title": "Bibliografia",
    "section": "",
    "text": "ABJ. Tempo dos processos relacionados à adoção., 2014.\nDisponível em: <https://abj.org.br/pesquisas/adocao/>.\n\n\nABJ. Observatório da insolvência: Rio de Janeiro.,\n2021. Disponível em: <https://abj.org.br/pesquisas/obsrjrj/>.\n\n\nABJ. Diagnóstico do Contencioso Tributário\nAdministrativo., 2022. Disponível em: <https://abj.org.br/pesquisas/bid-tributario/>.\n\n\nAHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web\nSecurity Measures. Science, v. 321, n. 5895, p.\n1465–1468, 12 set. 2008. Disponível em: <https://www.science.org/doi/10.1126/science.1160379>.\n\n\nAHN, L. VON; BLUM, M.; LANGFORD, J. Telling humans and computers\napart automatically or how lazy cryptographers do AI (Tech. Rep. No.\nCMU-CS-02-117). Disponível em: <http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf>.\n\n\nALLAIRE, J.; TANG, Y. tensorflow: R Interface to ’TensorFlow’. 2022.\nDisponível em: <https://CRAN.R-project.org/package=tensorflow>.\n\n\nBALDI, P.; SADOWSKI, P. J. Understanding dropout. Advances in\nneural information processing systems, v. 26, 2013.\n\n\nBLUM, A.; KALAI, A. A note on learning from multiple-instance examples.\nMachine learning, v. 30, n. 1, p. 2329, 1998.\n\n\nBOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub\nRepository. 2022. Disponível em: <https://CRAN.R-project.org/package=piggyback>.\n\n\nCHELLAPILLA, K. et al. Designing human friendly human\ninteraction proofs (HIPs). : CHI ’05.New York, NY, USA:\nAssociation for Computing Machinery, 2 abr. 2005. Disponível em: <https://doi.org/10.1145/1054972.1055070>.\n\n\nCHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human\ninteraction proofs (HIPs). Advances in neural information\nprocessing systems, v. 17, 2004.\n\n\nCOLOSIMO, E. A.; GIOLO, S. R. Análise de sobrevivência\naplicada. Editora Blucher, 2006.\n\n\nCOUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. The\nJournal of Machine Learning Research, v. 12, p. 15011536, 2011.\n\n\nFALBEL, D. luz: Higher Level ’API’ for ’torch’. a2022. Disponível em:\n<https://CRAN.R-project.org/package=luz>.\n\n\nFALBEL, D. torchvision: Models, Datasets and Transformations for Images.\nb2022. Disponível em: <https://CRAN.R-project.org/package=torchvision>.\n\n\nFALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with ’GPU’\nAcceleration. 2022. Disponível em: <https://CRAN.R-project.org/package=torch>.\n\n\nFENG, L. et al. Provably consistent partial-label learning.\nAdvances in Neural Information Processing Systems, v.\n33, p. 1094810960, a2020.\n\n\nFENG, L. et al. Learning with multiple complementary\nlabels. PMLR, b2020.\n\n\nGEORGE, D. et al. A generative vision model that trains with high data\nefficiency and breaks text-based CAPTCHAs. Science, v.\n358, n. 6368, p. eaag2612, 2017.\n\n\nGOODFELLOW, I. J. et al. Multi-digit number recognition from street view\nimagery using deep convolutional neural networks. arXiv preprint\narXiv:1312.6082, 2013.\n\n\nGOODFELLOW, I. J. et al. Generative Adversarial\nNetworks. arXiv, jun. 2014. Disponível em:\n<https://arxiv.org/abs/1406.2661>.\n\n\nGRANDVALET, Y. Logistic regression for partial labels.\n2002.\n\n\nHÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled\nexamples. Intelligent Data Analysis, v. 10, n. 5, p.\n419439, 2006.\n\n\nIOFFE, S.; SZEGEDY, C. Batch normalization: Accelerating deep\nnetwork training by reducing internal covariate shift. PMLR,\n2015.\n\n\nISHIDA, T. et al. Learning from complementary labels. Advances\nin neural information processing systems, v. 30, 2017.\n\n\nJIN, R.; GHAHRAMANI, Z. Learning with multiple labels. Advances\nin neural information processing systems, v. 15, 2002.\n\n\nKAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review.\nInternational Journal of Computer Science and Information\nTechnologies, v. 5, 1 jan. 2014.\n\n\nKINGMA, D. P.; BA, J. Adam: A Method for Stochastic\nOptimization. n. arXiv:1412.6980, jan. 2017. Disponível em:\n<https://arxiv.org/abs/1412.6980>.\n\n\nKUHN, M.; JOHNSON, K. Feature engineering and selection: A\npractical approach for predictive models. CRC Press, 2019.\n\n\nLECUN, Y. et al. Gradient-based learning applied to document\nrecognition. Proceedings of the IEEE, v. 86, n. 11, p.\n22782324, 1998.\n\n\nLECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.\n\n\nLECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning.\nnature, v. 521, n. 7553, p. 436444, 2015.\n\n\nLI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control\nchart. IIE Transactions, v. 46, n. 5, p. 526542, 2014.\n\n\nLILLIBRIDGE, M. D. et al. Method for Selectively Restricting\nAccess to Computer Systems., fev. 2001.\n\n\nLIU, L.; DIETTERICH, T. A conditional multinomial mixture model for\nsuperset label learning. Advances in neural information\nprocessing systems, v. 25, 2012.\n\n\nMICHENER, G.; MONCAU, L. F.; VELASCO, R. B. Estado brasileiro e\ntransparência avaliando a aplicação da Lei de Acesso à\nInformação.\n\n\nMORI, G.; MALIK, J. Recognizing objects in adversarial clutter:\nBreaking a visual CAPTCHA. IEEE, 2003.\n\n\nMURRAY, N.; MARCHESOTTI, L.; PERRONNIN, F. AVA: A large-scale\ndatabase for aesthetic visual analysis. IEEE, 2012.\n\n\nMURRAY-RUST, P. Open data in science. Nature\nPrecedings, p. 11, 2008.\n\n\nNA, B. et al. Deep Generative Positive-Unlabeled Learning under\nSelection Bias. : CIKM ’20.New York, NY, USA: Association for\nComputing Machinery, 19 out. 2020. Disponível em: <https://doi.org/10.1145/3340531.3411971>.\n\n\nNELDER, J. A.; WEDDERBURN, R. W. Generalized linear models.\nJournal of the Royal Statistical Society: Series A\n(General), v. 135, n. 3, p. 370384, 1972.\n\n\nNOH, H. et al. Regularizing deep neural networks by noise: Its\ninterpretation and optimization. Advances in Neural Information\nProcessing Systems, v. 30, 2017.\n\n\nOOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021.\nDisponível em: <https://CRAN.R-project.org/package=magick>.\n\n\nR CORE TEAM. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical\nComputing, 2021. Disponível em: <https://www.R-project.org/>.\n\n\nRAMESH, A. et al. Hierarchical Text-Conditional Image\nGeneration with CLIP Latents. n. arXiv:2204.06125,\nabr. 2022. Disponível em: <https://arxiv.org/abs/2204.06125>.\n\n\nRESHEF, E.; RAANAN, G.; SOLAN, E. Method and System for\nDiscriminating a Human Action from a Computerized Action.,\n2005.\n\n\nSUTTON, R. S.; BARTO, A. G. Reinforcement learning: An\nintroduction. MIT press, 2018.\n\n\nTRECENTI, J. et al. decryptr: An extensible API for breaking captchas.\n2022.\n\n\nTURING, A. M. Computing machinery and intelligence. Em: Springer, 2009.\np. 2365.\n\n\nUSHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to ’Python’.\n2022. Disponível em: <https://CRAN.R-project.org/package=reticulate>.\n\n\nVON AHN, L. et al. Captcha: Telling Humans and\nComputers Apart Automatically. Proceedings of Eurocrypt.\nAnais...2003.\n\n\nVON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart\nAutomatically. Communications of the ACM, v. 47, n. 2,\np. 56–60, 2004.\n\n\nW3C. Inaccessibility of CAPTCHA., 2021. Disponível em:\n<https://www.w3.org/TR/turingtest/>.\n\n\nWANG, Y. et al. Make complex captchas simple: a fast text captcha solver\nbased on a small number of samples. Information\nSciences, v. 578, p. 181194, 2021.\n\n\nWICKHAM, H. stringr: Simple, Consistent Wrappers for Common String\nOperations. b2022. Disponível em: <https://CRAN.R-project.org/package=stringr>.\n\n\nWICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível\nem: <https://CRAN.R-project.org/package=rvest>.\n\n\nWICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and\nProject Setup. 2022. Disponível em: <https://CRAN.R-project.org/package=usethis>.\n\n\nWICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em:\n<https://CRAN.R-project.org/package=xml2>.\n\n\nYE, G. et al. Yet another text captcha solver: A generative\nadversarial network based approach. 2018.\n\n\nYU, X. et al. Learning with biased complementary\nlabels. 2018.\n\n\nYUAN, X. et al. Adversarial examples: Attacks and defenses for deep\nlearning. IEEE transactions on neural networks and learning\nsystems, v. 30, n. 9, p. 28052824, 2019.\n\n\nZHAO, B. Web scraping. Encyclopedia of big data, p. 13,\n2017. Disponível em: <https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf>.\n\n\nZHOU, Z.-H. A brief introduction to weakly supervised learning.\nNational science review, v. 5, n. 1, p. 4453, 2018.\n\n\nZHU, X. J. Semi-supervised learning literature survey. 2005."
  },
  {
    "objectID": "pacote.html#sec-pacote-download",
    "href": "pacote.html#sec-pacote-download",
    "title": "Apêndice A — Pacotes",
    "section": "Pacote captchaDownload",
    "text": "Pacote captchaDownload\nO pacote {captchaDownload} foi construído para armazenar os códigos de baixar dados de Captchas de forma consistente. O pacote também inclui funções para trabalhar com oráculos.\nO pacote não foi criado para ser usado pelo público geral. O intuito de criar o pacote foi o de organizar as funções utilizadas para realizar as simulações e obter os resultados empíricos da tese. Apesar disso, o código está disponível publicamente para quem tiver interesse em usar como referência para construir funções que acessam o oráculo.\nAs funções do pacote {captchaDownload} são organizadas em dois tipos principais. As funções de acesso, identificadas pelo termo _access, fazem o download da imagem do Captcha e retornam todas as informações necessárias para fazer a verificação do oráculo, como, por exemplo, cookies e dados da sessão do usuário. Já as funções de teste, identificadas pelo termo _test, servem para verificar se um rótulo fornecido para o Captcha está correto ou não.\nAs funções ficam mais claras através de um exemplo. No caso do TRF5, por exemplo, o acesso é feito pela página do sistema PJe. A função captcha_access_trf5() recebe o parâmetro path=, que é a pasta para salvar a imagem, retornando uma lista com o caminho da imagem que foi salva e de componentes da sessão do usuário.\n\n\nCódigo\nacesso <- captchaDownload:::captcha_access_trf5(\"assets/img\")\nacesso\n\n\n$f_captcha\nassets/img/trf5ac031dafbd.jpeg\n\n$j_id\n[1] \"j_id1\"\n\n$u\n[1] \"https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam\"\n\n\n\nEm seguida, obtém-se o rótulo do modelo. Isso pode ser feito manualmente ou através de um modelo.\n\n\nCódigo\nlibrary(captcha)\ncaptcha <- read_captcha(acesso$f_captcha)\nplot(captcha)\nmodelo_trf5 <- captcha_load_model(\"trf5\")\n(lab <- decrypt(acesso$f_captcha, modelo_trf5))\n#> [1] \"969588\"\n\n\n\n\n\nFigura A.1: Exemplo de Captcha baixado diretamente do TRF5\n\n\n\n\nAgora, aplica-se a função captcha_test_trf5() para verificar se o rótulo está correto ou incorreto. A verificação é feita de forma automática, diretamente da internet, através do oráculo. A função recebe dois parâmetros: obj= com as informações obtidas da função de acesso; e label=, o rótulo obtido. A função retorna TRUE se o rótulo está correto e FALSE caso contrário.\n\n\nCódigo\n(acertou <- captchaDownload:::captcha_test_trf5(acesso, lab))\n\n\n[1] TRUE\nCada Captcha possui uma função de acesso e uma função de teste. Na prática, se uma pessoa desejar resolver um novo Captcha usando a técnica do oráculo, são essas funções que ela precisaria desenvolver. Todas as outras operações podem ser generalizadas para diferentes casos de uso e estão implementadas nos pacotes {captchaDownload} e {captchaOracle}. Vale notar que a construção dessas funções geralmente é necessária para a construção de web scrapers, ou seja, elas não criam dificuldades adicionais para pessoas interessadas em resolver Captchas para acessar dados da internet.\nA função principal do pacote {captchaDownload} é a captcha_oracle(). A função é responsável por realizar a anotação parcial automática dos Captchas utilizando um modelo inicial e o oráculo. A função possui os seguintes parâmetros:\n\npath=: caminho em que os arquivos serão salvos.\nmodel=: modelo para predizer o rótulo de uma imagem.\nmax_ntry=: quantidade máxima de chutes até desistir.\nmanual=: caso o máximo de tentativas seja alcançado, abrir o prompt para anotar manualmente? Por padrão, sim.\ncaptcha_access=: função que baixa um Captcha e retorna dados da sessão para validar o Captcha, como mostrada anteriormente.\ncaptcha_test=: função que testa se um Captcha está correto a partir de um rótulo específico, como mostrado anteriormente.\n\nA função amarra todos os conceitos necessários para criar bases de dados de forma automática. Primeiro, considera o caminho para salvar os dados. Em seguida, considera o modelo e formas de lidar com o oráculo. Por último, recebe as funções de acesso e de teste do Captcha. A função escreve um arquivo de log com os resultados dos testes. O arquivo contém max_ntry linhas, podendo ter uma linha adicional se manual=TRUE, já que, se o modelo errar todos os chutes, a anotação manual deve ser adicionada.\nNo exemplo do TRF5, a chamada da função captcha_oracle() com um chute ficaria da seguinte forma:\n\n\nCódigo\nmodelo_trf5 <- captcha_load_model(\"trf5\")\n\ncaptchaDownload::captcha_oracle(\n  path = \"assets/img/\",\n  model = modelo_trf5, \n  max_ntry = 1,\n  manual = TRUE, \n  captcha_access = captchaDownload:::captcha_access_trf5,\n  captcha_test = captchaDownload:::captcha_test_trf5\n)\n\n\n✔ Acertou!!!\nNo teste do exemplo, a função acertou, salvando o seguinte arquivo de log1.\nntry, label , type, result\n1,    569328, auto, TRUE\nAbaixo, foi colocado um modelo ruim para o TRT, para forçar o modelo a errar todos os chutes. O resultado é o log abaixo\n\n\nCódigo\nmodelo <- captcha_load_model(\"assets/modelo_ruim.pt\")\n\ncaptchaDownload::captcha_oracle(\n  path = \"assets/img/\",\n  model = modelo, \n  max_ntry = 10,\n  manual = TRUE, \n  captcha_access = captchaDownload:::captcha_access_trt,\n  captcha_test = captchaDownload:::captcha_test_trt\n)\n\n\nℹ Temos 10 candidatos...\nℹ Errou! O chute foi: v2su7w\nℹ Errou! O chute foi: t2su7w\nℹ Errou! O chute foi: v2su7y\nℹ Errou! O chute foi: t2su7y\nℹ Errou! O chute foi: y2su7w\nℹ Errou! O chute foi: v2su7h\nℹ Errou! O chute foi: t2su7h\nℹ Errou! O chute foi: y2su7y\nℹ Errou! O chute foi: v2wu7w\nLabel: v2xu7w\nNo novo exemplo, a função errou todos os dez chutes, salvando o seguinte arquivo de log2. O último valor é um rótulo inserido manualmente.\nntry,  label,   type, result\n   1, v2su7w,   auto,  FALSE\n   2, t2su7w,   auto,  FALSE\n   3, v2su7y,   auto,  FALSE\n   4, t2su7y,   auto,  FALSE\n   5, y2su7w,   auto,  FALSE\n   6, v2su7h,   auto,  FALSE\n   7, t2su7h,   auto,  FALSE\n   8, y2su7y,   auto,  FALSE\n   9, v2wu7w,   auto,  FALSE\n  10, 92su7w,   auto,  FALSE\n  NA, v2xu7w, manual,   TRUE\nSe o parâmetro manual=FALSE e o modelo não consegue acertar o rótulo, a função também adiciona a mensagem:\n✖ Errado depois de todas as tentativas...\nEm alguns casos, é possível que a função realize menos do que max_ntry chutes. Isso acontece quando a probabilidade do melhor rótulo depois do chute errado é muito pequena, segundo o modelo. Isso é feito pela função captcha_candidates(), que considera como padrão o corte de 0.01 de probabilidade. Ou seja, na prática, a função testa no máximo os max_ntry rótulos com probabilidades maiores que 0.01 segundo o modelo.\nEm resumo, o pacote {captchaDownload} contém toda a parte de web scraping utilizada no desenvolvimento da tese. Adicionalmente, o pacote contém funções para orquestrar o download automático de Captchas parcialmente rotulados, a partir de um modelo inicial e um oráculo.\nOs dados fornecidos pelo pacote ficam tanto na forma de imagens rotuladas quanto na forma de arquivos de log, disponibilizados em arquivos CSV. Para lidar com essa estrutura de dados, mais um pacote foi desenvolvido: o {captchaOracle}, definido a seguir."
  },
  {
    "objectID": "pacote.html#sec-pacote-oracle",
    "href": "pacote.html#sec-pacote-oracle",
    "title": "Apêndice A — Pacotes",
    "section": "Pacote captchaOracle",
    "text": "Pacote captchaOracle\nO pacote {captchaOracle}, assim como o {captchaDownload}, foi desenvolvido para a construção da tese. O pacote, portanto, não apresenta documentação extensiva e suas funções podem não estar com a sintaxe final. Futuramente, o pacote poderá funcionar como novo backend para o pacote {captcha}, aplicando o WAWL como uma alternativa no fluxo de resolução de Captchas definido na Subseção 3.2.3.\nO pacote possui quatro funções principais: a captcha_dataset_oracle(), a net_captcha_oracle(), a oracle_loss() e a captcha_accuracy_oracle(). Cada função desempenha um papel similar a seus pares do pacote {captcha}, mas conseguem lidar com a estrutura de dados fornecida pelo oráculo.\nA primeira função a ser utilizada é a captcha_dataset_oracle(). Trata-se de uma função similar à captcha_dataset() do pacote {captcha}, mas com um parâmetro adicional, path_logs=, que recebe o caminho dos arquivos de log.\nA estrutura de dados no caso do oráculo é mais complexa do que no caso canônico. Na resposta, ao invés de guardar uma matriz one hot para cada Captcha, é armazenada uma lista com várias matrizes one hot, uma para cada tentativa do Captcha. Além disso, é armazenado um vetor z, com zeros e uns, informando se algum rótulo está correto ou se todos os rótulos estão incorretos. A variável z é construída a partir dos nomes dos arquivos, que contém um _1 caso o rótulo esteja correto e _0 caso contrário. Por último, a imagem de entrada é armazenada da mesma forma que na função captcha_dataset().\nO módulo net_captcha_oracle() faz poucos ajustes à estrutura inicial fornecida pelo módulo net_captcha() do pacote {captcha}. A única modificação da função é que ela recebe um modelo inicial de entrada, transferindo os pesos ajustados do modelo ao novo módulo. O módulo net_captcha_oracle(), inclusive, poderia ser utilizado fora do contexto do WAWL, já que só utiliza os dados de input, que não são alterados.\nA função captcha_accuracy_oracle() é utilizada para estimar a acurácia do modelo. Para isso, a função precisa lidar com o fato de que os dados de validação apresentam uma estrutura diferente dos dados de treino, já que estão completamente anotados. No treino, a acurácia é calculada considerando apenas os casos em que a resposta é conhecida. Na validação, a acurácia é calculada considerando-se todas as observações.\nPor último, a função oracle_loss() é a que contém a proposta de função de perda do método WAWL. Nos casos corretos, a função de perda é obtida calculando-se uma entropia cruzada simples. Nos casos incorretos, a perda é calculada pela estratégia 1-p, ou seja, considerando o complementar da probabilidade de observar os chutes que foram apresentados segundo o modelo.\nEm resumo, o pacote {captchaOracle} é o que contém os principais avanços da tese do ponto de vista estatístico. Na prática, é utilizado como backend computacional para ajuste dos modelos que utilizam o oráculo, dentro de um fluxo de trabalho igual ao que é construído para ajuste dos modelos canônicos.\nOs códigos para realizar as simulações do modelo foram adicionados na pasta data-raw do pacote {captchaOracle}. Os códigos foram organizados da seguinte forma:\n\npasso_01_*.R. Contêm os códigos utilizados para ajustar os modelos iniciais. Os códigos são organizados de forma a permitir que vários modelos sejam rodados em paralelo, aproveitando o máximo do poder computacional da máquina utilizada para realizar os ajustes.\npasso_02_*.R. Contêm os códigos utilizados para construir as bases de treino e validação para o passo 03. Foi o passo mais demorado da simulação, já que envolveu acessar os sites dos tribunais pela internet para obtenção dos Captchas anotados automaticamente. Para realizar a simulação, foram baixados mais de 500.000 Captchas da internet.\npasso_03_*.R. Contêm os códigos utilizados para ajustar os modelos finais. Os códigos foram organizados de forma similar ao passo 01, mas utilizando as funções desenvolvidas no pacote {captchaOracle} para considerar os dados fornecidos pelo oráculo.\n\nPor fim, foi adicionado também um script report.R, que monta as bases principais e os resumos dos modelos ajustados. As bases fornecidas pelo último script foram adicionadas ao repositório da tese."
  }
]