% Arquivo LaTeX de exemplo de dissertação/tese a ser apresentada à CPG do IME-USP
%
% Criação: Jesús P. Mena-Chalco
% Revisão: Fabio Kon e Paulo Feofiloff
% Adaptação para UTF8, biblatex e outras melhorias: Nelson Lago
%
% Except where otherwise indicated, these files are distributed under
% the MIT Licence. The example text, which includes the tutorial and
% examples as well as the explanatory comments in the source, are
% available under the Creative Commons Attribution International
% Licence, v4.0 (CC-BY 4.0) - https://creativecommons.org/licenses/by/4.0/


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PREÂMBULO LaTeX %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% A opção twoside (frente-e-verso) significa que a aparência das páginas pares
% e ímpares pode ser diferente. Por exemplo, as margens podem ser diferentes ou
% os números de página podem aparecer à direita ou à esquerda alternadamente.
% Mas nada impede que você crie um documento "só frente" e, ao imprimir, faça
% a impressão frente-e-verso.
%
% Aqui também definimos a língua padrão do documento
% (a última da lista) e línguas adicionais.
%\documentclass[12pt,twoside,brazilian,english]{book}
\documentclass[12pt,twoside,brazilian]{book}

% Ao invés de definir o tamanho das margens, vamos definir os tamanhos do
% texto, do cabeçalho e do rodapé, e deixamos a package geometry calcular
% o tamanho das margens em função do tamanho do papel. Assim, obtemos o
% mesmo resultado impresso, mas com margens diferentes, se o tamanho do
% papel for diferente.
\usepackage[a4paper]{geometry}

\geometry{
  textwidth=152mm,
  hmarginratio=12:17, % 24:34 -> com papel A4, 24mm + 152mm + 34mm = 210mm
  textheight=237mm,
  vmarginratio=8:7, % 32:28 -> com papel A4, 32mm + 237mm + 28mm = 297mm
  headsep=11mm, % distância entre a base do cabeçalho e o texto
  headheight=21mm, % qualquer medida grande o suficiente, p.ex., top - headsep
  footskip=10mm,
  marginpar=20mm,
  marginparsep=5mm,
}

% \usepackage{libertinus}
% \usepackage{libertinust1math}
% \usepackage{imagechapter}

% \usepackage[brazilian](babel)

% Vários pacotes e opções de configuração genéricos; para personalizar o
% resultado, modifique estes arquivos.
\input{assets/tex/extras/basics}
\input{assets/tex/extras/languages}
\input{assets/tex/extras/fonts}

\input{assets/tex/extras/floats}

\input{assets/tex/extras/imeusp-thesis} % capa, páginas preliminares e alguns detalhes
\input{assets/tex/extras/imeusp-formatting}
\input{assets/tex/extras/index}
\input{assets/tex/extras/bibconfig}
\input{assets/tex/extras/hyperlinks}
%\nocolorlinks % para impressão em P&B
\input{assets/tex/extras/source-code}
\input{assets/tex/extras/utils}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}


% Diretórios onde estão as figuras; com isso, não é preciso colocar o caminho
% completo em \includegraphics (e nem a extensão).
% \graphicspath{{figuras/},{logos/}}

% Comandos rápidos para mudar de língua:
% \en -> muda para o inglês
% \br -> muda para o português
% \texten{blah} -> o texto "blah" é em inglês
% \textbr{blah} -> o texto "blah" é em português
\babeltags{br=brazilian,en=english}

% Bibliografia
\usepackage[
  style=assets/tex/extras/plainnat-ime, % variante de autor-data, similar a plainnat
  %style=alphabetic, % similar a alpha
  %style=numeric, % comum em artigos
  %style=authoryear-comp, % autor-data "padrão" do biblatex
  %style=apa, % variante de autor-data, muito usado
  %style=abnt,
]{biblatex}

\usepackage{bookmark}
\usepackage{hhline}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% METADADOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% O arquivo com os dados bibliográficos para biblatex; você pode usar
% este comando mais de uma vez para acrescentar múltiplos arquivos
\addbibresource{assets/bib/book.bib}

% Este comando permite acrescentar itens à lista de referências sem incluir
% uma referência de fato no texto (pode ser usado em qualquer lugar do texto)
%\nocite{bronevetsky02,schmidt03:MSc, FSF:GNU-GPL, CORBA:spec, MenaChalco08}
% Com este comando, todos os itens do arquivo .bib são incluídos na lista
% de referências
%\nocite{*}

% É possível definir como determinadas palavras podem (ou não) ser
% hifenizadas; no entanto, a hifenização automática geralmente funciona bem
% \babelhyphenation{documentclass latexmk soft-ware clsguide} % todas as línguas
\babelhyphenation[brazilian]{cons-tru-í-da}
\babelhyphenation[brazilian]{res-pon-sa-bi-li-da-de}
\babelhyphenation[brazilian]{ins-ti-tui-ção}
\babelhyphenation[brazilian]{de-mons-tra-da}
\babelhyphenation[brazilian]{su-per-vi-sio-na-do}
\babelhyphenation[brazilian]{a-pre-sen-tar}
\babelhyphenation[brazilian]{mo-de-lo}
\babelhyphenation[brazilian]{e-xis-tem}
\babelhyphenation[brazilian]{i-ma-gem}
\babelhyphenation[brazilian]{pro-ce-di-men-to}
\babelhyphenation[brazilian]{des-ci-da}
\babelhyphenation[brazilian]{pro-ble-ma}
\babelhyphenation[brazilian]{re-a-li-za-das}
\babelhyphenation[brazilian]{ma-nu-al}
\babelhyphenation[brazilian]{fi-na-li-za-do}
\babelhyphenation[brazilian]{con-si-de-ra-dos}
\babelhyphenation[brazilian]{i-ma-gens}
\babelhyphenation[brazilian]{a-no-tan-do}
\babelhyphenation[brazilian]{hi-per-pa-râ-me-tros}
\babelhyphenation[brazilian]{con-se-cu-ti-vas}
\babelhyphenation[brazilian]{con-so-le}
\babelhyphenation[brazilian]{mo-de-los}
\babelhyphenation[brazilian]{má-xi-mo}
\babelhyphenation[brazilian]{pa-râ-me-tros}
\babelhyphenation[brazilian]{a-no-ta-ção}
\babelhyphenation[brazilian]{va-li-da-ção}
\babelhyphenation[brazilian]{mo-di-fi-ca-ções}
\babelhyphenation[brazilian]{re-pre-sen-tar}
\babelhyphenation[brazilian]{a-pre-sen-ta-das}
\babelhyphenation[brazilian]{re-co-nhe-ci-men-to}
\babelhyphenation[brazilian]{des-cre-ven-do}
\babelhyphenation[brazilian]{des-co-nhe-ci-da}
\babelhyphenation[brazilian]{con-si-de-ra-da}
\babelhyphenation[brazilian]{trans-pa-ren-te}
\babelhyphenation[brazilian]{cons-tru-ção}
% \babelhyphenation[english]{what-ever}

% Estes comandos definem o título e autoria do trabalho e devem sempre ser
% definidos, pois além de serem utilizados para criar a capa, também são
% armazenados nos metadados do PDF.
\title{
    % Obrigatório nas duas línguas
    titlept={Resolvendo Captchas},
    titleen={Solving Captchas},
    % Opcional, mas se houver deve existir nas duas línguas
    subtitlept={usando raspagem de dados e aprendizado fracamente supervisionado},
    subtitleen={using web scraping and weak supervised learning},
}

\author{Julio Adolfo Zucon Trecenti}

% Para TCCs, este comando define o supervisor
\orientador{Prof. Dr. Victor Fossaluza}

% Se não houver, remova; se houver mais de um, basta
% repetir o comando quantas vezes forem necessárias
% \coorientador{Prof. Dr. Ciclano de Tal}
% \coorientador[fem]{Profª. Drª. Beltrana de Tal}

% A página de rosto da versão para depósito (ou seja, a versão final
% antes da defesa) deve ser diferente da página de rosto da versão
% definitiva (ou seja, a versão final após a incorporação das sugestões
% da banca).
\defesa{
  nivel=doutorado, % mestrado, doutorado ou tcc
  % É a versão para defesa ou a versão definitiva?
  definitiva,
  % É qualificação?
  %quali,
  programa={Estatística},
  membrobanca={Prof. Dr. Victor Fossaluza (orientador) -- IME-USP},
  % Em inglês, não há o "ª"
  %membrobanca{Prof. Dr. Fulana de Tal (advisor) -- IME-USP [sem ponto final]},
  membrobanca={Profa. Dra. Daiane Zuanetti -- UFSCar},
  membrobanca={Profa. Dra. Florencia Leonardi -- IME-USP},
  membrobanca={Prof. Dr. Jony Arrais -- UFF},
  membrobanca={Prof. Dr. Rafael Izbicki -- UFSCar},
  % Se não houve bolsa, remova
  %
  % Norma sobre agradecimento por auxílios da FAPESP:
  % https://fapesp.br/11789/referencia-ao-apoio-da-fapesp-em-todas-as-formas-de-divulgacao
  %
  % Norma sobre agradecimento por auxílios da CAPES (Portaria 206,
  % de 4 de Setembro de 2018):
  % https://www.in.gov.br/materia/-/asset_publisher/Kujrw0TZC2Mb/content/id/39729251/do1-2018-09-05-portaria-n-206-de-4-de-setembro-de-2018-39729135
  %
  %apoio={O presente trabalho foi realizado com apoio da Coordenação
  %       de Aperfeiçoamento\\ de Pessoal de Nível Superior -- Brasil
  %       (CAPES) -- Código de Financiamento 001}, % o código é sempre 001
  %
  %apoio={This study was financed in part by the Coordenação de
  %       Aperfeiçoamento\\ de Pessoal de Nível Superior -- Brasil
  %       (CAPES) -- Finance Code 001}, % o código é sempre 001
  %
  %apoio={Durante o desenvolvimento deste trabalho, o autor recebeu\\
  %       auxílio financeiro da FAPESP -- processo nº aaaa/nnnnn-d},
  %
  %apoio={During the development if this work, the author received\\
  %       financial support from FAPESP -- grant \#aaaa/nnnnn-d},
  %
  % apoio={Durante o desenvolvimento deste trabalho o autor
  %        recebeu auxílio financeiro da XXXX},
  % local={São Paulo},
  % data=2017-08-10, % YYYY-MM-DD
  % A licença do seu trabalho. Use CC-BY, CC-BY-NC, CC-BY-ND, CC-BY-SA,
  % CC-BY-NC-SA ou CC-BY-NC-ND para escolher a licença Creative Commons
  % correspondente (o sistema insere automaticamente o texto da licença).
  % Se quiser estabelecer regras diferentes para o uso de seu trabalho,
  % converse com seu orientador e coloque o texto da licença aqui, mas
  % observe que apenas TCCs sob alguma licença Creative Commons serão
  % acrescentados ao BDTA. Se você tem alguma intenção de publicar o
  % trabalho comercialmente no futuro, sugerimos a licença CC-BY-NC-ND.
  direitos={CC-BY}, % Creative Commons Attribution 4.0 International License
  %direitos={CC-BY-NC-ND}, % Creative Commons Attribution / NonCommercial /
                           % NoDerivatives 4.0 International License
  %direitos={Autorizo a reprodução e divulgação total ou parcial
  %          deste trabalho, por qualquer meio convencional ou
  %          eletrônico, para fins de estudo e pesquisa, desde que
  %          citada a fonte.},
  %direitos={I authorize the complete or partial reproduction and disclosure
  %          of this work by any conventional or electronic means for study
  %          and research purposes, provided that the source is acknowledged.}
  % Para gerar a ficha catalográfica, acesse https://fc.ime.usp.br/,
  % preencha o formulário e escolha a opção "Gerar Código LaTeX".
  % Basta copiar e colar o resultado aqui.
  fichacatalografica={},
}


\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}


\setkeys{Gin}{width=0.8\textwidth,height=0.8\textheight,keepaspectratio}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% AQUI COMEÇA O CONTEÚDO DE FATO %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%% CAPA E PÁGINAS INICIAIS %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Aqui começa o conteúdo inicial que aparece antes do capítulo 1, ou seja,
% página de rosto, resumo, sumário etc. O comando frontmatter faz números
% de página aparecem em algarismos romanos ao invés de arábicos e
% desabilita a contagem de capítulos.
\frontmatter

\pagestyle{plain}

\onehalfspacing % Espaçamento 1,5 na capa e páginas iniciais

\maketitle % capa e folha de rosto

%%%%%%%%%%%%%%%% DEDICATÓRIA, AGRADECIMENTOS, RESUMO/ABSTRACT %%%%%%%%%%%%%%%%%%

\begin{dedicatoria}
Aos meus pais,
Cidimir e Vera
\end{dedicatoria}

% Reinicia o contador de páginas (a próxima página recebe o número "i") para
% que a página da dedicatória não seja contada.
\pagenumbering{roman}

% Agradecimentos:
% Se o candidato não quer fazer agradecimentos, deve simplesmente eliminar
% esta página. A epígrafe, obviamente, é opcional; é possível colocar
% epígrafes em todos os capítulos. O comando "\chapter*" faz esta seção
% não ser incluída no sumário.
\chapter*{Agradecimentos}

Escrever a parte de agradecimento é uma tarefa muito fácil, pois o sentimento de gratidão que sinto a todas as pessoas queridas estiveram ao meu lado no processo de construção da tese é muito forte e verdadeiro. Ao mesmo tempo, é uma tarefa muito difícil, pois acredito não sou capaz de expressar em palavras o tamanho dessa gratidão e o quanto o apoio dessas pessoas significou para mim.

Primeiramente, gostaria de agradecer ao Victor Fossaluza, meu querido amigo e orientador. Victor foi um irmão mais velho, com a paciência necessária para lidar com minhas limitações por fazer um doutorado sem bolsa e trabalhando muito. Foi amigo, fazendo o trabalho motivacional para me convencer de que eu estava fazendo algo relevante. E foi um grande sábio, dando sugestões muito interessantes para resolver os desafios que foram postos.

Agradeço ao Daniel Falbel, não só pela amizade, mas por ter me salvado este trabalho pelo menos duas vezes. Se não fosse pelo trabalho do Daniel, o trabalho nem teria começado, já que foi ele que deu a ideia de modelar Captchas usando deep learning pela primeira vez, usando o TensorFlow. E se não fosse pelo maravilhoso trabalho na família de pacotes em torno do torch, como o próprio torch, luz e torchvision.

Agradeço ao Caio Lente, por ser essa pessoa incrível, gentil e modesta, apesar da enorme capacidade. Caio é a única pessoa capaz de me aturar como sócio em duas empresas diferentes, a Curso-R e a Terranova. Caio foi a pessoa que desenvolveu o pacote e o site do decryptr, nossa primeira ferramenta geral de resolver Captchas. Caio também é meu influencer digital, sendo a pessoa por trás de coisas que acompanham minha vida até hoje, como o Todoist e o podcast Philosophize This.

Agradeço à minha noiva Beatriz Milz, por todo o apoio, dedicação e paciência que teve comigo, especialmente nas etapas finais do desenvolvimento da tese. Beatriz é a melhor pessoa que conheço e tenho muita sorte de poder viver ao seu lado. Agradeço pelos excelentes comentários que colocou na tese (é possível \href{https://github.com/jtrecenti/doutorado/pulls?q=is\%3Apr}{visualizá-los no repositório da tese no GitHub}) e pela ajuda na tomada de várias decisões ao longo da construção da tese.

Agradeço ao Fernando Corrêa, por tantas coisas que é difícil de expressar. Fernando foi quem me convenceu a desenvolver o doutorado em torno dos Captchas, em uma conversa que tivemos no carro. Cada conversa com Fernando é um aprendizado novo, seja sobre as filosofias mais profundas, os problemas mais importantes da humanidade ou sobre os personagens mais engraçados do BBB.

Agradeço ao Athos Damiani, meu grande amigo, colega de TCC e \textit{roomate}, pelas grandes discussões. O Athos é uma pessoa maravilhosa de discutir, pois ele não desiste! Isso fez com que eu precisasse entender mais dos assuntos para argumentar, percebendo que na verdade eu não estava entendendo tanto. Além disso, Athos foi quem me ensinou a resolver Captchas de áudio, o que me ajudou muito na construção das soluções.

Para completar o grupo de sócios da Curso-R, agradeço imensamente ao William Amorim, meu grande amigo e parceiro no processo de doutoramento. Talvez ele não saiba, mas sempre foi o pilar que me apoiou nas horas difíceis, já que terminou o doutorado antes de mim e me mostrou empiricamente que isso era possível.

Agradeço também a todas as pessoas das outras empresas que faço parte: ABJ, Insper e Terranova. O suporte de vocês foi fundamental para que eu conseguisse tempo para desenvolver a tese. Agradecimentos especiais à Barbara Tassoni, Bruno Daleffi, Igor Pretel, Marcelo Guedes Nunes, Rafael Stern (que foi quem deu a ideia da função de perda utilizada na tese!), Ricardo Feliz e Renata Hirota.

Também gostaria de agradecer a uma instituição, o Instituto de Matemática e Estatística da Universidade de São Paulo. Fazer a graduação, mestrado e doutorado nessa instituição foi uma experiência transformadora. Espero poder retribuir pelo menos em parte tudo o que o maravilhoso universo da estatística me proporcionou. Agradeço a todos os professores, alunos e funcionários que fizeram e continuam fazendo parte dessa história.

Finalmente, agradeço aos meus pais, Cidimir e Vera, e ao meu irmão Lucas, por estarem sempre me apoiando e me cobrando sobre o doutorado. Sem esse apoio, provavelmente teria desistido no meio do caminho.

% \input{conteudo/resumoabstract}

% As palavras-chave são obrigatórias, em português e em inglês, e devem ser
% definidas antes do resumo/abstract. Acrescente quantas forem necessárias.

\palavrachave{captcha}
\palavrachave{aprendizado de máquinas}
\palavrachave{aprendizado estatístico}
\palavrachave{aprendizado fracamente supervisionado}
\palavrachave{rótulos parciais}
\palavrachave{rótulos complementares}
\palavrachave{raspagem de dados}

\keyword{captcha}
\keyword{machine learning}
\keyword{statistical learning}
\keyword{weak supervised learning}
\keyword{partial label}
\keyword{complementary label}
\keyword{web scraping}

% O resumo é obrigatório, em português e inglês. Estes comandos também
% geram automaticamente a referência para o próprio documento, conforme
% as normas sugeridas da USP


\resumo{
Captcha (Completely Automated Public Turing tests to tell Computers and Humans Apart), é um desafio utilizado para identificar se o acesso à uma página na internet é realizada por uma pessoa ou uma máquina. O desafio é projetado para ser fácil de resolver por humanos, mas difícil de resolver por máquinas. A utilização de Captchas em serviços públicos pode ser prejudicial à população, limitando o acesso a dados e incentivando empresas a contratarem serviços que utilizam mão de obra humana para resolução dos Captchas. Este trabalho tem como foco os Captchas com textos (números e letras) em imagens. Já existem soluções para resolver Captchas deste tipo utilizando aprendizado de máquinas, sendo as redes neurais profundas os modelos com melhor desempenho. No entanto, esses modelos precisam de grandes bases de dados anotadas ou de procedimentos de ajuste intrincados e pouco acessíveis. Neste trabalho, é proposto um método inovador, chamado Web Automatic Weak Learning (WAWL), que alia técnicas de raspagem de dados e aprendizado de máquinas com rótulos parciais, utilizando dados obtidos automaticamente da internet para acelerar o ajuste dos modelos. O método é agnóstico à arquitetura utilizada para o modelo, sendo necessário realizar apenas uma adaptação na função de perda. O método apresenta resultados significativos, aumentando a acurácia inicial de modelos fracos em mais de 30\% nos mais de 10 Captchas estudados, sem a necessidade de realizar uma nova rodada de anotação manual. Adicionalmente, um novo pacote computacional de uso livre foi desenvolvido para resolver Captchas e disponibilizar os resultados publicamente. Espera-se que o trabalho possa reduzir o incentivo econômico de contratar serviços que utilizam mão de obra humana para resolver Captchas.
}

\clearpage

\abstract{
Captchas, or Completely Automated Public Turing tests to tell Computers and Humans Apart, are challenges designed to differentiate between human and machine access to web pages. While Captchas are intended to be easy for humans to solve, they can pose a challenge for machines. Their use in public services can limit access to public data and incentivize companies to hire services that use human labor to solve them. In this work, we propose a new method called Web Automatic Weak Learning (WAWL), which combines web scraping and machine learning with partial labels techniques to quickly and accurately fit models to solve Captchas with text in images. Our method is agnostic to the model architecture and only requires a small adaptation of the loss function. By increasing the accuracy of weak initial models by more than 30\% on various Captchas studied, our method can reduce the economic incentive to hire services that use human labor to solve Captchas. We have also developed a computational package to easily solve Captchas and make our results available to the developer community.
}



%%%%%%%%%%%%%%%%%%%%%%%%%%% LISTAS DE FIGURAS ETC. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Como as listas que se seguem podem não incluir uma quebra de página
% obrigatória, inserimos uma quebra manualmente aqui.
\makeatletter
\if@openright\cleardoublepage\else\clearpage\fi
\makeatother

% Todas as listas são opcionais; Usando "\chapter*" elas não são incluídas
% no sumário. As listas geradas automaticamente também não são incluídas por
% conta das opções "notlot" e "notlof" que usamos para a package tocbibind.

% Normalmente, "\chapter*" faz o novo capítulo iniciar em uma nova página, e as
% listas geradas automaticamente também por padrão ficam em páginas separadas.
% Como cada uma destas listas é muito curta, não faz muito sentido fazer isso
% aqui, então usamos este comando para desabilitar essas quebras de página.
% Se você preferir, comente as linhas com esse comando e des-comente as linhas
% sem ele para criar as listas em páginas separadas. Observe que você também
% pode inserir quebras de página manualmente (com \clearpage, veja o exemplo
% mais abaixo).
\newcommand\disablenewpage[1]{{\let\clearpage\par\let\cleardoublepage\par #1}}

% Nestas listas, é melhor usar "raggedbottom" (veja basics.tex). Colocamos
% a opção correspondente e as listas dentro de um grupo para ativar
% raggedbottom apenas temporariamente.
\bgroup
\raggedbottom

%%%%% Listas criadas manualmente

%\chapter*{Lista de abreviaturas}
\disablenewpage{\chapter*{Lista de siglas}}

\begin{tabular}{rl}
   ABJ & Associação Brasileira de Jurimetria\\
   ADAM & ADaptive Moment Estimator\\
   API & Application Programming Interface\\
   CADESP & Centro de Apoio ao Desenvolvimento da Saúde Pública\\
   Captcha & Completely Automated Public Turing test to tell Computers and Humans Apart\\
   CF & Constituição Federal\\
   CLT & Consolidação das Leis do Trabalho\\
   CKAN & Comprehensive Knowledge Archive Network\\
   CNJ & Conselho Nacional de Justiça\\
   CNN & Convolutional Neural Networks\\
   CNPJ & Cadastro Nacional da Pessoa Jurídica\\
   CSV & Comma Separated Values\\
   ENCE & Escola Nacional de Ciências Estatísticas\\
   HIP & Human Interaction Proofs\\
   HTTP & HypertText Transfer Protocol\\
   HTML & HyperText Markup Language\\
   IETF & Internet Engineering Task Force\\
   JPEG & Join Photographic Experts Groups\\
   GAN & Generative Adversarial Networks\\
   GPT & Generative Pre-Training Transformer\\
   GPU & Graphical Processing Unit\\
   JUCESP & Junta Comercial de São Paulo\\
   LAI & Lei de Acesso à Informação\\
   ICMC & Instituto de Ciências Matemáticas e de Computação\\
   IME & Instituto de Matemática e Estatística\\
   LGPD & Lei Geral de Proteção de Dados\\
   ME & Ministério da Economia\\
\end{tabular}

\begin{tabular}{rl}
   MNIST & Modified National Institute of Standards and Technology Database\\
   OCR & Optical Character Recognition\\
   OKFN & Open Knowledge Foundation\\
   PDF & Portable Document Format\\
   PJe & Processo Judicial eletrônico\\
   PLL & Partial Label Learning\\
   PNG & Portable Network Graphics\\
   RCN & Recursive Cortical Network\\
   RFB & Receita Federal do Brasil\\
   ReLU & Rectified Linear Unit\\
   SAJ & Sistema de Automação da Justiça\\
   SEI & Sistema Eletrônico de Informações\\
   SGT & Sistema de Gestão de Tabelas\\
   SPAM & Sending and Posting Advertisement in Mass\\
   TJBA & Tribunal de Justiça da Bahia\\
   TJMG & Tribunal de Justiça de Minas Gerais\\
   TJPE & Tribunal de Justiça de Pernambuco\\
   TJRS & Tribunal de Justiça do Rio Grande do Sul\\
   TJSP & Tribunal de Justiça de São Paulo\\
   TRF & Tribunal Regional Federal\\
   TRT & Tribunal Regional do Trabalho\\
   UFAM & Universidade Federal do Amazonas\\
   UFBA & Universidade Federal da Bahia\\
   UFF & Universidade Federal Fluminense\\
   UFG & Universidade Federal de Goiás\\
   UFMG & Universidade Federal de Minas Gerais\\
   UFPE & Universidade Federal de Pernambuco\\
   UFPR & Universidade Federal do Paraná\\
   UFRGS & Universidade Federal do Rio Grande do Sul\\
   UFRJ & Universidade Federal do Rio de Janeiro\\
   UFRN & Universidade Federal do Rio Grande do Norte\\
   UFSCar & Universidade Federal de São Carlos\\
   UnB & Universidade de Brasília\\
   Unicamp & Universidade Estadual de Campinas\\
   UNESP & Universidade Estadual de São Paulo\\
   URL & Uniform Resource Locator\\
   USP & Universidade de São Paulo\\
   WAWL & Web Automatic Weak Learner\\
   XPath & XML Path Language\\
   XML & eXtensible Markup Language
\end{tabular}

\chapter*{Lista de símbolos}
% \disablenewpage{\chapter*{Lista de símbolos}}

\begin{displaymath}
\begin{array}{ll}
   x & \text{imagem (na forma de matriz)}\\
   N & \text{linhas de uma imagem (altura)}\\
   M & \text{colunas de uma imagem (largura)}\\
   R & \text{canais de uma imagem (cores)}\\
   c & \text{caractere}\\
   L & \text{comprimento do Captcha}\\
   \mathcal A & \text{alfabeto (quantidade de caracteres distintos possíveis)}\\
   y & \text{variável resposta (observada), na forma de matriz}\\
   \mathbf y & \text{variável resposta na forma de rótulo parcial}\\
   \mathcal U & \text{distribuição uniforme}\\
   X & \text{variável aleatória representando a imagem}\\
   Y & \text{variável aleatória representando a matriz-resposta}\\
   f, g, h & \text{função que leva uma imagem a uma estimativa para } y\\
   \mathcal Y & \text{valores possíveis da variável resposta}\\
   \mathcal O & \text{função do oráculo}\\
   K & \text{Kernel (núcleo) em uma operação de convolução}\\
   \epsilon & \text{erro ou valor pequeno}\\
   \beta & \text{viés (intercepto) em um passo de batch normalization}\\
   \gamma & \text{parâmetro em um passo de batch normalization}\\
   I & \text{função indicadora}\\
   \theta & \text{parâmetros de um modelo}\\
   \nabla & \text{gradiente (vetor de derivadas parciais)}\\
   m,v,\hat m, \hat v, \beta_2, \beta_2, \epsilon & \text{parâmetros do otimizador ADAM}\\
   \mathcal L & \text{função de perda}\\
   \mathcal R & \text{função de risco}\\
   \bar {\mathbf y} & \text{observação complementar de } y \text{ (ou seja, tudo menos } y \text{)}
\end{array}
\end{displaymath}

% Quebra de página manual
\clearpage

%%%%% Listas criadas automaticamente

% Você pode escolher se quer ou não permitir a quebra de página
%\listoffigures
\disablenewpage{\listoffigures}

% Você pode escolher se quer ou não permitir a quebra de página
%\listoftables
\disablenewpage{\listoftables}

% Esta lista é criada "automaticamente" pela package float quando
% definimos o novo tipo de float "program" (em utils.tex)
% Você pode escolher se quer ou não permitir a quebra de página
%\listof{program}{\programlistname}
% \disablenewpage{\listof{program}{\programlistname}}

% Sumário (obrigatório)
\tableofcontents

\egroup % Final de "raggedbottom"

% Referências indiretas ("x", veja "y") para o índice remissivo (opcionais,
% pois o índice é opcional). É comum colocar esses itens no final do documento,
% junto com o comando \printindex, mas em alguns casos isso torna necessário
% executar texindy (ou makeindex) mais de uma vez, então colocar aqui é melhor.
% \index{Inglês|see{Língua estrangeira}}
% \index{Figuras|see{Floats}}
% \index{Tabelas|see{Floats}}
% \index{Código-fonte|see{Floats}}
% \index{Subcaptions|see{Subfiguras}}
% \index{Sublegendas|see{Subfiguras}}
% \index{Equações|see{Modo matemático}}
% \index{Fórmulas|see{Modo matemático}}
% \index{Rodapé, notas|see{Notas de rodapé}}
% \index{Captions|see{Legendas}}
% \index{Versão original|see{Tese/Dissertação, versões}}
% \index{Versão corrigida|see{Tese/Dissertação, versões}}
% \index{Palavras estrangeiras|see{Língua estrangeira}}
% \index{Floats!Algoritmo|see{Floats, ordem}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CAPÍTULOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Aqui vai o conteúdo principal do trabalho, ou seja, os capítulos que compõem
% a dissertação/tese. O comando mainmatter reinicia a contagem de páginas,
% modifica a numeração para números arábicos e ativa a contagem de capítulos.
\mainmatter

\pagestyle{mainmatter}

% Espaçamento simples
\singlespacing

\bookmarksetup{startatroot}

\hypertarget{sobre-este-documento}{%
\chapter*{Sobre este documento}\label{sobre-este-documento}}
\addcontentsline{toc}{chapter}{Sobre este documento}

\markboth{Sobre este documento}{Sobre este documento}

Este documento foi construído utilizando o
\href{https://quarto.org/}{Quarto}, um sistema de publicação científica
de código aberto desenvolvido com base no
\href{https://pandoc.org/}{Pandoc}. Os códigos foram escritos com o
\href{https://cran.r-project.org/}{software estatístico R} na
\href{https://cran.r-project.org/bin/windows/base/}{versão 4.2.2}.

O documento foi escrito em duas versões: PDF e HTML. A versão em HTML
foi construída com \href{https://quarto.org/docs/books/}{Quarto Books}.
A versão em PDF incorpora o
\href{https://gitlab.com/ccsl-usp/modelo-latex}{template do IME-USP},
mantido pelo \href{https://ccsl.ime.usp.br/}{Centro de Competência de
Software Livre}.

Todos os códigos e textos da tese podem ser acessados publicamente
\href{https://github.com/jtrecenti/doutorado}{neste link}. Boa leitura!

\bookmarksetup{startatroot}

\hypertarget{sec-introducao}{%
\chapter{Introdução}\label{sec-introducao}}

\epigrafe{Why do we need to prove we're not robots to a robot? Isn't that a robot's job?}{ChatGPT, a robot}

Captcha (\emph{Completely Automated Public Turing test to tell Computers
and Humans Apart}) é um desafio utilizado para identificar se o acesso à
uma página na internet é realizada por uma pessoa ou um robô\footnote{Para
  os fins dessa tese, a menos que mencionado de forma explícita, os
  termos ``máquina'' e ``robô'', ou ainda ``procedimento automatizado''
  serão tratados como sinônimos, geralmente com o nome ``robô''.}. O
desafio é projetado para ser fácil de resolver por humanos, mas difícil
de resolver por máquinas. Outro nome para os Captchas é \emph{Human
Interaction Proofs,} ou HIPs
(\protect\hyperlink{ref-chellapilla2005}{CHELLAPILLA et al., 2005}).

Um Captcha pode ser classificado como uma variação do teste de Turing
(\protect\hyperlink{ref-turing2009}{TURING, 2009}). A diferença no caso
do Captcha é que a avaliação da humanidade do agente é feita por um robô
ao invés de uma pessoa -- por isso o termo \emph{automated}. Em algumas
situações, Captchas também podem ser entendidos como \textbf{testes de
Turing reversos}, apesar dos autores originais afastarem essa
caracterização
(\protect\hyperlink{ref-vonahnTellingHumansComputers2002}{AHN; BLUM;
LANGFORD, 2002}).

A tarefa de resolver Captchas também pode ser pensada como uma variação
do reconhecimento óptico de caracteres (\emph{Optical Character
Recognition}, OCR). No entanto, os Captchas objetivam enganar justamente
as ferramentas de OCR, através de distorções aplicadas às imagens. Como
efeito, tais ferramentas costumam apresentar baixo poder preditivo nesse
desafio.

Captchas estão presentes em toda a internet. Inicialmente criados para
prevenir \emph{spam} (\emph{Sending and Posting Advertisement in Mass}),
os desafios se tornaram populares rapidamente
(\protect\hyperlink{ref-vonahnReCAPTCHAHumanBasedCharacter2008}{AHN et
al., 2008}), sendo utilizados como forma de evitar o uso indevido de
aplicações da \emph{web}. Algumas ações que os desafios podem ajudar a
evitar são:

\begin{itemize}
\tightlist
\item
  Criação de contas falsas nos sites.
\item
  Envio automático de mensagens, via \emph{email} ou formulários de
  contato.
\item
  Operações automatizadas, como compra de ingressos para eventos e voto
  automático em sites de votação.
\item
  Consulta automatizada em sites para obtenção de dados.
\end{itemize}

Por princípio, o uso de Captchas tem como objetivos aumentar a segurança
das pessoas que acessam a internet e proteger os sistemas \emph{web} de
uso abusivo. Para pessoas que acessam os sites pontualmente, a presença
de Captchas representa um mero dissabor; para quem realiza acessos
massivos, uma grande dificuldade.

No entanto, o uso de Captchas não é adequado em todas as situações. Um
exemplo são os sites de vendas: o uso dos desafios pode aborrecer
usuários, reduzindo a qualidade da experiência ao consumir nesses sites.
Os sites devem levar esse fator de aborrecimento em conta para não
reduzir a taxa de conversão. Em alguns casos, pode fazer mais sentido
abandonar os Captchas e utilizar outros mecanismos de prevenção à
fraude, como monitoramento da sessão do usuário
(\protect\hyperlink{ref-inaccess}{W3C, 2021}).

Também existem casos em que o uso de Captchas é prejudicial. Por
exemplo, sua utilização em serviços públicos do Brasil é problemática.
Para explicar esse problema, no entanto, é necessário descrever o
contexto jurídico e como pesquisas aplicadas podem ser prejudicadas com
o uso de Captchas.

\hypertarget{sec-captchas-publicos}{%
\section{Captchas em serviços públicos}\label{sec-captchas-publicos}}

A Constituição Federal de 1988 (CF), em seu
\href{https://constituicao.stf.jus.br/dispositivo/cf-88-parte-1-titulo-2-capitulo-1-artigo-5-inciso-33}{inciso
XXXIII do art. 5º}, prevê que ``todos têm direito a receber dos órgãos
públicos informações de seu interesse particular, ou de interesse
coletivo ou geral, que serão prestadas no prazo da lei, sob pena de
responsabilidade, ressalvadas aquelas cujo sigilo seja imprescindível à
segurança da sociedade e do Estado;''. Essa previsão é implementada pela
Lei de Acesso à Informação
(\href{https://www.planalto.gov.br/ccivil_03/_ato2011-2014/2011/lei/l12527.htm}{Lei
12.527/2011}; LAI), que se aplica ``aos órgãos públicos integrantes da
administração direta dos Poderes Executivo, Legislativo, incluindo as
Cortes de Contas, e Judiciário e do Ministério Público'', bem como ``as
autarquias, as fundações públicas, as empresas públicas, as sociedades
de economia mista e demais entidades controladas direta ou indiretamente
pela União, Estados, Distrito Federal e Municípios'' (Art. 1º).

A LAI, apesar de trazer diversos benefícios à sociedade, tem dois
problemas. O primeiro é o \textbf{esforço}: tanto a pessoa/órgão que
solicita os dados, quanto o órgão que retorna os dados precisam
trabalhar para disponibilizar as informações, sendo necessário deslocar
equipes para realizar os levantamentos pedidos. O segundo é o
\textbf{formato}: os dados enviados como resultado de pedidos de LAI
podem chegar em formatos inadequados para consumo da solicitante, muitas
vezes em \emph{Portable Document Format} (PDF), que dificulta a leitura
e análise dos dados (\protect\hyperlink{ref-michener2015}{MICHENER;
MONCAU; VELASCO, 2015}, pág. 55); além disso, como o levantamento é
realizado de forma individualizada, o mesmo pedido feito em diferentes
períodos (e.g.~uma atualização mensal dos dados) pode vir em formatos
diferentes, dificultando a leitura e arrumação dos dados.

Uma forma eficiente de evitar os problemas de esforço e formato em
pedidos de LAI é disponibilizar os dados de \textbf{forma aberta}. Como
definido pela \emph{Open Knowledge Foundation} (OKFN), a base de dados
``deve ser fornecida em uma forma conveniente e modificável, isenta de
obstáculos tecnológicos desnecessários para a realização dos direitos
licenciados. Especificamente, os dados devem ser legíveis por máquina,
disponíveis em todo o seu volume, e fornecidos em um formato aberto (ou
seja, um formato com sua especificação livremente disponível, e
publicada sem quaisquer restrições, monetárias ou não, da sua
utilização) ou, no mínimo, podem ser processados com pelo menos uma
ferramenta de software livre e gratuita.''\footnote{Link:
  \url{https://okfn.org/opendata/}. Último acesso em 01/11/2022.}

As vantagens ao disponibilizar dados públicos de forma aberta para a
sociedade é um tema pacífico na comunidade científica
(\protect\hyperlink{ref-murray-rust2008}{MURRAY-RUST, 2008}). No Brasil,
existem plataformas dedicadas à abertura de dados governamentais, como o
\href{https://dados.gov.br}{dados.gov.br}. No entanto, existem diversos
dados públicos que ainda não estão disponíveis de forma aberta.

A dificuldade de acesso é particularmente evidente no Poder Judiciário,
que além de não disponibilizar um portal de dados abertos, impõe
barreiras aos pedidos de acesso à informação por utilizar diversos
sistemas para armazenar os dados. Por exemplo, para pedir uma lista de
todos os processos judiciais relacionados à recuperação judicial de
empresas, as únicas alternativas são i) pedir os dados ao Conselho
Nacional de Justiça (CNJ), que não possui informações suficientes para
obter a lista\footnote{O CNJ só consegue listar os processos
  relacionados a um tema a partir da definição de Classes e Assuntos,
  disponíveis no
  \href{https://www.cnj.jus.br/sgt/consulta_publica_classes.php}{Sistema
  de Gestão de Tabelas (SGT) do CNJ}. Processos relacionados a
  recuperação judicial, no entanto, não respeitam a taxonomia do SGT
  (\protect\hyperlink{ref-observat}{ABJ, 2021}).} ou ii) expedir ofícios
aos 27 Tribunais Estaduais. Cada tribunal apresentaria diferentes opções
e critérios de acesso aos dados, diferentes prazos para atendimento e
diferentes formatos, podendo, inclusive, negar o pedido de acesso.

A dificuldade para acessar os dados do judiciário é a principal barreira
para realização de pesquisas pela Associação Brasileira de Jurimetria
(ABJ), empresa na qual o autor desta tese trabalha. A entidade tem como
missão principal realizar estudos empíricos para implementar políticas
públicas utilizando dados do judiciário.

Dos 16 projetos disponibilizados na
\href{https://abj.org.br/pesquisas/}{página de pesquisas no site da
ABJ}, pelo menos 12 (75\%) apresentaram dificuldades na obtenção dos
dados via pedidos de acesso aos órgãos. Três exemplos emblemáticos são o
da pesquisa sobre Tempo dos processos relacionados à adoção no Brasil
(\protect\hyperlink{ref-tempodo}{ABJ, 2014}), o Observatório da
Insolvência: Rio de Janeiro (\protect\hyperlink{ref-observat}{ABJ,
2021}) e o Diagnóstico do Contencioso Tributário Administrativo
(\protect\hyperlink{ref-diagnosticoABJ}{ABJ, 2022}). No primeiro caso,
dois tribunais enviaram os dados em arquivos em papel, sendo que um
deles ultrapassou mil páginas com números de processos impressos. No
segundo caso, o pedido foi respondido com uma planilha de contagens ao
invés da lista de processos. No último caso, até mesmo órgãos que faziam
parte do grupo de trabalho da pesquisa negaram pedido de acesso a dados
de processos tributários em primeira instância, com argumentos que
variavam desde a dificuldade técnica de levantar os dados até a Lei
Geral de Proteção de Dados (LGPD).

Em muitas situações a única alternativa para realizar as pesquisas é
acessando os dados via coleta automatizada nos sites. Todos os tribunais
possuem ferramentas de consulta individualizadas de processos, por conta
do que está previsto na CF. A solução, portanto, passa a ser construir
uma ferramenta que obtém todos os dados automaticamente. Tal conceito é
conhecido como \emph{raspagem de dados}
(\protect\hyperlink{ref-zhao2017}{ZHAO, 2017}) e será desenvolvido com
maiores detalhes no Capítulo~\ref{sec-metodologia}.

Os Captchas se tornam prejudiciais à sociedade quando o acesso
automatizado é necessário para realizar pesquisas científicas.
Infelizmente, vários tribunais utilizam a barreira do Captcha. Alguns
tribunais, inclusive, têm o entendimento de que o acesso automatizado é
prejudicial, como o Tribunal de Justiça do Rio Grande do Sul (TJRS), que
emitiu um
\href{https://www.tjrs.jus.br/novo/processos-e-servicos/processo-eletronico/acesso-robotizado-a-dados-publicos-e-duplamente-arriscado/}{comunicado}
sobre o tema.

Uma justificativa comum para implementar Captchas em consultas públicas
é a estabilidade dos sistemas. Ao realizar muitas consultas de forma
automática, um robô que faz consultas automatizadas pode tornar o
sistema instável e, em algumas situações, até mesmo derrubar o servidor
ou banco de dados que disponibiliza as consultas.

O problema é que utilizar Captchas não impede o acesso automatizado. As
empresas que fazem acesso automatizado em tribunais podem construir
ferramentas ou utilizar serviços externos de resolução de Captchas. Ou
seja, ao utilizar Captchas, o acesso não é impedido, apenas
especializado.

Utilizar Captchas também é uma solução ineficiente. Do ponto de vista
técnico, a solução mais eficiente para disponibilizar os dados é através
de ferramentas de dados abertos como o
\href{https://ckan.org/}{\emph{Comprehensive Knowledge Archive Network}
(CKAN)}. Ao disponibilizar os dados de forma aberta, as consultas
automatizadas ficariam isoladas dos sites de consulta pública, o que
garantiria o acesso das pessoas sem problemas de indisponibilidade.

Não é só quem faz pesquisa com dados públicos que o uso de Captchas pode
ser prejudicial. No mercado, existem serviços de resolução de Captchas
que utilizam mão de obra humana, em regimes que pagam muito menos do que
um salário-mínimo a 8 horas de trabalho. Um exemplo é o
2Captcha\footnote{\href{https://2captcha.com/make-money-online}{Link do
  2Captcha}. Último acesso em 01/11/2022.}, que funciona como um Uber
dos Captchas: o algoritmo automatizado envia o Captcha para a
plataforma, que é acessado e resolvido por uma pessoa, retornando a
solução para o algoritmo. O 2Captcha é operado pela ALTWEB LLC-FZ, uma
empresa com base em Dubai\footnote{\href{https://2captcha.com/terms-of-service}{Link
  dos termos de serviço do 2Captcha}. Último acesso em 01/11/2022.}.

Segundo o site, o valor pago pelo 2Captcha é de US\$ 0,5 para 1 a 2
horas de trabalho. No regime da Consolidação das Leis do Trabalho
(\href{https://www.planalto.gov.br/ccivil_03/decreto-lei/del5452.htm}{Decreto-Lei
5.452/1943}, CLT) as horas mensais de trabalho são 220. Trabalhando
continuamente no 2Captcha, isso daria um salário de 55 a 110 dólares por
mês, valor bem abaixo do salário-mínimo do Brasil, que no ano de 2022
era de R\$ 1.100,00\footnote{Fonte:
  \href{http://www.ipeadata.gov.br/exibeserie.aspx?stub=1\&serid1739471028=1739471028}{IPEA}.
  Último acesso em 01/11/2022.}, mesmo considerando os valores mais
altos de taxa de câmbio. Ou seja, os serviços públicos acabam,
indiretamente, incentivando um mercado que paga abaixo do
salário-mínimo. Luis von Ahn, um dos criadores dos Captchas, define o
2Captcha como um \emph{sweatshop}, um termo utilizado para caracterizar
empresas que têm condições de trabalho inaceitáveis.

A solução definitiva para os problemas gerados pelos Captchas é a
disponibilização dos dados públicos de forma aberta. Na ausência dessa
solução, seja por falta de interesse ou iniciativa dos órgãos públicos,
a alternativa é desenvolver uma solução para resolver Captchas que seja
gratuita e aberta. Tal solução desincentivaria economicamente o uso de
sistemas como o 2Captcha, protegendo as pessoas que fazem as resoluções
e auxiliando pesquisadores em seus estudos.

O presente trabalho busca avançar nesse sentido. A solução desenvolvida
envolve um modelo que resolve alguns Captchas automaticamente, reduzindo
significativamente a necessidade de anotação manual.

Para compreender completamente o avanço que a tese representa, no
entanto, é necessário apresentar o histórico de desenvolvimento dos
Captchas. A descrição é feita através de uma luta entre geradores e
resolvedores de Captchas, que pode ser dada como encerrada no ano de
2018, com o advento do \emph{reCaptcha v3}.

\hypertarget{sec-historia}{%
\section{Uma luta entre geradores e resolvedores}\label{sec-historia}}

O primeiro texto técnico sobre Captchas foi publicado por AHN; BLUM;
LANGFORD
(\protect\hyperlink{ref-vonahnTellingHumansComputers2002}{2002}). O
texto apresenta o Captcha e seu significado através do problema de
geração de \emph{emails} automáticos no Yahoo. Em seguida, apresenta
alguns exemplos de candidatos a Captcha, com tarefas de reconhecimento
de padrões ou textos. Uma característica interessante dos autores sobre
o Captcha é que suas imagens devem ser disponíveis publicamente. O texto
também faz a conexão entre a tarefa dos Captchas e os desafios da
inteligência artificial. Um ponto a destacar é que os autores incentivam
pesquisas para resolver Captchas, pois isso implica em avanços na
inteligência artificial. O site original do projeto,
\href{https://web.archive.org/web/20010723114217/http://www.captcha.net/}{\emph{The
Captcha Project}}, foi lançado em 2000.

O relatório técnico de AHN; BLUM; LANGFORD
(\protect\hyperlink{ref-vonahnTellingHumansComputers2002}{2002}) não foi
o primeiro a apresentar o nome Captcha, nem suas aplicações. RESHEF;
RAANAN; SOLAN
(\protect\hyperlink{ref-reshefMethodSystemDiscriminating2005}{2005}) foi
o primeiro registro de patente com o termo e LILLIBRIDGE et al.
(\protect\hyperlink{ref-lillibridgeMethodSelectivelyRestricting2001}{2001})
foi o primeiro registro de patente que implementou uma solução aos
sistemas de Captchas. No entanto, o relatório técnico de 2002 é o
primeiro que reconhecidamente trata do tema como um problema de
inteligência artificial.

Os artigos mais conhecidos de introdução aos Captchas são VON AHN et al.
(\protect\hyperlink{ref-vonahnCaptchaTellingHumans2003}{2003}) e VON
AHN; BLUM; LANGFORD
(\protect\hyperlink{ref-vonahnTellingHumansComputers2004}{2004}). O
conteúdo dos trabalhos é o mesmo, sendo o primeiro deles na forma de
apresentação e o segundo na forma de relatório. Um detalhe interessante
é a ênfase dos autores no termo \emph{Public} dos Captchas, mostrando a
preocupação em manter os códigos públicos.

Os autores também defendem que o Captcha é uma forma de fazer com que
pessoas mal-intencionadas contribuam com os avanços da inteligência
artificial. Se uma pessoa (ainda que mal-intencionada) resolve um
Captcha e publica essa solução, isso significa que a comunidade
científica avançou na área de inteligência artificial.

Não demorou para surgirem os primeiros resolvedores de
Captchas\footnote{Outro termo para \emph{resolver} Captchas é
  \emph{quebrar} Captchas. Nesta tese, optou-se por utilizar o termo
  \emph{resolver}, para enfatizar a interpretação do Captcha como um
  desafio, não como um problema de criptografia.}. MORI; MALIK
(\protect\hyperlink{ref-mori2003a}{2003}) foi um dos primeiros trabalhos
publicados sobre o tema e utiliza diversas técnicas de processamento de
imagens para obter os rótulos corretos. Também não demorou para a
comunidade científica perceber que redes neurais eram úteis nesse
contexto (\protect\hyperlink{ref-chellapilla2004}{CHELLAPILLA; SIMARD,
2004}). No artigo de 2004, Chellapilla e Simard desenvolvem um algoritmo
baseado em heurísticas para segmentar a imagem e redes neurais para
identificar as imagens individuais.

A partir desse ponto, foi iniciada uma luta entre geradores e
resolvedores de Captchas. Do lado dos geradores, as pessoas envolvidas
foram tanto acadêmicos tentando desenvolver desafios cada vez mais
difíceis para avançar na pesquisa em inteligência artificial, quanto
empresas de tecnologia tentando se proteger contra robôs sofisticados.
Do lado dos resolvedores, as pessoas envolvidas foram tanto acadêmicos
tentando desenvolver novas técnicas para avançar nos modelos de
reconhecimento de imagens, quanto \emph{spammers} buscando novas formas
de realizar ataques cibernéticos.

Uma das pessoas envolvidas com geradores de Captchas mais conhecidas é
Luis von Ahn, um dos criadores do artigo original do Captcha. Um pedaço
da história dos Captchas está disponível nos primeiros cinco minutos de
sua entrevista em um programa britânico chamado \emph{Spark}\footnote{Spark,
  2011.
  \href{https://web.archive.org/web/20120603142110/http://www.cbc.ca/spark/2011/11/full-interview-luis-von-ahn-on-duolingo/}{Link
  no Web Archive}. Último acesso em 01/11/2022.}. Na entrevista, Von Ahn
conta um pouco sobre origem dos Captchas em Carnegie Mellon, contando
que ficou frustrado com o fato de as pessoas perderem tempo de
inteligência humana ao resolver Captchas, o que deu origem ao reCaptcha.
Outro vídeo instrutivo é uma palestra de Von Ahn na \emph{Thinking
Digital Conference} sobre a história do reCaptcha\footnote{\href{https://www.youtube.com/watch?v=i_5ew4btJiQ}{Link
  do vídeo no YouTube}. Último acesso em 01/11/2022.}. Segundo ele, a
\emph{startup} foi criada em maio de 2007\footnote{Segundo o
  \href{https://www.wired.com/2007/06/ff-humancomp/}{texto da Wired}:
  ``\emph{So he's fighting back. In late May, von Ahn launched
  reCaptcha, a service that he believes is the toughest Captcha yet
  devised. ReCaptcha presents users with two stretched and skewed words,
  each bisected by a diagonal line''.} Último acesso em 01/11/2022.},
depois de Von Ahn verificar que aproximadamente 200 milhões de Captchas
eram resolvidos diariamente.

O reCaptcha v1 aproveitou o tempo das pessoas que resolvem Captchas para
digitalizar livros
(\protect\hyperlink{ref-vonahnReCAPTCHAHumanBasedCharacter2008}{AHN et
al., 2008}). A ideia do reCaptcha, como demonstrada na
Figura~\ref{fig-recaptcha-v1}, foi apresentar duas palavras distorcidas
para a pessoa. Imagine que uma ferramenta de OCR (\emph{Optical
Character Recognition}) está digitalizando a página de um livro que foi
escaneada de um documento físico, ou seja, está transformando a foto da
página do livro em um arquivo de texto. Na Figura, ``upon'' seria uma
palavra que a ferramenta de OCR conseguiu transformar a imagem em texto
com sucesso, enquanto ``between'' seria uma palavra em que a ferramenta
de OCR falhou. A primeira palavra seria utilizada para verificar se o
agente era ou não humano, e a segunda seria utilizada para decifrar a
palavra e aprimorar as ferramentas de OCR. Em 2009, a empresa foi
comprada pela Google, que utilizou o reCaptcha v1 para digitalizar os
livros que estão presentes no site
\href{https://books.google.com.br/}{Google Books}.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./assets/img/recaptcha-v1.png}

}

\caption{\label{fig-recaptcha-v1}Explicação de von Ahn sobre o
funcionamento do reCaptcha}

\end{figure}

Curiosamente, foi com a própria Google que os resolvedores ficaram em
vantagem na luta contra geradores. Os modelos de inteligência artificial
continuaram avançando, notadamente com o avanço dos modelos de redes
neurais profundas (\protect\hyperlink{ref-lecun2015}{LECUN; BENGIO;
HINTON, 2015}). No trabalho de GOODFELLOW et al.
(\protect\hyperlink{ref-goodfellow2013}{2013}), foi apresentado um
modelo de redes neurais convolucionais que resolvia o reCaptcha v1 com
99,8\% de acurácia. No ano seguinte, em 2014, a Google descontinuou o
reCaptcha v1, lançando o reCaptcha v2.\footnote{\emph{Are you a robot?
  Introducing No Captcha reCaptcha.} Acessível no
  \href{https://security.googleblog.com/2014/12/are-you-robot-introducing-no-captcha.html}{blog
  da Google}. Último acesso em 01/11/2022.}

O reCaptcha v2 apresentou duas inovações importantes. O primeiro foi o
botão ``\emph{I'm not a robot}'', um verificador automático do navegador
que utiliza heurísticas para detectar se o padrão de acesso ao site se
assemelha com um robô ou humano. O segundo foi a mudança no tipo de
tarefa: ao invés de rotular um texto distorcido, o desafio passou a ser
identificar objetos e animais, como na Figura~\ref{fig-turkey}.

\begin{figure}

{\centering \includegraphics[width=0.4\textwidth,height=\textheight]{./assets/img/turkey.png}

}

\caption{\label{fig-turkey}Exemplo do reCaptcha v2 com a imagens de
perus}

\end{figure}

A mudança do tipo de tarefa de visão computacional foi importante para o
sucesso do reCaptcha v2. O desafio é mais difícil, já que existem muito
mais objetos e imagens do que letras e números, aumentando
significativamente o suporte da variável resposta. Por exemplo, um
modelo para identificar perus pode ser facilmente desenvolvido a partir
de uma base anotada, potencialmente custosa para ser construída. O
reCaptcha v2, no entanto, pode facilmente mudar a tarefa para
identificar leões, cães, hidrantes e semáforos, inutilizando o modelo
criado para classificar perus.

O reCaptcha v2 também foi usado para gerar novas bases de dados para a
Google, usando o mesmo princípio do reCaptcha v1. A humanidade do agente
é verificada apenas com uma parte das imagens. As outras imagens eram
utilizadas para anotar imagens, utilizadas para aprimorar modelos
utilizados nos projetos de carros autônomos, Google Street View e outras
iniciativas da empresa.

Com o advento do reCaptcha v2, a pergunta de interesse dos resolvedores
de Captcha passou a ser: como criar modelos que funcionam razoavelmente
bem sem a necessidade de anotar muitas imagens? Se esse desafio fosse
resolvido, dois avanços aconteceriam: i) um grande avanço na
inteligência artificial, especificamente na área de visão computacional,
e ii) uma nova forma de vencer a luta de geradores e resolvedores.

Até o momento de escrita da tese, não existia um modelo geral que
resolvesse com alta acurácia todos os desafios colocados pelo reCaptcha
v2 e seus concorrentes. No entanto, vários avanços apareceram no sentido
de reduzir a quantidade de imagens anotadas para criar candidatos a
resolvedores. Dentre eles, os mais significativos são os baseados nas
redes generativas adversariais (\emph{Generative Adversarial Networks,}
ou GANs), propostas no famoso trabalho de GOODFELLOW et al.
(\protect\hyperlink{ref-goodfellowGenerativeAdversarialNetworks2014}{2014}).
O primeiro trabalho que utiliza modelos generativos no contexto de
Captchas mostrou uma redução de 300x na quantidade de dados anotados
necessários para resolver um Captcha
(\protect\hyperlink{ref-george2017}{GEORGE et al., 2017}). Nesse caso,
os autores propõem uma rede diferente do GAN, chamada \emph{Recursive
Cortical Network}, ou RCN. Outros trabalhos mais recentes
(\protect\hyperlink{ref-wang2021}{WANG et al., 2021};
\protect\hyperlink{ref-ye2018}{YE et al., 2018}) avançam ainda mais na
pesquisa, reduzindo o trabalho de classificação para um novo Captcha de
texto para aproximadamente 2 horas.

Mas foi em 2018, com o reCaptcha v3, que a Google fez um passo
definitivo. Com a nova versão, as verificações do navegador \emph{web}
passaram a ser muito mais poderosas, sendo raros os casos em que o site
fica em dúvidas se a pessoa é ou não um robô. Versões mais recentes,
como o reCaptcha \emph{Enterprise}, de 2020, ainda permitem que as
mantenedoras dos sites façam o ajuste fino de modelos de detecção de
robôs. Dessa forma, desafios de reconhecimento de texto e objetos em
imagens perderam a importância.

Então, no final, quem venceu a luta de geradores e resolvedores? Na
verdade, nenhuma das duas! O que ocorreu com o reCaptcha v3 e seus
sucessores foi, no fundo, uma mudança de perspectiva: o Captcha deixou
de ser um sistema \textbf{passivo} e passou a ser um sistema
\textbf{ativo} de verificação do agente. Ao invés de criar uma tarefa
difícil de resolver por robôs e fácil de resolver por pessoas, os
sistemas criaram uma camada de verificação da sessão de acesso do
usuário, incluindo análises do navegador, dos \emph{cookies} e dos
padrões de cliques. Antes mesmo de chegar no desafio de reconhecimento,
o algoritmo de acesso precisa enganar os verificadores. Essa tarefa é
muito mais parecida com um problema de \emph{cyberataque} do que uma
tarefa de inteligência artificial.

A luta entre sites e \emph{spammers} continua, mas não é mais uma luta
entre geradores e resolvedores. Por conta disso, os desafios dos
Captchas, sejam de texto ou de imagem, são hoje muito mais uma questão
acadêmica do que uma questão de segurança. A pesquisa sobre Captchas
ainda é promissora e pode gerar muitos resultados importantes para a
área de inteligência artificial.

Apesar dos avanços do reCaptcha v3, Captchas de textos em imagens
continuam sendo populares na \emph{internet}. Isso é especialmente
evidente nos serviços públicos -- objeto deste trabalho --, já que os
serviços raramente são atualizados com ferramentas mais recentes.
Desenvolver uma ferramenta que facilita a resolução de Captchas em sites
públicos é uma forma de incentivar os sites a serem atualizados,
disponibilizando os dados públicos de forma mais eficiente.

Desenvolver e disponibilizar novos métodos para resolução de Captchas de
textos em imagens pode ter um impacto positivo na transparência dos
serviços públicos. Essa é a lacuna identificada a partir da observação
do estado atual dos serviços públicos e dos trabalhos acadêmicos
analisados.

A pesquisa apresenta um fluxo de trabalho que pode ser facilmente
aplicado a diferentes modelos de resolução de Captchas, incluindo
arquiteturas que ainda não foram desenvolvidas. O fluxo de trabalho
funcionará como um acelerador do aprendizado, possibilitando a criação
de modelos que não precisam de intervenção humana.

O resultado será encontrado explorando o potencial de uso do
\textbf{oráculo}, disponível em todos os Captchas de textos em imagens.
Para definir e contextualizar o uso do oráculo, no entanto, é necessário
apresentar algumas características sobre o problema estudado.

\hypertarget{sec-intro-oraculo}{%
\section{Oráculo}\label{sec-intro-oraculo}}

Modelos de aprendizagem profunda usuais podem ser sensíveis a
perturbações pequenas nas imagens (\protect\hyperlink{ref-yuan2019}{YUAN
et al., 2019}). Por isso, para resolver o Captcha de um tribunal, um
modelo que resolve o Captcha de outro tribunal pode não ser eficaz,
sendo necessário baixar e anotar uma nova base e treinar um novo modelo.

Avanços em técnicas de regularização fazem com que o modelo seja menos
afetado por mudanças nos desafios gerados. Uma técnica de regularização
que ajuda na capacidade de generalização é a aumentação de dados com
adição de ruídos (\protect\hyperlink{ref-noh2017}{NOH et al., 2017}). No
entanto, nenhuma técnica garante que o modelo terá excelentes resultados
em novos desafios.

Uma alternativa é desenvolver modelos que aprendem com poucos dados
anotados. Como comentado anteriormente, GANs e modelos relacionados
podem apresentar bons resultados na resolução de tarefas de imagens,
mesmo com uma base de dados pequena. Nesse sentido, ainda que um site
mude seu Captcha, é possível ajustar um modelo que resolve esse Captcha
sem a necessidade de anotar muitos exemplos para construir uma nova base
de treino.

Nessa tese, apresenta-se uma nova técnica para resolver Captchas com
poucas ou nenhuma imagem anotada, chamada \emph{Web Automatic Weak
Learning} (WAWL). A técnica alia técnicas de raspagem de dados com
técnicas de aprendizado fracamente supervisionado, especificamente o
aprendizado com rótulos parciais, explorando uma característica
específica dos Captchas, que é a presença de um \emph{oráculo}.

Oráculo é a resposta do site pesquisado, afirmando se o rótulo enviado
está correto ou errado. Eles estão disponíveis em todos os sites com
Captchas, já que, por definição, o Captcha precisa apresentar o
resultado do teste para o usuário. O nome ``oráculo'' foi inspirado na
mitologia grega, partindo do fato de que o site já possui a informação
correta, como um deus. O site, no entanto, se comunica com o usuário
através de um intermediário (o oráculo) que apresenta a resposta de
forma limitada.

Oráculos se manifestam de diversas formas nos sites com Captchas. Por
exemplo, pode dar a possibilidade de realizar apenas um teste por
imagem, vários testes por imagem, ou ainda retornar informações
ruidosas. Um exemplo de oráculo ruidoso é o reCaptcha v1, que pode
retornar com um ``bom o suficiente'' quando o rótulo não está totalmente
correto
(\protect\hyperlink{ref-vonahnReCAPTCHAHumanBasedCharacter2008}{AHN et
al., 2008}).

O oráculo é uma forma de obter uma base de dados virtualmente infinita.
Do ponto de vista de modelagem, é similar a um problema de aprendizado
por reforço (\protect\hyperlink{ref-sutton2018}{SUTTON; BARTO, 2018}),
mas com uma resposta binária (acertou ou errou) no lugar de um escore.

O método WAWL consiste em aproveitar o fato de que o Captcha, por
definição, aplica um teste de Turing automático para gerar bases de
dados parcialmente anotadas. Ou seja, a técnica resolve o problema não
com modelos mais sofisticados, mas com a utilização eficiente dos
recursos disponíveis. Qualquer modelo pode se aproveitar dessa
característica dos Captchas, incluindo as arquiteturas mais sofisticadas
ou técnicas que ainda não foram desenvolvidas.

A metodologia parte de um modelo inicial, que pode ter baixo poder
preditivo. O modelo inicial pode ser ajustado com as técnicas usuais de
modelagem, ou utilizando um modelo mais sofisticado como GAN. Em
seguida, o site na \emph{web} é acessado múltiplas vezes, gerando uma
nova base de dados virtualmente infinita, que é completamente anotada
nos casos de acerto e que apresenta o histórico de erros no caso de
erro. Os dados gerados automaticamente são então aproveitados para
aprimorar o modelo inicial.

Um ponto importante do WAWL é como aproveitar a informação oferecida
pelo oráculo. Utilizar somente os casos anotados corretamente, obtidos
de acertos no teste do oráculo, induz viés de seleção na amostra
(\protect\hyperlink{ref-na2020}{NA et al., 2020}). Como o modelo só tem
acesso aos casos em que já funciona bem, a informação obtida não é tão
relevante. O desafio de modelagem da tese reside em como considerar a
informação fornecida pelo oráculo nos casos em que o modelo inicial
erra.

Do ponto de vista estatístico, a informação produzida pelo oráculo pode
ser entendida como uma informação censurada
(\protect\hyperlink{ref-colosimo2006}{COLOSIMO; GIOLO, 2006}). Isso
acontece pois a informação existe e é correta, mas não está completa. No
entanto, como a informação é resultado do teste de um rótulo produzido
por um modelo, faz sentido afirmar que a censura não é gerada por acaso.

Na área de aprendizado de máquinas, um modelo que apresenta resposta
censurada ou incompleta faz parte da classe de \textbf{aprendizado
fracamente supervisionado} (\protect\hyperlink{ref-zhou2018}{ZHOU,
2018}). Trata-se de uma área ainda pouco investigada na literatura, mas
bastante ampla, englobando não só os métodos supervisionados como também
os métodos semi-supervisionados. A tese apresentará os conceitos de
aprendizado fracamente supervisionado, com foco na classe de problemas
que a modelagem utilizando Captchas representa.

O custo técnico de implementar o WAWL está na necessidade de utilizar
técnicas de raspagem de dados para criar uma nova base usando o oráculo.
Essas técnicas imitam repetidamente o que um humano faria para acessar o
site, precisando ser desenvolvidas de forma customizada para cada
Captcha analisado.

No entanto, resolver Captchas é uma tarefa meio, não uma tarefa fim. Na
prática, o interesse é construir ferramentas que acessam os sites e
realizar pesquisas com os dados obtidos. E as ferramentas que acessam os
sites para obter dados já envolvem a construção de raspadores de dados.
Como o desenvolvimento de raspadores de dados é necessário em todas as
pesquisas, a parte de raspagem de dados no método WAWL possui tempo de
desenvolvimento negligenciável.

A tese tem como foco principal descrever e testar a eficácia do método
WAWL. Mas a tese também tem objetivos práticos, relacionados à resolução
de Captchas que estão presentes em serviços públicos e disponibilização
das soluções desenvolvidas para a comunidade de programadores. A seguir,
apresenta-se a lista de objetivos completa, de forma concisa.

\hypertarget{sec-objetivos}{%
\section{Objetivo}\label{sec-objetivos}}

O objetivo geral da tese é desenvolver um método inovador, chamado WAWL
(\emph{Web Automatic Weak Learning}) para resolver Captchas, misturando
técnicas de aprendizado profundo com raspagem de dados e aproveitando os
dados fornecidos pelo oráculo.

Especificamente, a pesquisa tem como objetivos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Descrever o método proposto e estudar suas características.
\item
  Construir e disponibilizar um repositório de dados para realização de
  mais pesquisas no ramo.
\item
  Ajustar modelos e testar a eficácia do método.
\item
  Disponibilizar um pacote computacional aberto que possibilita a
  implementação de soluções para resolver Captchas presentes em serviços
  públicos.
\end{enumerate}

\hypertarget{sec-justificativa}{%
\section{Justificativa}\label{sec-justificativa}}

O presente trabalho é relevante para a ciência por três motivos:
importância teórica, viabilidade técnica e importância prática. Os
pontos são explicados abaixo.

Do ponto de vista teórico, a tese é importante por apresentar uma
aplicação muito especial do aprendizado fracamente supervisionado. No
caso do Captcha, como a base de dados fracamente supervisionados é
virtualmente infinita, trata-se de uma excelente oportunidade para
testar novas técnicas e verificar como elas se comportam empiricamente.
Os objetivos 1 e 2 estão relacionados a essa justificativa.

Com relação à viabilidade técnica, o trabalho parte de uma lista de
Captchas que já foram resolvidos utilizando técnicas tradicionais de
aprendizado profundo. Como os Captchas já foram resolvidos previamente,
mesmo que a WAWL não apresentasse bons resultados -- e apresenta -- o
projeto ainda teria como subprodutos as bases de dados e o pacote
computacional disponibilizados abertamente. O objetivo 3 é o que torna a
proposta tecnicamente viável.

Finalmente, do ponto de vista prático, Captchas em serviços públicos
causam desequilíbrio de mercado e incentivam o uso de serviços com
formas de remuneração duvidosas. O objetivo 4 vai de encontro direto com
esse problema, ao disponibilizar uma ferramenta gratuita e aberta para
resolução de Captchas que pode ser utilizada em diversos serviços
públicos.

\hypertarget{sec-hipoteses}{%
\section{Hipóteses}\label{sec-hipoteses}}

O projeto foi desenvolvido em torno de duas hipóteses principais. As
hipóteses têm origem tanto do levantamento bibliográfico realizado para
desenvolver a pesquisa, quanto da experiência pessoal do autor em
projetos de pesquisa aplicados.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A utilização do WAWL gera modelos que resolvem Captchas de textos em
  imagens sem a necessidade de criar grandes bases anotadas.
\item
  É possível aliar a área de raspagem de dados com a área de modelagem
  estatística.
\end{enumerate}

\hypertarget{sec-organizacao}{%
\section{Organização do trabalho}\label{sec-organizacao}}

O segundo capítulo, ``metodologia'', contém todos os passos dados para
construção da tese, tanto do ponto de vista teórico como prático.
Parte-se da definição técnica dos Captchas, chegando até as redes
neurais e a classe problema trabalhada de forma ampla. Em seguida,
apresenta-se o método WAWL e suas características. Depois, a base de
dados é descrita, mostrando as fontes de dados consideradas e as
técnicas de raspagem de dados utilizadas. Por último, descreve-se, com
detalhes, as simulações realizadas para obter os resultados empíricos.

O terceiro capítulo, ``resultados'', apresenta os resultados da
pesquisa. Primeiro são apresentados os resultados das simulações e
outros experimentos realizados com a técnica WAWL. Em seguida,
descreve-se o pacote \texttt{\{captcha\}}, criado para atingir o
objetivo 4 da pesquisa. O capítulo também apresenta uma breve discussão
dos resultados obtidos.

No quarto e último capítulo, ``conclusão'', a pesquisa é concluída, com
apresentação das considerações finais e próximos passos. No final,
também foi incluído um apêndice descrevendo e documentando os pacotes
\texttt{\{captchaDownload\}} e \texttt{\{captchaOracle\}}, criados para
atuar em conjunto com o pacote \texttt{\{captcha\}} para implementar o
método WAWL.

\bookmarksetup{startatroot}

\hypertarget{sec-metodologia}{%
\chapter{Metodologia}\label{sec-metodologia}}

\epigrafe{If machine learning can decipher captchas, what's next? Toilets that can read our minds?}{ChatGPT}

O capítulo foi organizado em três seções: definição do problema, dados e
simulações. A primeira mostra a base matemática do problema estudado e
as escolhas de sintaxe e terminologias. A segunda descreve as fontes de
dados e o processo de coleta, já que a base foi construída totalmente do
zero. A terceira mostra como foram conduzidas as simulações para
verificar se a solução proposta funciona bem empiricamente.

Na parte de redes neurais, optou-se por trabalhar nas pontes entre os
modelos clássicos de estatística e os modelos de redes neurais, mas sem
tecer todos os detalhes técnicos que podem ser encontrados em livros
didáticos. Antes de 2015, a pesquisa em redes neurais nos departamentos
de estatística era uma novidade, sofrendo até certo preconceito por ser
uma classe de modelos ``caixa preta''. Com o passar do tempo, no
entanto, a área está ficando cada vez mais popular. Por isso, optou-se
por trazer poucos detalhes da área, focando nas pontes entre os modelos
clássicos e as redes neurais. Espera-se que o conteúdo possa ser
aproveitado por pessoas interessadas em ensinar redes neurais para
estudantes de estatística.

Na seção de dados, procurou-se apresentar a metodologia de coleta de
dados de forma detalhada. Isso foi feito porque a área de raspagem de
dados não é comum para estudantes de estatística, existindo até uma
percepção entre acadêmicos de que se trata de uma área separada da
estatística. Uma das hipóteses de pesquisa, bem como a solução técnica
apresentada neste trabalho é justamente que existe uma ponte entre as
duas áreas, justificando um detalhamento maior dos conceitos.

Implementações de raspagem de dados, no entanto, são inconstantes. Um
site de interesse pode mudar sua estrutura ou simplesmente trocar o
Captcha para um reCaptcha, alterando completamente o fluxo de coleta.
Isso aconteceu, inclusive, com um dos sites mais importantes dentro do
contexto da jurimetria: em 2018, o Tribunal de Justiça de São Paulo
(TJSP) passou a utilizar o reCaptcha v2 para bloquear ferramentas
automatizadas. Qualquer código ou fluxo para acessar as fontes de dados
consideradas no trabalho, portanto, estariam datadas no momento da
publicação. Por isso, optou-se por apresentar essa parte de forma
genérica e deixar as atualizações para os códigos, que estão disponíveis
publicamente e serão mantidos com contribuições da comunidade.

Na seção de simulações, procurou-se descrever todos os passos em
detalhe. Nesse caso, a escolha do detalhamento se deu por motivos
puramente científicos, para que qualquer pessoa possa reproduzir o que
foi feito. Dessa forma, pessoas interessadas na área podem replicar os
resultados em outros exemplos com alterações mínimas no fluxo, além de
sugerir melhorias.

\hypertarget{definiuxe7uxe3o-do-problema}{%
\section{Definição do problema}\label{definiuxe7uxe3o-do-problema}}

O problema a ser trabalhado é um caso de \emph{aprendizado fracamente
supervisionado} (\protect\hyperlink{ref-zhou2018}{ZHOU, 2018}). Trata-se
de uma generalização do aprendizado supervisionado e do aprendizado
\emph{semi-supervisionado}. Usualmente, a área de aprendizado
estatístico (ou aprendizado de máquinas) se concentra em dois tipos de
problemas principais: o aprendizado supervisionado e o aprendizado não
supervisionado. Isso ocorre principalmente por fins didáticos, pois é
mais fácil passar os modelos que fazem parte de cada área.

No entanto, a estatística evolui com os problemas que ocorrem no mundo.
No mundo, os problemas nem sempre recaem em uma ou outra categoria. O
que temos, na verdade, é que os problemas não supervisionados e
supervisionados estão conectados quando o objetivo da pesquisa é
predizer valores (regressão) ou categorias (classificação).

Nesse sentido, uma área que ficou popular nos últimos anos, até por
conta dos avanços na área de \emph{deep learning}, é o \emph{aprendizado
semi-supervisionado} (\protect\hyperlink{ref-zhu2005}{ZHU, 2005}).
Trata-se de uma classe de problemas contendo uma amostra completamente
anotada e uma amostra sem anotações. A amostra sem anotações é usada
para compreender como os dados foram gerados, e os parâmetros podem ser
compartilhados com a parte supervisionada do modelo. Isso poderia
indicar que existem três classes de problemas: o não supervisionado, o
supervisionado e o semi-supervisionado.

Mas isso também não representa todas as classes de problemas. Em muitas
aplicações reais, obter uma anotação completa e correta pode ser custoso
ou até impraticável. Além disso, por envolver trabalho humano, é comum
que classificações contenham erros. A área que generaliza os casos
anteriores é o aprendizado fracamente supervisionado.

Aprendizado fracamente supervisionado é um termo guarda-chuva. Dentro da
área existem diversos tipos de problemas, como aprendizado
semi-supervisionado, aprendizado de múltiplas instâncias
(\protect\hyperlink{ref-blum1998}{BLUM; KALAI, 1998}) e o aprendizado
com rótulos incorretos ou incompletos
(\protect\hyperlink{ref-zhou2018}{ZHOU, 2018}). O método WAWL é um
exemplo de aplicação de uma classe chamada \textbf{\emph{aprendizado com
rótulos parciais}} (\emph{partial label learning}, PLL, JIN; GHAHRAMANI
(\protect\hyperlink{ref-jin2002}{2002})). Essa classe apresenta uma
especialização ainda mais próxima do problema estudado, chamado
\textbf{\emph{aprendizado com rótulos complementares}}
(\emph{complementary label learning}, ISHIDA et al.
(\protect\hyperlink{ref-ishida2017}{2017})).

A interpretação do Captcha como um problema de PLL será apresentada no
final do capítulo. A jornada começa descrevendo um pouco melhor os
Captchas, que são o objeto de análise do trabalho.

\hypertarget{sec-definicao-captcha}{%
\subsection{Captcha}\label{sec-definicao-captcha}}

Captcha é um \emph{desafio} do tipo \emph{desafio-resposta} usado para
determinar se o usuário do sistema é um humano. Existem diversos tipos
de Captcha diferentes, que envolvem a identificação de textos em imagens
até a resolução de expressões matemáticas complexas.

O foco deste trabalho reside nos Captchas baseados em imagens rotuladas,
que é o tipo mais comum. Em seguida, a menos que se mencione ao
contrário, todas as menções a Captchas se referem a este tipo.

O fluxo completo de um Captcha envolve cinco componentes: um
\emph{rótulo}, um \emph{gerador}, uma \emph{imagem}, um agente e um
\emph{oráculo}. O ciclo de um Captcha é completado ao seguir os passos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  O rótulo (segredo) é definido, usualmente com algum procedimento
  aleatório, ocultado do agente.
\item
  A imagem é gerada a partir do rótulo e apresentada para o agente.
\item
  O agente produz uma ou mais respostas a partir da imagem (que pode
  estar certa ou errada)
\item
  O oráculo verifica se a resposta está correta.
\item
  Dependendo da resposta, o agente é direcionado para a página
  autenticada ou para uma página de erro.
\end{enumerate}

A Figura~\ref{fig-esquema-captcha} esquematiza o fluxo do Captcha. As
caixas com fundo azul são passos realizados pelo servidor, de forma
oculta ao agente. As caixas em branco são interações do agente com o
site. O agente pode ser tanto um ser humano quanto um robô imitando um
ser humano.

\begin{figure}

{\centering \includegraphics{./assets/img/esquema-captcha.png}

}

\caption{\label{fig-esquema-captcha}Fluxo do Captcha}

\end{figure}

Dependendo da forma que um Captcha foi construído, existe a
possibilidade de realizar \textbf{múltiplas tentativas} (chutes) para
acertar o rótulo. Isso pode ocorrer tanto por uma escolha deliberada dos
desenvolvedores do Captcha quanto por falhas na construção do site. A
possibilidade de realizar múltiplos chutes pode ter impactos positivos
nos resultados do método WAWL, como será visto no
Capítulo~\ref{sec-results}.

\hypertarget{imagem-ruxf3tulo-e-variuxe1vel-resposta}{%
\subsubsection{Imagem, rótulo e variável
resposta}\label{imagem-ruxf3tulo-e-variuxe1vel-resposta}}

A imagem é uma matriz
\(\mathbf x = \{x_{nmr} \in [0,1]\}_{N\times M \times R}\), contendo
padrões que levam ao rótulo do Captcha. O \emph{rótulo} é dado por um
vetor de caracteres \(\mathbf c = [c_1,\dots,c_L]^\top\). O comprimento
\(L\) pode ser fixo ou variável, ou seja, duas imagens criadas pelo
mesmo gerador podem vir com comprimentos diferentes. Nas definições que
seguem considerou-se \(L\) como fixo, por simplicidade.

Captchas costumam ter dimensões relativamente pequenas, com a altura
\(N\) variando entre 30 e 200 \emph{pixels} e a largura \(M\) variando
entre 100 e 300 \emph{pixels}. As imagens costumam ser retangulares para
comportar várias letras lado a lado, ou seja, geralmente \(M > N\). O
valor de \(R\) é 1 para imagens em escala de cinza e 3 para imagens
coloridas.

O elemento da matriz \(x_{nm\cdot}\) é denominado \emph{pixel}. Um pixel
é um vetor de comprimento \(R\) que representa a menor unidade da
imagem. Em uma imagem colorida, por exemplo, \(R=3\), sendo o pixel um
vetor de três dimensões com valores entre zero e um, representando a
intensidade de vermelho, verde e azul da coordenada \((n, m)\) da
imagem. Em imagens em escala de cinza, \(R=1\) e o pixel, de uma
dimensão, representa a intensidade do cinza, sendo 1 o equivalente da
cor branca e 0 da cor preta.

Os elementos do vetor \(\mathbf c\) fazem parte de um alfabeto
\(\mathcal A\), com cardinalidade \(|\mathcal A|\), finito e conhecido.
O alfabeto contém todos os possíveis caracteres que podem aparecer na
imagem. Na maioria dos casos, \(\mathcal A\) corresponde a uma
combinação de algarismos arábicos (0-9) e letras do alfabeto latino
(a-z), podendo diferenciar ou não as letras maiúsculas e
minúsculas\footnote{existem exemplos de Captchas baseados em imagens que
  não são limitados a letras e números para constituir o rótulo
  (\protect\hyperlink{ref-kaur2014}{KAUR; BEHAL, 2014}). Como esses
  casos não aparecem nas aplicações práticas de interesse, estão fora do
  escopo do trabalho.}.

A Figura~\ref{fig-exemplo-tjmg} mostra um exemplo Captcha do Tribunal de
Justiça de Minas Gerais (TJMG). Nesse caso, tem-se \(L=5\) e
\(|\mathcal A|=10\), apenas os dez algarismos arábicos. A imagem tem
dimensões \(N=110\), \(M=40\) e \(R=3\). O rótulo da imagem é
\([5,2,4,3,2]^\top\).

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/tjmg16283c1e6d06.jpeg}

}

\caption{\label{fig-exemplo-tjmg}Exemplo de Captcha no TJMG}

\end{figure}

A \textbf{variável resposta} é uma matriz binária
\(\mathbf y_{L \times |\mathcal A|}\), em que cada linha representa um
dos valores do vetor \(\mathbf c\), enquanto as colunas possuem um
representante para cada elemento de \(\mathcal A\). Um elemento
\(y_{ij}\) vale 1 se o elemento \(i\) do rótulo \(\mathbf c\)
corresponde ao elemento \(j\) do alfabeto \(\mathcal A\), valendo zero
caso contrário. A variável resposta é uma transformação do rótulo
conhecida comumente na área de aprendizado estatístico como
\emph{one-hot encoding}.

Uma maneira alternativa de definir a variável resposta seria com um
vetor de índices representando cada elemento do alfabeto em um vetor. O
problema de trabalhar dessa forma é que a variável resposta
\(\mathbf y\) tem um número exponencial de combinações: o rótulo possui
\(L\) caracteres, sendo que cada caractere pode ter \(|\mathcal A|\)
valores, totalizando \(|\mathcal A|^L\) combinações. Por exemplo, um
Captcha com \(L=6\) letras e \(|\mathcal A| = 36\) possibilidades em
cada letra (26 letras do alfabeto latino e 10 algarismos arábicos),
possui um total de 2.176.782.336 (\(>\) 2 bilhões) combinações. Por
isso, modelar as imagens diretamente através de uma única variável
resposta categórica é tecnicamente inviável.

A forma \emph{one-hot} da resposta pode ser entendida como uma
\textbf{multinomial} \textbf{multivariada}
(\protect\hyperlink{ref-li2014}{LI; TSUNG; ZOU, 2014}). A resposta é
multivariada porque existem \(L\) caracteres na imagem e multinomial
porque existem \(|\mathcal A|\) possíveis caracteres em cada posição.
Dessa forma, é possível pensar que um modelo que resolve o Captcha
envolve \(L\) classificadores com resposta multinomial, cada um dando
conta de um dos caracteres. Os classificadores podem ser independentes e
podem até contar com etapas de pré-processamento separadas.

Seguindo o exemplo da Figura~\ref{fig-exemplo-tjmg}, é possível
representar o rótulo da seguinte forma:

\[
\mathbf c = \left[\begin{array}{c}
     5  \\
     2 \\
     4 \\
     3 \\
     2
\end{array}\right] \rightarrow \mathbf{y} = \left[\begin{array}{cccccccccc}
    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{array}\right]
\]

A forma da variável resposta facilita os trabalhos que seguem. Como será
visto mais adiante, o modelo de rede neural gerará uma matriz de
probabilidades que somam \(1\) em cada linha, contendo as probabilidades
atribuídas a cada caractere nas posições da matriz.

\hypertarget{gerador}{%
\subsubsection{Gerador}\label{gerador}}

O \textbf{gerador} é uma função que recebe um rótulo como entrada e
devolve uma imagem como saída. Um bom gerador é aquele que é capaz de
gerar uma imagem fácil de interpretar por humanos, mas difícil de
interpretar por robôs.

Um exemplo de gerador é a função \texttt{captcha\_generate()} criada no
pacote \texttt{\{captcha\}}, que foi descrito em maiores detalhes na
Seção~\ref{sec-pacote-captcha}. A função foi criada para realizar
simulações do sistema de resolução proposto na tese, a partir do pacote
\texttt{\{magick\}} (\protect\hyperlink{ref-magick}{OOMS, 2021}), que
utiliza o \emph{software} \emph{ImageMagick}. A função aplica uma série
de distorções e efeitos comuns no contexto de Captchas, gerando imagens
como a da Figura~\ref{fig-captcha-r-exemplo}.

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./metodologia_files/figure-pdf/fig-captcha-r-exemplo-1.pdf}

}

\caption{\label{fig-captcha-r-exemplo}Exemplo de captcha gerado pela
função \texttt{captcha::captcha\_generate()}}

\end{figure}

O gerador segue os passos abaixo, a partir do momento em que um rótulo
\(\mathbf c\) existe:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  É criada uma matriz \(N\times M \times R\), com valores entre zero e
  um gerados por simulações de uma \(\mathcal U(0,1)\).
\item
  É adicionada uma cor base ao ruído, definida de forma aleatória.
\item
  A matriz é transformada em um objeto do tipo \texttt{magick-image}.
\item
  A imagem é preenchida com o valor do rótulo, adicionando-se efeitos
  como rotação, uma linha unindo as letras e variação de cores.
\item
  A imagem recebe outros tipos de distorções, como adição de ruído,
  alteração de cores e outros efeitos.
\end{enumerate}

No final, o gerador retorna a imagem, que é a única informação enviada
ao agente. O rótulo fica escondido para verificação do oráculo.

\hypertarget{sec-oraculo}{%
\subsubsection{Oráculo}\label{sec-oraculo}}

Para definir o oráculo, utilizou-se uma terminologia que é facilmente
encaixada com a teoria de aprendizado fracamente supervisionado. Neste
caso, para facilitar a notação, considera-se uma resposta como uma
variável multinomial, sem ser multivariada, denotada por \(y\). Seja
\(f\) um classificador utilizado para predizer o rótulo de uma imagem e
seja \(\mathbf x_{n+1}\) uma nova imagem que é observada, com sua
resposta \(y_{n+1}\), desconhecida. A operação \(f(\mathbf x_{n+1})\)
retorna um candidato para \(y_{n+1}\), que pode estar correto ou errado.

O oráculo é uma função
\(\mathcal O: \mathcal Y \rightarrow 2^{\mathcal Y}\), que recebe um
elemento do domínio da resposta \(\mathcal Y\) (do conjunto de todas as
combinações de rótulos) para o conjunto de subconjuntos (partes) de
\(\mathcal Y\). Na prática, a função retorna uma lista de possíveis
valores de \({y}_{n+1}\), da seguinte forma:

\[
\mathcal O(f(\mathbf x_{n+1})) = \left\{\begin{array}{ll}
    \{ y_{n+1}\}, & \text{ se } y_{n+1} = f(\mathbf x_{n+1})  \\
    \mathcal Y \setminus \{f(\mathbf x_{n+1})\}, & \text{ se } y_{n+1} \neq f(\mathbf x_{n+1})
\end{array}\right..
\]

Quando o classificador \(f\) acerta o rótulo, o oráculo retorna o valor
``1'', acompanhado de uma lista que contém apenas um elemento: o próprio
rótulo. Quando o classificador \(f\) retorna o rótulo errado, o oráculo
retorna o valor ``0'', acompanhado de uma lista com todos os outros
possíveis rótulos do rótulo, o que inclui o verdadeiro valor
\(y_{n+1}\). Para simplificar a notação, também é possível chamar essa
informação como o \emph{rótulo complementar}
\(\bar{\mathbf y} = \mathcal Y \setminus \{ \hat {y}_{n+1}\}\). Neste
caso utiliza-se o símbolo \(\bar{\mathbf y}\), indicando que é uma lista
valores possíveis de \(y\).

A Figura~\ref{fig-esquema-oraculo} mostra o funcionamento do oráculo no
exemplo do TJMG. Quando a predição é igual ao rótulo, o resultado
apresentado é o valor ``1'', indicando que o rótulo está correto. Quando
a predição é diferente do rótulo, o resultado apresentado é o valor
``0'', indicando que o valor testado está incorreto e que, portanto, o
rótulo real é um dentre todos os outros possíveis rótulos.

\begin{figure}

{\centering \includegraphics{./assets/img/esquema-oraculo.png}

}

\caption{\label{fig-esquema-oraculo}Esquema mostrando o funcionamento do
oráculo}

\end{figure}

É possível generalizar naturalmente o oráculo para Captchas que aceitam
múltiplos chutes mudando a definição da função que faz predições. Seja
\(\mathbf f\) uma função que retorna um conjunto de \(k\) respostas
possíveis, \(k\in \mathbb N\), \(k\geq 1\), com \(\mathbf x_{n+1}\) e
\(y_{n+1}\) iguais aos definidos anteriormente. Então o oráculo tem o
funcionamento definido abaixo:

\[
\mathcal O(\mathbf f(\mathbf x_{n+1})) = \left\{\begin{array}{ll}
    \{y_{n+1}\}, & \text{ se } y_{n+1} \in \mathbf f(\mathbf x_{n+1})  \\
   \mathcal Y \setminus \mathbf f(\mathbf x_{n+1}), & \text{ se } y_{n+1} \notin \mathbf f(\mathbf x_{n+1})
\end{array}\right..
\]

Nesse caso, o oráculo também retorna uma lista contendo a resposta
\(y_{n+1}\), além de outros valores. A única diferença é que, quando o
Captcha aceita múltiplos chutes, a lista retornada em caso de erro tem
um comprimento menor.

O oráculo tem um papel fundamental na elaboração do método WAWL. O fato
do oráculo sempre retornar a resposta correta na lista de opções faz com
que ele necessariamente reduza o espaço de respostas a serem buscadas em
uma tentativa futura.

\hypertarget{fatos-estilizados-dos-captchas}{%
\subsubsection{Fatos estilizados dos
Captchas}\label{fatos-estilizados-dos-captchas}}

Abaixo, listou-se três características e discussões comuns no contexto
dos Captchas, chamados \emph{fatos estilizados}. Estes pontos vão além
da evolução histórica dos Captchas e ajudam a contextualizar melhor o
problema.

\begin{itemize}
\item
  Uma alternativa para resolver Captchas é separando o problema em duas
  tarefas: segmentar e classificar. A tarefa de segmentação consiste em
  receber uma imagem com várias letras e detectar pontos de corte,
  separando-a em várias imagens de uma letra. Já a classificação
  consiste em receber uma imagem com uma letra e identificar o caractere
  correspondente. Nesse caso, a resposta é reduzida para
  \(|\mathcal A|\) categorias. Como \(|\mathcal A|\) cresce linearmente,
  o problema é tratável pelos algoritmos tradicionais de aprendizado.
\item
  A tarefa de resolver Captchas também poderia ser vista como um
  problema de reconhecimento óptico de caracteres (\emph{Optical
  Character Recognition}, OCR). No entanto, as distorções encontradas em
  Captchas são bem diferentes das distorções encontradas em textos
  escaneados, que são o objeto de aplicação de ferramentas de OCR. Por
  esse motivo, as ferramentas usuais de OCR apresentam resultados pouco
  satisfatórios em vários Captchas.
\item
  As distorções encontradas em Captchas podem ser agrupadas em
  distorções para dificultar a segmentação e distorções para dificultar
  a classificação. Na parte de classificação, as principais formas de
  dificultar o trabalho dos modelos são i) mudar as fontes (serifa ou
  sem serifa ou negrito/itálico, por exemplo), ii) mudar letras
  minúsculas para maiúsculas e iii) adicionar distorções nos caracteres.
  Já na parte de segmentação, as principais formas são i) colar os
  caracteres e ii) adicionar linhas ligando os dígitos. Essas técnicas
  são combinadas com a adição de ruído e distorção nas imagens completas
  para compor a imagem final.
\end{itemize}

\hypertarget{redes-neurais}{%
\subsection{Redes neurais}\label{redes-neurais}}

O método WAWL apresentado na Seção~\ref{sec-wawl} utiliza uma
arquitetura básica de redes neurais convolucionais. Por isso, é
importante apresentar as definições sobre redes neurais e sobre a
operação de convolução no contexto de Captchas.

O método WAWL pode utilizar diversas arquiteturas de redes neurais. A
escolha de uma arquitetura mais simples foi feita para demonstrar a
eficácia do procedimento de forma mais contundente. Outras arquiteturas
mais rebuscadas, como as apresentadas na introdução
(\protect\hyperlink{ref-george2017}{GEORGE et al., 2017};
\protect\hyperlink{ref-ye2018}{YE et al., 2018}) podem melhorar os
resultados do modelo. A única restrição é que ela possa receber uma
função de perda modificada, como será mostrado na na
Seção~\ref{sec-wawl}.

A seguir, apresenta-se como funcionam as redes neurais no contexto de
Captchas. O modelo descrito é o que foi utilizado nas simulações, que é
um modelo de redes neurais convolucionais simples, similar ao LeNet, com
três camadas convolucionais e duas camadas densas
(\protect\hyperlink{ref-lecun1998}{LECUN et al., 1998}).

É possível organizar a estrutura de uma rede neural em três componentes:
a \textbf{arquitetura da rede}, a \textbf{função de perda} e o
\textbf{otimizador}. Os componentes são detalhados nas próximas
subseções.

Como uma rede neural possui muitos componentes e subcomponentes, é usual
apresentar sua estrutura na forma de um diagrama. Redes neurais costumam
ser fáceis de representar através de grafos, que podem ser utilizados de
forma mais ou menos detalhada, dependendo do interesse.

A Figura~\ref{fig-diagrama-modelo-cnn} mostra, de forma esquemática, os
componentes (retângulos tracejados) e subcomponentes (partes internas
dos componentes) do modelo utilizado. As partes de fora dos componentes
são entradas de dados ou decisões de parada do ajuste.

\begin{figure}

{\centering \includegraphics{./assets/img/diagrama-modelo-cnn.png}

}

\caption{\label{fig-diagrama-modelo-cnn}Diagrama representando o modelo
utilizado de forma genérica, com todos os componentes e subcomponentes
apresentados de forma esquemática}

\end{figure}

\hypertarget{sec-arquitetura-rede}{%
\subsubsection{Arquitetura da rede}\label{sec-arquitetura-rede}}

A arquitetura da rede é uma função que leva os dados de entrada na
estrutura de dados (dimensões) da variável resposta. A arquitetura tem
papel similar ao exercido pelo componente sistemático em um modelo
linear generalizado (\protect\hyperlink{ref-nelder1972}{NELDER;
WEDDERBURN, 1972}). Trata-se da parte mais complexa da rede neural,
carregando todos os parâmetros que serão otimizados.

A arquitetura da rede possui três componentes principais, com algumas
subdivisões:

\begin{itemize}
\tightlist
\item
  as camadas ocultas: camadas \textbf{convolucionais} e camadas
  \textbf{densas};
\item
  as técnicas de regularização: \textbf{normalização em lote}
  (\emph{batch normalization}), \textbf{\emph{dropout}} e junção de
  pixels (\emph{max pooling});
\item
  as funções de ativação: função de ativação linear retificada
  (\emph{rectified linear unit}, ReLU) e a função de normalização
  exponencial (\emph{softmax}).
\end{itemize}

Abaixo, apresenta-se as definições seguindo-se a ordem de aplicação das
operações na arquitetura da rede neural: camada convolucional, ReLU,
\emph{max pooling}, \emph{batch normalization}, \emph{dropout}, camada
densa e \emph{softmax}.

A \textbf{convolução} é uma operação linear que recebe como entrada uma
matriz e retorna outra matriz. Ela é diferente de uma operação usual de
multiplicação de matrizes vista no contexto de modelos lineares
generalizados, por envolver uma soma ponderada dos elementos na
vizinhança de cada pixel.

Uma forma organizada de fazer a soma ponderada da convolução é criando
uma matriz de pesos. Com ela, não é necessário procurar os pontos da
vizinhança. Para cada ponto \((i,j)\), obtém-se a matriz de vizinhança,
multiplica-se pontualmente pela matriz de pesos e soma-se os valores
resultantes. A matriz de pesos é chamada de núcleo, ou \emph{kernel}.

Considere o \emph{kernel}

\[
K = \left[\begin{array}{rrr}-1&-1&-1\\0&0&0\\1&1&1\end{array}\right]
\]

e a imagem da Figura~\ref{fig-tjmg-exemplo-conv}. Como visto
anteriormente, trata-se de uma matriz de dimensão
\(40\times110\times3\).

\begin{figure}

{\centering \includegraphics[width=1.14583in,height=\textheight]{./assets/img/tjmg16283c1e6d06.jpeg}

}

\caption{\label{fig-tjmg-exemplo-conv}Imagem de Captcha utilizado em
exemplos anteriores}

\end{figure}

Tome por exemplo a primeira dimensão do pixel \((n,m,r) = (12,16,1)\). A
vizinhança 3x3 em torno desse ponto é dada por

\[
P_{n,m,r} = \left[\begin{array}{rrr}
0.094 & 0.412 & 0.686 \\ 
0.051 & 0.063 & 0.529 \\ 
0.071 & 0.000 & 0.086 
\end{array}\right].
\]

A operação de convolução é feita da seguinte forma:

\[
\begin{aligned}
(P_{12,16,1} *K )_{12,16,1}
&= k_{1,1}p_{11,15,1} + k_{1,2}p_{11,16,1} + k_{1,3}p_{11,17,1} + \\
&+ k_{2,1}p_{12,15,1} + k_{2,2}p_{12,16,1} + k_{2,3}p_{12,17,1} + \\
&+ k_{3,1}p_{13,15,1} + k_{3,2}p_{13,16,1} + k_{3,3}p_{13,17,1} \\
& = -1.035.
\end{aligned}
\]

Esse é o valor resultante da convolução, a ser colocado no ponto
\((i,j,k)\). A operação funciona da mesma forma em todos os pontos que
não estão na borda da imagem.

Existem duas formas de trabalhar com as bordas da imagem. A primeira é
preenchendo as bordas com zeros, de forma a considerar apenas os pontos
que estão na imagem na conta. A segunda é descartar os pontos da borda e
retornar uma imagem menor, contendo somente os pixels em que foi
possível aplicar todo o \emph{kernel}.

No caso do exemplo, o resultado da convolução fica como na
Figura~\ref{fig-tjmg-exemplo-conv-horizontal}. Como a imagem resultante
tem apenas uma dimensão, ela aparenta ficar em preto e branco. Na
prática, no entanto, serão aplicados vários núcleos diferentes,
resultando em uma imagem com várias cores, que são chamados de
\emph{canais}.

A matriz de exemplo não foi escolhida por acaso: ela serve para destacar
padrões horizontais da imagem. Como a primeira linha é formada por
\(-1\) e a última é formada por \(1\), a matriz fica com valor alto se a
parte de cima do pixel for preta e a parte de baixo for branca
(\(\text{grande} * 1 + \text{pequeno} * (-1)\)). A parte destacada da
imagem acabou sendo a parte de baixo dos números e, principalmente, a
linha que une os números.

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/tjmg_conv_horizontal.jpeg}

}

\caption{\label{fig-tjmg-exemplo-conv-horizontal}Aplicação de uma
convolução com kernel horizontal}

\end{figure}

Aplicando o kernel vertical abaixo

\[
K = \left[\begin{array}{rrr}-1&0&1\\-1&0&1\\-1&0&1\end{array}\right],
\]

as partes destacadas são as laterais dos números, conforme
Figura~\ref{fig-tjmg-exemplo-conv-vertical}.

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/tjmg_conv_vertical.jpeg}

}

\caption{\label{fig-tjmg-exemplo-conv-vertical}Aplicação de uma
convolução com kernel vertical}

\end{figure}

O resultado da convolução pode ter números negativos ou maiores que um.
Para que seja possível visualizar, os números das imagens mostradas
acima foram ajustados para que ficassem no intervalo \([0,1]\).

Uma característica das imagens mostradas acima é que elas ficaram
escuras, ou seja, com muitos valores próximos de zero. Uma técnica para
modificar a imagem é adicionar uma constante numérica ao resultado da
convolução. Esse é o chamado \textbf{viés} (\emph{bias}) da convolução.

A Figura~\ref{fig-tjmg-exemplo-conv-vertical-bias} mostra o efeito de
adicionar um viés de \texttt{0.6} após aplicação da convolução com
kernel vertical. É possível identificar claramente a diferença entre os
números (mais suaves) e as curvas usadas para conectar os números (mais
proeminentes).

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/tjmg_conv_vertical_bias.jpeg}

}

\caption{\label{fig-tjmg-exemplo-conv-vertical-bias}Aplicação de uma
convolução com kernel vertical e viés}

\end{figure}

Uma \textbf{camada convolucional} envolve a aplicação de convoluções com
\(d\) \emph{kernels} em uma matriz, além da adição do \emph{bias}. Tais
\emph{kernels}, bem como o intercepto, terão seus valores ajustados ao
longo do processo de otimização do modelo. O resultado da aplicação de
uma camada convolucional com preenchimento das bordas é uma matriz com
as mesmas dimensões \(N\) e \(M\) da matriz de entrada, mas com \(d\)
entradas na dimensão das cores. Como o valor de \(d\) pode ser diferente
de 1 ou 3, não faz mais sentido tratar essa dimensão como responsável
pelas cores. Por isso essa dimensão é chamada de \textbf{canais} da
matriz resultante.

A Figura~\ref{fig-tjmg-exemplo-camada-conv} mostra a aplicação de uma
camada convolucional para a imagem utilizada nos exemplos anteriores. Os
\emph{kernels} foram escolhidos com base em um modelo que já foi
ajustado para o Captcha. Note que os canais capturam a informação dos
números e dos ruídos, focando em detalhes diferentes.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./assets/img/tjmg_conv1_modelo.jpeg}

}

\caption{\label{fig-tjmg-exemplo-camada-conv}Resultado da aplicação da
primeira convolução à imagem}

\end{figure}

Antes da aplicação da camada convolucional, a operação de
\textbf{\emph{batch normalization}} é aplicada. Essa operação normaliza
os números da matriz de entrada antes da aplicação da convolução,
retirando a média e dividindo pelo desvio padrão, conforme equação
abaixo.

\[
x_z = \left(\frac{x-\bar x}{\sqrt{\sigma^2_x + \epsilon}}\right) \gamma + \beta
\]

Na equação acima, o valor \(\epsilon\), geralmente um valor pequeno, é
adicionado para evitar problemas numéricos quando a variância é muito
baixa. Os parâmetros \(\gamma\) e \(\beta\) podem ser adicionados no
passo da normalização, fazendo parte do fluxo de aprendizagem do modelo.
Apesar de não ser uma teoria fechada, alguns resultados indicam que o
uso de \emph{batch normalization} reduz o tempo de aprendizado dos
modelos (\protect\hyperlink{ref-ioffe2015}{IOFFE; SZEGEDY, 2015}). O
passo foi adicionado nos modelos por apresentar bons resultados nas
simulações.

Após a aplicação da convolução, também é aplicada a função não linear
\textbf{ReLU}. A transformação ReLU é a mais simples das funções da
ativação na teoria de redes neurais, sendo igual à função identidade
quando a entrada é positiva e zero caso contrário:

\[
\text{ReLU}(x) = xI_{(x>0)}.
\]

A função ReLU serve para tornar a arquitetura do modelo uma operação não
linear. Qualquer operação não linear poderia ser utilizada, mas a mais
simples e mais popular é a ReLU.

Em seguida, aplica-se uma operação para reduzir a dimensão da imagem,
chamada \textbf{\emph{max pooling}}. Trata-se de uma operação que recebe
a imagem e um \emph{kernel}, retornando, para cada janela, o maior valor
dos pixels presentes neste \emph{kernel}. Usualmente, a técnica também
utiliza \emph{strides}, pulando as interseções entre janelas e fazendo
com que cada pixel seja avaliado apenas uma vez. Por exemplo, para uma
matriz com dimensões \(M_{10\times10}\) e \emph{kernel} com dimensões
\(2\times2\), aplica-se uma redução pelo fator de \(2\) tanto nas linhas
quanto nas colunas, resultando em uma matriz \(M^p_{5\times5}\), onde
cada elemento é o valor máximo de cada janela \(2\times2\)
correspondente ao pixel.

A Figura~\ref{fig-tjmg-exemplo-camada-conv-max-pool} mostra um exemplo
de operação \emph{max pooling} aplicada ao Captcha. É possível notar que
a imagem fica simplificada se comparada com a original. A operação
\emph{max pooling} é muito comum no contexto de redes neurais
convolucionais, pois permite que os \emph{kernels} sejam aplicados em
diferentes níveis de \emph{zoom} da imagem de entrada.

\begin{figure}

{\centering \includegraphics[width=0.6\textwidth,height=\textheight]{./assets/img/tjmg_conv1_modelo_max_pool.jpeg}

}

\caption{\label{fig-tjmg-exemplo-camada-conv-max-pool}Resultado da
aplicação da primeira convolução à imagem e da operação de \emph{max
pooling}}

\end{figure}

A aplicação das camadas convolucionais é repetida três vezes. Ou seja,
as seguintes operações são aplicadas a partir da imagem original:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{batch normalization}: 6 parâmetros
\item
  camada convolucional: 896 parâmetros
\item
  ReLU
\item
  \emph{max pooling}
\item
  \emph{batch normalization}: 64 parâmetros
\item
  camada convolucional: 18.496 parâmetros
\item
  ReLU
\item
  \emph{max pooling}
\item
  \emph{batch normalization}: 128 parâmetros
\item
  camada convolucional: 36.928 parâmetros
\item
  ReLU
\item
  \emph{max pooling}
\item
  \emph{batch normalization}: 128 parâmetros.
\end{enumerate}

A dimensão da imagem de entrada, bem como quantidade de canais gerados
por cada camada convolucional foram fixadas. Tais números podem ser
considerados como hiperparâmetros do modelo, mas foram fixados para
facilitar as simulações, que já contam com diversos hiperparâmetros.

A imagem de entrada foi fixada na dimensão \(32\times192\). O valor foi
definido dessa forma porque um dos Captchas de referência, da Receita
Federal do Brasil (RFB), possui 6 letras e porque \(32*6=192\). Ou seja,
é como se a imagem fosse a colagem lado a lado de 6 imagens
\(32\times32\).

A quantidade de canais gerados pelas camadas convolucionais foram
fixadas em 32, 64 e 64, respectivamente. Ou seja, a primeira camada
convolucional retorna uma imagem com 32 canais, a segunda camada
convolucional retorna uma imagem com 64 canais, e a terceira camada
convolucional retorna uma imagem com 64 canais. A utilização de números
não-decrescentes de canais nas camadas convolucionais é comum
(\protect\hyperlink{ref-lecun1998}{LECUN et al., 1998}), bem como a
utilização de números que são potências de 2
(\protect\hyperlink{ref-lecun2015}{LECUN; BENGIO; HINTON, 2015}), apesar
dessa última escolha não ser necessária. Nesse sentido, um possível
valor para a terceira camada era de 128 canais, mas optou-se por 64
canais para que a quantidade de parâmetros não ficasse grande demais, já
que isso exigiria mais tempo de computação ou computadores mais
poderosos.

O total de parâmetros que podem ser otimizados até o final das camadas
convolucionais é 56.646. Esse número pode parecer grande no contexto de
modelos estatísticos tradicionais como uma regressão linear, que teria,
considerando cada pixel como uma covariável, 4.401 parâmetros
(\(40\times110\) e o intercepto). No entanto, é uma quantidade
relativamente pequena no contexto de redes neurais. Redes neurais
recentes aplicadas a imagens, como o DALL-E 2 possui 3,5 bilhões de
parâmetros
(\protect\hyperlink{ref-rameshHierarchicalTextConditionalImage2022}{RAMESH
et al., 2022}).

Em seguida, o resultado é transformado para um formato retangular,
similar ao que se encontra em modelos de regressão. Aqui, as dimensões
da imagem não são mais importantes e os pixels de cada canal são
tratados como variáveis preditoras. Esse passo pode ser interpretado da
seguinte forma: as camadas convolucionais funcionam como um
pré-processamento aplicado às imagens, aplicando uma engenharia de
variáveis (\protect\hyperlink{ref-kuhn2019}{KUHN; JOHNSON, 2019}). No
entanto, trata-se de uma engenharia de variáveis otimizada, já que os
parâmetros da operação fazem parte do ajuste do modelo.

Uma vez obtidas as variáveis preditoras com o pré-processamento, é hora
de aplicar as camadas densas. Tais camadas são as mais comuns no
contexto de redes neurais. Nesse caso, a operação linear aplicada é uma
multiplicação de matrizes, similar ao que é feito em um modelo linear
generalizado. Na verdade, o componente sistemático de um modelo linear
generalizado é equivalente a uma camada densa com a aplicação de viés,
com a função de ativação (como, por exemplo, uma ativação sigmoide)
fazendo o papel da função de ligação. Na rede neural utilizada no
modelo, todas as camadas possuem ativação ReLU, com exceção da última,
que utiliza ativação \emph{softmax}.

Assim como existem os canais das camadas convolucionais, existem os
filtros das camadas densas. A quantidade de filtros define a dimensão do
vetor de saída. O número de parâmetros da camada densa é igual ao número
de itens no vetor de entrada multiplicado pelo número de filtros, somado
à quantidade de filtros novamente, por conta do \emph{bias}. No caso do
exemplo, a saída das camadas convolucionais tem dimensão
\(2\times22\times64\), ou seja, 64 canais de imagens \(2\times 22\). Com
a transformação em vetor, concatenando lado a lado os dados dos canais
resultantes, a quantidade de colunas da base passa a ser a multiplicação
das dimensões, ou 2.816. No modelo ajustado que foi utilizado como
exemplo, aplicou-se 200 filtros na camada densa, totalizando 563.400
parâmetros. Esses parâmetros são os pesos que multiplicam os valores em
cada camada convolucional, passando pela função de ativação ReLU e pelas
camadas densas. Nas simulações, a quantidade de filtros foi variada para
produzir modelos com mais ou menos parâmetros de ajuste.

É no contexto da grande quantidade de parâmetros que entra o conceito do
\emph{dropout} (\protect\hyperlink{ref-baldi2013}{BALDI; SADOWSKI,
2013}). Muitos parâmetros podem levar a sobreajuste do modelo, que acaba
precisando de técnicas de regularização para funcionar bem. O
\emph{dropout} é uma regra de regularização simples de implementar, mas
que possui boas propriedades de regularização. A técnica consiste em
selecionar uma amostra dos parâmetros em uma das camadas e apagá-los,
forçando que os valores sejam fixados em zero. Na prática, essa técnica
obriga o modelo a ser ajustado de forma que amostras aleatórias dos
parâmetros sejam boas para predizer a variável resposta. Quando o modelo
é usado para predições, o \emph{dropout} é desativado e o modelo pode
utilizar todos os parâmetros, obtendo-se, na prática, uma média
ponderada das predições de cada submodelo.

O primeiro \emph{dropout} é aplicado após a finalização das camadas
convolucionais. Em seguida, vem a primeira camada densa, um ReLU e um
\emph{batch normalization}. Depois, é aplicada mais um \emph{dropout} e
mais uma camada densa. Com isso, a aplicação de operações é finalizada.
O total de parâmetros na configuração do modelo apresentado foi de
630.496. Os modelos mais simples utilizados nas simulações, com 100
filtros na camada densa, têm 343.696 parâmetros. Os mais complexos, com
300 filtros na camada densa, têm 917.396 parâmetros.

Para finalizar a arquitetura do modelo, as quantidades resultantes devem
ser ajustadas ao formato da variável resposta. O número de filtros da
segunda camada densa precisa ser escolhido cuidadosamente, pois deve ser
igual à multiplicação das dimensões da variável resposta. No caso do
TJMG, os rótulos têm comprimento igual a 5 e vocabulário de comprimento
10 (algarismos arábicos), organizados em uma matriz \(5\times10\), com
50 entradas. Por isso, a quantidade de filtros da última camada densa
também é 50, e o vetor de saída é formatado para uma matriz de dimensão
\(5\times10\).

No final, o resultado precisa ser normalizado para que fique no mesmo
escopo de variação da resposta. A resposta possui apenas zeros e uns,
sendo que cada linha da matriz tem somente um número ``1'',
correspondendo ao índice do rótulo no alfabeto e, nas outras entradas, o
valor zero. A saída do modelo deve, portanto, apresentar números entre
zero e um que somam 1 em cada linha.

Isso é feito através da função \emph{softmax}, aplicada a cada linha da
matriz de saída. A função softmax é uma normalização que utiliza a
função exponencial no denominador, forçando que a soma dos valores do
vetor seja um.

\[
\text{soft}\max(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{|\mathcal A|} e^{y_j}}.
\]

No exemplo, a saída do modelo é a matriz abaixo:

\[
\hat{\mathbf z} = \left[\begin{array}{rrrrrrrrrr}
  -17.5 & -13.5 & -15.4 & -6.6 & -9.9 & 9.9 & -11.4 & -10.9 & -11.8 & -9.3 \\ 
  -10.9 & -15.6 & 8.3 & -6.5 & -11.0 & -10.3 & -10.0 & -5.8 & -11.4 & -15.1 \\ 
  -10.5 & -13.6 & -9.6 & -11.4 & 11.2 & -14.3 & -9.9 & -11.3 & -9.9 & -10.0 \\ 
  -18.1 & -9.6 & -10.9 & 5.3 & -10.1 & -6.6 & -15.5 & -13.3 & -6.8 & -10.8 \\ 
  -11.3 & -8.7 & 6.4 & -7.0 & -6.1 & -9.2 & -18.9 & -10.3 & -16.1 & -9.6 \\ 
\end{array}\right].
\]

Note que a matriz apresenta valores negativos e positivos. Na primeira
linha, por exemplo, o valor positivo está na sexta coluna,
correspondendo ao algarismo ``5''. De fato, esse é o valor do primeiro
elemento do rótulo para esta imagem. Após a aplicação do \emph{softmax},
a matriz de predições obtida é a matriz abaixo\footnote{A matriz foi
  multiplicada por 1000 para não extrapolar as margens do documento.}. O
modelo de exemplo aparenta ter confiança nas respostas, já que dá
probabilidades bem altas para alguns valores e quase zero para outros
valores.

\[
\hat{\mathbf Y}\times 1000 = \left[\begin{array}{rrrrrrrrrr}
  0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 \\ 
  0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\ 
  0.00 & 0.00 & 0.00 & 0.00 & 1000.0 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\ 
  0.00 & 0.00 & 0.00 & 999.99 & 0.00 & 0.01 & 0.00 & 0.00 & 0.00 & 0.00 \\ 
  0.00 & 0.00 & 999.99 & 0.00 & 0.00 & 0.00 & 0.00 & 0.01 & 0.00 & 0.00 \\
\end{array}\right].
\]

Vale notar que, dependendo da implementação, nem sempre é necessário
aplicar a função \emph{softmax}. Em alguns pacotes computacionais como o
\texttt{torch}\footnote{Mais sobre o (py)torch:
  \url{https://pytorch.org}. Último acesso em 22 de novembro de 2022.},
utilizado nesta tese, a normalização pode ser feita diretamente na
função de perda, que aproveita a expressão completa para realizar
algumas simplificações matemáticas e, com isso, melhorar a precisão das
computações. O uso da função de perda ficará claro na próxima subseção.

\hypertarget{sec-funcao-perda-original}{%
\subsubsection{Perda}\label{sec-funcao-perda-original}}

A função de perda utilizada em um problema de classificação deve levar
em conta as probabilidades (ou pesos) associadas aos rótulos. A perda
deve ser pequena se a probabilidade associada ao rótulo correto for alta
e deve ser grande se a probabilidade associada ao rótulo correto for
baixa.

Uma função de perda natural e popular nesse sentido é a de entropia
cruzada, ou \emph{cross-entropy}. Trata-se de uma perda com a formulação

\begin{equation}\protect\hypertarget{eq-perda-crossentropy}{}{
\mathcal L(g(x), y) = -\sum_{i=1}^c I(y=i)\log(g_i(x)).
}\label{eq-perda-crossentropy}\end{equation}

Na equação, \(g_i(x)\) é a probabilidade dada ao rótulo \(i\) pela
função \(g\). Se o rótulo \(i\) é diferente do rótulo correto \(y\), a
função de perda vale zero por conta da função indicadora. Quando
\(i=y\), a perda é igual ao oposto do logaritmo da probabilidade
associada ao rótulo \(i\). Quanto menor a probabilidade, maior o valor
da perda.

Ao trabalhar com o oráculo, a entropia cruzada passa a não fazer sentido
nos casos em que o modelo inicial erra. Por isso, a função de perda será
adaptada no método WAWL. Essa é a única modificação estritamente
necessária para aplicar o método.

\hypertarget{sec-otimizador}{%
\subsubsection{Otimizador}\label{sec-otimizador}}

O otimizador utilizado para os modelos ajustados na tese foi o ADAM
(\protect\hyperlink{ref-kingmaAdamMethodStochastic2017}{KINGMA; BA,
2017}). A sigla significa \emph{Adaptive Moment Estimator} e funciona
como uma extensão da descida de gradiente estocástica
(\protect\hyperlink{ref-lecun2012}{LECUN et al., 2012}). Considere que
\(\theta\) é o conjunto de todos os parâmetros do modelo, ou seja, os
parâmetros das camadas convolucionais, densas e \emph{batch
normalization}. Os parâmetros são atualizados da seguinte forma:

\[
\begin{array}{cl}
m_{\theta}^{(t+1)} &\leftarrow \beta_1m_{\theta}^{(t)} + (1-\beta_1)\nabla_\theta \mathcal{L}^{(t)} \\
v_{\theta}^{(t+1)} &\leftarrow \beta_2v_{\theta}^{(t)} + (1-\beta_2)(\nabla_\theta \mathcal{L}^{(t)})^2 \\
\hat{m}_{\theta} &= \frac{m_\theta^{(t+1)}}{1-\beta_1^t} \\
\hat{v}_{\theta} &= \frac{v_\theta^{(t+1)}}{1-\beta_2^t} \\
\theta^{(t+1)} &\leftarrow \theta^{(t)} - \eta \frac{\hat{m}_{\theta}}{\sqrt{\hat{v}_{\theta}} + \epsilon}.
\end{array}
\]

Na equação, \(m\) e \(v\) são médias móveis para atualização dos
parâmetros, ponderando a perda e a perda ao quadrado com o passo
anterior usando pesos \(\beta_1\) e \(\beta_2\), respectivamente. Nessa
notação \(\eta\) é a taxa de aprendizado, um hiperparâmetro a ser
ajustado. Por último, o valor de \(\epsilon\) é uma constante,
usualmente pequena, para evitar divisão por zero.

Ainda que o ADAM seja um método adaptativo, pode ser vantajoso
considerar uma taxa de decaimento no parâmetro \(\eta\). Esse fator pode
ser desnecessário em alguns casos, mas pode auxiliar o modelo a dar
passos menores quando o modelo já está com uma acurácia razoável. Neste
trabalho, foram consideradas alguns valores de decaimento na taxa de
aprendizado, como \texttt{1\%} ou \texttt{3\%} de decaimento ao final de
cada época, ou seja, ao final de cada ciclo de particionamento da base.

\hypertarget{sec-aprendizado-estatistico}{%
\subsection{Aprendizado estatístico}\label{sec-aprendizado-estatistico}}

Apresentados o objeto de estudo e as redes neurais utilizadas, passa-se
a discutir o significado disso tudo no contexto de aprendizado
estatístico. Essa parte foi escrita para proporcionar a base teórica
para apresentar o modelo WAWL.

O aprendizado fracamente supervisionado pode ser dividido em três tipos
principais. A supervisão com erros, a supervisão com rótulos incompletos
e a supervisão de grupos de observações. O caso do Captcha pode ser
entendido como uma subárea do aprendizado fracamente supervisionado com
rótulos incompletos chamada aprendizado com dados parcialmente rotulados
(PLL), já que uma parte da base pode ser anotada sem erros e uma parte
da base é a resposta do oráculo indicando uma lista de rótulos
possíveis, incluindo o correto.

A área de PLL não é nova
(\protect\hyperlink{ref-grandvalet2002}{GRANDVALET, 2002}) e aparece com
outros nomes, como aprendizado com rótulos ambiguos
(\protect\hyperlink{ref-hullermeier2006}{HÜLLERMEIER; BERINGER, 2006}) e
aprendizado de rótulos em superconjuntos (\emph{superset-label
learning)} (\protect\hyperlink{ref-liu2012}{LIU; DIETTERICH, 2012}). Um
caso particular de PLL, aplicável ao tema do Captcha são rótulos
complementares (\protect\hyperlink{ref-ishida2017}{ISHIDA et al.,
2017}), que considera os chutes errados na notação do problema.

As definições seguem uma terminologia adaptada a partir da leitura de
JIN; GHAHRAMANI (\protect\hyperlink{ref-jin2002}{2002}), COUR; SAPP;
TASKAR (\protect\hyperlink{ref-cour2011}{2011}) e FENG et al.
(\protect\hyperlink{ref-feng2020}{2020a}). Sempre que possível, os casos
são adaptados para o problema do Captcha diretamente. Para simplificar a
notação, no entanto, foi considerado o problema univariado do Captcha,
ou seja, como se uma imagem tivesse apenas uma letra. Não há perda de
generalidade nessa escolha, já que o problema do Captcha pode ser, de
fato, separado em vários problemas, um para cada letra da imagem.

Em um problema de aprendizado supervisionado tradicional, tem-se um
conjunto de \(S\) casos rotulados
\(\{(\mathbf x_i,y_i), i=1,\dots, S\}\) com uma distribuição
\(p(\mathbf x,y)\) desconhecida, onde \(\mathbf x\) é uma imagem e \(y\)
é o rótulo, que possui \(|\mathcal A|\) possíveis valores. O objetivo é
obter um classificador \(f\) que leva um valor de \(\mathbf x\) para o
rótulo correto \(y\).

Para delimitar se o classificador está bom ou ruim, utiliza-se uma
função de perda. No caso do Captcha, como o interesse é simplesmente
acertar o rótulo inteiro (não importa se o classificador acerta só uma
parte do rótulo), utiliza-se uma função chamada 0-1:

\begin{equation}\protect\hypertarget{eq-perda}{}{
\mathcal L(f(\mathbf x),y) = I (f(\mathbf x) \neq y).
}\label{eq-perda}\end{equation}

Na equação, \(I(\cdot)\) é uma função indicadora. Como a função de perda
é aplicada a apenas um par \((\mathbf x,y)\), define-se que o objetivo
do problema de aprendizado é minimizar o \emph{risco}, que é o valor
esperado da função de perda, calculado para as variáveis aleatórias
\(\mathbf X\) e \(Y\):

\begin{equation}\protect\hypertarget{eq-risco}{}{
\mathcal R(g) = \mathbb E_{p(\mathbf x,y)}[\mathcal L(g(\mathbf X),Y)].
}\label{eq-risco}\end{equation}

A função de risco, no entanto, não é observada, já que depende da
distribuição desconhecida de \(p(\mathbf x,y)\). Por isso, utiliza-se um
estimador do risco, que pode ser calculado em uma amostra, como uma base
usada na validação cruzada ou na base de teste. Para uma amostra com
\(S\) observações, tem-se

\[
\hat{\mathcal R}(g) = \sum_{s=1}^S \mathcal L(g(\mathbf x_s),y_s))
\]

Na base de teste, utilizada para estimar o risco, a função de perda 0-1
é apropriada. Na etapa de validação cruzada de um modelo de aprendizado
profundo, é útil considerar uma função de perda que seja contínua e
derivável, funcionando como uma versão suavizada da perda 0-1. A partir
de um vetor de parâmetros \(\boldsymbol \theta\) originados da
arquitetura do modelo, uma escolha de função de perda é a entropia
cruzada, como na Equação~\ref{eq-perda-crossentropy}. Os parâmetros são
estimados a partir de um otimizador, como o ADAM, apresentado na
Seção~\ref{sec-otimizador}.

As definições começam a precisar de ajustes quando \(y\) deixa de ser um
rótulo fixado. Como descrito na Seção~\ref{sec-oraculo}, quando o modelo
inicial erra, o que se observa é uma lista de possíveis valores para
\(y\), que contém o rótulo correto e outros incorretos. Se o Captcha
aceita apenas um chute, essa lista contém todos os possíveis valores do
rótulo, menos o valor incorreto que foi utilizado no oráculo. Se o
Captcha aceita vários chutes, a lista contém todos os valores possíveis
de \(y\) menos os valores que foram testados.

Para isso, utiliza-se a notação do \(\bar {\mathbf y}\). A notação
utiliza negrito para enfatizar que o objeto contém uma lista de
possíveis valores, e não apenas um valor. Por exemplo, considere
\(\mathcal A = \{0,1,\dots,9\}\) um alfabeto com os algarismos de zero
até nove, como no MNIST, e um Captcha que aceita múltiplos chutes. Nesse
caso, para uma imagem \(\mathbf x\) com rótulo \(3\), seguindo as
definições da Seção~\ref{sec-definicao-captcha}, o valor de \(y\) seria
dado pela matriz

\[
y = [0\;0\;0\;1\;0\;0\;0\;0\;0\;0].
\]

Aqui, o valor \(3\) é colocado na quarta posição da primeira (e única)
linha da matriz. Como o problema está sendo trabalhado na forma
univariada, para simplificar a notação, pode-se considerar apenas os
valores dos rótulos, ou seja, \(y=3\).

Considere, agora, que o modelo inicial produziu as tentativas incorretas
\(\mathbf g(\mathbf x) = \{6,8\}\). O valor observado
\(\bar{\mathbf y}\) envolve todos os valores de \(y\) menos as
tentativas incorretas:

\[
\bar{\mathbf y} = \{0,1,2,3,4,5,7,9\}.
\]

Na prática, o que se observa, então, são pares \((\mathbf x,y)\), nos
casos corretos, ou pares \((\mathbf x,\bar{\mathbf y})\), nos casos
incorretos. Para generalizar a notação, é possível considerar uma
variável indicadora de acerto do modelo inicial \(z\) e a lista
\(\mathbf y\), definida da seguinte forma:

\[
\mathbf y = \left\{\begin{array}{cl}\{y\}&,\text{ se }z=1\\\bar{\mathbf y}&,\text{ se }z=0\end{array}\right..
\]

Assim, observa-se uma amostra de
\(\{(\mathbf x_s,\mathbf y_s, z_s)\}, s = 1,\dots,S\). A distribuição
desses dados está diretamente relacionada com a acurácia do modelo
inicial. Por exemplo, se o modelo inicial acerta todos os chutes, o
resultado será sempre o valor correto \(y\), e o problema recai em um
caso supervisionado tradicional. Quando o modelo inicial erra todos os
casos, todos os rótulos são parciais e o problema recai em um caso de
PLL puro. Na prática, o que se espera é que a amostra tenha uma mistura
de rótulos corretos e de rótulos parciais.

É possível desconsiderar o valor \(z\) na notação. Como os rótulos
parciais sempre incluem o rótulo correto \(y\), quanto o conjunto contém
apenas um elemento, este é o rótulo correto. Ou seja:

\[
z=1 \iff |\mathbf y|=1.
\]

Portanto, basta considerar os pares \((\mathbf x_s, \mathbf y_s)\) da
amostra para definir o problema. Definida a estrutura de dados da
amostra, passa-se a discutir a forma de obter um classificador com boas
propriedades.

Uma estratégia eficaz para derivar propriedades de classificadores na
área de PLL é escrever a distribuição dos dados de forma explícita
(\protect\hyperlink{ref-feng2020}{FENG et al., 2020a},
\protect\hyperlink{ref-feng2020a}{2020b};
\protect\hyperlink{ref-ishida2017}{ISHIDA et al., 2017};
\protect\hyperlink{ref-yu2018}{YU et al., 2018}). A partir dessa
distribuição, a função de risco do problema completamente supervisionado
é reescrita em termos da função de risco do problema com rótulos
parciais. Depois, é criado um estimador para essa função de risco, a
partir de uma amostra observada. Finalmente, utilizando funções de perda
adequadas, demonstra-se que a função de risco do problema com rótulos
parciais se aproxima da função de risco com dados completamente
supervisionados, conforme a base de dados aumenta.

A forma mais fácil de definir a distribuição dos dados com rótulos
parciais é considerando que os valores dos rótulos parciais aparecem ao
acaso. Por exemplo, considere que as imagens são geradas com uma
distribuição \(p(\mathbf x, y)\), que não precisa ser conhecida. Então a
distribuição dos rótulos parciais \(\tilde p (\mathbf x, \mathbf y)\) é
dada por (\protect\hyperlink{ref-feng2020}{FENG et al., 2020a}):

\begin{equation}\protect\hypertarget{eq-distribuicao}{}{
\tilde p (\mathbf x, \mathbf y) = \sum_{y}p(\mathbf y|y)p(\mathbf x, y), \text{ onde } p(\mathbf y|y)=\left\{\begin{array}{ll}\frac{1}{2^{|\mathcal A|-1}-1},&\text{ se } y\in\mathbf y,\\0,&\text{ se } y\notin \mathbf y\end{array}\right..
}\label{eq-distribuicao}\end{equation}

A distribuição pode ser interpretada da seguinte forma. Os valores
possíveis de \(\mathbf y\) são todos os possíveis subconjuntos do
alfabeto, menos os casos extremos (vazio e o alfabeto completo). Por
exemplo, no caso de um alfabeto com os 10 algarismos, os valores de
\(\mathbf y\) podem ser todas as combinações dos algarismos, menos o
conjunto vazio e o conjunto \(\{0,\dots,9\}\). Isso dá
\(2^{|\mathcal A|}-2\) combinações no total.

Considerando a restrição de PLL de que a resposta \(\mathbf y\) sempre
contém o verdadeiro rótulo, é intuitivo que \(p(\mathbf y|y)=0\) quando
\(y\notin \mathbf y\). Ou seja, a probabilidade de observar
\(\mathbf y\) quando se sabe que o \(y\) correto foi observado e este
\(y\) não está no conjunto \(\mathbf y\) é zero. Agora, quando
\(y \in \mathbf y\), a probabilidade é calculada considerando todos os
possíveis subconjuntos do alfabeto que contêm \(y\), que são
\(2^{|\mathcal A|-1}-1\). Por exemplo, de todos os subconjuntos válidos
do conjunto \(\{0,\dots,2\}\), ou seja,
\(\{0\},\{1\},\{2\}, \{0,1\}, \{0,2\}\) e \(\{1,2\}\), tem-se
\(2^{3-1}-1=3\) conjuntos que contêm o valor \(2\). Por isso, a
probabilidade atribuída a \(p(\mathbf y|y)\) é uma uniforme, dando pesos
iguais para todos os possíveis rótulos.

Uma suposição implícita da distribuição na Equação~\ref{eq-distribuicao}
é que \({\mathbf y}\) é condicionalmente independente de \({\mathbf x}\)
dado \(y\). Ou seja, para qualquer valor de \(y\),

\[
p(\mathbf y|\mathbf x, y) = p(\mathbf y| y).
\]

Essa suposição significa que o valor do rótulo complementar não depende
da imagem quando se sabe o rótulo da imagem. No caso dos Captchas, essa
suposição é verificada, porque a imagem é simplesmente uma representação
do rótulo, então a probabilidade do modelo inicial errar depende apenas
do rótulo e não das distorções realizadas pela imagem gerada a partir do
rótulo.

Como comentado anteriormente, a partir da distribuição dos dados é
possível reescrever a função de risco do problema completamente
supervisionado em termos do problema de rótulos parciais
(\protect\hyperlink{ref-feng2020}{FENG et al., 2020a}, eq (6)). A partir
de um estimador desse risco, utiliza-se um método de aprendizado de
máquinas (como redes neurais) para obter um classificador \(\hat f\).
Considerando que \(f^*\) é a função obtida em um problema completamente
supervisionado e seguindo algumas suposições adicionais, é possível
demonstrar que

\[
|\mathcal R(\hat f) - \mathcal R(f^*)|
\] é limitada e converge para zero quando tamanho da amostra vai para
infinito. Mais do que isso, é possível obter a taxa de convergência do
risco, em função da complexidade de Rademacher. Os detalhes e a
demonstração podem ser encontrados no artigo de FENG et al.
(\protect\hyperlink{ref-feng2020}{2020a}).

Nas descrições dadas acima, a única suposição que não é satisfeita é a
de que os valores de \(\mathbf y\) são distribuídos uniformemente. Essa
suposição é inválida porque os valores observados de \(\mathbf y\) são
resultado dos erros do modelo inicial aplicado ao oráculo e porque o
número de tentativas geralmente é limitado. Como o modelo inicial não
tem distribuição uniforme, o resultado também não é uniforme.

O tipo de problema nesse caso é conhecido como \emph{biased partial
label} (\protect\hyperlink{ref-yu2018}{YU et al., 2018}). Um dos artigos
estudados apresenta uma solução para o caso em que o rótulo parcial é um
rótulo complementar (ou seja, quando o Captcha aceita apenas um chute).
Nesse caso as probabilidades \(p(\mathbf y| y)\) podem ser organizadas
em uma matriz de transição \(\mathbf Q\), contendo as probabilidades de
se obter um rótulo incorreto para cada possível valor do rótulo. Para
resolver problemas desse tipo, é possível realizar um ajuste na função
de predição:

\[
f_{\text{adj}} (\mathbf x) = \mathbf Q ^{\top}f(\mathbf x).
\]

O caso do oráculo e dos Captchas é um problema com múltiplos rótulos
complementares e com viés. Até o momento, não existe uma solução geral
para este tipo de problema. No entanto, espera-se que as soluções para
problemas desse tipo tenham taxas de convergência mais estreitas do que
o caso de rótulos complementares, com ou sem viés, já que rótulos
complementares múltiplos trazem mais informação do que rótulos
complementares simples.

\hypertarget{sec-wawl}{%
\section{Método WAWL}\label{sec-wawl}}

O método WAWL (\emph{Web Automatic Weak Learning}) é a solução proposta
na pesquisa. Trata-se da técnica baixar dados da web para compor parte
da amostra que é utilizada no ajuste do modelo.

O método WAWL é inovador por dois motivos. Primeiro, porque o método faz
a ponte entre áreas que até o momento eram partes separadas no ciclo da
ciência de dados: a raspagem de dados e o aprendizado estatístico. Além
disso, o método é uma nova alternativa para resolver Captchas com pouca
ou nenhuma intervenção humana.

A Figura~\ref{fig-esquema-wawl} mostra o funcionamento básico do WAWL.
Primeiro, ajusta-se um modelo inicial para o Captcha desejado, que pode
ser uma adaptação de modelos existentes ou um modelo construído com base
em uma pequena amostra completamente anotada. Em seguida, aplica-se as
predições do modelo inicial no oráculo para obter uma nova base de dados
parcialmente anotada da internet. Finalmente, um novo modelo é ajustado
com os dados obtidos, utilizando uma adaptação na função de perda.

\begin{figure}

{\centering \includegraphics{./assets/img/wawl.png}

}

\caption{\label{fig-esquema-wawl}Esquema mostrando o funcionamento do
método WAWL}

\end{figure}

A arquitetura do modelo WAWL pode ser a mesma de um modelo ajustado com
uma base completamente anotada. O modelo pode, inclusive, aproveitar os
parâmetros já ajustados do modelo inicial, acelerando o aprendizado.
Nada impede, no entanto, que uma arquitetura diferente seja utilizada,
desde que a entrada seja uma imagem e a saída seja uma matriz com as
dimensões da variável resposta. O WAWL é agnóstico à arquitetura do
modelo.

A função de perda deve ser adaptada para considerar a informação
limitada fornecida pelo oráculo. Quando o rótulo fornecido pelo modelo
está correto, a informação é considerada normalmente, através da função
de perda da regressão multinomial multivariada. Já quando o rótulo
fornecido pelo modelo é incorreto, a função de perda é calculada com
base na probabilidade do rótulo estar incorreto:

\[
1 - p(y|\boldsymbol \theta).
\]

Considere o rótulo parcial \({\mathbf y}\) e a função \(g\), dada pela
rede neural, que retorna um vetor de probabilidades
\([g_y], y \in \mathcal A\). Os valores de \(g_y\) somam 1 e têm os
pesos relacionados a cada possível rótulo a partir da imagem
\(\mathbf x\). O WAWL modifica a entropia cruzada (função de perda
original) nos casos anotados pelo oráculo como errados, e mantém a
função de perda original nos casos corretamente anotados. A fórmula para
descrever a função de perda modificada é:

\[
\mathcal L(g(\mathbf x), {\mathbf y}) = -\log\left[1 - \sum_{y \in \mathcal A} {g_y}(\mathbf x) I(y\notin {\mathbf y})\right].
\]

Por conta da função indicadora, a perda só é calculada nos pontos que
estão de fora do rótulo parcial observado \(\mathbf y\). Ou seja, o
valor é calculado somente nos casos que o modelo inicial errou. Outra
forma de escrever a mesma função de perda é fazendo:

\[
\mathcal L(g(\mathbf x), {\mathbf y}) = -\log\left[ \sum_{y \in \textbf{y}} g_y(\mathbf x)\right].
\]

A função proposta pode ser explicada de maneira intuitiva através de
exemplos. Considere um problema com apenas \(10\) possíveis valores para
o rótulo e uma resposta multinomial, sem ser multivariada, como
considerado na Seção~\ref{sec-aprendizado-estatistico}. Considere também
que a rede neural retorna uma alta probabilidade, por exemplo, \(0.99\),
para o valor \(j\), que o oráculo identificou como incorreta. Logo,
\(\mathbf {\bar y} = \{1,\dots,10\}\setminus \{j\}\), e a função de
perda é dada por

\[
\mathcal L(g(\mathbf x), \{1,\dots,10\}\setminus \{j\}) = -\log\left[1-{g_j}(\mathbf x)\right] = -\log\left[1-0.99 \right] = 4.61.
\]

Como é possível ver no exemplo, quanto maior a probabilidade dada a um
rótulo identificado como incorreto pelo oráculo, mais a função de perda
penaliza essa predição. Dessa forma, a função de perda consegue
incorporar a informação dada pelo oráculo adequadamente.

Considere, agora, que a rede neural retorna uma probabilidade pequena,
por exemplo, \(0.01\), para o valor \(k\), que o oráculo identificou
como incorreta. Logo,
\(\mathbf {\bar y} = \{1,\dots,10\}\setminus \{k\}\), e a função de
perda é um valor pequeno:

\[
\mathcal L(g(\mathbf x), \{1,\dots,10\}\setminus \{k\}) = -\log\left[1-{g_k}(\mathbf x)\right] = -\log\left[1-0.01 \right] = 0.01.
\]

Quando o Captcha aceita múltiplos chutes, a mesma conta é válida,
bastando subtrair as probabilidades de todos os rótulos incorretos. No
final, o valor da função de perda é a soma das perdas para todas as
observações do \emph{minibatch}. A soma considera tanto as perdas
calculadas com base nos rótulos corretos quanto as perdas calculadas com
base nos rótulos incorretos.

O otimizador que obtém novas estimativas dos parâmetros também não
precisa ser modificado. Basta aplicar a mesma técnica utilizada na
modelagem usual, como descida de gradiente estocástica ou métodos
adaptativos, como o ADAM.

Um detalhe importante sobre o método é sobre a implementação. Com a
utilização de ferramentas que fazem diferenciação automática como o
\emph{torch} e o \emph{TensorFlow}\footnote{Mais detalhes em
  \url{https://www.tensorflow.org}. Último acesso em 22 de novembro de
  2022.}, basta implementar a parte da arquitetura, a função de perda e
especificar o otimizador, já que o processo de atualização dos
parâmetros é feito automaticamente. No entanto, dependendo da
implementação, não é possível fazer a atualização dos parâmetros usando
o componente de computação gráfica, que potencialmente acelera o ajuste
dos modelos de forma significativa. Na implementação atual, a função de
perda apresentada não permite utilização deste componente, sendo uma
melhoria possível em futuros trabalhos.

O ajuste dos modelos, tanto para simulações quanto para construção dos
modelos finais, utilizou o pacote \texttt{\{torch\}}
(\protect\hyperlink{ref-torch}{FALBEL; LURASCHI, 2022}), que é uma
implementação do PyTorch para a linguagem de programação R
(\protect\hyperlink{ref-rcran}{R CORE TEAM, 2021}). O pacote
\texttt{\{luz\}} (\protect\hyperlink{ref-luz}{FALBEL, 2022a}) foi
utilizado para organizar as funções de perda e hiperparâmetros, enquanto
o pacote \texttt{\{torchvision\}}
(\protect\hyperlink{ref-torchvision}{FALBEL, 2022b}) foi utilizado para
utilidades no tratamento de imagens.

\hypertarget{dados}{%
\section{Dados}\label{dados}}

Nesta seção, descreve-se em detalhes como foi a obtenção dos dados para
realizar a pesquisa. Como comentado anteriormente, a base foi construída
do zero para os fins do projeto, sendo uma parte significativa dos
esforços para chegar nos resultados.

No total, foram construídas bases de dados de dez Captchas que estavam
disponíveis publicamente no período de realização da pesquisa. Os
Captchas foram revisados pela última vez no dia 14/09/2022, para
verificar se ainda estavam ativos. Além disso, foram construídas duas
bases de dados de Captchas desenvolvidos internamente para fins de
teste.

Parte dos dados foram obtidos como um passo intermediário das
simulações. A presente seção descreve como os robôs de coleta foram
construídos, bem como a metodologia para obter os modelos iniciais. Na
Seção~\ref{sec-construcao-dados}, são apresentadas informações sobre os
dados baixados para realizar as simulações.

\hypertarget{escolha-dos-captchas-analisados}{%
\subsection{Escolha dos Captchas
analisados}\label{escolha-dos-captchas-analisados}}

Para selecionar os Captchas, foram adotados alguns critérios objetivos.
Os critérios foram:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  O site acessado é de um serviço público (governo federal, tribunal
  etc).
\item
  O Captcha contém letras (A a Z) e números (0 a 9) em uma imagem com
  extensão \texttt{jpeg} ou \texttt{png}.
\item
  O comprimento do Captcha é fixo, ou seja, dois Captchas da mesma
  origem devem ter sempre o mesmo comprimento.
\end{enumerate}

A primeira restrição para escolha dos Captchas é de ordem
principiológica: um serviço público não deveria restringir o acesso aos
dados para robôs. Como já discutido na
Seção~\ref{sec-captchas-publicos}, nesses casos, a existência do Captcha
pode ser prejudicial para a sociedade.

As restrições 2 e 3 foram escolhidas com o objetivo de facilitar as
simulações e comparações dos resultados. Em princípio, nada impede que
os modelos desenvolvidos trabalhem com caracteres diferentes de
\texttt{{[}a-zA-Z0-9{]}}, desde que exista uma lista prévia de
caracteres. Além disso, é possível realizar adaptações no tratamento das
bases para lidar com diferentes comprimentos de Captchas.

A Tabela~\ref{tbl-lista-captcha} mostra os Captchas trabalhados. Dos 10
exemplos trabalhados, 6 têm origem no judiciário, que são conhecidos por
não disponibilizarem os dados de forma aberta. Vale notar que alguns dos
Captchas da tabela são utilizados por vários tribunais. O Captcha TRT,
por exemplo, existe em todos os Tribunais Regionais do Trabalho que
compartilham a mesma versão do sistema do Processo Judicial eletrônico
(PJe) do TRT3 (TRT da terceira região).

\hypertarget{tbl-lista-captcha}{}
\begin{table}[H]

\providecommand{\docline}[3]{\noalign{\global\setlength{\arrayrulewidth}{#1}}\arrayrulecolor[HTML]{#2}\cline{#3}}

\setlength{\tabcolsep}{0pt}

\renewcommand*{\arraystretch}{1.5}

\begin{longtable}[c]{|p{0.75in}|p{1.50in}|p{3.00in}}

\caption{\label{tbl-lista-captcha}Lista de captchas analisados } \\ 


\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}

\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Captcha}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Exemplo}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Descrição}}} \\

\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}\endhead



\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://pje.trf5.jus.br/pje/ConsultaPublica/listView.seam}{trf5}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-1.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ Regional\ Federal\ 5}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www4.tjmg.jus.br/juridico/sf/proc\_resultado.jsp?comrCodigo=24\&numero=1\&listaProcessos=50718889720218130024\&btn\_pesquisar=Pesquisar}{tjmg}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-2.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ de\ Justiça\ de\ Minas\ Gerais}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://pje-consulta.trt3.jus.br/pje-consulta-api/api/processos/2104879}{trt}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-3.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ Regional\ do\ Trabalho\ 3}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{http://esaj.tjba.jus.br/cpopg/open.do}{esaj}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-4.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ de\ Justiça\ da\ Bahia}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.jucesponline.sp.gov.br/ResultadoBusca.aspx}{jucesp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-5.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Junta\ Comercial\ de\ São\ Paulo}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://srv01.tjpe.jus.br/consultaprocessualunificada/}{tjpe}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-6.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ de\ Justiça\ de\ Pernambuco}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.tjrs.jus.br/site\_php/consulta/verificador.php}{tjrs}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-7.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Tribunal\ de\ Justiça\ do\ Rio\ Grande\ do\ Sul}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.cadesp.fazenda.sp.gov.br/(S(vyfz1cfybbxj3sgpf4eqhxd3}{cadesp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-8.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Centro\ de\ Apoio\ ao\ Desenvolvimento\ da\ Saúde\ Pública}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://sei.economia.gov.br/sei/modulos/pesquisa/md\_pesq\_processo\_pesquisar.php?acao\_externa=protocolo\_pesquisar\&acao\_origem\_externa=protocolo\_pesquisar\&id\_orgao\_acesso\_externo=0}{sei}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-9.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sistema\ Eletrônico\ de\ Informações\ -\ ME}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://servicos.receita.fazenda.gov.br/servicos/cnpjreva/Cnpjreva\_Solicitacao\_CS.asp}{rfb}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.5in+0\tabcolsep+0\arrayrulewidth}}{\includegraphics[width=0.9in, height=0.45in]{metodologia_files/figure-pdf/tbl-lista-captcha-10.png}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Receita\ Federal}}} \\

\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}



\end{longtable}

\end{table}

Além dos Captchas de sites, também foram consideradas imagens geradas
artificialmente. O motivo de criar Captchas artificiais é a facilidade
de rodar modelos e simulações, já que nos casos reais é necessário ter
acesso à internet e construir bases de dados de cada Captcha.

Foram gerados dois tipos de Captchas artificiais. O primeiro, chamado
\textbf{MNIST-Captcha}, é simplesmente uma adaptação da conhecida base
MNIST para ficar no formato de um Captcha. A partir da escolha do
comprimento e dos caracteres que fazem parte da imagem, o gerador
simplesmente faz uma amostra aleatória da base do MNIST e compõe as
imagens horizontalmente.

A Figura~\ref{fig-captcha-mnist} mostra um exemplo do Captcha gerado a
partir da base MNIST. No exemplo, o comprimento escolhido para o Captcha
foi de 4 valores.

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/mnist128c49c36e13_6297.png}

}

\caption{\label{fig-captcha-mnist}Exemplo de MNIST-Captcha}

\end{figure}

O problema do MNIST-Captcha é que a base de dados original é finita.
Apesar de possuir por volta de 60 mil observações, o MNIST-Captcha pode
gerar Captchas repetidos. Além disso, é necessário tomar cuidado com as
bases de treino e teste, já que os elementos de teste não poderiam fazer
parte de nenhuma observação de treino.

Um novo tipo de Captcha também foi gerado inteiramente por programação,
chamado \textbf{R-Captcha}. O Captcha é gerado utilizando a ferramenta
ImageMagick, com a possibilidade de customizar diversos parâmetros, como

\begin{itemize}
\tightlist
\item
  Quais caracteres usar na imagem
\item
  O comprimento do Captcha
\item
  Dimensões da imagem
\item
  Probabilidade de rotação da imagem
\item
  Probabilidade de adicionar um risco entre as letras
\item
  Probabilidade de adicionar uma borda nas letras
\item
  Probabilidade de adicionar uma caixa (retângulo) em torno das letras
\item
  Probabilidade de adicionar um ruído branco no fundo da imagem
\item
  Probabilidade de adicionar efeitos de tinta óleo e implosão
\end{itemize}

A Figura~\ref{fig-captcha-r} mostra um exemplo de R-Captcha. O exemplo
apresenta uma linha ligando as letras, comprimento 4, dígitos maiúsculos
e minúsculos e distorções.

\begin{figure}

{\centering \includegraphics[width=1.5625in,height=\textheight]{./assets/img/captcha128c4a9c32e4_boy4.png}

}

\caption{\label{fig-captcha-r}Exemplo de R-Captcha}

\end{figure}

Por ser uma versão mais flexível e completa, optou-se por trabalhar
principalmente com o R-Captcha nas simulações. O MNIST-Captcha foi
implementado mas não foi utilizado nas simulações.

\hypertarget{sec-construcao-dados}{%
\subsection{Construção dos dados}\label{sec-construcao-dados}}

Para obter os dados da pesquisa, foram utilizadas técnicas de raspagem
de dados (\protect\hyperlink{ref-zhao2017}{ZHAO, 2017}). A raspagem de
dados é uma área da ciência da computação responsável por criar rotinas
que automatizam a coleta de dados provenientes da web. Trata-se de uma
atividade muito comum em pesquisas aplicadas, especialmente as que
envolvem análise de dados públicos que não estão disponíveis de forma
aberta, como os dados do Judiciário.

Dentro do ciclo da ciência de dados, pode-se considerar que a raspagem
de dados está inserida nas tarefas de coleta e arrumação de dados. É
possível comparar a raspagem com uma consulta a um banco de dados
remoto, ou mesmo à obtenção de informações através de uma
\emph{Application Programming Interface} (API).

Para raspar uma página da web, o fluxo descrito na
Figura~\ref{fig-fluxo-web-scraping} é seguido. O exemplo da RFB foi
utilizado para dar contexto aos passos.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./assets/img/cycle.png}

}

\caption{\label{fig-fluxo-web-scraping}Ciclo da raspagem de dados.
Fonte: \href{https://curso-r.github.io/main-web-scraping}{curso de Web
Scraping da Curso-R}}

\end{figure}

No caso da RFB, a etapa de identificação é realizada acessando-se a
\href{http://servicos.receita.fazenda.gov.br/Servicos/cnpjreva/Cnpjreva_Solicitacao.asp}{página
inicial de busca de CNPJ}, como mostrado na
Figura~\ref{fig-raspagem-rfb-inicial}. É possível notar que o desafio
disponível é do tipo \emph{hCaptcha}, que não é o Captcha de interesse
da pesquisa. No entanto, ao clicar em ``Captcha Sonoro'', é possível
acessar o Captcha de interesse, como mostrado na
Figura~\ref{fig-raspagem-rfb-sonoro}. O motivo pelo qual o Captcha de
texto em imagem foi mantido após a implementação do \emph{hCaptcha} não
foi encontrado.

\begin{figure}

{\centering \includegraphics{./assets/img/raspagem-rfb-inicial.png}

}

\caption{\label{fig-raspagem-rfb-inicial}Página de busca de CNPJ da RFB}

\end{figure}

\begin{figure}

{\centering \includegraphics{./assets/img/raspagem-rfb-sonoro.png}

}

\caption{\label{fig-raspagem-rfb-sonoro}Página de busca de CNPJ da RFB,
com Captcha de texto}

\end{figure}

A segunda tarefa é a de navegar pelo site, registrando as requisições
realizadas pelo navegador para realizar a consulta. Isso envolve abrir o
inspetor de elementos do navegador, na aba Rede (ou \emph{Network}, em
inglês), anotando as requisições que são realizadas.

No exemplo, testou-se o CNPJ 13.612.840/0001-57, da ABJ. Ao preencher o
CNPJ e o rótulo do Captcha, algumas requisições aparecem na aba
``Rede'', como mostrado na Figura~\ref{fig-raspagem-rfb-rede}. A
primeira requisição é do tipo POST\footnote{Existem dois tipos
  principais de requisição HTTP. A requisição GET serve para capturar
  uma página da internet, enquanto a requisição POST serve para enviar
  dados para o servidor como, um login e uma senha. A lista completa de
  requisições está disponível na
  \href{https://www.rfc-editor.org/rfc/rfc9110.html}{documentação da
  \emph{Internet Engineering Task Force} (IETF)}.}, responsável por
enviar os dados de CNPJ e do rótulo da imagem para o servidor, que
retorna com os dados da empresa.

\begin{figure}

{\centering \includegraphics{./assets/img/raspagem-rfb-rede.png}

}

\caption{\label{fig-raspagem-rfb-rede}Resultado da busca por CNPJ,
mostrando a aba Rede}

\end{figure}

Investigando a requisição POST, na aba ``Requisição'', é possível
observar os dados da consulta. Trata-se de um conjunto de parâmetros
enviados na forma de lista, com as informações abaixo. Para replicar a
requisição na linguagem de programação, estes são os dados enviados.

\begin{verbatim}
{
    "origem": "comprovante",
    "cnpj": "13.612.840/0001-57",
    "txtTexto_captcha_serpro_gov_br": "7hkhze",
    "search_type": "cnpj"
}
\end{verbatim}

As etapas de replicar e validar envolvem baixar e processar os dados
obtidos no navegador, mas utilizando linguagem de programação. No caso
do Captcha da RFB, essa tarefa envolve os passos abaixo.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Acessar a página inicial de
  \href{http://servicos.receita.fazenda.gov.br/Servicos/cnpjreva/Cnpjreva_Solicitacao_CS.asp}{busca
  com Captcha sonoro}, através de uma requisição GET.
\item
  Baixar a imagem do Captcha com uma requisição GET, usando o
  \href{http://servicos.receita.fazenda.gov.br/Servicos/cnpjreva/captcha/gerarCaptcha.asp}{link
  gerado} ao clicar no botão de atualizar o Captcha.
\item
  Obter o rótulo a partir da imagem do Captcha.
\item
  Realizar a requisição POST com os dados do exemplo e o rótulo correto
  da imagem, baixando arquivo resultante em um HTML.
\item
  Utilizar técnicas de raspagem de arquivos HTML para obter os dados de
  interesse (como, por exemplo, a razão social da empresa) e validar os
  resultados, verificando, por exemplo, se o resultado estava completo e
  disponível.
\end{enumerate}

Todos os passos descritos acima devem ser realizados em uma sessão
persistente. Isso significa que a biblioteca utilizada para realizar as
requisições deve ser capaz de guardar os \emph{cookies} entre a
requisição GET do primeiro passo e a requisição POST do quarto passo, de
forma que as requisições sejam interligadas.

O quinto passo da lista acima descreve a parte de \emph{parsear}, que é
a responsável pelo nome ``raspagem'' nesta área do conhecimento. O nome
\emph{parsear} aparece porque os arquivos baixados estão em um formato
bruto, inadequado para realização de análises. Os dados precisam ser
então extraídos -- raspados -- do arquivo HTML, utilizando ferramentas
como a \emph{libxml2} (\protect\hyperlink{ref-xml2}{WICKHAM; HESTER;
OOMS, 2021}) para acessar pedaços do documento, como o XPath
(\protect\hyperlink{ref-rvest}{WICKHAM, 2022a}) e posteriormente aplicar
técnicas de manipulação de textos, como expressões regulares
(\protect\hyperlink{ref-stringr}{WICKHAM, 2022b}).

A iteração encerra o fluxo da raspagem de dados. Nessa etapa, as
operações de replicar, parsear e validar o resultado são repetidas, com
o fim de baixar dados para compor uma base maior. No exemplo da RFB,
isso significaria montar uma base de dados a partir de uma lista de
CNPJs.

No contexto dos Captchas, o interesse principal está nos passos de
replicar e validar. Primeiro, a imagem é baixada e o rótulo é anotado --
replicar. Em seguida, o rótulo é testado pelo oráculo -- validar.

O oráculo envolve a possibilidade de checar, de forma automática, se uma
predição do rótulo de uma imagem está correta. O Captcha é obrigado a
mencionar se uma predição está correta: se a predição foi correta, a
página de interesse é acessada; se a predição está incorreta, o site
envia uma mensagem de erro.

De forma geral, as etapas de replicar e validar em todos os sites de
interesse envolveram os passos a seguir.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Acessar a página do site de interesse.
\item
  Preencher o formulário de pesquisa com a informação a ser consultada.
  Por exemplo, no site da RFB, a informação é o CNPJ da empresa a ser
  consultada. Em um site de tribunal, a informação é um número
  identificador de processo.
\item
  Baixar a imagem do Captcha da busca.
\item
  Obter o rótulo da imagem, aplicando um modelo na imagem baixada ou
  anotando manualmente.
\item
  Submeter a consulta no site, informando o rótulo.
\item
  Verificar o resultado. Se acessou a página desejada, o rótulo está
  correto. Caso contrário, o rótulo está incorreto.
\end{enumerate}

O procedimento descrito pode ser reproduzido indefinidamente. Isso
significa que é possível criar uma base de dados virtualmente infinita
de imagens rotuladas, com a informação adicional do rótulo estar correto
ou incorreto. Isso foi feito para gerar os dados utilizados na
simulação.

Uma oportunidade que o oráculo pode oferecer é a possibilidade de testar
mais de uma predição. Sites com essa característica permitem que a
pessoa ou robô teste mais de uma predição caso a tentativa anterior
tenha resultado em fracasso. Como é possível observar na
Tabela~\ref{tbl-lista-captcha}, dos 10 Captchas trabalhados, 7 permitem
a realização de múltiplos chutes.

Neste momento, cabe uma nota sobre oráculos e força bruta. O poder de
testar vários rótulos para o mesmo Captcha implica na possibilidade
teórica de resolver um Captcha por força bruta. Bastaria testar todos os
rótulos possíveis para acessar a página de interesse. Na prática, no
entanto, essa estratégia não funciona, já que a quantidade de rótulos
possíveis é muito grande para testar no site, seja por demorar muito
tempo ou pelo site forçar a troca do desafio após a passagem de
determinado tempo ou quantidade de tentativas.

Voltando ao ciclo da raspagem, ao longo do procedimento de baixar
imagens de Captchas e aplicar o oráculo, pelo menos duas operações devem
ser implementadas: \textbf{acesso} e \textbf{teste}. A operação de
acesso é responsável por preencher o formulário de busca e baixar o
Captcha (passos 1, 2 e 3 da lista acima). A operação de teste é
responsável por submeter um rótulo do Captcha e verificar se o rótulo
está correto ou incorreto (passos 5 e 6 da lista acima). O passo 4 pode
ser realizado de forma unificada, pois não depende de interação com o
site específico. Em alguns casos, as funções de acesso e teste precisam
compartilhar parâmetros que contêm a sessão do usuário, para garantir
que o teste envolva o mesmo Captcha da etapa de acesso.

Os Captchas foram anotados manualmente com um procedimento que foi
chamado de semi-automático, definido a seguir. No pacote
\texttt{\{captchaDownload\}} (ver Apêndice \ref{sec-pacote-download}),
foram desenvolvidas ferramentas para baixar e organizar cada Captcha,
utilizando o oráculo para garantir que as imagens eram corretamente
anotadas.

Cada Captcha teve as primeiras 100 observações anotadas manualmente.
Isso foi feito a partir do próprio RStudio, utilizando a ferramenta de
anotação manual do pacote \texttt{\{captcha\}}.

A partir das anotações iniciais, um modelo inicial foi ajustado. Esse
passo também foi feito com o pacote \texttt{\{captcha\}}, que possui uma
função de ajuste de modelos que usa redes neurais convolucionais,
definidas da mesma forma que nas seções anteriores.

O modelo, então, foi utilizado como uma ferramenta para otimizar a
anotação manual, funcionando da seguinte forma. Primeiro, o modelo tenta
realizar a predição automaticamente e o oráculo informa se a predição
está correta ou não. Se estiver incorreto e o site aceitar vários
chutes, o modelo tenta novamente, mas com uma segunda alternativa de
predição. Caso o site não aceite vários chutes ou o modelo não consiga
acertar o Captcha em \(T\) tentativas (arbitrado como dez), o Captcha é
anotado manualmente.

Com o procedimento destacado acima, é criada uma nova base de dados, que
por sua vez é utilizada para ajustar um novo modelo. O modelo,
atualizado, é utilizado para classificar novos Captchas, e assim por
diante, até que o modelo ajustado alcance uma acurácia razoável, que foi
arbitrada em 80\%. Com isso o procedimento de anotação é finalizado.

O único problema do procedimento de anotação descrito diz respeito aos
Captchas que não aceitam várias tentativas. Nesses casos, não é possível
verificar com certeza que um caso anotado manualmente (após a tentativa
do modelo) foi anotado corretamente, já que a anotação manual seria a
segunda tentativa. No entanto, esse problema aparece somente em três
Captchas (\texttt{cadesp}, \texttt{jucesp} e \texttt{trf5}). A anotação
manual dos 100 primeiros Captchas, no entanto, mostrou que pelo menos
95\% dos Captchas foram anotados corretamente quando anotados
manualmente. A proporção máxima de 5\% de erro é negligenciável
considerando que a maior parte das bases de dados foi construída com
verificação do oráculo.

Em alguns casos, os rótulos dos Captchas podem ser obtidos sem
intervenção humana, utilizando técnicas de raspagem de dados ou
processamento de sinais. Um exemplo é o Captcha do SEI, que mostra
informações suficientes para resolver o Captcha na própria URL que gera
a imagem. Outro exemplo é o TJMG, que libera, além da imagem, um áudio
contendo o mesmo rótulo da imagem, sem a adição de ruídos. Como o áudio
não tem ruídos, basta ler o áudio, separar os áudios de cada caractere e
calcular uma estatística simples (como a soma dos valores absolutos das
amplitudes). Essa estatística é utilizada para associar um pedaço de
áudio a um caractere.

A Tabela~\ref{tbl-lista-captcha-carac} caracteriza os Captchas anotados.
Todos os Captchas possuem comprimento entre 4 e 6 dígitos e, com exceção
do SEI, não são sensíveis a maiúsculas e minúsculas.

\hypertarget{tbl-lista-captcha-carac}{}
\begin{table}[H]

\providecommand{\docline}[3]{\noalign{\global\setlength{\arrayrulewidth}{#1}}\arrayrulecolor[HTML]{#2}\cline{#3}}

\setlength{\tabcolsep}{0pt}

\renewcommand*{\arraystretch}{1.5}

\begin{longtable}[c]{|p{0.75in}|p{0.80in}|p{1.10in}|p{1.10in}|p{0.75in}|p{1.30in}}

\caption{\label{tbl-lista-captcha-carac}Lista de captchas analisados e suas características } \\ 


\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}

\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Captcha}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Vários\ chutes}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Caracteres}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Comprimento}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Colorido}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\#\ Rótulos\ anotados}}} \\

\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}\endhead



\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://pje.trf5.jus.br/pje/ConsultaPublica/listView.seam}{trf5}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{6}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{1000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www4.tjmg.jus.br/juridico/sf/proc\_resultado.jsp?comrCodigo=24\&numero=1\&listaProcessos=50718889720218130024\&btn\_pesquisar=Pesquisar}{tjmg}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{5}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{1000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://pje-consulta.trt3.jus.br/pje-consulta-api/api/processos/2104879}{trt}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{6}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{1500}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{http://esaj.tjba.jus.br/cpopg/open.do}{esaj}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{5}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{3000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.jucesponline.sp.gov.br/ResultadoBusca.aspx}{jucesp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{5}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://srv01.tjpe.jus.br/consultaprocessualunificada/}{tjpe}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{5}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.tjrs.jus.br/site\_php/consulta/verificador.php}{tjrs}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{2000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://www.cadesp.fazenda.sp.gov.br/(S(vyfz1cfybbxj3sgpf4eqhxd3}{cadesp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{3000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://sei.economia.gov.br/sei/modulos/pesquisa/md\_pesq\_processo\_pesquisar.php?acao\_externa=protocolo\_pesquisar\&acao\_origem\_externa=protocolo\_pesquisar\&id\_orgao\_acesso\_externo=0}{sei}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-zA-Z0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{10000}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{\href{https://servicos.receita.fazenda.gov.br/servicos/cnpjreva/Cnpjreva\_Solicitacao\_CS.asp}{rfb}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.8in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{Sim}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{a-z0-9}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.1in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{6}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{não}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\centering}p{\dimexpr 1.3in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\textcolor[HTML]{000000}{\fontsize{11}{22}\selectfont{4000}}} \\

\hhline{>{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}->{\arrayrulecolor[HTML]{000000}\global\arrayrulewidth=1pt}-}



\end{longtable}

\end{table}

As bases de dados com imagens anotadas foram disponibilizadas na aba de
lançamentos (\emph{releases}) do
\href{https://github.com/decryptr/captcha/releases}{repositório
principal do projeto de pesquisa}. As bases com imagens e modelos
ajustados estão disponíveis para quem tiver interesse em fazer novas
pesquisas e utilizar os resultados em suas aplicações, sem restrições de
uso.

\hypertarget{sec-simulacoes}{%
\section{Simulações}\label{sec-simulacoes}}

Para verificar o poder do uso do oráculo para o aprendizado do modelo,
uma série de simulações foram desenvolvidas. As simulações foram
organizadas em três passos: modelo inicial, dados e modelo final. Os
passos foram descritos em maior detalhe a seguir.

\hypertarget{primeiro-passo-modelo-inicial}{%
\subsection{Primeiro passo: modelo
inicial}\label{primeiro-passo-modelo-inicial}}

A simulação do modelo inicial teve como objetivo obter modelos
preditivos de Captchas com acurácias distintas. O modelo inicial seria
usado, então, para baixar dados diretamente do site usando o oráculo e,
por fim, ajustar um modelo final com os novos dados provenientes do
oráculo.

Os modelos iniciais para cada Captcha foram construídos em dois passos.
O primeiro foi montar a base de dados completa, suficiente para ajustar
um modelo com alta acurácia, que arbitrados em 80\%, como descrito
anteriormente. Depois, montou-se 10 amostras de dados com subconjuntos
das bases completas, cada uma contendo 10\%, 20\%, e assim por diante,
até a base completa. Por exemplo: no Captcha da Jucesp, construiu-se um
modelo com acurácia maior que 80\% com 4000 Captchas. A partir disso,
foi feita uma partição dos dados com 400 imagens (10\% do total), 800
imagens (20\% do total) e assim por diante, até o modelo com 4000
Captchas. A utilização de diferentes tamanhos de base de dados foi
realizada para obter modelos com diferentes acurácias.

Para cada tamanho de amostra \(S\), aplicou-se uma bateria de 27
modelos. Isso foi feito porque para diferentes quantidades de amostra, a
configuração dos hiperparâmetros que resulta no melhor modelo pode ser
diferente. Os modelos seguiram uma grade de hiperparâmetros considerando
três informações:

\begin{itemize}
\tightlist
\item
  A quantidade de unidades computacionais na primeira camada densa após
  as camadas convolucionais, com os valores considerados: 100, 200 e
  300.
\item
  O valor do \emph{dropout} aplicado às camadas densas, com os valores
  considerados: 10\%, 30\% e 50\%.
\item
  O fator de decaimento na taxa de aprendizado a cada época, com os
  valores considerados: 1\%, 2\% e 3\%.
\end{itemize}

Os diferentes valores de hiperparâmetros foram escolhidos com base em
vários testes empíricos realizados antes da simulação. Nesses testes,
foram considerados Captchas com diferentes complexidades e bases de
dados com diferentes tamanhos. Os números escolhidos visaram
proporcionar uma boa cobertura de modelos que poderiam ser os melhores,
ao mesmo tempo que seria uma grade simples o suficiente para permitir a
realização da simulação em tempo hábil.

Combinando os três valores dos três hiperparâmetros, tem-se um total de
\(27=3^3\) hiperparâmetros. Com isso, foi possível identificar, para
cada tamanho de amostra \(S\), o classificador com a melhor acurácia
dentre os modelos ajustados.

Todos os modelos foram ajustados utilizando-se um computador com um
processador Intel Core i7 10700KF, 3.80GHz (5.10GHz Turbo), 64GB de RAM
e uma placa GeForce RTX 3080 Eagle OC 10G. Os códigos utilizaram a
linguagem de programação R na versão 4.1.2 e o pacote \texttt{\{torch\}}
na versão 0.7.1.

No final do primeiro passo, portanto, considera-se apenas o melhor
modelo para cada tamanho de amostra, dentre os 27 ajustados. É claro que
os modelos encontrados por essa técnica não são, necessariamente, os
melhores modelos possíveis. No entanto, como a técnica é a mesma para
todos os Captchas, é possível fazer comparações através de uma
metodologia mais transparente.

Uma discussão interessante que aparece nesse contexto é a escolha de
pacotes da linguagem de programação R no lugar de Python para o ajuste
dos modelos. Para a construção deste trabalho, utilizou-se o R em todos
os passos, seja na construção do pacote \texttt{\{captcha\}}, o ajuste
dos modelos e raspadores de dados. No entanto, o Python é uma linguagem
reconhecidamente popular para tarefas de aprendizado de máquina e
raspagem de dados. Neste trabalho, optou-se utilizar o R por dois
motivos: i) a experiência do autor nesta linguagem, que é muito maior em
R do que em Python e ii) a possibilidade de utilizar o pacote
\texttt{\{torch\}}, que foi desenvolvido por um ex-aluno do IME-USP,
Daniel Falbel. A utilização do \texttt{\{torch\}} não só facilitou a
construção da solução como também pode ser pensada como um incentivo
para que outros pesquisadores da estatística utilizem esse pacote
computacional.

Uma possível desvantagem ao utilizar o R é que isso poderia trazer
dificuldades na velocidade da simulação. No entanto, isso não acontece
na prática. No momento do ajuste dos modelos, existia uma diferença de
performance do \texttt{\{torch\}} com relação ao PyTorch, do Python. No
entanto, essa diferença é negligenciável ao considerar o tempo total de
ajuste dos modelos, incluindo a parte de acesso à internet. O que torna
o \emph{download} dos dados lento não é a linguagem utilizada, e sim a
própria conexão com a internet e potenciais bloqueios do site de origem.
Por isso, os tempos para executar as simulações usando R ou Python
seriam similares.

\hypertarget{segundo-passo-dados}{%
\subsection{Segundo passo: dados}\label{segundo-passo-dados}}

O segundo passo teve como objetivo construir as bases de dados
utilizando o oráculo. Primeiro, foi necessário decidir quais modelos,
dentre os 10 ajustados para cada Captcha, seriam utilizados para
construir novas bases. Não faria sentido, por exemplo, considerar um
modelo com acurácia de 0\%, já que ele não produziria nenhuma observação
comparado com um modelo que chuta aleatoriamente. Também não faria
sentido considerar um classificador com acurácia de 100\%, já que nesse
caso não há o que testar com a técnica do oráculo.

Decidiu-se que seria necessário considerar somente os modelos que
resultaram em acurácias maiores de 5\% e menores de 50\%. O valor máximo
foi decidido após realizar alguns testes empíricos e verificar,
informalmente, que a técnica do oráculo realmente resultava em ganhos
expressivos, mesmo com modelos de baixa acurácia. Concluiu-se então que
não seria necessário testar a eficácia da técnica para classificadores
com alta acurácia. Já o valor mínimo foi decidido de forma arbitrária,
retirando-se os classificadores com acurácia muito baixa.

A segunda decisão a ser tomada para construção dos dados foi a
quantidade de imagens que seria baixada para cada Captcha. Como são
Captchas de diferentes dificuldades, a quantidade de dados seria
diferente para cada tipo. Optou-se por baixar a quantidade de dados de
forma a montar uma base de treino que contém a quantidade de observações
necessária para obter o melhor modelo daquele Captcha. Por exemplo, no
TJRS, um modelo com acurácia próxima de 100\% foi identificado com 2000
observações. O melhor modelo com 300 imagens (240 para treino, 60 para
teste) resultou em uma acurácia de 35\%. Foram, então, baixadas 1760
observações para compor o total de 2000 na base de treino. As imagens de
teste do modelo inicial poderiam até ser utilizadas, mas optamos por
descartar para garantir que o modelo não ficasse sobreajustado para a
primeira base.

O motivo de baixar a mesma quantidade de observações que o melhor modelo
inicial foi feita por três motivos. O primeiro é que existem evidências
de que é possível construir um bom modelo com essa quantidade de
imagens, ainda que em um caso as informações são completas e, no outro,
incompletas. O segundo é que isso permite a comparação do resultado do
modelo completamente anotado contra o modelo que é parcialmente anotado
e com anotações incompletas provenientes do oráculo. A terceira é que
essa estratégia proporciona bases de dados com diferentes proporções de
dados parcialmente anotados, o que pode trazer resultados empíricos de
interesse, como avaliar se muitos casos parcialmente rotulados podem
atrapalhar o ajuste do modelo.

A terceira e última decisão tomada para baixar os dados foi a quantidade
de chutes que o modelo poderia fazer, nos casos em que isso é permitido
pelo site. Optou-se, de forma arbitrária, por três valores: 1, que é
equivalente a um site que não permite múltiplos chutes, 5 chutes e 10
chutes.

Portanto, o procedimento de coleta dos dados foi feito, para cada
Captcha, da seguinte forma:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Listou-se todos os melhores modelos ajustados para cada tamanho de
  amostra.
\item
  Filtrou-se os modelos para os que apresentaram acurácia de 5\% até
  50\%.
\item
  Definiu-se o tamanho da base a ser obtida, com base no tamanho da base
  de treino utilizada no modelo e a quantidade total que se objetivou
  obter.
\item
  Para cada quantidade de tentativas disponível (1, 5 e 10), baixou-se
  as imagens, anotando com o valor ``1'' se o rótulo de alguma das
  tentativas estivesse correto e com o valor ``0'' caso contrário.
\item
  Nos casos com erros, armazenou-se um arquivo de log para cada Captcha
  com o histórico de tentativas incorretas, que é a informação mais
  importante a ser passada para o modelo final.
\end{enumerate}

No final, obteve-se bases de dados de treino para todos os Captchas
analisados, com quantidades de imagens que variam de acordo com os
parâmetros definidos anteriormente e pela quantidade de tentativas. A
quantidade total de bases de dados geradas foi 65.

Além das bases de treino, foi construída uma base de teste para cada
Captcha. O tamanho das bases de teste foi arbitrado em 1000 imagens para
cada Captcha. As bases de teste foram construídas completamente do zero,
sem utilizar informações de bases anteriores. Para construir as bases,
utilizou-se a mesma técnica semiautomática definida anteriormente,
usando o melhor modelo disponível para classificar a maioria das imagens
e classificando manualmente em caso de falha. Em alguns casos, como TJMG
e TJRS, a anotação humana quase não foi necessária, pois os melhores
classificadores obtidos apresentaram acurácia próxima de 100\%.

\hypertarget{sec-modelo-final}{%
\subsection{Terceiro passo: modelo final}\label{sec-modelo-final}}

O modelo final foi ajustado para cada uma das 65 bases de treino
disponíveis após a realização dos passos 1 e 2. Nesse caso, utilizou-se
o modelo proposto na Seção~\ref{sec-wawl}. Caso a imagem tenha sido
corretamente anotada, a função de perda é calculada normalmente. Caso
ela tenha sido anotada incorretamente, considera-se a probabilidade de
não observar nenhum dos chutes.

Além de modificar a forma de calcular a função de perda do modelo, foi
necessário realizar uma nova busca de hiperparâmetros. Optou-se por
utilizar os mesmos hiperparâmetros dos modelos iniciais para manter a
consistência. O único detalhe nesse ponto é que, como os parâmetros de
partida são os do modelo inicial, optou-se por não modificar a
quantidade de unidades na camada densa, variando somente os valores de
\emph{dropout} e de decaimento na taxa de aprendizado. Portanto,
ajustou-se 9 e não 27 modelos para cada base de dados.

No final, assim como no primeiro passo, os classificadores com melhor
acurácia foram selecionados para cada modelo. Obteve-se, então, uma
lista de 65 modelos ajustados para comparar com os modelos iniciais e
estimar a efetividade do oráculo. As comparações foram feitas através de
gráficos de barras, explorando o efeito do uso do oráculo para
diferentes Captchas, diferentes modelos iniciais e diferentes
quantidades de chutes, além de um gráfico de dispersão para relacionar
as acurácias iniciais e finais.

Além do terceiro passo, outros experimentos foram realizados para
verificar se, ao aplicar a técnica do oráculo iterativamente, os
resultados continuariam melhorando. Ou seja, é possível considerar os
modelos obtidos no passo 3 como os modelos iniciais do passo 1, aplicar
novamente o passo 2 (baixar dados) e o passo 3 (rodar modelo com os
novos dados). Isso foi feito para apenas um conjunto selecionado de
Captchas para verificar essa possibilidade, não fazendo parte das
simulações principais do estudo.

As bases de dados das simulações também foram disponibilizadas na aba de
lançamentos (\emph{releases}) do
\href{https://github.com/jtrecenti/doutorado/releases}{repositório
principal do projeto de pesquisa}. As bases podem ser utilizadas para
aumentar as bases de treino e para testar outras arquiteturas de redes
neurais ao tema dos Captchas com uso de aprendizado fracamente
supervisionado.

\bookmarksetup{startatroot}

\hypertarget{sec-results}{%
\chapter{Resultados}\label{sec-results}}

\epigrafe{I'm not a robot, I'm a human. But I'm pretty sure the robot is better at this than I am.}{ChatGPT}

Neste capítulo, discute-se os resultados empíricos do método WAWL e
descreve-se o pacote computacional desenvolvido para trabalhar com
Captchas. A Seção~\ref{sec-result-sim} mostra os resultados empíricos e
a Seção~\ref{sec-pacote-captcha} detalha o pacote \texttt{\{captcha\}}.
No final, a Seção~\ref{sec-discussao} apresenta uma discussão dos
resultados obtidos.

\hypertarget{sec-result-sim}{%
\section{Resultados empíricos}\label{sec-result-sim}}

Os resultados foram obtidos a partir das simulações com diversos
Captchas. Foram realizadas 65 simulações no total, variando o tipo de
Captcha, a acurácia do modelo inicial e a quantidade de tentativas no
oráculo, como descrito na Seção~\ref{sec-simulacoes}.

A base de dados com os resultados das simulações está disponível
publicamente no
\href{https://github.com/jtrecenti/doutorado}{repositório da
tese}\footnote{Para acessar a base, é necessário rodar
  \texttt{remotes::install\_github("jtrecenti/doutorado")} e depois
  acessar a base rodando \texttt{doutorado::da\_results\_simulacao}.}. A
base contém informações do Captcha ajustado (\texttt{captcha}), da
quantidade de observações do modelo inicial (\texttt{n}), da quantidade
de tentativas do oráculo (\texttt{ntry}), da etapa de simulação
(\texttt{fase}, inicial ou WAWL), do caminho do modelo ajustado
(\texttt{model}) e da acurácia obtida (\texttt{acc}).

Os resultados gerais mostram um ganho de 333\% na acurácia após a
aplicação do método WAWL. Ou seja, em média, a acurácia do modelo no
terceiro passo da simulação (ver a Seção~\ref{sec-modelo-final}) foi de
mais de \textbf{três vezes} a acurácia do modelo inicial. Em termos
absolutos (diferença entre as acurácias), o ganho foi de 33\%, ou seja,
após o terceiro passo, os modelos ganharam, em média, 33\% de acurácia.

As Figuras~\ref{fig-simulacao-geral-ntry-relativo} e
\ref{fig-simulacao-geral-ntry-absoluto} mostram os ganhos relativos e
absolutos, separando os resultados gerais por quantidade de tentativas.
Cada ponto é o resultado de uma simulação e o ponto em destaque é o
valor médio, acompanhado de intervalo \(m \mp 2*s/\sqrt(n)\), com \(m\)
sendo a média, \(s\) o desvio padrão e \(n\) a quantidade de dados. A
linha pontilhada indica se a acurácia aumentou ou diminuiu após a
aplicação da técnica.

Na Figura~\ref{fig-simulacao-geral-ntry-relativo}, é possível notar que
os ganhos em acurácia apresentam alta variabilidade, mas que apresentam
uma tendência positiva com relação ao número de tentativas. O ganho
entre aplicar 5 e 10 tentativas é menos expressivo do que o ganho entre
aplicar 1 e 5 tentativas, indicando que a oportunidade oferecida por
sites que aceitam vários chutes é relevante, mas não há necessidade de
realizar tantos chutes para aproveitar essa oportunidade. Uma possível
explicação para isso é que o modelo ficaria indeciso entre poucas
opções.

\begin{figure}

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-geral-ntry-relativo-1.pdf}

}

\caption{\label{fig-simulacao-geral-ntry-relativo}Ganho percentual ao
utilizar a técnica do oráculo, para cada quantidade de tentativas}

\end{figure}

A Figura~\ref{fig-simulacao-geral-ntry-absoluto}, com as os ganhos
absolutos, mostra a mesma informação, mas em valores com interpretação
mais direta. O ganho médio absoluto em sites que permitem mais de um
chute ficou em torno de 40\%, enquanto o ganho com apenas um chute ficou
um pouco acima de 25\%. Também é possível notar que a técnica é efetiva
de forma consistente, já que resultou em pioras nas acurácias em poucos
casos, sendo todos eles no cenário com apenas um chute.

\begin{figure}

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-geral-ntry-absoluto-1.pdf}

}

\caption{\label{fig-simulacao-geral-ntry-absoluto}Ganhos absolutos ao
utilizar a técnica do oráculo, para cada quantidade de tentativas}

\end{figure}

As Figuras~\ref{fig-simulacao-geral-inicial-relativo} e
\ref{fig-simulacao-geral-inicial-absoluto} apresentam os resultados
gerais separando por acurácia inicial do modelo. A estrutura do gráfico
é similar às visualizações anteriores, que separaram os resultados por
quantidade de tentativas. As categorias escolhidas foram: até 10\%, mais
de 10\% até 35\% e mais de 35\% de acurácia no modelo inicial. A escolha
dos intervalos se deram pela quantidade de observações em cada
categoria.

A Figura~\ref{fig-simulacao-geral-inicial-relativo} mostra os ganhos
relativos. É possível notar uma tendência de queda no ganho de acurácia
com uso do oráculo conforme aumenta a acurácia do modelo inicial. Esse
resultado é esperado, pois, como a acurácia é um número entre zero e um,
um modelo que já possui alta acurácia não tem a possibilidade de
aumentar muito de forma relativa.

\begin{figure}

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-geral-inicial-relativo-1.pdf}

}

\caption{\label{fig-simulacao-geral-inicial-relativo}Ganho percentual ao
utilizar a técnica do oráculo, para cada categoria de acurácia do modelo
inicial}

\end{figure}

A Figura~\ref{fig-simulacao-geral-inicial-absoluto} mostra os ganhos
absolutos. O gráfico apresenta o mesmo problema que o anterior, já que o
ganho máximo depende da acurácia inicial do modelo. Ainda assim, é
possível notar que, em termos absolutos, modelos com acurácia inicial
entre 10\% e 35\% apresentaram um ganho maior que modelos com acurácia
inicial de até 10\%.

\begin{figure}

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-geral-inicial-absoluto-1.pdf}

}

\caption{\label{fig-simulacao-geral-inicial-absoluto}Ganho absoluto ao
utilizar a técnica do oráculo, para cada categoria de acurácia do modelo
inicial}

\end{figure}

Para lidar com o fato de a acurácia ser um número limitado, fizemos o
mesmo gráficos de antes, mas ajustado pelo máximo possível que a técnica
do oráculo poderia proporcionar. O ganho absoluto ajustado de uma
simulação é dado por

\[
\text{ganho} = \frac{\text{wawl } - \text{ inicial}}{1\; - \text{ inicial}}.
\]

A Figura~\ref{fig-simulacao-geral-inicial-absoluto-ajustado} mostra os
ganhos ajustados. Pelo gráfico, é possível notar que existe um ganho
expressivo do WAWL para modelos iniciais com mais de 10\% de acurácia
com relação a modelos iniciais com até 10\% de acurácia. Ou seja, quando
o modelo inicial é fraco, o ganho ao usar o método é um pouco menor. É
importante notar, no entanto, que as simulações consideram a aplicação
do WAWL apenas uma vez -- é possível baixar mais dados e atualizar o
modelo indefinidamente, como mostrado mais adiante na
Figura~\ref{fig-aplicacao-iterada}. O menor efeito do método para
modelos iniciais fracos não significa, portanto, que a técnica não
funciona para modelos iniciais fracos; pelo contrário: ela ajuda o
modelo a sair do estado inicial e o leva para um estado com acurácia
maior, de onde seria possível aplicar a técnica novamente para obter
resultados mais expressivos.

\begin{figure}

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-geral-inicial-absoluto-ajustado-1.pdf}

}

\caption{\label{fig-simulacao-geral-inicial-absoluto-ajustado}Ganho
absoluto ao utilizar a técnica do oráculo, para cada categoria de
acurácia do modelo inicial}

\end{figure}

Na Figura~\ref{fig-simulacao-captcha}, são apresentados os resultados
separados por Captcha. Cada linha é uma combinação de Captcha,
quantidade de tentativas e acurácia modelo inicial, classificados nas
três categorias mostradas anteriormente. As linhas pontilhadas indicam
modelos ajustados com mais de uma tentativa, enquanto as linhas
contínuas mostram modelos ajustados com apenas uma tentativa. A primeira
extremidade de cada linha, do lado esquerdo, indica a acurácia do modelo
inicial e a segunda extremidade, do lado direito, a acurácia do modelo
usando o método WAWL.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-simulacao-captcha-1.pdf}

}

\caption{\label{fig-simulacao-captcha}Resultados da simulação por
captcha, quantidade de tentativas e modelo inicial}

\end{figure}

Pelo gráfico, é possível identificar duas informações relevantes. Como
já verificado anteriormente, os modelos ajustados com mais de uma
tentativa apresentam maiores ganhos do que os modelos ajustados com
apenas uma tentativa. Verifica-se também que modelos com acurácia
inicial de até 10\% só apresentam ganhos menores que os modelos com
acurácia inicial maior que 10\% nos casos com apenas um chute. Ou seja,
existe interação entre a quantidade de chutes e a acurácia do modelo
inicial ao avaliar o impacto nos ganhos empíricos do método WAWL.

Pelos resultados das simulações, é possível concluir que o método WAWL
foi bem-sucedido. Primeiro, o método apresenta resultados expressivos e
de forma consistente, mesmo sem realizar novas anotações manuais. Além
disso, a técnica consegue aproveitar oportunidade oferecida pelos sites
de obter o \emph{feedback} oráculo múltiplas vezes na mesma imagem.
Finalmente, o método apresenta, em média, resultados positivos mesmo
para modelos iniciais muito fracos (com acurácia de até 10\%), indicando
que sua aplicação é possível para qualquer modelo inicial, o que é
bastante factível de atingir com bases pequenas ou com modelos
generalistas para resolver Captchas.

Um possível problema em aplicar o WAWL é que a técnica poderia
introduzir viés de seleção no modelo, impedindo-o de ser aprimorado
indefinidamente. Mesmo que os resultados teóricos deem uma boa base para
concluir que isso não seja verdade, foi feito um experimento adicional,
com apenas um dos Captchas, para verificar se a aplicação da técnica
múltiplas vezes apresenta bons resultados.

O Captcha escolhido para a simulação foi o \texttt{trf5}, por ser um
Captcha que não aceita múltiplos chutes, em uma tentativa de obter um
pior caso. Para esse Captcha, o melhor modelo obtido com a técnica do
oráculo foi considerado como modelo inicial, sendo usado para baixar
novos dados do site do Tribunal. Os novos dados foram adicionados à base
de treino, ajustando-se um novo modelo.

A Figura~\ref{fig-aplicacao-iterada} mostra os resultados da aplicação
iterativa. A utilização da técnica não só funcionou como levou o modelo
a uma acurácia de 100\%.

\begin{figure}

{\centering \includegraphics[width=0.85\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-aplicacao-iterada-1.pdf}

}

\caption{\label{fig-aplicacao-iterada}Resultados da aplicação iterativa
do WAWL}

\end{figure}

O resultado sugere que o método WAWL pode ser aplicado iterativamente
para aprimorar o aprendizado do modelo. Ele sugere, ainda, que uma
técnica de aprendizado ativo com \emph{feedback} automático do oráculo
pode dar bons resultados, já que a forma de obter os dados não introduz
viés de seleção no ajuste do modelo.

Nesse sentido, foi aplicado também um experimento de uma ferramenta de
\emph{online learning}. A ferramenta funciona da seguinte forma: ao
invés de aplicar os passos do WAWL (baixar dados e ajustar novo modelo)
de forma separada, obtêm-se amostras do oráculo em cada passo do ajuste
do modelo. Ou seja, as técnicas de raspagem de dados entram de forma
direta no ciclo de aprendizagem.

O experimento foi feito utilizando o Captcha do TJRS com os passos a
seguir. O modelo, função de perda e base de testes são exatamente os
mesmos utilizados na simulação completa. No entanto, os dados baixados
pelo oráculo não são considerados. Ao invés disso, o \emph{minibatch} é
construído baixando dados diretamente da internet e aplicando o modelo
inicial.

Para permitir que o modelo aproveite casos baixados em
\emph{minibatches} anteriores, o modelo considera uma probabilidade de
baixar novos casos, arbitrada em 80\%. Assim, para cada elemento do
\emph{minibatch}, com 80\% de probabilidade, a observação é baixada da
internet, e com 20\% de probabilidade, a observação é uma amostra dos
casos anteriores já baixados. Como forma de obter um pior caso, o modelo
não considera nem mesmo os dados utilizados para construir o modelo
inicial.

O valor do \emph{minibatch} foi arbitrado em 40 observações, como na
etapa de simulação. O número de \emph{minibatches} de uma época é
indefinido, porque não existe um número máximo de amostras. A época foi
arbitrada como sendo a passagem de 2 \emph{minibatches}, para permitir a
atualização do modelo inicial.

A atualização do modelo inicial é realizada ao fim de cada época. Se ao
fim do ciclo (ou seja, ao fim de 2 \emph{minibatches}) o modelo ajustado
possui uma acurácia melhor na base de teste do que o modelo inicial, o
modelo é atualizado para a versão atual. Se não, o modelo inicial é
mantido. Dessa forma, os \emph{minibatches} construídos ficam cada vez
mais informativos, uma vez que vão acertar mais o rótulo da imagem.

O experimento considerou um modelo inicial com apenas 11\% de acurácia.
O TJRS foi escolhido como exemplo porque o site é relativamente estável,
além de permitir múltiplos chutes. O número de chutes permitidos ao
modelo foi arbitrado em 5. Na parte dos hiperparâmetros, como a época é
curta (apenas 80 observações por época), o decaimento na taxa de
aprendizado considerado foi 0.999. Os valores de \emph{dropout} e
quantidade de unidades na camada densa foram as mesmas do modelo
inicial.

O resultado do experimento foi promissor. A partir do modelo inicial
11\% de acurácia, após 100 épocas, o modelo baixou 6391 imagens e chegou
em uma acurácia de 87\% na base de teste. A
Figura~\ref{fig-online-learning} mostra a evolução da acurácia do modelo
ao longo das épocas. Como as épocas são relativamente curtas (apenas 80
observações), o ganho em acurácia é pequeno e apresenta variabilidade.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-online-learning-1.pdf}

}

\caption{\label{fig-online-learning}Resultados do experimento com
aprendizado online}

\end{figure}

Um possível motivo do Captcha não ter chegado no máximo de acurácia
(100\% no caso do TJRS) é que a arquitetura e os hiperparâmetros
considerados não eram poderosos o suficiente para alcançar o melhor
modelo. De qualquer forma, a partir do experimento, conclui-se que a
utilização de \emph{online learning} também é muito promissora. A
principal vantagem do método é ser menos burocrático para
desenvolvedores, no sentido de que basta passar o modelo inicial e
funções para baixar e testar os Captchas para aprimorar o modelo. A
desvantagem é que o procedimento precisa de conexão ativa com a internet
e o aprendizado é mais lento, já que os dados são baixados no processo
de construção dos \emph{minibatches}.

\hypertarget{sec-pacote-captcha}{%
\section{Pacote captcha}\label{sec-pacote-captcha}}

O trabalho de resolução de Captchas pelo autor da tese surgiu no ano de
2016. Como foi comentado na introdução da tese, é muito comum se deparar
com desafios de Captchas ao raspar dados do judiciário, já que estes
dados não são abertos.

O primeiro Captcha a ser investigado foi o do sistema e-SAJ. O desafio
era utilizado no site do TJSP que, depois de alguns anos, passou a
utilizar o sistema reCaptcha. O Captcha do e-SAJ faz parte da tese, mas
tem como fonte de dados o TJBA, que continua utilizando o desafio até o
momento que os sites foram investigados pela última vez, em setembro de
2022.

A primeira abordagem para resolver o Captcha do e-SAJ foi utilizando
heurísticas para separar as letras, em 2016. Infelizmente o pacote
original, chamado \texttt{\{captchasaj\}}, foi removido da
\emph{internet}, mas um código legado construído para o TJRS está
disponível
\href{https://github.com/decryptr/captchaTJRS/blob/master/R/tools.R}{neste
link}. Nessa abordagem, as letras primeiro são segmentadas, alimentando
um modelo de florestas aleatórias que considera os pixels da imagem como
variáveis preditoras e a letra como resposta. Esses trabalhos tiveram
contribuições importantes de Fernando Corrêa e Athos Damiani, ambos do
IME-USP.

A segunda abordagem para resolver os Captchas foi utilizando o áudio,
também em 2016. O código para resolver o Captcha da RFB utilizando áudio
está disponível
\href{https://github.com/decryptr/captchaReceitaAudio}{neste link}. A
ideia de resolução era parecida, passando pelo procedimento de
segmentação e depois de modelagem, mas tinha um passo intermediário de
processamento envolvendo engenharia de \emph{features}
(\protect\hyperlink{ref-kuhn2019}{KUHN; JOHNSON, 2019}). O trabalho teve
contribuições importantes de Athos Damiani.

Com o advento da ferramenta TensorFlow para o R
(\protect\hyperlink{ref-tensorflow}{ALLAIRE; TANG, 2022}), os modelos
para resolver Captchas passaram a utilizar modelos de redes neurais. No
início, por falta de conhecimento da área, a arquitetura das redes era
demasiadamente complexa. Depois que os primeiros modelos começaram a
funcionar, notou-se que as etapas de pré-processamento com segmentação e
algumas camadas das redes eram desnecessárias para ajustar os modelos.
Essa parte teve grande contribuição de Daniel Falbel, também do IME-USP,
que foi a pessoa que introduziu o TensorFlow e a área de \emph{deep
learning} para a comunidade brasileira de R.

Depois de resolver com sucesso alguns Captchas, notou-se que seria
possível criar um ambiente completo de modelagem de Captchas. Isso deu
origem ao pacote \texttt{\{decryptr\}}
(\protect\hyperlink{ref-decryptr}{TRECENTI et al., 2022}), que foi
construído em 2017. O trabalho teve grandes contribuições de Caio Lente,
do curso de Ciência da Computação do IME-USP e outros colegas de
faculdade.

Com o passar do tempo, o pacote \texttt{\{decryptr\}} ficou cada vez
mais estável, funcionando como dependência de várias ferramentas
utilizadas em trabalhos de jurimetria. O pacote também ganhou um site:
\url{https://decryptr.xyz} e uma API com acesso gratuito, precisando
apenas de uma chave de acesso. A ferramenta ficou bastante popular, com
\href{https://github.com/decryptr/decryptr}{178 estrelas no GitHub} no
mês de dezembro de 2022. Essas ferramentas envolveram contribuições
principalmente de Caio Lente e Daniel Falbel.

A construção do pacote \texttt{\{captcha\}} separada do
\texttt{\{decryptr\}} se deu por dois motivos. Primeiro, o pacote
\texttt{\{decryptr\}}, por ser o primeiro a tratar do assunto, possui
muitos códigos legados e dificuldades de instalação por conta da
dependência do python, necessário para o funcionamento do TensorFlow,
que é chamado através do pacote \texttt{\{reticulate\}}
(\protect\hyperlink{ref-reticulate}{USHEY; ALLAIRE; TANG, 2022}). Além
disso, a implementação das técnicas do oráculo envolviam modificações na
função de perda, que são mais difíceis de implementar no ambiente do
\texttt{\{tensorflow\}}, justamente por conta da necessidade de conhecer
o código python que roda por trás dos códigos em R.

Com o advento do pacote \texttt{\{torch\}}
(\protect\hyperlink{ref-torch}{FALBEL; LURASCHI, 2022}), no entanto,
tudo foi facilitado. O pacote não possui dependências com o python, além
de ser bastante transparente e flexível na construção da arquitetura do
modelo, funções de perda e otimização. O pacote, também construído por
Daniel Falbel, é um grande avanço científico e facilitou muito a
construção dos códigos desta tese.

O pacote \texttt{\{captcha\}}, apesar de ter sido construído do zero,
foi desenvolvido durante \emph{lives} realizadas na plataforma
\emph{Twitch}. A construção em \emph{lives} foi interessante porque era
possível obter \emph{feedback} e ideias da comunidade durante a
construção da ferramenta, o que acelerou o desenvolvimento e auxiliou na
arquitetura do pacote.

O pacote \texttt{\{captcha\}} foi construído para funcionar como uma
caixa de ferramentas para quem deseja trabalhar com Captchas. O pacote
possui funções de leitura, visualização, anotação, preparação de dados,
modelagem, carregamento de modelos pré-treinados e predição. O pacote
também permite a construção de um fluxo de trabalho para resolver um
novo Captcha, criando um novo repositório para orquestrar o
passo-a-passo.

\hypertarget{uso-buxe1sico}{%
\subsection{Uso básico}\label{uso-buxe1sico}}

A utilização básica do \texttt{\{captcha\}} envolve as funções
\texttt{read\_captcha()}, \texttt{plot()}, \texttt{captcha\_annotate()},
\texttt{captcha\_load\_model()} e \texttt{decrypt()}. As funções são
explicadas abaixo.

A função \texttt{read\_captcha()} lê um vetor de arquivos de imagens e
armazena na memória do computador. Por trás, a função utiliza o pacote
\texttt{\{magick\}} para lidar com os tipos de arquivos mais comuns
(JPEG, PNG, entre outros).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(captcha)}
\NormalTok{exemplo }\OtherTok{\textless{}{-}} \StringTok{"assets/img/dados\_tjmg.jpeg"}
\NormalTok{captcha }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplo)}

\NormalTok{captcha}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 7}
\CommentTok{\#\textgreater{}   format width height colorspace matte filesize density}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}  \textless{}int\textgreater{}  \textless{}int\textgreater{} \textless{}chr\textgreater{}      \textless{}lgl\textgreater{}    \textless{}int\textgreater{} \textless{}chr\textgreater{}  }
\CommentTok{\#\textgreater{} 1 JPEG     100     50 sRGB       FALSE     4530 72x72}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-uso-basico-captcha-1.png}

}

\caption{\label{fig-uso-basico-captcha}Resultado observado ao imprimir
um objeto de classe captcha}

\end{figure}

A função retorna um objeto com a classe \texttt{captcha}, que pode ser
utilizada por outros métodos do pacote.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(captcha)}
\CommentTok{\#\textgreater{} [1] "captcha"}
\end{Highlighting}
\end{Shaded}

O objeto de classe \texttt{captcha} é uma lista com três elementos:
\texttt{\$img}, que contém imagem lida com o pacote \texttt{\{magick\}},
\texttt{\$lab}, que contém o rótulo da imagem (por padrão,
\texttt{NULL}) e \texttt{\$path}, que contém o caminho da imagem que foi
lida.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(captcha)}
\CommentTok{\#\textgreater{} Class \textquotesingle{}captcha\textquotesingle{}  hidden list of 3}
\CommentTok{\#\textgreater{}  $ img :Class \textquotesingle{}magick{-}image\textquotesingle{} \textless{}externalptr\textgreater{} }
\CommentTok{\#\textgreater{}  $ lab : NULL}
\CommentTok{\#\textgreater{}  $ path: chr "assets/img/dados\_tjmg.jpeg"}
\end{Highlighting}
\end{Shaded}

A função \texttt{read\_captcha()} possui um parâmetro
\texttt{lab\_in\_path=}, que indica se o rótulo está contido no caminho
da imagem. Se \texttt{lab\_in\_path=TRUE}, a função tentará extrair o
rótulo do arquivo, obtendo o texto que vem depois do último \texttt{\_}
do caminho, armazenando o resultado no elemento \texttt{\$lab}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exemplo }\OtherTok{\textless{}{-}} \StringTok{"assets/img/mnist128c49c36e13\_6297.png"}
\NormalTok{captcha }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplo, }\AttributeTok{lab\_in\_path =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{str}\NormalTok{(captcha)}
\CommentTok{\#\textgreater{} Class \textquotesingle{}captcha\textquotesingle{}  hidden list of 3}
\CommentTok{\#\textgreater{}  $ img :Class \textquotesingle{}magick{-}image\textquotesingle{} \textless{}externalptr\textgreater{} }
\CommentTok{\#\textgreater{}  $ lab : chr "6297"}
\CommentTok{\#\textgreater{}  $ path: chr "assets/img/mnist128c49c36e13\_6297.png"}
\end{Highlighting}
\end{Shaded}

A função \texttt{plot()} é um método de classe S3 do R básico. A função
foi implementada para facilitar a visualização de Captchas. A função
recebe uma lista de imagens obtida pela função \texttt{read\_captcha()}
e mostra o Captcha visualmente, como na Figura~\ref{fig-exemplo-plot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exemplo }\OtherTok{\textless{}{-}} \StringTok{"assets/img/dados\_tjmg.jpeg"}
\NormalTok{captcha }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplo)}
\FunctionTok{plot}\NormalTok{(captcha)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-exemplo-plot-1.pdf}

}

\caption{\label{fig-exemplo-plot}Exemplo de aplicação da função plot a
um objeto \texttt{captcha}}

\end{figure}

Um aspecto interessante da função \texttt{plot()} é que ela lida com uma
lista de Captchas. Isso é útil quando o interesse é visualizar vários
Captchas de uma vez na imagem. A Figura~\ref{fig-exemplo-plot-multi}
mostra um exemplo de aplicação.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exemplos }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"assets/img/"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}
  \StringTok{"dados\_tjmg.jpeg"}\NormalTok{,}
  \StringTok{"dados\_esaj.png"}\NormalTok{,}
  \StringTok{"dados\_rfb.png"}\NormalTok{,}
  \StringTok{"dados\_sei.png"}
\NormalTok{))}
\NormalTok{captchas }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplos)}
\FunctionTok{plot}\NormalTok{(captchas)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-exemplo-plot-multi-1.pdf}

}

\caption{\label{fig-exemplo-plot-multi}Exemplo de aplicação da função
plot a um objeto \texttt{captcha} com várias imagens}

\end{figure}

Por padrão, a função plot dispõe as imagens em quatro colunas. Para
mudar o padrão, é possível modificar as opções usando
\texttt{options(captcha.print.cols\ =\ N)}, onde \texttt{N} é o número
de colunas desejado. A Figura~\ref{fig-exemplo-plot-multi-2col} mostra
um exemplo com duas colunas.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{captcha.print.cols =} \DecValTok{2}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(captchas)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.6\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-exemplo-plot-multi-2col-1.pdf}

}

\caption{\label{fig-exemplo-plot-multi-2col}Exemplo de aplicação da
função plot a um objeto \texttt{captcha} com várias imagens,
disponibilizadas em duas colunas}

\end{figure}

Quando o vetor de Captchas é muito grande, a função \texttt{plot()}
mostra um número máximo de 100 imagens, acompanhado de uma mensagem. O
padrão de 100 imagens está organizado em uma grade com 25 linhas e 4
colunas, podendo ser sobrescrito ao combinar as opções
\texttt{captcha.print.cols=} e \texttt{captcha.print.rows=}. A
Figura~\ref{fig-exemplo-plot-multi-varias} mostra um exemplo do
comportamento da função quando o número de imagens excede 100.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mais de 100 imagens:}
\NormalTok{exemplos }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{"assets/img/dados\_tjmg.jpeg"}\NormalTok{, }\DecValTok{110}\NormalTok{)}
\NormalTok{captchas }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplos)}
\FunctionTok{plot}\NormalTok{(captchas)}
\CommentTok{\#\textgreater{} i Too many images, printing first 100. To override, run}
\CommentTok{\#\textgreater{} * options(\textquotesingle{}captcha.print.rows\textquotesingle{} = MAX\_ROWS)}
\CommentTok{\#\textgreater{} * options(\textquotesingle{}captcha.print.cols\textquotesingle{} = COLUMNS)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./resultados_files/figure-pdf/fig-exemplo-plot-multi-varias-1.pdf}

}

\caption{\label{fig-exemplo-plot-multi-varias}Demonstração da função
\texttt{plot()} com muitas imagens}

\end{figure}

É possível criar subconjuntos de um objeto de classe \texttt{captcha}
utilizando o operador \texttt{{[}}. A função \texttt{length()} também
pode ser utilizada para medir a quantidade de imagens lidas. A
Figura~\ref{fig-exemplo-plot-multi-varias-subset} mostra um exemplo
dessas operações.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{captchas\_subset }\OtherTok{\textless{}{-}}\NormalTok{ captchas[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{20}\NormalTok{]}
\FunctionTok{length}\NormalTok{(captchas\_subset) }\CommentTok{\# 20}
\CommentTok{\#\textgreater{} [1] 20}
\FunctionTok{plot}\NormalTok{(captchas\_subset)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./resultados_files/figure-pdf/fig-exemplo-plot-multi-varias-subset-1.pdf}

}

\caption{\label{fig-exemplo-plot-multi-varias-subset}Demonstração das
funções de subset e length aplicadas a um objeto do tipo
\texttt{captcha}}

\end{figure}

Se a imagem possui um rótulo, por padrão, a função \texttt{plot()}
mostra o rótulo no canto da imagem. A
Figura~\ref{fig-exemplo-plot-rotulado} mostra um exemplo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exemplo }\OtherTok{\textless{}{-}} \StringTok{"assets/img/mnist128c49c36e13\_6297.png"}
\NormalTok{captcha }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(exemplo, }\AttributeTok{lab\_in\_path =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(captcha)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./resultados_files/figure-pdf/fig-exemplo-plot-rotulado-1.pdf}

}

\caption{\label{fig-exemplo-plot-rotulado}Demonstração da função
\texttt{plot()} quando o Captcha possui um rótulo}

\end{figure}

A função \texttt{captcha\_annotate()} serve para anotar o rótulo de uma
imagem de Captcha, manual ou automaticamente. Isso é feito modificando o
caminho da imagem, adicionando o texto \texttt{\_rotulo} ao final do
caminho do arquivo. A função possui os parâmetros listados abaixo:

\begin{itemize}
\tightlist
\item
  \texttt{files=}: objeto de classe \texttt{captcha} lido com a função
  \texttt{read\_captcha()} (recomendado) ou vetor de caminhos de
  arquivos.
\item
  \texttt{labels=}: (opcional) vetor com os rótulos das imagens. Deve
  ter o mesmo \texttt{length()} do que \texttt{files=}. Por padrão, o
  valor é \texttt{NULL}, indicando que deve ser aberto um
  \texttt{prompt} para que o usuário insira a resposta manualmente.
\item
  \texttt{path=}: (opcional) caminho da pasta onde os arquivos anotados
  serão salvos. Por padrão, salva os arquivos com nomes modificados na
  mesma pasta dos arquivos originais.
\item
  \texttt{rm\_old=}: (opcional) deletar ou não os arquivos originais.
  Por padrão, é \texttt{FALSE}.
\end{itemize}

A função, depois de aplicada, retorna um vetor com os caminhos dos
arquivos modificados. O parâmetro \texttt{labels=} é útil para lidar com
situações em que sabemos o rótulo do Captcha. Por exemplo, em um fluxo
de trabalho que utiliza o oráculo, pode ser que um modelo inicial já
forneça o valor correto do rótulo.

Quando não existe um rótulo, a função \texttt{captcha\_annotate()}, que
abre o \texttt{prompt} para anotação e aplica \texttt{plot()} para
visualizar a imagem. A Figura~\ref{fig-exemplo-annotate} mostra um
exemplo de aplicação da função \texttt{captcha\_annotate()} no software
\href{https://posit.co/download/rstudio-desktop/}{RStudio}.

\begin{figure}

{\centering \includegraphics{./assets/img/exemplo_annotate.png}

}

\caption{\label{fig-exemplo-annotate}Exemplo de aplicação da função
\texttt{captcha\_annotate()}. O rótulo \texttt{bhusp5} foi inserido
manualmente}

\end{figure}

Por último, a função \texttt{decrypt()} tem o papel de obter o rótulo de
uma imagem utilizando um modelo já treinado para aquele tipo de imagem.
A função recebe dois argumentos: \texttt{file=} que pode ser tanto o
caminho do arquivo quanto um objeto de classe \texttt{captcha}, e um
argumento \texttt{model=}, que contém um modelo de classe
\texttt{luz\_module\_fitted}, ajustado utilizando as ferramentas que
serão apresentadas na próxima subseção.

Para a tese, foram desenvolvidos modelos para vários Captchas
diferentes. É possível carregar um modelo já treinado usando a função
\texttt{captcha\_load\_model()}, podendo receber em seu único parâmetro
\texttt{path=} o caminho de um arquivo contendo um modelo ajustado ou
uma \emph{string} com o nome de um modelo já treinado, como
\texttt{"rfb"}, por exemplo. Os modelos treinados são armazenados nos
\href{https://github.com/decryptr/captcha/releases}{releases do
repositório do pacote captcha}, são baixados e controlados pelo pacote
\texttt{\{piggyback\}} (\protect\hyperlink{ref-piggyback}{BOETTIGER; HO,
2022}) e são lidos utilizando o pacote \texttt{\{luz\}}, que será
descrito em maiores detalhes na próxima subseção. No momento de
submissão da tese, os Captchas com modelos desenvolvidos eram
\texttt{trf5}, \texttt{tjmg}, \texttt{trt}, \texttt{esaj},
\texttt{jucesp}, \texttt{tjpe}, \texttt{tjrs}, \texttt{cadesp},
\texttt{sei} e \texttt{rfb}. Mais modelos serão adicionados no futuro.

A Figura~\ref{fig-diagrama-captcha-simples} resume visualmente as
funções apresentadas até o momento. As setas indicam a dependência das
funções de objetos gerados por outras funções.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./assets/img/diagram.png}

}

\caption{\label{fig-diagrama-captcha-simples}Diagrama das funções
básicas do pacote \texttt{\{captcha\}}}

\end{figure}

\hypertarget{sec-ap-modelagem}{%
\subsection{Modelagem}\label{sec-ap-modelagem}}

O pacote \texttt{\{captcha\}} também fornece uma interface básica para o
desenvolvimento de modelos a partir de uma base completamente anotada. A
anotação pode ser feita manualmente pela função
\texttt{captcha\_annotate()}, apresentada anteriormente, ou por outro
método desenvolvido pelo usuário.

A parte de modelagem parte de algumas premissas sobre a base de dados.
As imagens precisam estar em uma pasta e ter o padrão
\texttt{caminho/do/arquivo/\textless{}id\textgreater{}\_\textless{}lab\textgreater{}.\textless{}ext\textgreater{}},
onde:

\begin{itemize}
\tightlist
\item
  \texttt{\textless{}id\textgreater{}}: pode ser qualquer nome, de
  preferência sem acentuação ou outros caracteres especiais, para evitar
  problemas de \emph{encoding}. Geralmente, é um \emph{hash}
  identificando o tipo e id do captcha. \textbf{Nota}: ao anotar um
  caso, é importante que o \texttt{id} seja único, já que dois Captchas
  podem ter o mesmo rótulo.
\item
  \texttt{\textless{}lab\textgreater{}}: é o rótulo do Captcha. Pode ser
  um conjunto de caracteres entre \texttt{{[}a-zA-Z0-9{]}},
  diferenciando maiúsculas e minúsculas se necessário. No momento, todos
  os arquivos em uma pasta devem ter a mesma quantidade de caracteres
  (comprimento homogêneo). Futuramente, o pacote poderá considerar
  Captchas de comprimento heterogêneo.
\item
  \texttt{\textless{}ext\textgreater{}}: extensão do arquivo. Pode ser
  \texttt{.png}, \texttt{.jpeg} ou \texttt{.jpg}. As operações também
  funcionam para o formato \texttt{.svg}, mas pode apresentar problemas
  por conta da transparência da imagem.
\end{itemize}

Atendidas as premissas da base anotada, é possível ajustar um modelo de
redes neurais usando o pacote \texttt{\{captcha\}}. No entanto, como o
ajuste de modelos de redes neurais tem uma série de nuances e pequenas
adaptações, optou-se por exportar funções em dois níveis de
aprofundamento. A primeira é a \textbf{automatizada}, utilizando a
função \texttt{captcha\_fit\_model()} descrita a seguir, enquanto a
segunda é a \textbf{procedimental}, utilizando o passo a passo descrito
na Subseção \ref{sec-captcha-do-zero}.

A função \texttt{captcha\_fit\_model()} ajusta um modelo a partir de uma
pasta com arquivos anotados. A função recebe os parâmetros:
\texttt{dir=}, contendo o caminho dos arquivos anotados;
\texttt{dir\_valid=}, (opcional) contendo o caminho dos arquivos
anotados para validação; \texttt{prop\_valid=}, contendo a proporção da
base de treino a ser considerada como validação, ignorada quando
\texttt{dir\_valid=} é fornecida (por padrão, considera-se 20\% da base
para validação).

A função \texttt{captcha\_fit\_model()} também possui alguns parâmetros
relacionados à modelagem. São eles: \texttt{dropout=}, especificando o
percentual de \emph{dropout} aplicado às camadas ocultas da rede (por
padrão, \texttt{0.25}); \texttt{dense\_units=}, especificando a
quantidade de unidades na camada oculta que vem depois das camadas
convolucionais (por padrão, 200); \texttt{decay=}, especificando o
percentual de decaimento da taxa de aprendizado (por padrão,
\texttt{0.99}); \texttt{epochs=} número de épocas (voltas completas na
base de treino) para ajuste do modelo (por padrão 100). O modelo está
configurado para parar o ajuste após 20 iterações sem redução
significativa na função de perda (arbitrado em 1\%; para mais detalhes
ver a Subseção \ref{sec-captcha-do-zero}).

No final, a função retorna um modelo ajustado com classe
\texttt{luz\_module\_fitted}, que pode ser salvo em disco utilizando-se
a função \texttt{luz\_save()}. O modelo também pode ser serializado para
utilização em outros pacotes como pytorch. Um tutorial sobre
serialização pode ser encontrado na
\href{https://torch.mlverse.org/docs/articles/serialization.html}{documentação
do pacote torch}.

O pacote \texttt{\{captchaOracle\}} possui uma interface similar para
trabalhar com bases com rótulos parciais. Como a estrutura de dados
nesse caso é mais complexa e pode evoluir no futuro, os códigos foram
organizados em outro pacote. Mais detalhes na Seção
\ref{sec-pacote-oracle}.

Na documentação do pacote \texttt{\{captcha\}}, foi adicionado um
exemplo de aplicação. O exemplo utiliza captchas gerados usando a função
\texttt{captcha\_generate()}, que gera Captchas utilizando o pacote
\texttt{\{magick\}}. O Captcha foi criado para a construção da tese,
apelidado de \texttt{R-Captcha}, e possui os seguintes parâmetros:

\begin{itemize}
\tightlist
\item
  \texttt{write\_disk=}: salvar os arquivos em disco? Por padrão, é
  falso.
\item
  \texttt{path=}: Caminho para salvar arquivos em disco, caso o
  parâmetro anterior seja verdadeiro.
\item
  \texttt{chars=}: Quais caracteres usar na imagem.
\item
  \texttt{n\_chars=}: O comprimento do Captcha.
\item
  \texttt{n\_rows=}: Altura da imagem, em pixels.
\item
  \texttt{n\_cols=}: Largura da imagem, em pixels.
\item
  \texttt{p\_rotate=}: Probabilidade de rotação da imagem.
\item
  \texttt{p\_line=}: Probabilidade de adicionar um risco entre as
  letras.
\item
  \texttt{p\_stroke=}: Probabilidade de adicionar uma borda nas letras.
\item
  \texttt{p\_box=}: Probabilidade de adicionar uma caixa (retângulo) em
  torno das letras.
\item
  \texttt{p\_implode=}: Probabilidade de adicionar efeitos de implosão.
\item
  \texttt{p\_oilpaint=}: Probabilidade de adicionar efeitos de tinta a
  óleo.
\item
  \texttt{p\_noise=}: Probabilidade de adicionar um ruído branco no
  fundo da imagem.
\item
  \texttt{p\_lat=}: Probabilidade de aplicar o algoritmo \emph{local
  adaptive thresholding} à imagem.
\end{itemize}

\hypertarget{sec-captcha-do-zero}{%
\subsection{Resolvendo um novo Captcha do
zero}\label{sec-captcha-do-zero}}

Em algumas situações, pode ser desejável rodar modelos de forma
customizada. Isso acontece pois modelos de aprendizagem profunda
costumam precisar de diversos pequenos ajustes, como na taxa de
aprendizado, funções de otimização, camadas computacionais e funções de
pré-processamento.

A função \texttt{captcha\_fit\_model()}, apresentada na subseção
anterior, é engessada. Ela aceita alguns parâmetros para estruturar o
modelo, mas não possui elementos suficientes para customização. É para
isso que pacotes como \texttt{\{torch\}} e \texttt{\{luz\}} existem,
pois criam ambientes de computação mais flexíveis para operar os modelos
de aprendizado profundo.

Outra desvantagem da utilização do \texttt{captcha\_fit\_model()} é
possibilidade de disponibilizar modelos. Um modelo pode ser utilizado
localmente, mas a tarefa de disponibilizar as bases de dados e o modelo
publicamente não tem um procedimento bem definido.

Para organizar o fluxo de trabalho, implementou-se passo-a-passo de
anotação e modelagem de Captchas dentro do pacote \texttt{\{captcha\}}.
A função que orquestra as atividades é a \texttt{new\_captcha()}. A
função possui apenas um parâmetro, \texttt{path=}, que é o caminho de
uma nova pasta a ser criada.

A função também pode ser chamada criando-se um projeto dentro do próprio
RStudio. A Figura~\ref{fig-exemplo-rstudio-template} mostra um exemplo
de utilização do template dentro do RStudio, após clicar em
\texttt{Novo\ Projeto\ \textgreater{}\ Novo\ Diretório}.

\begin{figure}

{\centering \includegraphics{./assets/img/exemplo-rstudio-template.png}

}

\caption{\label{fig-exemplo-rstudio-template}Exemplo de criação de um
novo projeto de Captcha utilizando o RStudio}

\end{figure}

Ao criar um novo projeto, pelo comando \texttt{new\_captcha()} ou pela
interface do RStudio, uma nova janela é aberta. O projeto contém quatro
arquivos:

\begin{itemize}
\tightlist
\item
  \texttt{01\_download.R}: Contém códigos que auxiliam no
  desenvolvimento de funções para baixar Captchas de um site. Na
  prática, as funções que baixam Captchas precisam ser adaptadas porque
  os sites são organizados de formas muito diferentes.
\item
  \texttt{02\_annotate.R}: Contém um \emph{template} para anotação
  manual de Captchas. A anotação manual pode tanto ser realizada usando
  a interface criada pelo pacote \texttt{\{captcha\}} quanto
  externamente. No final, os arquivos anotados devem ser salvos na pasta
  \texttt{img}, no formato descrito na Subseção \ref{sec-ap-modelagem}.
\item
  \texttt{03\_model.R}: Contém um \emph{template} para modelagem,
  permitindo a customização completa do procedimento de ajuste. O
  \emph{script} contém comandos para carregar os dados, especificar o
  modelo, realizar o ajuste e salvar o modelo ajustado.
\item
  \texttt{04\_share.R}: Contém funções para criar um repositório
  \emph{git} da solução e disponibilizar o modelo ajustado. O modelo
  poderá ser lido e aplicado utilizando-se a função
  \texttt{captcha\_load\_model()}, que pode ser aplicado em diferentes
  contextos, sem a necessidade de copiar arquivos localmente.
\end{itemize}

Sobre a parte de modelagem, cabe uma descrição mais detalhada com
apresentação de parte do código. O primeiro passo do \emph{script} é
criar objetos do tipo \emph{dataset} (objeto que armazena os dados de
forma consistente) e \emph{dataloader} (objeto que obtém amostras do
dataset, que são utilizadas como os \emph{minibatches} do modelo), com
uma estrutura orquestrada pelo pacote \texttt{\{torch\}}.

A função \texttt{captcha\_dataset()} cria o \emph{dataset}, recebendo
como parâmetro uma pasta de arquivos e gera um objeto com classes
\texttt{my\_captcha}, \texttt{dataset} e \texttt{R6}. A função é, na
verdade, um objeto do tipo \texttt{dataset\_generator}, criada
utilizando a função \texttt{dataset()} do pacote \texttt{\{torch\}}. O
objeto é chamado da mesma forma que uma função usual do R, aceitando
alguns parâmetros adicionais:

\begin{itemize}
\tightlist
\item
  \texttt{transform\_image=}: operação de transformação a ser aplicada à
  imagem. Por padrão, utiliza a função
  \texttt{captcha\_transform\_image()}, que lê a imagem e redimensiona
  para ficar com dimensões \texttt{32x192}. A dimensão foi escolhida
  para facilitar a implementação das camadas convolucionais e para lidar
  com o fato de que usualmente os Captchas são imagens retangulares.
\item
  \texttt{transform\_label=}: operação de transformação para gerar a
  variável resposta. Por padrão, utiliza a função
  \texttt{captcha\_transform\_label()}, que recebe um vetor de todos os
  possíveis caracteres do Captcha e aplica a operação
  \texttt{one\_hot()}, obtendo-se a versão matricial da resposta com
  zeros e uns, como descrito na Seção~\ref{sec-definicao-captcha}.
\item
  \texttt{augmentation=}: operações para aumentação de dados. Por
  exemplo, pode ser uma função que adiciona um ruído aleatório à imagem
  original para que, ao gerar uma nova amostra, os dados utilizados
  sejam sempre diferentes.
\end{itemize}

A função \texttt{captcha\_dataset()} deve ser aplicada duas vezes, uma
para criar a base de treino e outra para criar a base de validação. A
separação de bases de treino e validação deve ser feita de forma manual,
copiando parte dos Captchas anotados para uma nova pasta, com
aleatorização. É papel do usuário separar as bases em pastas distintas
carregá-as em um \emph{dataset}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# datasets}
\NormalTok{captcha\_ds }\OtherTok{\textless{}{-}}\NormalTok{ captcha}\SpecialCharTok{::}\FunctionTok{captcha\_dataset}\NormalTok{(}
  \AttributeTok{root =}\NormalTok{ parm}\SpecialCharTok{$}\NormalTok{path\_img,}
  \AttributeTok{captcha =} \ConstantTok{NULL}\NormalTok{,}
  \AttributeTok{download =} \ConstantTok{FALSE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Em seguida, os \emph{dataloaders} são criados utilizando-se a função
\texttt{dataloader()} do pacote \texttt{\{torch\}}. Nessa parte é
definido o tamanho do \emph{minibatch}, além de outros possíveis
parâmetros disponíveis na função do \texttt{\{torch\}}. Para mais
detalhes, o usuário pode
\href{https://torch.mlverse.org/docs/reference/dataloader.html}{acessar
a documentação da função neste link}. Devem ser criados
\emph{dataloaders} tanto para a base de treino quanto para a base de
validação.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# dataloaders (training and validation)}
\NormalTok{captcha\_dl\_train }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{dataloader}\NormalTok{(}
  \AttributeTok{dataset =}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{dataset\_subset}\NormalTok{(captcha\_ds, id\_train),}
  \AttributeTok{batch\_size =}\NormalTok{ parm}\SpecialCharTok{$}\NormalTok{batch\_size,}
  \AttributeTok{shuffle =} \ConstantTok{TRUE}
\NormalTok{)}

\NormalTok{captcha\_dl\_valid }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{dataloader}\NormalTok{(}
  \AttributeTok{dataset =}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{dataset\_subset}\NormalTok{(captcha\_ds, id\_valid),}
  \AttributeTok{batch\_size =}\NormalTok{ parm}\SpecialCharTok{$}\NormalTok{batch\_size}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A próxima etapa é a especificação do modelo. No \emph{script} de
modelagem, o modelo é fornecido pelo objeto \texttt{net\_captcha} do
pacote \texttt{\{captcha\}}. Assim como no caso do \emph{dataset}, o
\texttt{net\_captcha} é um objeto especial do \texttt{\{torch\}}, com
classes \texttt{CAPTCHA-CNN}, \texttt{nn\_module} e
\texttt{nn\_module\_generator}. O objeto pode ser utilizado como uma
função, gerando um módulo do \texttt{\{torch\}}, similar a uma função de
predição. No entanto, por conta da forma que o objeto é utilizado em
passos posteriores pelo pacote \texttt{\{luz\}}, o objeto a ser
considerado é mesmo o \texttt{nn\_module\_generator}, como colocado no
\emph{script}.

Para customizar o modelo, o usuário deve criar um novo módulo
modificando os métodos \texttt{initialize()} e \texttt{forward()},
acessados dentro do objeto \texttt{net\_captcha\$public\_methods}. O
primeiro é responsável pela inicialização do modelo, contendo a
descrição das operações que são realizadas, como convoluções. O segundo
é a função \emph{feed forward} das redes neurais, que recebe uma imagem
e retorna um objeto contendo os escores ou probabilidades, no formato da
variável resposta.

Por padrão, o código de inicialização do modelo é o descrito abaixo. Os
parâmetros \texttt{input\_dim=}, \texttt{output\_ndigits=},
\texttt{output\_vocab\_size=} e \texttt{vocab=} descrevem,
respectivamente, as dimensões da imagem, o comprimento da resposta, o
comprimento do alfabeto e os elementos do alfabeto. Os parâmetros
\texttt{transform=}, \texttt{dropout=} e \texttt{dense\_units=}
controlam, respectivamente, a função de transformação da imagem, os
hiperparâmetros de \emph{dropout} e a quantidade de unidades na camada
densa. É possível notar que os parâmetros das convoluções são fixos, já
preparados para funcionar bem com uma imagem de dimensões
\texttt{32x192}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{initialize }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(input\_dim,}
\NormalTok{                      output\_ndigits,}
\NormalTok{                      output\_vocab\_size,}
\NormalTok{                      vocab,}
\NormalTok{                      transform,}
                      \AttributeTok{dropout =} \FunctionTok{c}\NormalTok{(.}\DecValTok{25}\NormalTok{, .}\DecValTok{25}\NormalTok{),}
                      \AttributeTok{dense\_units =} \DecValTok{400}\NormalTok{) \{}
  
  \CommentTok{\# in\_channels, out\_channels, kernel\_size, stride = 1, padding = 0}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{batchnorm0 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_batch\_norm2d}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{conv1 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_conv2d}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{32}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{batchnorm1 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_batch\_norm2d}\NormalTok{(}\DecValTok{32}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{conv2 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_conv2d}\NormalTok{(}\DecValTok{32}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{batchnorm2 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_batch\_norm2d}\NormalTok{(}\DecValTok{64}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{conv3 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_conv2d}\NormalTok{(}\DecValTok{64}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{batchnorm3 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_batch\_norm2d}\NormalTok{(}\DecValTok{64}\NormalTok{)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{dropout1 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_dropout2d}\NormalTok{(dropout[}\DecValTok{1}\NormalTok{])}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{dropout2 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_dropout2d}\NormalTok{(dropout[}\DecValTok{2}\NormalTok{])}
  
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{fc1 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_linear}\NormalTok{(}
    \CommentTok{\# must be the same as last convnet}
    \AttributeTok{in\_features =} \FunctionTok{prod}\NormalTok{(}\FunctionTok{calc\_dim\_conv}\NormalTok{(input\_dim)) }\SpecialCharTok{*} \DecValTok{64}\NormalTok{,}
    \AttributeTok{out\_features =}\NormalTok{ dense\_units}
\NormalTok{  )}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{batchnorm\_dense }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_batch\_norm1d}\NormalTok{(dense\_units)}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{fc2 }\OtherTok{\textless{}{-}}\NormalTok{ torch}\SpecialCharTok{::}\FunctionTok{nn\_linear}\NormalTok{(}
    \AttributeTok{in\_features =}\NormalTok{ dense\_units,}
    \AttributeTok{out\_features =}\NormalTok{ output\_vocab\_size }\SpecialCharTok{*}\NormalTok{ output\_ndigits}
\NormalTok{  )}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{output\_vocab\_size }\OtherTok{\textless{}{-}}\NormalTok{ output\_vocab\_size}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{input\_dim }\OtherTok{\textless{}{-}}\NormalTok{ input\_dim}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{output\_ndigits }\OtherTok{\textless{}{-}}\NormalTok{ output\_ndigits}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{vocab }\OtherTok{\textless{}{-}}\NormalTok{ vocab}
\NormalTok{  self}\SpecialCharTok{$}\NormalTok{transform }\OtherTok{\textless{}{-}}\NormalTok{ transform}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

A função de \emph{feed forward} foi descrita abaixo. A função aplica o
passo-a-passo descrito na Seção~\ref{sec-arquitetura-rede}, recebendo
uma imagem \texttt{x} como entrada e retornando uma matriz com números
reais, que dão os pesos (positivos ou negativos) do modelo para cada
letra da resposta. O modelo retorna os valores de forma irrestrita, e
não os números no intervalo \([0,1]\) porque, no passo seguinte, a
função de perda considera como entrada esses valores. Se o usuário
decidir modificar o método \texttt{forward} para retornar
probabilidades, precisará também adaptar a função de perda utilizada.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{forward }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x) \{}

\NormalTok{  out }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{|\textgreater{}}
    \CommentTok{\# normalize}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{batchnorm0}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
    \CommentTok{\# layer 1}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{conv1}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_relu}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_max\_pool2d}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{batchnorm1}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
    
    \CommentTok{\# layer 2}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{conv2}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_relu}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_max\_pool2d}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{batchnorm2}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
    
    \CommentTok{\# layer 3}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{conv3}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_relu}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_max\_pool2d}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{batchnorm3}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
    
    \CommentTok{\# dense}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{torch\_flatten}\NormalTok{(}\AttributeTok{start\_dim =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{dropout1}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{fc1}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    torch}\SpecialCharTok{::}\FunctionTok{nnf\_relu}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{batchnorm\_dense}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{dropout2}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    self}\SpecialCharTok{$}\FunctionTok{fc2}\NormalTok{()}
  
\NormalTok{  out}\SpecialCharTok{$}\FunctionTok{view}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \FunctionTok{dim}\NormalTok{(out)[}\DecValTok{1}\NormalTok{],}
\NormalTok{    self}\SpecialCharTok{$}\NormalTok{output\_ndigits,}
\NormalTok{    self}\SpecialCharTok{$}\NormalTok{output\_vocab\_size}
\NormalTok{  ))}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Definida a arquitetura do modelo, o penúltimo passo é o ajuste. O ajuste
do modelo é conduzido pelo pacote \texttt{\{luz\}}, que facilita a
criação do \emph{loop} de ajuste dos parâmetros, desempenhando um papel
similar ao que o \texttt{keras} realiza para o \texttt{tensorflow} puro.

No caso dos Captchas, o código \texttt{\{luz\}} para ajuste do modelo
segue quatro passos, encadeados pelo operador \emph{pipe}, ou
\texttt{\textbar{}\textgreater{}}:

\begin{itemize}
\tightlist
\item
  \texttt{setup()}: serve para determinar a função de perda, o
  otimizador e as métricas a serem acompanhadas. No \emph{script}, a
  função de perda utilizada é a
  \texttt{nn\_multilabel\_soft\_margin\_loss()} do \texttt{\{torch\}}, o
  otimizador é o \texttt{optim\_adam()} do \texttt{\{torch\}} e a
  métrica é a \texttt{captcha\_accuracy()}, desenvolvida no pacote
  \texttt{\{captcha\}} para apresentar a acurácia considerando a imagem
  completa do Captcha e não a acurácia de cada letra da imagem, que
  seria o resultado se fosse utilizada a função
  \texttt{luz\_metric\_accuracy()}, do pacote \texttt{\{luz\}}.
\item
  \texttt{set\_hparams()}: serve para informar os hiperparâmetros e
  outras informações do modelo. Os parâmetros colocados dentro dessa
  função são exatamente os parâmetros do método \texttt{initialize()} da
  rede neural criada no passo anterior.
\item
  \texttt{set\_opt\_hparams()}: serve para informar os hiperparâmetros
  da otimização. Os parâmetros colocados nessa função são passados para
  a função de otimização. No script, o único parâmetro informado é a
  taxa de aprendizado, fixada em \texttt{0.01}.
\item
  \texttt{fit()}: serve para inicializar o \emph{loop} de ajuste do
  modelo. Aqui, é necessário passar os \emph{dataloaders} de treino e
  validação, a quantidade de épocas (fixada em 100), e os
  \emph{callbacks}, que são operações a serem aplicadas em diferentes
  momentos do ajuste (por exemplo, ao final de cada iteração). Por
  padrão, os \emph{callbacks} são:

  \begin{itemize}
  \tightlist
  \item
    O decaimento da taxa de aprendizado, utilizando uma taxa
    multiplicativa. A cada iteração, a taxa de aprendizado decai em um
    fator determinado pela função definida em \texttt{lr\_lambda}, que
    por padrão é \texttt{0.99}. Ou seja, em cada época, a taxa de
    aprendizado fica 1\% menor.
  \item
    A parada adiantada, ou \emph{early stopping}. Por padrão, está
    configurado para parar o ajuste do modelo se forem passadas 20
    épocas sem que o modelo melhore a acurácia em 1\% na base de
    validação. Por exemplo, se em 20 épocas consecutivas o modelo
    permanecer com acurácia em 53\%, o ajuste será encerrado, mesmo que
    não tenha passado pelas 100 épocas.
  \item
    O arquivo de \texttt{log}. Por padrão, o modelo guarda o histórico
    de ajuste em um arquivo do tipo \emph{comma separated values} (CSV),
    contendo a perda e a acurácia do modelo na base de treino e na base
    de validação, ao final de cada época. O arquivo de \texttt{log} é
    importante para acompanhar o ajuste do modelo e verificar sua
    performance ao longo das épocas, podendo dar \emph{insights} sobre
    possíveis ajustes nos hiperparâmetros.
  \end{itemize}
\end{itemize}

No final do fluxo definido pelo pacote \texttt{\{luz\}}, é obtido um
modelo ajustado. O modelo possui a classe \texttt{luz\_module\_fitted} e
pode ser investigado ao rodar o objeto no console do R. No exemplo do
\texttt{R-Captcha} apresentado na subseção anterior, o objeto possui as
características abaixo. O objeto contém um relatório conciso e bastante
informativo, mostrando o tempo de ajuste, as métricas obtidas no treino
e na validação e a arquitetura do modelo.

\begin{verbatim}
A `luz_module_fitted`
── Time ────────────────────────────────────────────────
• Total time: 10m 48.1s
• Avg time per training batch: 415ms
• Avg time per validation batch 217ms

── Results ─────────────────────────────────────────────
Metrics observed in the last epoch.

ℹ Training:
loss: 0.0049
captcha acc: 0.996
ℹ Validation:
loss: 0.0356
captcha acc: 0.905

── Model ───────────────────────────────────────────────
An `nn_module` containing 628,486 parameters.

── Modules ─────────────────────────────────────────────
• batchnorm0: <nn_batch_norm2d> #6 parameters
• conv1: <nn_conv2d> #896 parameters
• batchnorm1: <nn_batch_norm2d> #64 parameters
• conv2: <nn_conv2d> #18,496 parameters
• batchnorm2: <nn_batch_norm2d> #128 parameters
• conv3: <nn_conv2d> #36,928 parameters
• batchnorm3: <nn_batch_norm2d> #128 parameters
• dropout1: <nn_dropout> #0 parameters
• dropout2: <nn_dropout> #0 parameters
• fc1: <nn_linear> #563,400 parameters
• batchnorm_dense: <nn_batch_norm1d> #400 parameters
• fc2: <nn_linear> #8,040 parameters
\end{verbatim}

Por último, o modelo deve ser salvo em um arquivo local. Isso é feito
utilizando-se a função \texttt{luz\_save()} do pacote \texttt{\{luz\}},
guardando um objeto com extensão \texttt{.pt}, que será disponibilizado
no \texttt{04\_share.R}.

Cabe também um detalhamento do \emph{script} disponibilizado em
\texttt{04\_share.R}. O script utiliza o pacote \texttt{\{usethis\}}
(\protect\hyperlink{ref-usethis}{WICKHAM; BRYAN; BARRETT, 2022}) para
organizar o repositório, configurando o Git (\emph{software} de
versionamento de códigos) e o GitHub (sistema \emph{web} de organização
de repositórios). Além disso, o \emph{script} utiliza o pacote
\texttt{\{piggyback\}} (\protect\hyperlink{ref-piggyback}{BOETTIGER; HO,
2022}) para disponibilizar o modelo ajustado nos \emph{releases} do
repositório criado\footnote{O \emph{script} utiliza \emph{releases} para
  disponibilizar as soluções porque não é uma boa prática subir arquivos
  como modelos ajustados ou arquivos brutos de imagens diretamente no
  repositório. Isso acontece porque o repositório pode ficar
  demasiadamente pesado e o histórico do \emph{Git} fica alterado.}.
Opcionalmente, o usuário poderá também disponibilizar a base com os
arquivos anotados em um arquivo \texttt{.zip}, o que é recomendado, pois
permite que outras pessoas possam trabalhar com os mesmos dados e
aprimorar os modelos.

Uma vez compartilhado nos \emph{releases} do repositório, o modelo
poderá ser lido por qualquer pessoa, em outras máquinas utilizando o
pacote \texttt{\{captcha\}}. Basta rodar o código abaixo e o modelo será
carregado.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{captcha\_load\_model}\NormalTok{(}\StringTok{"\textless{}name\textgreater{}"}\NormalTok{, }\StringTok{"\textless{}user\textgreater{}/\textless{}repo\textgreater{}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Com isso, o trabalho pode ser compartilhado e Captchas podem ser
resolvidos de forma colaborativa. O fluxo do \texttt{new\_captcha()} é
flexível o suficiente para construir modelos customizados e consumidos
com o pacote \texttt{\{captcha\}}.

O fluxo também permite uma adaptação fácil ao método WAWL. Para isso,
basta substituir a função de perda e de leitura dos dados pelas funções
oferecidas pelo pacote \texttt{\{captchaOracle\}}, descrito no
Apêndice~\ref{sec-pacote}.

\hypertarget{sec-discussao}{%
\section{Discussão}\label{sec-discussao}}

Os resultados apresentados nas seções anteriores mostram que o método
WAWL possui bons resultados empíricos. Nesta seção, os resultados foram
confrontados com as hipóteses de pesquisa definidos na
Seção~\ref{sec-hipoteses} de forma crítica.

A primeira hipótese de pesquisa diz respeito à pertinência de utilizar
do aprendizado fracamente supervisionado como forma de ajustar modelos
para resolver Captchas. A hipótese foi verificada, já que os resultados
mostram um incremento significativo na acurácia do modelo em
praticamente todas as simulações.

Do ponto de vista teórico, várias pesquisas já apontavam que o
aprendizado com rótulos parciais ou rótulos complementares têm boas
propriedades. Por isso, já seria esperado que uma nova função de perda,
desde que pensada com cuidado, traria resultados positivos.

No entanto, até o momento, não existiam evidências de que a utilização
de rótulos parciais ou rótulos complementares teriam bons resultados
empíricos em Captchas. Isso foi verificado em todos os 12 Captchas
estudados, sendo 10 obtidos do mundo real. Em todos os casos, a função
de perda proposta funcionou bem e trouxe ganhos significativos na
acurácia do modelo, tanto em termos relativos quanto absolutos. Isso
demonstra que a escolha do método se alia bem ao problema que deu origem
à pesquisa, que são os Captchas.

Sobre a parte de aplicação iterada do WAWL, o resultado é positivo, mas
inconclusivo. A acurácia de 100\% encontrada pode sugerir que o método
WAWL sempre chegará em um resultado de 100\% para qualquer Captcha que
surgir. No entanto, pode ser que exista uma limitação na capacidade do
modelo, que é habilidade do modelo para se ajustar aos dados a partir
dos parâmetros. Pode ser que a arquitetura de rede neural escolhida para
resolver o Captcha não seja capaz de chegar a um modelo com 100\% de
acurácia, independente da quantidade de imagens observadas. É importante
olhar o resultado apresentado de forma crítica e compreender que estes
podem ser limitados, já que a arquitetura da rede neural não é parte do
método WAWL.

A segunda hipótese de pesquisa é a possibilidade de aliar a área de
raspagem de dados com a área de modelagem estatística. A hipótese também
foi verificada, já que o método WAWL, que utiliza técnicas de raspagem
de dados, apresentou bons resultados empíricos.

Neste momento, cabe um comentário sobre o ineditismo da utilização de
raspagem de dados em estudos estatísticos. É verdade que existem muitas
pesquisas que são possibilitadas por conta dos dados obtidos via
raspagem de dados: as pesquisas da ABJ, mencionadas na
Seção~\ref{sec-captchas-publicos} são alguns exemplos. Também existem
soluções que utilizam dados provenientes de raspagem de dados para
construção de modelos: por exemplo, o
\href{https://openai.com/dall-e-2/}{DALL-E-2}, que é parte de uma base
de dados construída utilizando imagens baixadas da internet
(\protect\hyperlink{ref-murray2012}{MURRAY; MARCHESOTTI; PERRONNIN,
2012};
\protect\hyperlink{ref-rameshHierarchicalTextConditionalImage2022}{RAMESH
et al., 2022}). No entanto, até o momento da realização da pesquisa, não
foi encontrado nenhum trabalho que utiliza a raspagem de dados como
parte do processo de aprendizado estatístico. O método WAWL conecta as
áreas de forma intrínseca, podendo ser entendida como uma nova variação
de aumentação de dados aplicada a redes neurais convolucionais.

O fato de a raspagem de dados ser relevante para o ajuste de um modelo
estatístico pode levar a algumas discussões sobre o ensino da
estatística. Primeiro, é importante mencionar que:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Raspagem de dados não faz parte dos currículos de Bacharelado em
  Estatística das principais universidades do país\footnote{Sites de
    universidades buscados: USP Butantã (IME), UFSCar, UNESP, Unicamp,
    USP São Carlos (ICMC), UFBA, UFPR, UFRGS, UFPE, UFAM, UFRN, UFF,
    ENCE, UFRJ, UFMG, UnB e UFG. A UFSCar possui uma disciplina com
    conteúdos de raspagem de dados, no entanto, o conteúdo nunca foi
    desenvolvido com os alunos na prática. Na UFPR, existem cursos de
    raspagem oferecidos de forma extracurricular.}. Logo, pode-se
  argumentar que raspagem de dados não é uma área de interesse da
  estatística.
\item
  Raspagem de dados não é uma área de conhecimento bem definida, como
  álgebra ou análise de sobrevivência. A área é melhor desenvolvida
  através de aplicações práticas e utilização de ferramentas (como R ou
  python) do que através de aulas teóricas.
\end{enumerate}

Os resultados levam, então, a um problema de equilíbrio entre
pertinência e oportunidade. De um lado, a área de raspagem não se
encaixa muito bem no currículo de estatística. Por outro lado, a área
expande as possibilidades de atuação de uma profissional da estatística.

Para aliar a pertinência e a oportunidade, uma opção seria oferecer
disciplinas optativas de raspagem de dados nos cursos de estatística.
Para aumentar a quantidade de potenciais ministrantes, a disciplina
poderia ser oferecida em parceria com outros cursos, como ciência da
computação, matemática aplicada e engenharias. Dessa forma, as pessoas
interessadas teriam a oportunidade de aprender um pouco sobre as
técnicas principais, conectando a raspagem de dados com as áreas de
conhecimento específicas, como é o caso do Captcha, que alia raspagem de
dados com estatística e inteligência artificial. Com isso, conclui-se a
discussão sobre a segunda hipótese de pesquisa.

Portanto, as duas hipóteses de pesquisa foram verificadas. No processo
de construção do trabalho, no entanto, um terceiro avanço muito
importante foi realizado na parte computacional. O pacote
\texttt{\{captcha\}} e os pacotes auxiliares
\texttt{\{captchaDownload\}} e \texttt{\{captchaOracle\}} são frutos
desse trabalho. Pela primeira vez, foi construída uma ferramenta aberta
contendo um fluxo de trabalho adaptado para trabalhar com Captchas. Além
disso, trata-se de uma das primeiras aplicações completas dos pacotes
\texttt{\{torch\}} e \texttt{\{luz\}}, que têm potencial de revolucionar
a forma em que os modelos estatísticos são desenvolvidos por pessoas que
fazem pesquisa em estatística. Os pacotes foram descritos em detalhes no
Apêndice~\ref{sec-pacote}.

Por fim, todos os modelos construídos foram disponibilizados no pacote
\texttt{\{captcha\}}. Os códigos, dados e resultados das simulações
estão disponíveis no pacote \texttt{\{captchaOracle\}}. Os dados
utilizados para elaboração da tese estão disponíveis no
\href{https://github.com/jtrecenti/doutorado}{repositório da tese no
GitHub}. Dessa forma, a pesquisa pode ser considerada como reprodutível,
podendo servir como base para pesquisas futuras.

\bookmarksetup{startatroot}

\hypertarget{sec-conclusao}{%
\chapter{Conclusões}\label{sec-conclusao}}

\epigrafe{Even robots need a break from the daily grind of solving captchas.}{ChatGPT}

Este trabalho de doutorado teve como objeto de estudo os Captchas, que
são desafios utilizados para identificar se o acesso à uma página na
internet é realizado por uma pessoa ou um robô. A pesquisa apresentou um
breve histórico dos Captchas, os problemas de sua utilização em serviços
públicos e as abordagens existentes para resolução automática de
Captchas. Em seguida, apresentou-se como um novo método, o WAWL, que
alia técnicas de raspagem de dados e aprendizado estatístico com rótulos
parciais para obter modelos poderosos de resolução de Captchas sem a
necessidade de anotar vários casos manualmente. Por fim, foram
apresentadas as propriedades do modelo proposto e os resultados
empíricos através de uma série de simulações.

Os resultados da pesquisa foram positivos. Na parte teórica, pesquisas
já apontavam que o aprendizado com rótulos parciais ou rótulos
complementares possuíam boas propriedades. O trabalho mostrou
empiricamente que a técnica apresenta bons resultados, aumentando a
acurácia dos modelos iniciais em mais de 3 vezes, sem a necessidade de
anotar novos dados. Além disso, foram encontradas evidências de que o
método pode ser aplicado iterativamente, resultando em modelos com poder
preditivo ainda maior.

As contribuições do estudo podem ser organizadas em três tipos:
contribuições para a sociedade em geral, contribuições para a pesquisa
acadêmica e contribuições para a comunidade de programação. Os próximos
parágrafos descrevem esses avanços.

A contribuição para a sociedade em geral está na quebra de um mecanismo
de incentivo nefasto, gerado pela utilização de Captchas em sites de
serviços públicos. Como comentado na introdução, o uso de Captchas gera
um incentivo para que pessoas e empresas que fazem raspagem de dados
utilizem serviços que se aproveitam de mão de obra humana com baixíssima
remuneração. Ao disponibilizar os modelos para resolução de Captchas
publicamente e uma ferramenta que facilita seu uso, as pessoas e
empresas interessadas podem resolver Captchas gratuitamente, afastando a
necessidade de utilizar esses serviços. Dessa forma, espera-se que o
trabalho possa ter um impacto positivo, ainda que pequeno, na qualidade
das relações de trabalho na sociedade.

A contribuição para a pesquisa acadêmica pode ser separada em três
partes. A primeira é que o método proposto apresenta bons resultados
empíricos, mostrando que pode ser um ponto de partida interessante para
quem deseja trabalhar com aprendizado com rótulos parcialmente anotados.
A segunda é relacionada ao uso da raspagem de dados como passo
intermediário na construção de modelos estatísticos, que pode ser a base
para o desenvolvimento de um novo campo de pesquisa. Espera-se que os
resultados obtidos sirvam como incentivo para que as técnicas de
raspagem de dados sejam ensinadas como disciplinas optativas em cursos
de estatística e similares. A terceira é que a ideia de explorar um
oráculo, ou seja, de obter informações parciais automaticamente pode
abrir um novo campo de estudos estatísticos: é possível encontrar,
futuramente, outras áreas do conhecimento em que oráculos estão
disponíveis, e este trabalho pode ajudar a utilizar a informação
fornecida pelo oráculo.

A contribuição para a comunidade de programadoras e programadores está
no pacote \texttt{\{captcha\}}. O pacote é uma caixa de ferramentas
completa para quem tiver interesse em resolver Captchas, além de ser uma
das primeiras aplicações que utilizam os pacotes \texttt{\{torch\}} e
\texttt{\{luz\}} como motor computacional. O pacote possui uma interface
que permite o compartilhamento de códigos, bases de dados e modelos
publicamente, possibilitando a criação de soluções que vão muito além do
próprio pacote.

Com isso, pode-se concluir que os quatro objetivos descritos na
Seção~\ref{sec-objetivos} foram atendidos. O modelo proposto foi
descrito e suas propriedades estudadas. Um repositório de dados completo
foi construído e disponibilizado no repositório do pacote
\href{https://github.com/decryptr/captcha/releases}{\texttt{\{captcha\}}},
contendo dados e modelos ajustados. O método foi utilizado e testado
para diferentes Captchas e diferentes situações, com sucesso.
Finalmente, foi disponibilizado um pacote computacional aberto,
possibilitando a resolução de novos Captchas que aparecerem em serviços
públicos.

É evidente, no entanto, que o trabalho apresenta algumas limitações. Na
parte teórica, os resultados matemáticos podem ser desenvolvidos com
maior detalhamento. Especificamente, podem ser apresentadas e testadas
outras propostas de função de perda, eventualmente com implementações
que aceitem o uso de aceleradores com placas de vídeo. Além disso, seria
interessante modificar as probabilidades fornecidas pelo modelo nos
casos em que o rótulo está errado, para que o modelo nunca dê
probabilidade zero para algum rótulo. A escolha de apenas uma
alternativa de perda e do uso direto dos resultados fornecidos pelo
oráculo foi feita por conta do foco em resolver o problema de pesquisa
(os Captchas), no lugar da discussão mais aprofundada do aprendizado com
rótulos parciais.

Outra limitação importante do estudo está na aplicação iterada. A
pesquisa apresentou essa parte como um resultado adicional, mas os
limites da aplicação iterada ainda não foram estudados de forma
completa. Essa limitação pode ser entendida também como um próximo
passo, que seria a solução de \emph{online learning}.

Uma extensão possível desta pesquisa é a criação de um modelo que
aprende diretamente da \emph{web}, sem a separação de passos descrita
pelo WAWL. A técnica consiste em inserir as funções de acesso e teste do
Captcha como método de obtenção de amostras do \emph{dataset} do Captcha
(mais detalhes na Seção~\ref{sec-captcha-do-zero}). Dessa forma, o
modelo pode obter novos dados em cada \emph{minibatch}, indefinidamente.
O experimento realizado com \emph{online learning} apresentou resultados
promissores, mas ainda carece de uma investigação sistemática. Se
funcionar bem, a vantagem dessa abordagem é que não precisa de uma
pessoa para escrever as aplicações iteradas, facilitando o método WAWL.
A desvantagem é que o ajuste do modelo depende de uma conexão com a
internet, mais suscetível a problemas de conexão, que precisam ser
tratados com cuidado.

Outra extensão oportuna seria a criação de um modelo geral de resolução
de Captchas, desenvolvido a partir das bases que foram construídas
durante a pesquisa. O modelo precisaria lidar com diferentes alfabetos e
comprimentos dos Captchas, o que tornaria o aprendizado mais complicado.
Esse modelo poderia ser utilizado como passo inicial do WAWL para a
resolução de novos Captchas, podendo até afastar completamente a
necessidade de anotação manual. No momento, não é possível saber se esse
modelo funcionaria na prática de forma consistente, já que i) nada
garante que ele tenha uma acurácia maior que 10\% para um novo Captcha,
mesmo se construído com base em Captchas de várias origens e ii) foram
encontradas evidências de que os modelos com acurácia menor de 10\% têm
mais dificuldades em melhorar com o método WAWL quando o Captcha não
aceita vários chutes.

A presente tese foi fruto de um longo processo de análise e
desenvolvimento, investigando os aspectos relevantes dos Captchas de
textos em imagens. Espera-se que a metodologia proposta, os resultados
obtidos e os pacotes computacionais desenvolvidos sejam úteis na luta
pela abertura dos dados públicos, especialmente no judiciário. O uso de
Captchas em sites de serviços públicos deve acabar.

\bookmarksetup{startatroot}

\hypertarget{bibliografia}{%
\chapter*{Bibliografia}\label{bibliografia}}
\addcontentsline{toc}{chapter}{Bibliografia}

\markboth{Bibliografia}{Bibliografia}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{1}
\leavevmode\vadjust pre{\hypertarget{ref-tempodo}{}}%
ABJ. \textbf{Tempo dos processos relacionados à adoção}., 2014.
Disponível em:
\textless{}\url{https://abj.org.br/pesquisas/adocao/}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-observat}{}}%
ABJ. \textbf{Observatório da insolvência: Rio de Janeiro}., 2021.
Disponível em:
\textless{}\url{https://abj.org.br/pesquisas/obsrjrj/}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-diagnosticoABJ}{}}%
ABJ. \textbf{Diagnóstico do Contencioso Tributário Administrativo}.,
2022. Disponível em:
\textless{}\url{https://abj.org.br/pesquisas/bid-tributario/}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-vonahnReCAPTCHAHumanBasedCharacter2008}{}}%
AHN, L. VON et al. reCAPTCHA: Human-Based Character Recognition via Web
Security Measures. \textbf{Science}, v. 321, n. 5895, p. 1465--1468, 12
set. 2008. Disponível em:
\textless{}\url{https://www.science.org/doi/10.1126/science.1160379}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-vonahnTellingHumansComputers2002}{}}%
AHN, L. VON; BLUM, M.; LANGFORD, J. \textbf{Telling humans and computers
apart automatically or how lazy cryptographers do AI (Tech. Rep. No.
CMU-CS-02-117)}. Disponível em:
\textless{}\url{http://reports-archive.adm.cs.cmu.edu/anon/2002/CMU-CS-02-117.pdf}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-tensorflow}{}}%
ALLAIRE, J.; TANG, Y. tensorflow: R Interface to 'TensorFlow'. 2022.
Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=tensorflow}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-baldi2013}{}}%
BALDI, P.; SADOWSKI, P. J. Understanding dropout. \textbf{Advances in
neural information processing systems}, v. 26, 2013.

\leavevmode\vadjust pre{\hypertarget{ref-blum1998}{}}%
BLUM, A.; KALAI, A. A note on learning from multiple-instance examples.
\textbf{Machine learning}, v. 30, n. 1, p. 2329, 1998.

\leavevmode\vadjust pre{\hypertarget{ref-piggyback}{}}%
BOETTIGER, C.; HO, T. piggyback: Managing Larger Data on a GitHub
Repository. 2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=piggyback}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-chellapilla2005}{}}%
CHELLAPILLA, K. et al. \textbf{Designing human friendly human
interaction proofs (HIPs)}. : CHI '05.New York, NY, USA: Association for
Computing Machinery, 2 abr. 2005. Disponível em:
\textless{}\url{https://doi.org/10.1145/1054972.1055070}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-chellapilla2004}{}}%
CHELLAPILLA, K.; SIMARD, P. Using machine learning to break visual human
interaction proofs (HIPs). \textbf{Advances in neural information
processing systems}, v. 17, 2004.

\leavevmode\vadjust pre{\hypertarget{ref-colosimo2006}{}}%
COLOSIMO, E. A.; GIOLO, S. R. \textbf{Análise de sobrevivência
aplicada}. Editora Blucher, 2006.

\leavevmode\vadjust pre{\hypertarget{ref-cour2011}{}}%
COUR, T.; SAPP, B.; TASKAR, B. Learning from partial labels. \textbf{The
Journal of Machine Learning Research}, v. 12, p. 15011536, 2011.

\leavevmode\vadjust pre{\hypertarget{ref-luz}{}}%
FALBEL, D. luz: Higher Level 'API' for 'torch'. a2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=luz}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-torchvision}{}}%
FALBEL, D. torchvision: Models, Datasets and Transformations for Images.
b2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=torchvision}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-torch}{}}%
FALBEL, D.; LURASCHI, J. torch: Tensors and Neural Networks with 'GPU'
Acceleration. 2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=torch}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-feng2020}{}}%
FENG, L. et al. Provably consistent partial-label learning.
\textbf{Advances in Neural Information Processing Systems}, v. 33, p.
1094810960, a2020.

\leavevmode\vadjust pre{\hypertarget{ref-feng2020a}{}}%
FENG, L. et al. \textbf{Learning with multiple complementary labels}.
PMLR, b2020.

\leavevmode\vadjust pre{\hypertarget{ref-george2017}{}}%
GEORGE, D. et al. A generative vision model that trains with high data
efficiency and breaks text-based CAPTCHAs. \textbf{Science}, v. 358, n.
6368, p. eaag2612, 2017.

\leavevmode\vadjust pre{\hypertarget{ref-goodfellow2013}{}}%
GOODFELLOW, I. J. et al. Multi-digit number recognition from street view
imagery using deep convolutional neural networks. \textbf{arXiv preprint
arXiv:1312.6082}, 2013.

\leavevmode\vadjust pre{\hypertarget{ref-goodfellowGenerativeAdversarialNetworks2014}{}}%
GOODFELLOW, I. J. et al. \textbf{Generative {Adversarial Networks}}.
{arXiv}, jun. 2014. Disponível em:
\textless{}\url{https://arxiv.org/abs/1406.2661}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-grandvalet2002}{}}%
GRANDVALET, Y. \textbf{Logistic regression for partial labels}. 2002.

\leavevmode\vadjust pre{\hypertarget{ref-hullermeier2006}{}}%
HÜLLERMEIER, E.; BERINGER, J. Learning from ambiguously labeled
examples. \textbf{Intelligent Data Analysis}, v. 10, n. 5, p. 419439,
2006.

\leavevmode\vadjust pre{\hypertarget{ref-ioffe2015}{}}%
IOFFE, S.; SZEGEDY, C. \textbf{Batch normalization: Accelerating deep
network training by reducing internal covariate shift}. PMLR, 2015.

\leavevmode\vadjust pre{\hypertarget{ref-ishida2017}{}}%
ISHIDA, T. et al. Learning from complementary labels. \textbf{Advances
in neural information processing systems}, v. 30, 2017.

\leavevmode\vadjust pre{\hypertarget{ref-jin2002}{}}%
JIN, R.; GHAHRAMANI, Z. Learning with multiple labels. \textbf{Advances
in neural information processing systems}, v. 15, 2002.

\leavevmode\vadjust pre{\hypertarget{ref-kaur2014}{}}%
KAUR, K.; BEHAL, S. Captcha and Its Techniques: A Review.
\textbf{International Journal of Computer Science and Information
Technologies,} v. 5, 1 jan. 2014.

\leavevmode\vadjust pre{\hypertarget{ref-kingmaAdamMethodStochastic2017}{}}%
KINGMA, D. P.; BA, J. Adam: {A Method} for {Stochastic Optimization}. n.
arXiv:1412.6980, jan. 2017. Disponível em:
\textless{}\url{https://arxiv.org/abs/1412.6980}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-kuhn2019}{}}%
KUHN, M.; JOHNSON, K. \textbf{Feature engineering and selection: A
practical approach for predictive models}. CRC Press, 2019.

\leavevmode\vadjust pre{\hypertarget{ref-lecun1998}{}}%
LECUN, Y. et al. Gradient-based learning applied to document
recognition. \textbf{Proceedings of the IEEE}, v. 86, n. 11, p.
22782324, 1998.

\leavevmode\vadjust pre{\hypertarget{ref-lecun2012}{}}%
LECUN, Y. A. et al. Efficient backprop. Em: Springer, 2012. p. 948.

\leavevmode\vadjust pre{\hypertarget{ref-lecun2015}{}}%
LECUN, Y.; BENGIO, Y.; HINTON, G. Deep learning. \textbf{nature}, v.
521, n. 7553, p. 436444, 2015.

\leavevmode\vadjust pre{\hypertarget{ref-li2014}{}}%
LI, J.; TSUNG, F.; ZOU, C. Multivariate binomial/multinomial control
chart. \textbf{IIE Transactions}, v. 46, n. 5, p. 526542, 2014.

\leavevmode\vadjust pre{\hypertarget{ref-lillibridgeMethodSelectivelyRestricting2001}{}}%
LILLIBRIDGE, M. D. et al. \textbf{Method for Selectively Restricting
Access to Computer Systems}., fev. 2001.

\leavevmode\vadjust pre{\hypertarget{ref-liu2012}{}}%
LIU, L.; DIETTERICH, T. A conditional multinomial mixture model for
superset label learning. \textbf{Advances in neural information
processing systems}, v. 25, 2012.

\leavevmode\vadjust pre{\hypertarget{ref-michener2015}{}}%
MICHENER, G.; MONCAU, L. F.; VELASCO, R. B. \textbf{Estado brasileiro e
transparência avaliando a aplicação da Lei de Acesso à Informação}.

\leavevmode\vadjust pre{\hypertarget{ref-mori2003a}{}}%
MORI, G.; MALIK, J. \textbf{Recognizing objects in adversarial clutter:
Breaking a visual CAPTCHA}. IEEE, 2003.

\leavevmode\vadjust pre{\hypertarget{ref-murray2012}{}}%
MURRAY, N.; MARCHESOTTI, L.; PERRONNIN, F. \textbf{AVA: A large-scale
database for aesthetic visual analysis}. IEEE, 2012.

\leavevmode\vadjust pre{\hypertarget{ref-murray-rust2008}{}}%
MURRAY-RUST, P. Open data in science. \textbf{Nature Precedings}, p. 11,
2008.

\leavevmode\vadjust pre{\hypertarget{ref-na2020}{}}%
NA, B. et al. \textbf{Deep Generative Positive-Unlabeled Learning under
Selection Bias}. : CIKM '20.New York, NY, USA: Association for Computing
Machinery, 19 out. 2020. Disponível em:
\textless{}\url{https://doi.org/10.1145/3340531.3411971}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-nelder1972}{}}%
NELDER, J. A.; WEDDERBURN, R. W. Generalized linear models.
\textbf{Journal of the Royal Statistical Society: Series A (General)},
v. 135, n. 3, p. 370384, 1972.

\leavevmode\vadjust pre{\hypertarget{ref-noh2017}{}}%
NOH, H. et al. Regularizing deep neural networks by noise: Its
interpretation and optimization. \textbf{Advances in Neural Information
Processing Systems}, v. 30, 2017.

\leavevmode\vadjust pre{\hypertarget{ref-magick}{}}%
OOMS, J. magick: Advanced Graphics and Image-Processing in R. 2021.
Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=magick}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-rcran}{}}%
R CORE TEAM. \textbf{R: A Language and Environment for Statistical
Computing}. Vienna, Austria: R Foundation for Statistical Computing,
2021. Disponível em:
\textless{}\url{https://www.R-project.org/}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-rameshHierarchicalTextConditionalImage2022}{}}%
RAMESH, A. et al. Hierarchical {Text-Conditional Image Generation} with
{CLIP Latents}. n. arXiv:2204.06125, abr. 2022. Disponível em:
\textless{}\url{https://arxiv.org/abs/2204.06125}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-reshefMethodSystemDiscriminating2005}{}}%
RESHEF, E.; RAANAN, G.; SOLAN, E. \textbf{Method and System for
Discriminating a Human Action from a Computerized Action}., 2005.

\leavevmode\vadjust pre{\hypertarget{ref-sutton2018}{}}%
SUTTON, R. S.; BARTO, A. G. \textbf{Reinforcement learning: An
introduction}. MIT press, 2018.

\leavevmode\vadjust pre{\hypertarget{ref-decryptr}{}}%
TRECENTI, J. et al. decryptr: An extensible API for breaking captchas.
2022.

\leavevmode\vadjust pre{\hypertarget{ref-turing2009}{}}%
TURING, A. M. Computing machinery and intelligence. Em: Springer, 2009.
p. 2365.

\leavevmode\vadjust pre{\hypertarget{ref-reticulate}{}}%
USHEY, K.; ALLAIRE, J.; TANG, Y. reticulate: Interface to 'Python'.
2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=reticulate}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-vonahnCaptchaTellingHumans2003}{}}%
VON AHN, L. et al. \textbf{Captcha: {Telling} Humans and Computers Apart
Automatically}. Proceedings of Eurocrypt. \textbf{Anais}...2003.

\leavevmode\vadjust pre{\hypertarget{ref-vonahnTellingHumansComputers2004}{}}%
VON AHN, L.; BLUM, M.; LANGFORD, J. Telling Humans and Computers Apart
Automatically. \textbf{Communications of the ACM}, v. 47, n. 2, p.
56--60, 2004.

\leavevmode\vadjust pre{\hypertarget{ref-inaccess}{}}%
W3C. \textbf{Inaccessibility of CAPTCHA}., 2021. Disponível em:
\textless{}\url{https://www.w3.org/TR/turingtest/}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-wang2021}{}}%
WANG, Y. et al. Make complex captchas simple: a fast text captcha solver
based on a small number of samples. \textbf{Information Sciences}, v.
578, p. 181194, 2021.

\leavevmode\vadjust pre{\hypertarget{ref-stringr}{}}%
WICKHAM, H. stringr: Simple, Consistent Wrappers for Common String
Operations. b2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=stringr}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-rvest}{}}%
WICKHAM, H. rvest: Easily Harvest (Scrape) Web Pages. a2022. Disponível
em:
\textless{}\url{https://CRAN.R-project.org/package=rvest}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-usethis}{}}%
WICKHAM, H.; BRYAN, J.; BARRETT, M. usethis: Automate Package and
Project Setup. 2022. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=usethis}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-xml2}{}}%
WICKHAM, H.; HESTER, J.; OOMS, J. xml2: Parse XML. 2021. Disponível em:
\textless{}\url{https://CRAN.R-project.org/package=xml2}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-ye2018}{}}%
YE, G. et al. \textbf{Yet another text captcha solver: A generative
adversarial network based approach}. 2018.

\leavevmode\vadjust pre{\hypertarget{ref-yu2018}{}}%
YU, X. et al. \textbf{Learning with biased complementary labels}. 2018.

\leavevmode\vadjust pre{\hypertarget{ref-yuan2019}{}}%
YUAN, X. et al. Adversarial examples: Attacks and defenses for deep
learning. \textbf{IEEE transactions on neural networks and learning
systems}, v. 30, n. 9, p. 28052824, 2019.

\leavevmode\vadjust pre{\hypertarget{ref-zhao2017}{}}%
ZHAO, B. Web scraping. \textbf{Encyclopedia of big data}, p. 13, 2017.
Disponível em:
\textless{}\url{https://www.researchgate.net/profile/Bo-Zhao-3/publication/317177787_Web_Scraping/links/5c293f85a6fdccfc7073192f/Web-Scraping.pdf}\textgreater.

\leavevmode\vadjust pre{\hypertarget{ref-zhou2018}{}}%
ZHOU, Z.-H. A brief introduction to weakly supervised learning.
\textbf{National science review}, v. 5, n. 1, p. 4453, 2018.

\leavevmode\vadjust pre{\hypertarget{ref-zhu2005}{}}%
ZHU, X. J. Semi-supervised learning literature survey. 2005.

\end{CSLReferences}

\appendix
\addcontentsline{toc}{part}{Apêndices}

\hypertarget{sec-pacote}{%
\chapter{Pacotes}\label{sec-pacote}}

Este apêndice foi construído para mostrar a estrutura dos pacotes
\texttt{\{captchaDownload\}} e \texttt{\{captchaOracle\}}, utilizados
como auxiliares para implementação do WAWL, orquestradas pelo pacote
\texttt{\{captcha\}}. Os pacotes \texttt{\{captchaDownload\}} e
\texttt{\{captchaOracle\}} foram desenvolvidos para facilitar a obtenção
dos resultados da tese, enquanto o pacote \texttt{\{captcha\}} pode ser
utilizado por qualquer pessoa interessada em visualizar, anotar e
resolver Captchas. As próximas subseções do apêndice descrevem os
pacotes \texttt{\{captchaDownload\}} e \texttt{\{captchaOracle\}}.

\hypertarget{sec-pacote-download}{%
\section{Pacote captchaDownload}\label{sec-pacote-download}}

O pacote \texttt{\{captchaDownload\}} foi construído para armazenar os
códigos de baixar dados de Captchas de forma consistente. O pacote
também inclui funções para trabalhar com oráculos.

O pacote não foi criado para ser usado pelo público geral. O intuito de
criar o pacote foi o de organizar as funções utilizadas para realizar as
simulações e obter os resultados empíricos da tese. Apesar disso, o
código está disponível publicamente para quem tiver interesse em usar
como referência para construir funções que acessam o oráculo.

As funções do pacote \texttt{\{captchaDownload\}} são organizadas em
dois tipos principais. As funções de \emph{acesso}, identificadas pelo
termo \texttt{\_access}, fazem o \emph{download} da imagem do Captcha e
retornam todas as informações necessárias para fazer a verificação do
oráculo, como, por exemplo, \emph{cookies} e dados da sessão do usuário.
Já as funções de \emph{teste}, identificadas pelo termo \texttt{\_test},
servem para verificar se um rótulo fornecido para o Captcha está correto
ou não.

As funções ficam mais claras através de um exemplo. No caso do TRF5, por
exemplo, o acesso é feito pela página do
\href{https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam}{sistema
PJe}. A função \texttt{captcha\_access\_trf5()} recebe o parâmetro
\texttt{path=}, que é a pasta para salvar a imagem, retornando uma lista
com o caminho da imagem que foi salva e de componentes da sessão do
usuário.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{acesso }\OtherTok{\textless{}{-}}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\FunctionTok{captcha\_access\_trf5}\NormalTok{(}\StringTok{"assets/img"}\NormalTok{)}
\NormalTok{acesso}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$f_captcha
assets/img/trf5ac031dafbd.jpeg

$j_id
[1] "j_id1"

$u
[1] "https://pje.trf5.jus.br/pjeconsulta/ConsultaPublica/listView.seam"
\end{verbatim}

Em seguida, obtém-se o rótulo do modelo. Isso pode ser feito manualmente
ou através de um modelo.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(captcha)}
\NormalTok{captcha }\OtherTok{\textless{}{-}} \FunctionTok{read\_captcha}\NormalTok{(acesso}\SpecialCharTok{$}\NormalTok{f\_captcha)}
\FunctionTok{plot}\NormalTok{(captcha)}
\NormalTok{modelo\_trf5 }\OtherTok{\textless{}{-}} \FunctionTok{captcha\_load\_model}\NormalTok{(}\StringTok{"trf5"}\NormalTok{)}
\NormalTok{(lab }\OtherTok{\textless{}{-}} \FunctionTok{decrypt}\NormalTok{(acesso}\SpecialCharTok{$}\NormalTok{f\_captcha, modelo\_trf5))}
\CommentTok{\#\textgreater{} [1] "969588"}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.2\textwidth,height=\textheight]{./pacote_files/figure-pdf/fig-exemplo-acesso-trf5-1.pdf}

}

\caption{\label{fig-exemplo-acesso-trf5}Exemplo de Captcha baixado
diretamente do TRF5}

\end{figure}

Agora, aplica-se a função \texttt{captcha\_test\_trf5()} para verificar
se o rótulo está correto ou incorreto. A verificação é feita de forma
automática, diretamente da \emph{internet}, através do oráculo. A função
recebe dois parâmetros: \texttt{obj=} com as informações obtidas da
função de acesso; e \texttt{label=}, o rótulo obtido. A função retorna
\texttt{TRUE} se o rótulo está correto e \texttt{FALSE} caso contrário.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(acertou }\OtherTok{\textless{}{-}}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\FunctionTok{captcha\_test\_trf5}\NormalTok{(acesso, lab))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

Cada Captcha possui uma função de acesso e uma função de teste. Na
prática, se uma pessoa desejar resolver um novo Captcha usando a técnica
do oráculo, são essas funções que ela precisaria desenvolver. Todas as
outras operações podem ser generalizadas para diferentes casos de uso e
estão implementadas nos pacotes \texttt{\{captchaDownload\}} e
\texttt{\{captchaOracle\}}. Vale notar que a construção dessas funções
geralmente é necessária para a construção de \emph{web scrapers}, ou
seja, elas não criam dificuldades adicionais para pessoas interessadas
em resolver Captchas para acessar dados da \emph{internet}.

A função principal do pacote \texttt{\{captchaDownload\}} é a
\texttt{captcha\_oracle()}. A função é responsável por realizar a
anotação parcial automática dos Captchas utilizando um modelo inicial e
o oráculo. A função possui os seguintes parâmetros:

\begin{itemize}
\tightlist
\item
  \texttt{path=}: caminho em que os arquivos serão salvos.
\item
  \texttt{model=}: modelo para predizer o rótulo de uma imagem.
\item
  \texttt{max\_ntry=}: quantidade máxima de chutes até desistir.
\item
  \texttt{manual=}: caso o máximo de tentativas seja alcançado, abrir o
  \emph{prompt} para anotar manualmente? Por padrão, sim.
\item
  \texttt{captcha\_access=}: função que baixa um Captcha e retorna dados
  da sessão para validar o Captcha, como mostrada anteriormente.
\item
  \texttt{captcha\_test=}: função que testa se um Captcha está correto a
  partir de um rótulo específico, como mostrado anteriormente.
\end{itemize}

A função amarra todos os conceitos necessários para criar bases de dados
de forma automática. Primeiro, considera o caminho para salvar os dados.
Em seguida, considera o modelo e formas de lidar com o oráculo. Por
último, recebe as funções de acesso e de teste do Captcha. A função
escreve um arquivo de \emph{log} com os resultados dos testes. O arquivo
contém \texttt{max\_ntry} linhas, podendo ter uma linha adicional se
\texttt{manual=TRUE}, já que, se o modelo errar todos os chutes, a
anotação manual deve ser adicionada.

No exemplo do TRF5, a chamada da função \texttt{captcha\_oracle()} com
um chute ficaria da seguinte forma:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo\_trf5 }\OtherTok{\textless{}{-}} \FunctionTok{captcha\_load\_model}\NormalTok{(}\StringTok{"trf5"}\NormalTok{)}

\NormalTok{captchaDownload}\SpecialCharTok{::}\FunctionTok{captcha\_oracle}\NormalTok{(}
  \AttributeTok{path =} \StringTok{"assets/img/"}\NormalTok{,}
  \AttributeTok{model =}\NormalTok{ modelo\_trf5, }
  \AttributeTok{max\_ntry =} \DecValTok{1}\NormalTok{,}
  \AttributeTok{manual =} \ConstantTok{TRUE}\NormalTok{, }
  \AttributeTok{captcha\_access =}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\NormalTok{captcha\_access\_trf5,}
  \AttributeTok{captcha\_test =}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\NormalTok{captcha\_test\_trf5}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
✔ Acertou!!!
\end{verbatim}

No teste do exemplo, a função acertou, salvando o seguinte arquivo de
\emph{log}\footnote{Espaços foram adicionados manualmente para facilitar
  a visualização.}.

\begin{verbatim}
ntry, label , type, result
1,    569328, auto, TRUE
\end{verbatim}

Abaixo, foi colocado um modelo ruim para o TRT, para forçar o modelo a
errar todos os chutes. O resultado é o \emph{log} abaixo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{captcha\_load\_model}\NormalTok{(}\StringTok{"assets/modelo\_ruim.pt"}\NormalTok{)}

\NormalTok{captchaDownload}\SpecialCharTok{::}\FunctionTok{captcha\_oracle}\NormalTok{(}
  \AttributeTok{path =} \StringTok{"assets/img/"}\NormalTok{,}
  \AttributeTok{model =}\NormalTok{ modelo, }
  \AttributeTok{max\_ntry =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{manual =} \ConstantTok{TRUE}\NormalTok{, }
  \AttributeTok{captcha\_access =}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\NormalTok{captcha\_access\_trt,}
  \AttributeTok{captcha\_test =}\NormalTok{ captchaDownload}\SpecialCharTok{:::}\NormalTok{captcha\_test\_trt}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
ℹ Temos 10 candidatos...
ℹ Errou! O chute foi: v2su7w
ℹ Errou! O chute foi: t2su7w
ℹ Errou! O chute foi: v2su7y
ℹ Errou! O chute foi: t2su7y
ℹ Errou! O chute foi: y2su7w
ℹ Errou! O chute foi: v2su7h
ℹ Errou! O chute foi: t2su7h
ℹ Errou! O chute foi: y2su7y
ℹ Errou! O chute foi: v2wu7w
Label: v2xu7w
\end{verbatim}

No novo exemplo, a função errou todos os dez chutes, salvando o seguinte
arquivo de \emph{log}\footnote{Espaços foram adicionados para facilitar
  a visualização.}. O último valor é um rótulo inserido manualmente.

\begin{verbatim}
ntry,  label,   type, result
   1, v2su7w,   auto,  FALSE
   2, t2su7w,   auto,  FALSE
   3, v2su7y,   auto,  FALSE
   4, t2su7y,   auto,  FALSE
   5, y2su7w,   auto,  FALSE
   6, v2su7h,   auto,  FALSE
   7, t2su7h,   auto,  FALSE
   8, y2su7y,   auto,  FALSE
   9, v2wu7w,   auto,  FALSE
  10, 92su7w,   auto,  FALSE
  NA, v2xu7w, manual,   TRUE
\end{verbatim}

Se o parâmetro \texttt{manual=FALSE} e o modelo não consegue acertar o
rótulo, a função também adiciona a mensagem:

\begin{verbatim}
✖ Errado depois de todas as tentativas...
\end{verbatim}

Em alguns casos, é possível que a função realize menos do que
\texttt{max\_ntry} chutes. Isso acontece quando a probabilidade do
melhor rótulo depois do chute errado é muito pequena, segundo o modelo.
Isso é feito pela função \texttt{captcha\_candidates()}, que considera
como padrão o corte de \texttt{0.01} de probabilidade. Ou seja, na
prática, a função testa no máximo os \texttt{max\_ntry} rótulos com
probabilidades maiores que \texttt{0.01} segundo o modelo.

Em resumo, o pacote \texttt{\{captchaDownload\}} contém toda a parte de
\emph{web scraping} utilizada no desenvolvimento da tese.
Adicionalmente, o pacote contém funções para orquestrar o
\emph{download} automático de Captchas parcialmente rotulados, a partir
de um modelo inicial e um oráculo.

Os dados fornecidos pelo pacote ficam tanto na forma de imagens
rotuladas quanto na forma de arquivos de \emph{log}, disponibilizados em
arquivos \emph{CSV}. Para lidar com essa estrutura de dados, mais um
pacote foi desenvolvido: o \texttt{\{captchaOracle\}}, definido a
seguir.

\hypertarget{sec-pacote-oracle}{%
\section{Pacote captchaOracle}\label{sec-pacote-oracle}}

O pacote \texttt{\{captchaOracle\}}, assim como o
\texttt{\{captchaDownload\}}, foi desenvolvido para a construção da
tese. O pacote, portanto, não apresenta documentação extensiva e suas
funções podem não estar com a sintaxe final. Futuramente, o pacote
poderá funcionar como novo \emph{backend} para o pacote
\texttt{\{captcha\}}, aplicando o WAWL como uma alternativa no fluxo de
resolução de Captchas definido na Subseção \ref{sec-captcha-do-zero}.

O pacote possui quatro funções principais: a
\texttt{captcha\_dataset\_oracle()}, a \texttt{net\_captcha\_oracle()},
a \texttt{oracle\_loss()} e a \texttt{captcha\_accuracy\_oracle()}. Cada
função desempenha um papel similar a seus pares do pacote
\texttt{\{captcha\}}, mas conseguem lidar com a estrutura de dados
fornecida pelo oráculo.

A primeira função a ser utilizada é a
\texttt{captcha\_dataset\_oracle()}. Trata-se de uma função similar à
\texttt{captcha\_dataset()} do pacote \texttt{\{captcha\}}, mas com um
parâmetro adicional, \texttt{path\_logs=}, que recebe o caminho dos
arquivos de \emph{log}.

A estrutura de dados no caso do oráculo é mais complexa do que no caso
canônico. Na resposta, ao invés de guardar uma matriz \emph{one hot}
para cada Captcha, é armazenada uma lista com várias matrizes \emph{one
hot}, uma para cada tentativa do Captcha. Além disso, é armazenado um
vetor \texttt{z}, com zeros e uns, informando se algum rótulo está
correto ou se todos os rótulos estão incorretos. A variável \texttt{z} é
construída a partir dos nomes dos arquivos, que contém um \texttt{\_1}
caso o rótulo esteja correto e \texttt{\_0} caso contrário. Por último,
a imagem de entrada é armazenada da mesma forma que na função
\texttt{captcha\_dataset()}.

O módulo \texttt{net\_captcha\_oracle()} faz poucos ajustes à estrutura
inicial fornecida pelo módulo \texttt{net\_captcha()} do pacote
\texttt{\{captcha\}}. A única modificação da função é que ela recebe um
modelo inicial de entrada, transferindo os pesos ajustados do modelo ao
novo módulo. O módulo \texttt{net\_captcha\_oracle()}, inclusive,
poderia ser utilizado fora do contexto do WAWL, já que só utiliza os
dados de \emph{input}, que não são alterados.

A função \texttt{captcha\_accuracy\_oracle()} é utilizada para estimar a
acurácia do modelo. Para isso, a função precisa lidar com o fato de que
os dados de validação apresentam uma estrutura diferente dos dados de
treino, já que estão completamente anotados. No treino, a acurácia é
calculada considerando apenas os casos em que a resposta é conhecida. Na
validação, a acurácia é calculada considerando-se todas as observações.

Por último, a função \texttt{oracle\_loss()} é a que contém a proposta
de função de perda do método WAWL. Nos casos corretos, a função de perda
é obtida calculando-se uma entropia cruzada simples. Nos casos
incorretos, a perda é calculada pela estratégia \texttt{1-p}, ou seja,
considerando o complementar da probabilidade de observar os chutes que
foram apresentados segundo o modelo.

Em resumo, o pacote \texttt{\{captchaOracle\}} é o que contém os
principais avanços da tese do ponto de vista estatístico. Na prática, é
utilizado como \emph{backend} computacional para ajuste dos modelos que
utilizam o oráculo, dentro de um fluxo de trabalho igual ao que é
construído para ajuste dos modelos canônicos.

Os códigos para realizar as simulações do modelo foram adicionados na
pasta \texttt{data-raw} do pacote \texttt{\{captchaOracle\}}. Os códigos
foram organizados da seguinte forma:

\begin{itemize}
\tightlist
\item
  \texttt{passo\_01\_*.R}. Contêm os códigos utilizados para ajustar os
  modelos iniciais. Os códigos são organizados de forma a permitir que
  vários modelos sejam rodados em paralelo, aproveitando o máximo do
  poder computacional da máquina utilizada para realizar os ajustes.
\item
  \texttt{passo\_02\_*.R}. Contêm os códigos utilizados para construir
  as bases de treino e validação para o passo 03. Foi o passo mais
  demorado da simulação, já que envolveu acessar os sites dos tribunais
  pela \emph{internet} para obtenção dos Captchas anotados
  automaticamente. Para realizar a simulação, foram baixados mais de
  500.000 Captchas da \emph{internet}.
\item
  \texttt{passo\_03\_*.R}. Contêm os códigos utilizados para ajustar os
  modelos finais. Os códigos foram organizados de forma similar ao passo
  01, mas utilizando as funções desenvolvidas no pacote
  \texttt{\{captchaOracle\}} para considerar os dados fornecidos pelo
  oráculo.
\end{itemize}

Por fim, foi adicionado também um script \texttt{report.R}, que monta as
bases principais e os resumos dos modelos ajustados. As bases fornecidas
pelo último \emph{script} foram adicionadas ao repositório da tese.

% \input{conteudo/00-exemplo-introducao}
% \input{conteudo/01-exemplo-normas-ime}
% \input{conteudo/02-exemplo-usando-o-modelo}
% \input{conteudo/03-exemplo-latex}
% \input{conteudo/04-exemplo-tutorial}
% \input{conteudo/05-exemplo-exemplos}


%%%%%%%%%%%%%%%%%%%%%%%%%%%% APÊNDICES E ANEXOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Um apêndice é algum conteúdo adicional de sua autoria que faz parte e
% colabora com a ideia geral do texto mas que, por alguma razão, não precisa
% fazer parte da sequência do discurso; por exemplo, a demonstração de um
% teorema intermediário, as perguntas usadas em uma pesquisa qualitativa etc.
%
% Um anexo é um documento que não faz parte da tese (em geral, nem é de sua
% autoria) mas é relevante para o conteúdo; por exemplo, a especificação do
% padrão técnico ou a legislação que o trabalho discute, um artigo de jornal
% apresentando a percepção do público sobre o tema da tese etc.
%
% Os comandos appendix e annex reiniciam a numeração de capítulos e passam
% a numerá-los com letras. "annex" não faz parte de nenhuma classe padrão,
% foi criado para este modelo. Se o trabalho não tiver apêndices ou anexos,
% remova estas linhas.
%
% Diferentemente de \mainmatter, \backmatter etc., \appendix e \annex não
% forçam o início de uma nova página. Em geral isso não é importante, pois
% o comando seguinte costuma ser "\chapter", mas pode causar problemas com
% a formatação dos cabeçalhos. Assim, vamos forçar uma nova página antes
% de cada um deles.

%%%% Apêndices %%%%

\makeatletter
\if@openright\cleardoublepage\else\clearpage\fi
\makeatother

% \pagestyle{appendix}

% \appendix

% \addappheadtotoc acrescenta a palavra "Apêndice" ao sumário; se
% só há apêndices, sem anexos, provavelmente não é necessário.
% \addappheadtotoc

% \input{conteudo/apendice-exemplo-pseudocodigo}
% \par

%%%% Anexos %%%%

% \makeatletter
% \if@openright\cleardoublepage\else\clearpage\fi
% \makeatother

% \pagestyle{appendix} % repete o anterior, caso você não use apêndices

% \annex

% \addappheadtotoc acrescenta a palavra "Anexo" ao sumário; se
% só há anexos, sem apêndices, provavelmente não é necessário.
% \addappheadtotoc

% \input{conteudo/anexo-exemplo-faq}
% \par


%%%%%%%%%%%%%%% SEÇÕES FINAIS (BIBLIOGRAFIA E ÍNDICE REMISSIVO) %%%%%%%%%%%%%%%%

% O comando backmatter desabilita a numeração de capítulos.
\backmatter

\pagestyle{backmatter}

% Espaço adicional no sumário antes das referências / índice remissivo
\addtocontents{toc}{\vspace{2\baselineskip plus .5\baselineskip minus .5\baselineskip}}

% A bibliografia é obrigatória

\printbibliography[
  title=\refname\label{bibliografia}, % "Referências", recomendado pela ABNT
  %title=\bibname\label{bibliografia}, % "Bibliografia"
  heading=bibintoc, % Inclui a bibliografia no sumário
]

% \printindex % imprime o índice remissivo no documento (opcional)

\end{document}
